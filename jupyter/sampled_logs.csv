Project,log ID,Log,Log level,Log URL,Code(double click),Log content relation,Log-code relation
activemq,19634,"LOG.debug(""{} started XA transaction {}"", this, transactionId)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/TransactionContext.java/#L748,"private void setXid(Xid xid) throws XAException {

        try {
            this.connection.checkClosedOrFailed();
            this.connection.ensureConnectionInfoSent();
        } catch (JMSException e) {
            disassociate();
            throw toXAException(e);
        }

        if (xid != null) {
            // associate
            associatedXid = xid;
            transactionId = new XATransactionId(xid);

            TransactionInfo info = new TransactionInfo(getConnectionId(), transactionId, TransactionInfo.BEGIN);
            try {
                this.connection.asyncSendPacket(info);
                
---------------Reference log start----------------
LOG.debug(""{} started XA transaction {}"", this, transactionId)
---------------Reference log end----------------
            } catch (JMSException e) {
                disassociate();
                throw toXAException(e);
            }

        } else {

            if (transactionId != null) {
                TransactionInfo info = new TransactionInfo(getConnectionId(), transactionId, TransactionInfo.END);
                try {
                    this.connection.syncSendPacket(info);
                    LOG.debug(""{} ended XA transaction {}"", this, transactionId);
                } catch (JMSException e) {
                    disassociate();
                    throw toXAException(e);
                }

                // Add our self to the list of contexts that are interested in
                // post commit/rollback events.
                List<TransactionContext> l;
                synchronized(ENDED_XA_TRANSACTION_CONTEXTS) {
                    l = ENDED_XA_TRANSACTION_CONTEXTS.get(transactionId);
                    if (l == null) {
                        l = new ArrayList<TransactionContext>(3);
                        ENDED_XA_TRANSACTION_CONTEXTS.put(transactionId, l);
                    }
                    if (!l.contains(this)) {
                        l.add(this);
                    }
                }
            }

            disassociate();
        }
    }",,right after
activemq,19295,"LOG.trace(""MQTT-->ActiveMQ: MQTT_MSGID:{} client:{} connection:{} ActiveMQ_MSGID:{}"", command.messageId(), clientId, connectionInfo.getConnectionId(), msg.getMessageId())",trace,https://github.com/apache/activemq/blob/main/activemq-mqtt/src/main/java/org/apache/activemq/transport/mqtt/MQTTProtocolConverter.java/#L548,"ActiveMQMessage convertMessage(PUBLISH command) throws JMSException {
        ActiveMQBytesMessage msg = new ActiveMQBytesMessage();

        msg.setProducerId(producerId);
        MessageId id = new MessageId(producerId, publisherIdGenerator.getNextSequenceId());
        msg.setMessageId(id);
        
---------------Reference log start----------------
LOG.trace(""MQTT-->ActiveMQ: MQTT_MSGID:{} client:{} connection:{} ActiveMQ_MSGID:{}"", command.messageId(), clientId, connectionInfo.getConnectionId(), msg.getMessageId())
---------------Reference log end----------------
        msg.setTimestamp(System.currentTimeMillis());
        msg.setPriority((byte) Message.DEFAULT_PRIORITY);
        msg.setPersistent(command.qos() != QoS.AT_MOST_ONCE);
        msg.setIntProperty(QOS_PROPERTY_NAME, command.qos().ordinal());
        if (command.retain()) {
            msg.setBooleanProperty(RetainedMessageSubscriptionRecoveryPolicy.RETAIN_PROPERTY, true);
        }

        ActiveMQDestination destination;
        synchronized (activeMQDestinationMap) {
            destination = activeMQDestinationMap.get(command.topicName().toString());
            if (destination == null) {
                String topicName = MQTTProtocolSupport.convertMQTTToActiveMQ(command.topicName().toString());
                try {
                    destination = findSubscriptionStrategy().onSend(topicName);
                } catch (IOException e) {
                    throw JMSExceptionSupport.create(e);
                }

                activeMQDestinationMap.put(command.topicName().toString(), destination);
            }
        }

        msg.setJMSDestination(destination);
        msg.writeBytes(command.payload().data, command.payload().offset, command.payload().length);
        return msg;
    }",,
activemq,19535,"LOG.debug(""{} received with excessive redelivered: {}"", getConsumerId(), md)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQMessageConsumer.java/#L520,"private MessageDispatch dequeue(long timeout) throws JMSException {
        try {
            long deadline = 0;
            if (timeout > 0) {
                deadline = System.currentTimeMillis() + timeout;
            }
            while (true) {
                MessageDispatch md = unconsumedMessages.dequeue(timeout);
                if (md == null) {
                    if (timeout > 0 && !unconsumedMessages.isClosed()) {
                        timeout = Math.max(deadline - System.currentTimeMillis(), 0);
                    } else {
                        if (failureError != null) {
                            throw JMSExceptionSupport.create(failureError);
                        } else {
                            return null;
                        }
                    }
                } else if (md.getMessage() == null) {
                    return null;
                } else if (consumeExpiredMessage(md)) {
                    LOG.debug(""{} received expired message: {}"", getConsumerId(), md);
                    beforeMessageIsConsumed(md);
                    afterMessageIsConsumed(md, true);
                    if (timeout > 0) {
                        timeout = Math.max(deadline - System.currentTimeMillis(), 0);
                    }
                    sendPullCommand(timeout);
                } else if (redeliveryExceeded(md)) {
                    
---------------Reference log start----------------
LOG.debug(""{} received with excessive redelivered: {}"", getConsumerId(), md)
---------------Reference log end----------------
                    poisonAck(md, ""Dispatch["" + md.getRedeliveryCounter() + ""] to "" + getConsumerId() + "" exceeds redelivery policy limit:"" + redeliveryPolicy);
                    if (timeout > 0) {
                        timeout = Math.max(deadline - System.currentTimeMillis(), 0);
                    }
                    sendPullCommand(timeout);
                } else {
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(getConsumerId() + "" received message: "" + md);
                    }
                    return md;
                }
            }
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            throw JMSExceptionSupport.create(e);
        }
    }",,
activemq,18908,"LOG.info(""no limits set, slowConsumer strategy has nothing to do"")",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/policy/AbortSlowConsumerStrategy.java/#L72,"@Override
    public void slowConsumer(ConnectionContext context, Subscription subs) {
        if (maxSlowCount < 0 && maxSlowDuration < 0) {
            // nothing to do
            
---------------Reference log start----------------
LOG.info(""no limits set, slowConsumer strategy has nothing to do"")
---------------Reference log end----------------
            return;
        }

        if (taskStarted.compareAndSet(false, true)) {
            scheduler.executePeriodically(this, checkPeriod);
        }

        if (!slowConsumers.containsKey(subs)) {
            slowConsumers.put(subs, new SlowConsumerEntry(context));
        } else if (maxSlowCount > 0) {
            slowConsumers.get(subs).slow();
        }
    }",,
activemq,19815,"LOG.trace(""Ignoring exception on close as discarding session: "" + e1, e1)",trace,https://github.com/apache/activemq/blob/main/activemq-jms-pool/src/main/java/org/apache/activemq/jms/pool/PooledSession.java/#L143,"@Override
    public void close() throws JMSException {
        if (ignoreClose) {
            return;
        }

        if (closed.compareAndSet(false, true)) {
            boolean invalidate = false;
            try {
                // lets reset the session
                getInternalSession().setMessageListener(null);

                // Close any consumers and browsers that may have been created.
                for (Iterator<MessageConsumer> iter = consumers.iterator(); iter.hasNext();) {
                    MessageConsumer consumer = iter.next();
                    consumer.close();
                }

                for (Iterator<QueueBrowser> iter = browsers.iterator(); iter.hasNext();) {
                    QueueBrowser browser = iter.next();
                    browser.close();
                }

                if (transactional && !isXa) {
                    try {
                        getInternalSession().rollback();
                    } catch (JMSException e) {
                        invalidate = true;
                        LOG.warn(""Caught exception trying rollback() when putting session back into the pool, will invalidate. "" + e, e);
                    }
                }
            } catch (JMSException ex) {
                invalidate = true;
                LOG.warn(""Caught exception trying close() when putting session back into the pool, will invalidate. "" + ex, ex);
            } finally {
                consumers.clear();
                browsers.clear();
                for (PooledSessionEventListener listener : this.sessionEventListeners) {
                    listener.onSessionClosed(this);
                }
                sessionEventListeners.clear();
            }

            if (invalidate) {
                // lets close the session and not put the session back into the pool
                // instead invalidate it so the pool can create a new one on demand.
                if (sessionHolder != null) {
                    try {
                        sessionHolder.close();
                    } catch (JMSException e1) {
                        
---------------Reference log start----------------
LOG.trace(""Ignoring exception on close as discarding session: "" + e1, e1)
---------------Reference log end----------------
                    }
                }
                try {
                    sessionPool.invalidateObject(key, sessionHolder);
                } catch (Exception e) {
                    LOG.trace(""Ignoring exception on invalidateObject as discarding session: "" + e, e);
                }
            } else {
                try {
                    sessionPool.returnObject(key, sessionHolder);
                } catch (Exception e) {
                    javax.jms.IllegalStateException illegalStateException = new javax.jms.IllegalStateException(e.toString());
                    illegalStateException.initCause(e);
                    throw illegalStateException;
                }
            }

            sessionHolder = null;
        }
    }",,
activemq,17784,"LOG.debug(""Caught exception while closing connection: "" + e1, e1)",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/DefaultDatabaseLocker.java/#L93,"public void doStart() throws Exception {

        LOG.info(""Attempting to acquire the exclusive lock to become the Master broker"");
        String sql = getStatements().getLockCreateStatement();
        LOG.debug(""Locking Query is ""+sql);
        
        while (true) {
            try {
                connection = dataSource.getConnection();
                connection.setAutoCommit(false);
                lockCreateStatement = connection.prepareStatement(sql);
                lockCreateStatement.execute();
                break;
            } catch (Exception e) {
                try {
                    if (isStopping()) {
                        throw new Exception(
                                ""Cannot start broker as being asked to shut down. "" 
                                        + ""Interrupted attempt to acquire lock: ""
                                        + e, e);
                    }
                    if (exceptionHandler != null) {
                        try {
                            exceptionHandler.handle(e);
                        } catch (Throwable handlerException) {
                            LOG.error( ""The exception handler ""
                                    + exceptionHandler.getClass().getCanonicalName()
                                    + "" threw this exception: ""
                                    + handlerException
                                    + "" while trying to handle this exception: ""
                                    + e, handlerException);
                        }

                    } else {
                        LOG.debug(""Lock failure: ""+ e, e);
                    }
                } finally {
                    // Let's make sure the database connection is properly
                    // closed when an error occurs so that we're not leaking
                    // connections 
                    if (null != connection) {
                        try {
                            connection.rollback();
                        } catch (SQLException e1) {
                            LOG.debug(""Caught exception during rollback on connection: "" + e1, e1);
                        }
                        try {
                            connection.close();
                        } catch (SQLException e1) {
                            
---------------Reference log start----------------
LOG.debug(""Caught exception while closing connection: "" + e1, e1)
---------------Reference log end----------------
                        }
                        
                        connection = null;
                    }
                }
            } finally {
                if (null != lockCreateStatement) {
                    try {
                        lockCreateStatement.close();
                    } catch (SQLException e1) {
                        LOG.debug(""Caught while closing statement: "" + e1, e1);
                    }
                    lockCreateStatement = null;
                }
            }

            LOG.info(""Failed to acquire lock.  Sleeping for "" + lockAcquireSleepInterval + "" milli(s) before trying again..."");
            try {
                Thread.sleep(lockAcquireSleepInterval);
            } catch (InterruptedException ie) {
                LOG.warn(""Master lock retry sleep interrupted"", ie);
            }
        }

        LOG.info(""Becoming the master on dataSource: "" + dataSource);
    }",,
activemq,19116,"LOG.info(""Network Could not shutdown in a timely manner"")",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L324,"@Override
    public void stop() throws Exception {
        if (started.compareAndSet(true, false)) {
            if (disposed.compareAndSet(false, true)) {
                LOG.debug("" stopping {} bridge to {}"", configuration.getBrokerName(), remoteBrokerName);

                futureRemoteBrokerInfo.cancel(true);
                futureLocalBrokerInfo.cancel(true);

                NetworkBridgeListener l = this.networkBridgeListener;
                if (l != null) {
                    l.onStop(this);
                }
                try {
                    // local start complete
                    if (startedLatch.getCount() < 2) {
                        LOG.trace(""{} unregister bridge ({}) to {}"",
                                configuration.getBrokerName(), this, remoteBrokerName);
                        brokerService.getBroker().removeBroker(null, remoteBrokerInfo);
                        brokerService.getBroker().networkBridgeStopped(remoteBrokerInfo);
                    }

                    remoteBridgeStarted.set(false);
                    final CountDownLatch sendShutdown = new CountDownLatch(1);

                    brokerService.getTaskRunnerFactory().execute(new Runnable() {
                        @Override
                        public void run() {
                            try {
                                serialExecutor.shutdown();
                                if (!serialExecutor.awaitTermination(5, TimeUnit.SECONDS)) {
                                    List<Runnable> pendingTasks = serialExecutor.shutdownNow();
                                    LOG.info(""pending tasks on stop {}"", pendingTasks);
                                }
                                //Shutdown the syncExecutor, call countDown to make sure a thread can
                                //terminate if it is waiting
                                staticDestinationsLatch.countDown();
                                syncExecutor.shutdown();
                                if (!syncExecutor.awaitTermination(5, TimeUnit.SECONDS)) {
                                    List<Runnable> pendingTasks = syncExecutor.shutdownNow();
                                    LOG.info(""pending tasks on stop {}"", pendingTasks);
                                }
                                localBroker.oneway(new ShutdownInfo());
                                remoteBroker.oneway(new ShutdownInfo());
                            } catch (Throwable e) {
                                LOG.debug(""Caught exception sending shutdown"", e);
                            } finally {
                                sendShutdown.countDown();
                            }

                        }
                    }, ""ActiveMQ ForwardingBridge StopTask"");

                    if (!sendShutdown.await(10, TimeUnit.SECONDS)) {
                        
---------------Reference log start----------------
LOG.info(""Network Could not shutdown in a timely manner"")
---------------Reference log end----------------
                    }
                } finally {
                    ServiceStopper ss = new ServiceStopper();
                    stopFailoverTransport(remoteBroker);
                    ss.stop(remoteBroker);
                    ss.stop(localBroker);
                    ss.stop(duplexInboundLocalBroker);
                    // Release the started Latch since another thread could be
                    // stuck waiting for it to start up.
                    startedLatch.countDown();
                    startedLatch.countDown();
                    localStartedLatch.countDown();
                    staticDestinationsLatch.countDown();

                    ss.throwFirstException();
                }
            }

            LOG.info(""{} bridge to {} stopped"", configuration.getBrokerName(), remoteBrokerName);
        }
    }",,
activemq,18240,"LOG.trace(""Rolling back {} messages for redelivery. "", dispatchedInTx.size())",trace,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpSender.java/#L344,"@Override
    public void rollback(LocalTransactionId txnId) throws Exception {
        synchronized (outbound) {

            
---------------Reference log start----------------
LOG.trace(""Rolling back {} messages for redelivery. "", dispatchedInTx.size())
---------------Reference log end----------------

            for (Delivery delivery : dispatchedInTx) {
                // Only settled deliveries should be re-dispatched, unsettled deliveries
                // remain acquired on the remote end and can be accepted again in a new
                // TX or released or rejected etc.
                MessageDispatch dispatch = (MessageDispatch) delivery.getContext();
                dispatch.getMessage().setTransactionId(null);

                if (delivery.remotelySettled()) {
                    dispatch.setRedeliveryCounter(dispatch.getRedeliveryCounter() + 1);
                    outbound.addFirst(dispatch);
                }
            }

            dispatchedInTx.clear();
        }
    }",,
activemq,17927,"LOG.warn(""Error on queueing the Ack Compactor"", ex)",warn,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L2040,"Set<Integer> checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
        MDC.put(""activemq.persistenceDir"", getDirectory().getName());
        LOG.debug(""Checkpoint started."");

        // reflect last update exclusive of current checkpoint
        Location lastUpdate = metadata.lastUpdate;

        metadata.state = OPEN_STATE;
        metadata.producerSequenceIdTrackerLocation = checkpointProducerAudit();
        if (metadata.ackMessageFileMapDirtyFlag.get() || (metadata.ackMessageFileMapLocation == null)) {
            metadata.ackMessageFileMapLocation = checkpointAckMessageFileMap();
        }
        metadata.ackMessageFileMapDirtyFlag.lazySet(false);
        Location[] inProgressTxRange = getInProgressTxLocationRange();
        metadata.firstInProgressTransactionLocation = inProgressTxRange[0];
        tx.store(metadata.page, metadataMarshaller, true);

        final TreeSet<Integer> gcCandidateSet = new TreeSet<>();
        if (cleanup) {

            final TreeSet<Integer> completeFileSet = new TreeSet<>(journal.getFileMap().keySet());
            gcCandidateSet.addAll(completeFileSet);

            if (LOG.isTraceEnabled()) {
                LOG.trace(""Last update: "" + lastUpdate + "", full gc candidates set: "" + gcCandidateSet);
            }

            if (lastUpdate != null) {
                // we won't delete past the last update, ackCompaction journal can be a candidate in error
                gcCandidateSet.removeAll(new TreeSet<Integer>(gcCandidateSet.tailSet(lastUpdate.getDataFileId())));
            }

            // Don't GC files under replication
            if( journalFilesBeingReplicated!=null ) {
                gcCandidateSet.removeAll(journalFilesBeingReplicated);
            }

            if (metadata.producerSequenceIdTrackerLocation != null) {
                int dataFileId = metadata.producerSequenceIdTrackerLocation.getDataFileId();
                if (gcCandidateSet.contains(dataFileId) && gcCandidateSet.first() == dataFileId) {
                    // rewrite so we don't prevent gc
                    metadata.producerSequenceIdTracker.setModified(true);
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(""rewriting producerSequenceIdTracker:"" + metadata.producerSequenceIdTrackerLocation);
                    }
                }
                gcCandidateSet.remove(dataFileId);
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after producerSequenceIdTrackerLocation:"" + metadata.producerSequenceIdTrackerLocation + "", "" + gcCandidateSet);
                }
            }

            if (metadata.ackMessageFileMapLocation != null) {
                int dataFileId = metadata.ackMessageFileMapLocation.getDataFileId();
                gcCandidateSet.remove(dataFileId);
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after ackMessageFileMapLocation:"" + metadata.ackMessageFileMapLocation + "", "" + gcCandidateSet);
                }
            }

            // Don't GC files referenced by in-progress tx
            if (inProgressTxRange[0] != null) {
                for (int pendingTx=inProgressTxRange[0].getDataFileId(); pendingTx <= inProgressTxRange[1].getDataFileId(); pendingTx++) {
                    gcCandidateSet.remove(pendingTx);
                }
            }
            if (LOG.isTraceEnabled()) {
                LOG.trace(""gc candidates after in progress tx range:"" + Arrays.asList(inProgressTxRange) + "", "" + gcCandidateSet);
            }

            // Go through all the destinations to see if any of them can remove GC candidates.
            for (Entry<String, StoredDestination> entry : storedDestinations.entrySet()) {
                if( gcCandidateSet.isEmpty() ) {
                    break;
                }

                // Use a visitor to cut down the number of pages that we load
                entry.getValue().locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
                    int last=-1;
                    @Override
                    public boolean isInterestedInKeysBetween(Location first, Location second) {
                        if( first==null ) {
                            SortedSet<Integer> subset = gcCandidateSet.headSet(second.getDataFileId()+1);
                            if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
                                subset.remove(second.getDataFileId());
                            }
                            return !subset.isEmpty();
                        } else if( second==null ) {
                            SortedSet<Integer> subset = gcCandidateSet.tailSet(first.getDataFileId());
                            if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
                                subset.remove(first.getDataFileId());
                            }
                            return !subset.isEmpty();
                        } else {
                            SortedSet<Integer> subset = gcCandidateSet.subSet(first.getDataFileId(), second.getDataFileId()+1);
                            if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
                                subset.remove(first.getDataFileId());
                            }
                            if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
                                subset.remove(second.getDataFileId());
                            }
                            return !subset.isEmpty();
                        }
                    }

                    @Override
                    public void visit(List<Location> keys, List<Long> values) {
                        for (Location l : keys) {
                            int fileId = l.getDataFileId();
                            if( last != fileId ) {
                                gcCandidateSet.remove(fileId);
                                last = fileId;
                            }
                        }
                    }
                });

                // Durable Subscription
                if (entry.getValue().subLocations != null) {
                    Iterator<Entry<String, Location>> iter = entry.getValue().subLocations.iterator(tx);
                    while (iter.hasNext()) {
                        Entry<String, Location> subscription = iter.next();
                        int dataFileId = subscription.getValue().getDataFileId();

                        // Move subscription along if it has no outstanding messages that need ack'd
                        // and its in the last log file in the journal.
                        if (!gcCandidateSet.isEmpty() && gcCandidateSet.first() == dataFileId) {
                            final StoredDestination destination = entry.getValue();
                            final String subscriptionKey = subscription.getKey();
                            SequenceSet pendingAcks = destination.ackPositions.get(tx, subscriptionKey);

                            // When pending is size one that is the next message Id meaning there
                            // are no pending messages currently.
                            if (pendingAcks == null || pendingAcks.isEmpty() ||
                                (pendingAcks.size() == 1 && pendingAcks.getTail().range() == 1)) {

                                if (LOG.isTraceEnabled()) {
                                    LOG.trace(""Found candidate for rewrite: sub {} on {} from file {}"", subscriptionKey, entry.getKey(), dataFileId);
                                }

                                final KahaSubscriptionCommand kahaSub =
                                    destination.subscriptions.get(tx, subscriptionKey);
                                destination.subLocations.put(
                                    tx, subscriptionKey, checkpointSubscriptionCommand(kahaSub));

                                // Skips the remove from candidates if we rewrote the subscription
                                // in order to prevent duplicate subscription commands on recover.
                                // If another subscription is on the same file and isn't rewritten
                                // than it will remove the file from the set.
                                continue;
                            }
                        }

                        if (LOG.isTraceEnabled()) {
                            final StoredDestination destination = entry.getValue();
                            final String subscriptionKey = subscription.getKey();
                            final SequenceSet pendingAcks = destination.ackPositions.get(tx, subscriptionKey);
                            LOG.trace(""sub {} on {} in dataFile {} has pendingCount {}"", subscriptionKey, entry.getKey(), dataFileId, pendingAcks.rangeSize()-1);
                        }
                        gcCandidateSet.remove(dataFileId);
                    }
                }

                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after dest:"" + entry.getKey() + "", "" + gcCandidateSet);
                }
            }

            // check we are not deleting file with ack for in-use journal files
            if (LOG.isTraceEnabled()) {
                LOG.trace(""gc candidates: "" + gcCandidateSet);
                LOG.trace(""ackMessageFileMap: "" +  metadata.ackMessageFileMap);
            }

            boolean ackMessageFileMapMod = false;
            Iterator<Integer> candidates = gcCandidateSet.iterator();
            while (candidates.hasNext()) {
                Integer candidate = candidates.next();
                Set<Integer> referencedFileIds = metadata.ackMessageFileMap.get(candidate);
                if (referencedFileIds != null) {
                    for (Integer referencedFileId : referencedFileIds) {
                        if (completeFileSet.contains(referencedFileId) && !gcCandidateSet.contains(referencedFileId)) {
                            // active file that is not targeted for deletion is referenced so don't delete
                            candidates.remove();
                            break;
                        }
                    }
                    if (gcCandidateSet.contains(candidate)) {
                        ackMessageFileMapMod |= (metadata.ackMessageFileMap.remove(candidate) != null);
                        metadata.ackMessageFileMapDirtyFlag.lazySet(true);
                    } else {
                        if (LOG.isTraceEnabled()) {
                            LOG.trace(""not removing data file: "" + candidate
                                    + "" as contained ack(s) refer to referenced file: "" + referencedFileIds);
                        }
                    }
                }
            }

            if (!gcCandidateSet.isEmpty()) {
                LOG.debug(""Cleanup removing the data files: {}"", gcCandidateSet);
                for (Integer candidate : gcCandidateSet) {
                    for (Set<Integer> ackFiles : metadata.ackMessageFileMap.values()) {
                        ackMessageFileMapMod |= ackFiles.remove(candidate);
                        metadata.ackMessageFileMapDirtyFlag.lazySet(true);
                    }
                }
                if (ackMessageFileMapMod) {
                    checkpointUpdate(tx, false);
                }
            } else if (isEnableAckCompaction()) {
                if (++checkPointCyclesWithNoGC >= getCompactAcksAfterNoGC()) {
                    // First check length of journal to make sure it makes sense to even try.
                    //
                    // If there is only one journal file with Acks in it we don't need to move
                    // it since it won't be chained to any later logs.
                    //
                    // If the logs haven't grown since the last time then we need to compact
                    // otherwise there seems to still be room for growth and we don't need to incur
                    // the overhead.  Depending on configuration this check can be avoided and
                    // Ack compaction will run any time the store has not GC'd a journal file in
                    // the configured amount of cycles.
                    if (metadata.ackMessageFileMap.size() > 1 &&
                        (journalLogOnLastCompactionCheck == journal.getCurrentDataFileId() || isCompactAcksIgnoresStoreGrowth())) {

                        LOG.trace(""No files GC'd checking if threshold to ACK compaction has been met."");
                        try {
                            scheduler.execute(new AckCompactionRunner());
                        } catch (Exception ex) {
                            
---------------Reference log start----------------
LOG.warn(""Error on queueing the Ack Compactor"", ex)
---------------Reference log end----------------
                        }
                    } else {
                        LOG.trace(""Journal activity detected, no Ack compaction scheduled."");
                    }

                    checkPointCyclesWithNoGC = 0;
                } else {
                    LOG.trace(""Not yet time to check for compaction: {} of {} cycles"",
                              checkPointCyclesWithNoGC, getCompactAcksAfterNoGC());
                }

                journalLogOnLastCompactionCheck = journal.getCurrentDataFileId();
            }
        }
        MDC.remove(""activemq.persistenceDir"");

        LOG.debug(""Checkpoint done."");
        return gcCandidateSet;
    }",,
activemq,18317,"LOG.warn(""jms"", e)",warn,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/MessageListenerServlet.java/#L201,"@Override
    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {

        // lets turn the HTTP post into a JMS Message
        AjaxWebClient client = getAjaxWebClient( request );
        String messageIds = """";

        synchronized (client) {

            if (LOG.isDebugEnabled()) {
                LOG.debug(""POST client="" + client + "" session="" + request.getSession().getId() + "" clientId=""+ request.getParameter(""clientId"") + "" info="" + request.getPathInfo() + "" contentType="" + request.getContentType());
                // dump(request.getParameterMap());
            }

            int messages = 0;

            // loop until no more messages
            while (true) {
                // Get the message parameters. Multiple messages are encoded
                // with more compact parameter names.
                String destinationName = request.getParameter(messages == 0 ? ""destination"" : (""d"" + messages));

                if (destinationName == null) {
                    destinationName = request.getHeader(""destination"");
                }

                String message = request.getParameter(messages == 0 ? ""message"" : (""m"" + messages));
                String type = request.getParameter(messages == 0 ? ""type"" : (""t"" + messages));

                if (destinationName == null || message == null || type == null) {
                    break;
                }

                try {
                    Destination destination = getDestination(client, request, destinationName);

                    if (LOG.isDebugEnabled()) {
                        LOG.debug(messages + "" destination="" + destinationName + "" message="" + message + "" type="" + type);
                        LOG.debug(destination + "" is a "" + destination.getClass().getName());
                    }

                    messages++;

                    if (""listen"".equals(type)) {
                        AjaxListener listener = client.getListener();
                        Map<MessageAvailableConsumer, String> consumerIdMap = client.getIdMap();
                        Map<MessageAvailableConsumer, String> consumerDestinationNameMap = client.getDestinationNameMap();
                        client.closeConsumer(destination); // drop any existing
                        // consumer.
                        MessageAvailableConsumer consumer = (MessageAvailableConsumer)client.getConsumer(destination, request.getHeader(WebClient.selectorName));

                        consumer.setAvailableListener(listener);
                        consumerIdMap.put(consumer, message);
                        consumerDestinationNameMap.put(consumer, destinationName);
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Subscribed: "" + consumer + "" to "" + destination + "" id="" + message);
                        }
                    } else if (""unlisten"".equals(type)) {
                        Map<MessageAvailableConsumer, String> consumerIdMap = client.getIdMap();
                        Map<MessageAvailableConsumer, String> consumerDestinationNameMap = client.getDestinationNameMap();
                        MessageAvailableConsumer consumer = (MessageAvailableConsumer)client.getConsumer(destination, request.getHeader(WebClient.selectorName));

                        consumer.setAvailableListener(null);
                        consumerIdMap.remove(consumer);
                        consumerDestinationNameMap.remove(consumer);
                        client.closeConsumer(destination);
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Unsubscribed: "" + consumer);
                        }
                    } else if (""send"".equals(type)) {
                        TextMessage text = client.getSession().createTextMessage(message);
                        appendParametersToMessage(request, text);

                        client.send(destination, text);
                        messageIds += text.getJMSMessageID() + ""\n"";
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Sent "" + message + "" to "" + destination);
                        }
                    } else {
                        LOG.warn(""unknown type "" + type);
                    }

                } catch (JMSException e) {
                    
---------------Reference log start----------------
LOG.warn(""jms"", e)
---------------Reference log end----------------
                }
            }
        }

        if (""true"".equals(request.getParameter(""poll""))) {
            try {
                // TODO return message IDs
                doMessages(client, request, response);
            } catch (JMSException e) {
                throw new ServletException(""JMS problem: "" + e, e);
            }
        } else {
            // handle simple POST of a message
            if (request.getContentLength() != 0 && (request.getContentType() == null || !request.getContentType().toLowerCase().startsWith(""application/x-www-form-urlencoded""))) {
                try {
                    Destination destination = getDestination(client, request);
                    String body = getPostedMessageBody(request);
                    TextMessage message = client.getSession().createTextMessage(body);
                    appendParametersToMessage(request, message);

                    client.send(destination, message);
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Sent to destination: "" + destination + "" body: "" + body);
                    }
                    messageIds += message.getJMSMessageID() + ""\n"";
                } catch (JMSException e) {
                    throw new ServletException(e);
                }
            }

            response.setContentType(""text/plain"");
            response.setHeader(""Cache-Control"", ""no-cache"");
            response.getWriter().print(messageIds);
        }
    }",,
activemq,19330,"LOG.debug(""Failed to close active running server session {}, reason:{}"", ss, ignored.toString(), ignored)",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ServerSessionPoolImpl.java/#L317,"protected int closeSessions() {
        sessionLock.lock();
        try {
            List<ServerSessionImpl> alreadyClosedServerSessions = new ArrayList<>(activeSessions.size());
            for (ServerSessionImpl ss : activeSessions) {
                try {
                    ActiveMQSession session = (ActiveMQSession) ss.getSession();
                    if (!session.isClosed()) {
                        session.close();
                    } else {
                        LOG.debug(""Session {} already closed"", session);
                        alreadyClosedServerSessions.add(ss);

                    }
                } catch (JMSException ignored) {
                    if (LOG.isDebugEnabled()) {
                        
---------------Reference log start----------------
LOG.debug(""Failed to close active running server session {}, reason:{}"", ss, ignored.toString(), ignored)
---------------Reference log end----------------
                    }
                }
            }
            for (ServerSessionImpl ss : alreadyClosedServerSessions) {
                removeFromPool(ss);
            }
            alreadyClosedServerSessions.clear();

            for (ServerSessionImpl ss : idleSessions) {
                ss.close();
            }
            idleSessions.clear();
            return activeSessions.size();
        } finally {
            sessionLock.unlock();
        }
    }",, 
activemq,19679,"LOG.warn(""Exception suspending discoverAgent: {}"", discoveryAgent)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/discovery/DiscoveryTransport.java/#L115,"@Override
    public void transportResumed() {
        if( discoveryAgent instanceof Suspendable ) {
            try {
                ((Suspendable)discoveryAgent).suspend();
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.warn(""Exception suspending discoverAgent: {}"", discoveryAgent)
---------------Reference log end----------------
            }
        }
        super.transportResumed();
    }",,
activemq,18760,"LOG.debug(""cleared pending from afterCommit: {}"", destination)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransactionBroker.java/#L190,"@Override
        public void afterCommit() throws Exception {
            Destination dest = transactionBroker.addDestination(transactionBroker.context, destination, false);
            if (messageSend) {
                dest.clearPendingMessages(opCount);
                dest.getDestinationStatistics().getEnqueues().add(opCount);
                dest.getDestinationStatistics().getMessages().add(opCount);
                
---------------Reference log start----------------
LOG.debug(""cleared pending from afterCommit: {}"", destination)
---------------Reference log end----------------
            } else {
                dest.getDestinationStatistics().getDequeues().add(opCount);
            }
        }",,
activemq,17794,"LOG.debug(""Exception while closing connection on shutdown. This exception is ignored."", ignored)",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/DefaultDatabaseLocker.java/#L151,"public void doStop(ServiceStopper stopper) throws Exception {
        try {
            if (lockCreateStatement != null) {
                lockCreateStatement.cancel();    			
            }
        } catch (SQLFeatureNotSupportedException e) {
            LOG.warn(""Failed to cancel locking query on dataSource"" + dataSource, e);    		
        }
        try {
    	    if (lockUpdateStatement != null) {
        	    lockUpdateStatement.cancel();    			
    	    }
        } catch (SQLFeatureNotSupportedException e) {
            LOG.warn(""Failed to cancel locking query on dataSource"" + dataSource, e);    		
        }

        // when the connection is closed from an outside source (lost TCP
        // connection, db server, etc) and this connection is managed by a pool
        // it is important to close the connection so that we don't leak
        // connections

        if (connection != null) {
            try {
                connection.rollback();
            } catch (SQLException sqle) {
                LOG.debug(""Exception while rollbacking the connection on shutdown. This exception is ignored."", sqle);
            } finally {
                try {
                    connection.close();
                } catch (SQLException ignored) {
                    
---------------Reference log start----------------
LOG.debug(""Exception while closing connection on shutdown. This exception is ignored."", ignored)
---------------Reference log end----------------
                }
                lockCreateStatement = null;
            }
        }
    }",,
activemq,18206,"LOG.info(""Expiring connection "" + connection + "" on IOException: "" + error.getMessage())",info,https://github.com/apache/activemq/blob/main/activemq-pool/src/main/java/org/apache/activemq/pool/XaPooledConnectionFactory.java/#L101,"@Override
                    public void onException(IOException error) {
                        synchronized (this) {
                            setHasExpired(true);
                            // only log if not stopped
                            if (!stopped.get()) {
                                
---------------Reference log start----------------
LOG.info(""Expiring connection "" + connection + "" on IOException: "" + error.getMessage())
---------------Reference log end----------------
                                // log stacktrace at debug level
                                LOG.debug(""Expiring connection "" + connection + "" on IOException: "", error);
                            }
                        }
                    }",,
activemq,18837,"LOG.error(""{} Failed to get the outstanding message count from the store"", this, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/cursors/TopicStorePrefetch.java/#L121,"@Override
    protected synchronized long getStoreMessageSize() {
        try {
            return store.getMessageSize(clientId, subscriberName);
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""{} Failed to get the outstanding message count from the store"", this, e)
---------------Reference log end----------------
            throw new RuntimeException(e);
        }
    }",,
activemq,18134,"LOG.info(""Adding extension dir: "" + files[j].getAbsolutePath())",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/spi/ClassLoaderSPIConnectionFactory.java/#L66,"protected ClassLoader getContextClassLoader(Properties settings) {
        String extDir = (String)settings.remove(KEY_EXT_DIR);
        if (extDir != null) {
            StringTokenizer tokens = new StringTokenizer(extDir, "";,"");
            List<URL> urls = new ArrayList<URL>();
            while (tokens.hasMoreTokens()) {
                String dir = tokens.nextToken();
                try {
                    File f = new File(dir);
                    if (!f.exists()) {
                        LOG.warn(""Cannot find extension dir: "" + f.getAbsolutePath());
                    } else {
                        LOG.info(""Adding extension dir: "" + f.getAbsolutePath());

                        urls.add(f.toURI().toURL());

                        File[] files = f.listFiles();
                        if (files != null) {
                            for (int j = 0; j < files.length; j++) {
                                if (files[j].getName().endsWith("".zip"") || files[j].getName().endsWith("".jar"")) {
                                    
---------------Reference log start----------------
LOG.info(""Adding extension dir: "" + files[j].getAbsolutePath())
---------------Reference log end----------------
                                    urls.add(files[j].toURI().toURL());
                                }
                            }
                        }
                    }
                } catch (Exception e) {
                    LOG.warn(""Failed to load ext dir: "" + dir + "". Reason: "" + e);
                }
            }

            URL u[] = new URL[urls.size()];
            urls.toArray(u);
            return new URLClassLoader(u, Thread.currentThread().getContextClassLoader());
        }
        return ClassLoaderSPIConnectionFactory.class.getClassLoader();
    }",,
activemq,18985,"LOG.debug(""Virtual consumer pair added: {} for consumer: {} "", pair, info)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/advisory/AdvisoryBroker.java/#L612,"private void fireVirtualDestinationAddAdvisory(ConnectionContext context, ConsumerInfo info, ActiveMQDestination activeMQDest,
            VirtualDestination virtualDestination) throws Exception {
        //if no consumer info, we need to create one - this is the case when an advisory is fired
        //because of the existence of a destination matching a virtual destination
        if (info == null) {

            //store the virtual destination and the activeMQDestination as a pair so that we can keep track
            //of all matching forwarded destinations that caused demand
            VirtualConsumerPair pair = new VirtualConsumerPair(virtualDestination, activeMQDest);
            if (brokerConsumerDests.get(pair) == null) {
                ConnectionId connectionId = new ConnectionId(connectionIdGenerator.generateId());
                SessionId sessionId = new SessionId(connectionId, sessionIdGenerator.getNextSequenceId());
                ConsumerId consumerId = new ConsumerId(sessionId, consumerIdGenerator.getNextSequenceId());
                info = new ConsumerInfo(consumerId);

                if(brokerConsumerDests.putIfAbsent(pair, info) == null) {
                    
---------------Reference log start----------------
LOG.debug(""Virtual consumer pair added: {} for consumer: {} "", pair, info)
---------------Reference log end----------------
                    setConsumerInfoVirtualDest(info, virtualDestination, activeMQDest);
                    ActiveMQTopic topic = AdvisorySupport.getVirtualDestinationConsumerAdvisoryTopic(info.getDestination());

                    if (virtualDestinationConsumers.putIfAbsent(info, virtualDestination) == null) {
                        LOG.debug(""Virtual consumer added: {}, for virtual destination: {}"", info, virtualDestination);
                        fireConsumerAdvisory(context, info.getDestination(), topic, info);
                    }
                }
            }
        //this is the case of a real consumer coming online
        } else {
            info = info.copy();
            setConsumerInfoVirtualDest(info, virtualDestination, activeMQDest);
            ActiveMQTopic topic = AdvisorySupport.getVirtualDestinationConsumerAdvisoryTopic(info.getDestination());

            if (virtualDestinationConsumers.putIfAbsent(info, virtualDestination) == null) {
                LOG.debug(""Virtual consumer added: {}, for virtual destination: {}"", info, virtualDestination);
                fireConsumerAdvisory(context, info.getDestination(), topic, info);
            }
        }
    }",,
activemq,18361,"log.debug(""Looking for the user roles in LDAP with "")",debug,https://github.com/apache/activemq/blob/main/activemq-jaas/src/main/java/org/apache/activemq/jaas/LDAPLoginModule.java/#L369,"protected List<String> getRoles(DirContext context, String dn, String username, List<String> currentRoles) throws NamingException {
        List<String> list = currentRoles;
        MessageFormat roleSearchMatchingFormat;
        boolean roleSearchSubtreeBool;
        boolean expandRolesBool;
        roleSearchMatchingFormat = new MessageFormat(getLDAPPropertyValue(ROLE_SEARCH_MATCHING));
        roleSearchSubtreeBool = Boolean.valueOf(getLDAPPropertyValue(ROLE_SEARCH_SUBTREE)).booleanValue();
        expandRolesBool = Boolean.valueOf(getLDAPPropertyValue(EXPAND_ROLES)).booleanValue();
        
        if (list == null) {
            list = new ArrayList<String>();
        }
        if (!isLoginPropertySet(ROLE_NAME)) {
            return list;
        }
        String filter = roleSearchMatchingFormat.format(new String[] {
            doRFC2254Encoding(dn), doRFC2254Encoding(username)
        });

        SearchControls constraints = new SearchControls();
        if (roleSearchSubtreeBool) {
            constraints.setSearchScope(SearchControls.SUBTREE_SCOPE);
        } else {
            constraints.setSearchScope(SearchControls.ONELEVEL_SCOPE);
        }
        if (log.isDebugEnabled()) {
            log.debug(""Get user roles."");
            
---------------Reference log start----------------
log.debug(""Looking for the user roles in LDAP with "")
---------------Reference log end----------------
            log.debug(""  base DN: "" + getLDAPPropertyValue(ROLE_BASE));
            log.debug(""  filter: "" + filter);
        }
        HashSet<String> haveSeenNames = new HashSet<String>();
        Queue<String> pendingNameExpansion = new LinkedList<String>();
        NamingEnumeration<SearchResult> results = context.search(getLDAPPropertyValue(ROLE_BASE), filter, constraints);
        while (results.hasMore()) {
            SearchResult result = results.next();
            Attributes attrs = result.getAttributes();
            if (expandRolesBool) {
                haveSeenNames.add(result.getNameInNamespace());
                pendingNameExpansion.add(result.getNameInNamespace());
            }
            if (attrs == null) {
                continue;
            }
            list = addAttributeValues(getLDAPPropertyValue(ROLE_NAME), attrs, list);
        }
        if (expandRolesBool) {
            MessageFormat expandRolesMatchingFormat = new MessageFormat(getLDAPPropertyValue(EXPAND_ROLES_MATCHING));
            while (!pendingNameExpansion.isEmpty()) {
                String name = pendingNameExpansion.remove();
                filter = expandRolesMatchingFormat.format(new String[]{name});
                results = context.search(getLDAPPropertyValue(ROLE_BASE), filter, constraints);
                while (results.hasMore()) {
                    SearchResult result = results.next();
                    name = result.getNameInNamespace();
                    if (!haveSeenNames.contains(name)) {
                        Attributes attrs = result.getAttributes();
                        list = addAttributeValues(getLDAPPropertyValue(ROLE_NAME), attrs, list);
                        haveSeenNames.add(name);
                        pendingNameExpansion.add(name);
                    }
                }
            }
        }
        return list;
    }",,
activemq,18431,"LOG.debug(""GET timed out"")",debug,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/http/HttpClientTransport.java/#L181,"@Override
    public void run() {

        if (LOG.isTraceEnabled()) {
            LOG.trace(""HTTP GET consumer thread starting: "" + this);
        }
        HttpClient httpClient = getReceiveHttpClient();
        URI remoteUrl = getRemoteUrl();

        while (!isStopped() && !isStopping()) {

            httpMethod = new HttpGet(remoteUrl.toString());
            configureMethod(httpMethod);
            HttpResponse answer = null;

            try {
                answer = httpClient.execute(httpMethod);
                int status = answer.getStatusLine().getStatusCode();
                if (status != HttpStatus.SC_OK) {
                    if (status == HttpStatus.SC_REQUEST_TIMEOUT) {
                        
---------------Reference log start----------------
LOG.debug(""GET timed out"")
---------------Reference log end----------------
                        try {
                            Thread.sleep(1000);
                        } catch (InterruptedException e) {
                            onException(new InterruptedIOException());
                            Thread.currentThread().interrupt();
                            break;
                        }
                    } else {
                        onException(new IOException(""Failed to perform GET on: "" + remoteUrl + "" as response was: "" + answer));
                        break;
                    }
                } else {
                    receiveCounter++;
                    DataInputStream stream = createDataInputStream(answer);
                    Object command = getTextWireFormat().unmarshal(stream);
                    if (command == null) {
                        LOG.debug(""Received null command from url: "" + remoteUrl);
                    } else {
                        doConsume(command);
                    }
                    stream.close();
                }
            } catch (Exception e) { // handle RuntimeException from unmarshal
                onException(IOExceptionSupport.create(""Failed to perform GET on: "" + remoteUrl + "" Reason: "" + e.getMessage(), e));
                break;
            } finally {
                if (answer != null) {
                    try {
                        EntityUtils.consume(answer.getEntity());
                    } catch (IOException e) {
                    }
                }
            }
        }
    }",,
activemq,18850,"LOG.info(""Destroying durable subscriber due to inactivity: {}"", sub)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/TopicRegion.java/#L97,"public void doCleanup() {
        long now = System.currentTimeMillis();
        for (Map.Entry<SubscriptionKey, DurableTopicSubscription> entry : durableSubscriptions.entrySet()) {
            DurableTopicSubscription sub = entry.getValue();
            if (!sub.isActive()) {
                long offline = sub.getOfflineTimestamp();
                if (offline != -1 && now - offline >= broker.getBrokerService().getOfflineDurableSubscriberTimeout()) {
                    
---------------Reference log start----------------
LOG.info(""Destroying durable subscriber due to inactivity: {}"", sub)
---------------Reference log end----------------
                    try {
                        RemoveSubscriptionInfo info = new RemoveSubscriptionInfo();
                        info.setClientId(entry.getKey().getClientId());
                        info.setSubscriptionName(entry.getKey().getSubscriptionName());
                        ConnectionContext context = new ConnectionContext();
                        context.setBroker(broker);
                        context.setClientId(entry.getKey().getClientId());
                        removeSubscription(context, info);
                    } catch (Exception e) {
                        LOG.error(""Failed to remove inactive durable subscriber"", e);
                    }
                }
            }
        }
    }",,
activemq,19472,"LOG.trace(""Running task iteration {} - {}"", i, task)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/thread/PooledTaskRunner.java/#L132,"final void runTask() {

        synchronized (runable) {
            queued = false;
            if (shutdown) {
                iterating = false;
                runable.notifyAll();
                return;
            }
            iterating = true;
        }

        // Don't synchronize while we are iterating so that
        // multiple wakeup() calls can be executed concurrently.
        boolean done = false;
        try {
            for (int i = 0; i < maxIterationsPerRun; i++) {
                
---------------Reference log start----------------
LOG.trace(""Running task iteration {} - {}"", i, task)
---------------Reference log end----------------
                if (!task.iterate()) {
                    done = true;
                    break;
                }
            }
        } finally {
            synchronized (runable) {
                iterating = false;
                runable.notifyAll();
                if (shutdown) {
                    queued = false;
                    runable.notifyAll();
                } else {
                    // If we could not iterate all the items
                    // then we need to re-queue.
                    if (!done) {
                        queued = true;
                    }

                    if (queued) {
                        executor.execute(runable);
                    }
                }

            }
        }
    }",,
activemq,19263,"LOG.debug(""Waiting for completion for sub: {}, dispatched: {}"", localInfo.getConsumerId(), this.dispatched.get())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandSubscription.java/#L126,"public void waitForCompletion() {
        if (dispatched.get() > 0) {
            
---------------Reference log start----------------
LOG.debug(""Waiting for completion for sub: {}, dispatched: {}"", localInfo.getConsumerId(), this.dispatched.get())
---------------Reference log end----------------
            activeWaiter.set(true);
            if (dispatched.get() > 0) {
                synchronized (activeWaiter) {
                    try {
                        activeWaiter.wait(TimeUnit.SECONDS.toMillis(30));
                    } catch (InterruptedException ignored) {
                    }
                }
                if (this.dispatched.get() > 0) {
                    LOG.warn(""demand sub interrupted or timedout while waiting for outstanding responses, expect potentially {} duplicate forwards"", this.dispatched.get());
                }
            }
        }
    }",,
activemq,18914,"LOG.info(""exception on local remove of slow consumer: {}"", subscription.getConsumerInfo().getConsumerId(), e)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/policy/AbortSlowConsumerStrategy.java/#L212,"protected void abortSubscription(Map<Subscription, SlowConsumerEntry> toAbort, boolean abortSubscriberConnection) {

        Map<Connection, List<Subscription>> abortMap = new HashMap<Connection, List<Subscription>>();

        for (final Entry<Subscription, SlowConsumerEntry> entry : toAbort.entrySet()) {
            ConnectionContext connectionContext = entry.getValue().context;
            if (connectionContext == null) {
                continue;
            }

            Connection connection = connectionContext.getConnection();
            if (connection == null) {
                LOG.debug(""slowConsumer abort ignored, no connection in context: {}"", connectionContext);
            }

            if (!abortMap.containsKey(connection)) {
                abortMap.put(connection, new ArrayList<Subscription>());
            }

            abortMap.get(connection).add(entry.getKey());
        }

        for (Entry<Connection, List<Subscription>> entry : abortMap.entrySet()) {
            final Connection connection = entry.getKey();
            final List<Subscription> subscriptions = entry.getValue();

            if (abortSubscriberConnection) {

                LOG.info(""aborting connection:{} with {} slow consumers"",
                         connection.getConnectionId(), subscriptions.size());

                if (LOG.isTraceEnabled()) {
                    for (Subscription subscription : subscriptions) {
                        LOG.trace(""Connection {} being aborted because of slow consumer: {} on destination: {}"",
                                connection.getConnectionId(),
                                subscription.getConsumerInfo().getConsumerId(),
                                subscription.getActiveMQDestination());
                    }
                }

                try {
                    scheduler.executeAfterDelay(new Runnable() {
                        @Override
                        public void run() {
                            connection.serviceException(new InactivityIOException(
                                    subscriptions.size() + "" Consumers was slow too often (>""
                                    + maxSlowCount +  "") or too long (>""
                                    + maxSlowDuration + ""): ""));
                        }}, 0l);
                } catch (Exception e) {
                    LOG.info(""exception on aborting connection {} with {} slow consumers"",
                             connection.getConnectionId(), subscriptions.size());
                }
            } else {
                // just abort each consumer
                for (Subscription subscription : subscriptions) {
                    final Subscription subToClose = subscription;
                    LOG.info(""aborting slow consumer: {} for destination:{}"",
                             subscription.getConsumerInfo().getConsumerId(),
                             subscription.getActiveMQDestination());

                    // tell the remote consumer to close
                    try {
                        ConsumerControl stopConsumer = new ConsumerControl();
                        stopConsumer.setConsumerId(subscription.getConsumerInfo().getConsumerId());
                        stopConsumer.setClose(true);
                        connection.dispatchAsync(stopConsumer);
                    } catch (Exception e) {
                        LOG.info(""exception on aborting slow consumer: {}"", subscription.getConsumerInfo().getConsumerId(), e);
                    }

                    // force a local remove in case remote is unresponsive
                    try {
                        scheduler.executeAfterDelay(new Runnable() {
                            @Override
                            public void run() {
                                try {
                                    RemoveInfo removeCommand = subToClose.getConsumerInfo().createRemoveCommand();
                                    if (connection instanceof CommandVisitor) {
                                        // avoid service exception handling and logging
                                        removeCommand.visit((CommandVisitor) connection);
                                    } else {
                                        connection.service(removeCommand);
                                    }
                                } catch (IllegalStateException ignoredAsRemoteHasDoneTheJob) {
                                } catch (Exception e) {
                                    LOG.info(""exception on local remove of slow consumer: {}"", subToClose.getConsumerInfo().getConsumerId(), e);
                                }
                            }}, 1000l);

                    } catch (Exception e) {
                        
---------------Reference log start----------------
LOG.info(""exception on local remove of slow consumer: {}"", subscription.getConsumerInfo().getConsumerId(), e)
---------------Reference log end----------------
                    }
                }
            }
        }
    }",,
activemq,18079,"LOG.info(""pending local transactions: "" + pendingCommit.keySet())",info,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MultiKahaDBTransactionStore.java/#L425,"private void recoverPendingLocalTransactions() throws IOException {

        if (checkForCorruption) {
            for (DataFile dataFile: journal.getFileMap().values()) {
                if (!dataFile.getCorruptedBlocks().isEmpty()) {
                    LOG.error(""Corrupt Transaction journal records found in db-{}.log at {}"", dataFile.getDataFileId(),  dataFile.getCorruptedBlocks());
                    corruptJournalDetected.set(true);
                }
            }
        }
        if (!corruptJournalDetected.get()) {
            Location location = null;
            try {
                location = journal.getNextLocation(null);
                while (location != null) {
                    process(location, load(location));
                    location = journal.getNextLocation(location);
                }
            } catch (Exception oops) {
                LOG.error(""Corrupt journal record; unexpected exception on transaction journal replay of location:"" + location, oops);
                corruptJournalDetected.set(true);
            }
            pendingCommit.putAll(inflightTransactions);
            
---------------Reference log start----------------
LOG.info(""pending local transactions: "" + pendingCommit.keySet())
---------------Reference log end----------------
        }
    }",,
activemq,19026,"LOG.debug(""Caching consumer selector [{}] on  '{}'"", info.getSelector(), destinationName)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/plugin/SubQueueSelectorCacheBroker.java/#L142,"@Override
    public Subscription addConsumer(ConnectionContext context, ConsumerInfo info) throws Exception {
		// don't track selectors for advisory topics, temp destinations or console
		// related consumers
		if (!AdvisorySupport.isAdvisoryTopic(info.getDestination()) && !info.getDestination().isTemporary()
				&& !info.isBrowser()) {
            String destinationName = info.getDestination().getQualifiedName();
            
---------------Reference log start----------------
LOG.debug(""Caching consumer selector [{}] on  '{}'"", info.getSelector(), destinationName)
---------------Reference log end----------------

            String selector = info.getSelector() == null ? MATCH_EVERYTHING : info.getSelector();

            if (!(ignoreWildcardSelectors && hasWildcards(selector))) {

                Set<String> selectors = subSelectorCache.get(destinationName);
                if (selectors == null) {
                    selectors = Collections.synchronizedSet(new HashSet<String>());
                } else if (singleSelectorPerDestination && !MATCH_EVERYTHING.equals(selector)) {
                    // in this case, we allow only ONE selector. But we don't count the catch-all ""null/TRUE"" selector
                    // here, we always allow that one. But only one true selector.
                    boolean containsMatchEverything = selectors.contains(MATCH_EVERYTHING);
                    selectors.clear();

                    // put back the MATCH_EVERYTHING selector
                    if (containsMatchEverything) {
                        selectors.add(MATCH_EVERYTHING);
                    }
                }

                LOG.debug(""adding new selector: into cache "" + selector);
                selectors.add(selector);
                LOG.debug(""current selectors in cache: "" + selectors);
                subSelectorCache.put(destinationName, selectors);
            }
        }

        return super.addConsumer(context, info);
    }",,
activemq,18610,"LOG.debug(""Failure reason: "", e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedRegionBroker.java/#L531,"protected void addInactiveSubscription(SubscriptionKey key, SubscriptionInfo info, Subscription subscription) {
        try {
            ConsumerInfo offlineConsumerInfo = subscription != null ? subscription.getConsumerInfo() : ((TopicRegion)getTopicRegion()).createInactiveConsumerInfo(info);
            ObjectName objectName = BrokerMBeanSupport.createSubscriptionName(brokerObjectName, info.getClientId(), offlineConsumerInfo);
            SubscriptionView view = new InactiveDurableSubscriptionView(this, brokerService, key.getClientId(), info, subscription);

            try {
                if (AsyncAnnotatedMBean.registerMBean(asyncInvokeService, mbeanTimeout, managementContext, view, objectName) != null) {
                    registeredMBeans.add(objectName);
                }
            } catch (Throwable e) {
                LOG.warn(""Failed to register MBean {}"", key);
                
---------------Reference log start----------------
LOG.debug(""Failure reason: "", e)
---------------Reference log end----------------
            }

            inactiveDurableTopicSubscribers.put(objectName, view);
            subscriptionKeys.put(key, objectName);
        } catch (Exception e) {
            LOG.error(""Failed to register subscription {}"", info, e);
        }
    }",,
activemq,17907,"LOG.warn(""Duplicate message add attempt rejected. Destination: {}://{}, Message id: {}"", command.getDestination().getType(), command.getDestination().getName(), command.getMessageId())",warn,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L1558,"long updateIndex(Transaction tx, KahaAddMessageCommand command, Location location) throws IOException {
        StoredDestination sd = getExistingStoredDestination(command.getDestination(), tx);
        if (sd == null) {
            // if the store no longer exists, skip
            return -1;
        }
        // Skip adding the message to the index if this is a topic and there are
        // no subscriptions.
        if (sd.subscriptions != null && sd.subscriptions.isEmpty(tx)) {
            return -1;
        }

        // Add the message.
        int priority = command.getPrioritySupported() ? command.getPriority() : javax.jms.Message.DEFAULT_PRIORITY;
        long id = sd.orderIndex.getNextMessageId();
        Long previous = sd.locationIndex.put(tx, location, id);
        if (previous == null) {
            previous = sd.messageIdIndex.put(tx, command.getMessageId(), id);
            if (previous == null) {
                incrementAndAddSizeToStoreStat(tx, command.getDestination(), location.getSize());
                sd.orderIndex.put(tx, priority, id, new MessageKeys(command.getMessageId(), location));
                if (sd.subscriptions != null && !sd.subscriptions.isEmpty(tx)) {
                    addAckLocationForNewMessage(tx, command.getDestination(), sd, id);
                }
                metadata.lastUpdate = location;
            } else {

                MessageKeys messageKeys = sd.orderIndex.get(tx, previous);
                if (messageKeys != null && messageKeys.location.compareTo(location) < 0) {
                    // If the message ID is indexed, then the broker asked us to store a duplicate before the message was dispatched and acked, we ignore this add attempt
                    
---------------Reference log start----------------
LOG.warn(""Duplicate message add attempt rejected. Destination: {}://{}, Message id: {}"", command.getDestination().getType(), command.getDestination().getName(), command.getMessageId())
---------------Reference log end----------------
                }
                sd.messageIdIndex.put(tx, command.getMessageId(), previous);
                sd.locationIndex.remove(tx, location);
                id = -1;
            }
        } else {
            // restore the previous value.. Looks like this was a redo of a previously
            // added message. We don't want to assign it a new id as the other indexes would
            // be wrong..
            sd.locationIndex.put(tx, location, previous);
            // ensure sequence is not broken
            sd.orderIndex.revertNextMessageId();
            metadata.lastUpdate = location;
        }
        // record this id in any event, initial send or recovery
        metadata.producerSequenceIdTracker.isDuplicate(command.getMessageId());

       return id;
    }",,
activemq,18269,"LOG.error(""Failed to stop AMQP Transport "", e)",error,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpConnection.java/#L818,"void handleException(Throwable exception) {
        LOG.debug(""Exception detail"", exception);
        if (exception instanceof AmqpProtocolException) {
            onAMQPException((IOException) exception);
        } else {
            try {
                // Must ensure that the broker removes Connection resources.
                sendToActiveMQ(new ShutdownInfo());
                amqpTransport.stop();
            } catch (Throwable e) {
                
---------------Reference log start----------------
LOG.error(""Failed to stop AMQP Transport "", e)
---------------Reference log end----------------
            }
        }
    }",,
activemq,17814,"LOG.debug(""Stopped recover next messages"")",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/adapter/DefaultJDBCAdapter.java/#L1097,"@Override
    public void doRecoverNextMessages(TransactionContext c, ActiveMQDestination destination, long[] lastRecoveredEntries,
            long maxSeq, int maxReturned, boolean isPrioritizedMessages, JDBCMessageRecoveryListener listener) throws Exception {
        PreparedStatement s = null;
        ResultSet rs = null;
        try {
            if (isPrioritizedMessages) {
                s = c.getConnection().prepareStatement(limitQuery(this.statements.getFindNextMessagesByPriorityStatement()));
            } else {
                s = c.getConnection().prepareStatement(limitQuery(this.statements.getFindNextMessagesStatement()));
            }
            s.setMaxRows(Math.min(maxReturned, maxRows));
            s.setString(1, destination.getQualifiedName());
            s.setLong(2, maxSeq);
            int paramId = 3;
            if (isPrioritizedMessages) {
                for (int i=9;i>=0;i--) {
                    s.setLong(paramId++, lastRecoveredEntries[i]);
                }
            } else {
                s.setLong(paramId, lastRecoveredEntries[0]);
            }
            rs = s.executeQuery();
            int count = 0;
            if (this.statements.isUseExternalMessageReferences()) {
                while (rs.next() && count < maxReturned) {
                    if (listener.recoverMessageReference(rs.getString(1))) {
                        count++;
                    } else {
                        LOG.debug(""Stopped recover next messages"");
                        break;
                    }
                }
            } else {
                while (rs.next() && count < maxReturned) {
                    if (listener.recoverMessage(rs.getLong(1), getBinaryData(rs, 2))) {
                        count++;
                    } else {
                        
---------------Reference log start----------------
LOG.debug(""Stopped recover next messages"")
---------------Reference log end----------------
                        break;
                    }
                }
            }
        } catch (Exception e) {
            LOG.warn(""Exception recovering next messages"", e);
        } finally {
            close(rs);
            close(s);
        }
    }",,
activemq,17766,"LOG.trace(this + "", pending completion: "" + key + "", last: "" + recovered)",trace,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/JDBCTopicMessageStore.java/#L327,"public void pendingCompletion(String clientId, String subscriptionName, long sequenceId, byte priority) {
        final String key = getSubscriptionKey(clientId, subscriptionName);
        LastRecovered recovered = new LastRecovered();
        recovered.perPriority[priority].recovered = sequenceId;
        subscriberLastRecoveredMap.put(key, recovered);
        pendingCompletion.add(key);
        
---------------Reference log start----------------
LOG.trace(this + "", pending completion: "" + key + "", last: "" + recovered)
---------------Reference log end----------------
    }
    }",,
activemq,17934,"LOG.trace(""Compaction target:{} blocked by inflight transaction records: {}"", journalToAdvance, inProgressTxRange)",trace,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L2162,"private boolean blockedFromCompaction(int journalToAdvance) {
        // don't forward the current data file
        if (journalToAdvance == journal.getCurrentDataFileId()) {
            return true;
        }
        // don't forward any data file with inflight transaction records because it will whack the tx - data file link
        // in the ack map when all acks are migrated (now that the ack map is not just for acks)
        // TODO: prepare records can be dropped but completion records (maybe only commit outcomes) need to be migrated
        // as part of the forward work.
        Location[] inProgressTxRange = getInProgressTxLocationRange();
        if (inProgressTxRange[0] != null) {
            for (int pendingTx = inProgressTxRange[0].getDataFileId(); pendingTx <= inProgressTxRange[1].getDataFileId(); pendingTx++) {
                if (journalToAdvance == pendingTx) {
                    
---------------Reference log start----------------
LOG.trace(""Compaction target:{} blocked by inflight transaction records: {}"", journalToAdvance, inProgressTxRange)
---------------Reference log end----------------
                    return true;
                }
            }
        }
        return false;
    }",,
activemq,17783,"LOG.debug(""Caught exception during rollback on connection: "" + e1, e1)",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/DefaultDatabaseLocker.java/#L88,"public void doStart() throws Exception {

        LOG.info(""Attempting to acquire the exclusive lock to become the Master broker"");
        String sql = getStatements().getLockCreateStatement();
        LOG.debug(""Locking Query is ""+sql);
        
        while (true) {
            try {
                connection = dataSource.getConnection();
                connection.setAutoCommit(false);
                lockCreateStatement = connection.prepareStatement(sql);
                lockCreateStatement.execute();
                break;
            } catch (Exception e) {
                try {
                    if (isStopping()) {
                        throw new Exception(
                                ""Cannot start broker as being asked to shut down. "" 
                                        + ""Interrupted attempt to acquire lock: ""
                                        + e, e);
                    }
                    if (exceptionHandler != null) {
                        try {
                            exceptionHandler.handle(e);
                        } catch (Throwable handlerException) {
                            LOG.error( ""The exception handler ""
                                    + exceptionHandler.getClass().getCanonicalName()
                                    + "" threw this exception: ""
                                    + handlerException
                                    + "" while trying to handle this exception: ""
                                    + e, handlerException);
                        }

                    } else {
                        LOG.debug(""Lock failure: ""+ e, e);
                    }
                } finally {
                    // Let's make sure the database connection is properly
                    // closed when an error occurs so that we're not leaking
                    // connections 
                    if (null != connection) {
                        try {
                            connection.rollback();
                        } catch (SQLException e1) {
                            
---------------Reference log start----------------
LOG.debug(""Caught exception during rollback on connection: "" + e1, e1)
---------------Reference log end----------------
                        }
                        try {
                            connection.close();
                        } catch (SQLException e1) {
                            LOG.debug(""Caught exception while closing connection: "" + e1, e1);
                        }
                        
                        connection = null;
                    }
                }
            } finally {
                if (null != lockCreateStatement) {
                    try {
                        lockCreateStatement.close();
                    } catch (SQLException e1) {
                        LOG.debug(""Caught while closing statement: "" + e1, e1);
                    }
                    lockCreateStatement = null;
                }
            }

            LOG.info(""Failed to acquire lock.  Sleeping for "" + lockAcquireSleepInterval + "" milli(s) before trying again..."");
            try {
                Thread.sleep(lockAcquireSleepInterval);
            } catch (InterruptedException ie) {
                LOG.warn(""Master lock retry sleep interrupted"", ie);
            }
        }

        LOG.info(""Becoming the master on dataSource: "" + dataSource);
    }",,
activemq,18474,"LOG.warn(""suppressing duplicated message send [{}] with producerSequenceId [{}] <= last stored: {}"", (LOG.isTraceEnabled() ? messageSend : messageSend.getMessageId()), producerSequenceId, lastSendSequenceNumber)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/ProducerBrokerExchange.java/#L153,"public boolean canDispatch(Message messageSend) {
        boolean canDispatch = true;
        if (auditProducerSequenceIds && messageSend.isPersistent()) {
            final long producerSequenceId = messageSend.getMessageId().getProducerSequenceId();
            if (isNetworkProducer) {
                //  messages are multiplexed on this producer so we need to query the persistenceAdapter
                long lastStoredForMessageProducer = getStoredSequenceIdForMessage(messageSend.getMessageId());
                if (producerSequenceId <= lastStoredForMessageProducer) {
                    canDispatch = false;
                    LOG.warn(""suppressing duplicate message send [{}] from network producer with producerSequence [{}] less than last stored: {}"",
                            (LOG.isTraceEnabled() ? messageSend : messageSend.getMessageId()), producerSequenceId, lastStoredForMessageProducer);
                }
            } else if (producerSequenceId <= lastSendSequenceNumber.get()) {
                canDispatch = false;
                if (messageSend.isInTransaction()) {
                    
---------------Reference log start----------------
LOG.warn(""suppressing duplicated message send [{}] with producerSequenceId [{}] <= last stored: {}"", (LOG.isTraceEnabled() ? messageSend : messageSend.getMessageId()), producerSequenceId, lastSendSequenceNumber)
---------------Reference log end----------------
                } else {
                    LOG.debug(""suppressing duplicated message send [{}] with producerSequenceId [{}] <= last stored: {}"",
                            (LOG.isTraceEnabled() ? messageSend : messageSend.getMessageId()), producerSequenceId, lastSendSequenceNumber);

                }
            } else {
                // track current so we can suppress duplicates later in the stream
                lastSendSequenceNumber.set(producerSequenceId);
            }
        }
        return canDispatch;
    }",,
activemq,17913,"LOG.trace(""Last update: "" + lastUpdate + "", full gc candidates set: "" + gcCandidateSet)",trace,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L1835,"Set<Integer> checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
        MDC.put(""activemq.persistenceDir"", getDirectory().getName());
        LOG.debug(""Checkpoint started."");

        // reflect last update exclusive of current checkpoint
        Location lastUpdate = metadata.lastUpdate;

        metadata.state = OPEN_STATE;
        metadata.producerSequenceIdTrackerLocation = checkpointProducerAudit();
        if (metadata.ackMessageFileMapDirtyFlag.get() || (metadata.ackMessageFileMapLocation == null)) {
            metadata.ackMessageFileMapLocation = checkpointAckMessageFileMap();
        }
        metadata.ackMessageFileMapDirtyFlag.lazySet(false);
        Location[] inProgressTxRange = getInProgressTxLocationRange();
        metadata.firstInProgressTransactionLocation = inProgressTxRange[0];
        tx.store(metadata.page, metadataMarshaller, true);

        final TreeSet<Integer> gcCandidateSet = new TreeSet<>();
        if (cleanup) {

            final TreeSet<Integer> completeFileSet = new TreeSet<>(journal.getFileMap().keySet());
            gcCandidateSet.addAll(completeFileSet);

            if (LOG.isTraceEnabled()) {
                
---------------Reference log start----------------
LOG.trace(""Last update: "" + lastUpdate + "", full gc candidates set: "" + gcCandidateSet)
---------------Reference log end----------------
            }

            if (lastUpdate != null) {
                // we won't delete past the last update, ackCompaction journal can be a candidate in error
                gcCandidateSet.removeAll(new TreeSet<Integer>(gcCandidateSet.tailSet(lastUpdate.getDataFileId())));
            }

            // Don't GC files under replication
            if( journalFilesBeingReplicated!=null ) {
                gcCandidateSet.removeAll(journalFilesBeingReplicated);
            }

            if (metadata.producerSequenceIdTrackerLocation != null) {
                int dataFileId = metadata.producerSequenceIdTrackerLocation.getDataFileId();
                if (gcCandidateSet.contains(dataFileId) && gcCandidateSet.first() == dataFileId) {
                    // rewrite so we don't prevent gc
                    metadata.producerSequenceIdTracker.setModified(true);
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(""rewriting producerSequenceIdTracker:"" + metadata.producerSequenceIdTrackerLocation);
                    }
                }
                gcCandidateSet.remove(dataFileId);
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after producerSequenceIdTrackerLocation:"" + metadata.producerSequenceIdTrackerLocation + "", "" + gcCandidateSet);
                }
            }

            if (metadata.ackMessageFileMapLocation != null) {
                int dataFileId = metadata.ackMessageFileMapLocation.getDataFileId();
                gcCandidateSet.remove(dataFileId);
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after ackMessageFileMapLocation:"" + metadata.ackMessageFileMapLocation + "", "" + gcCandidateSet);
                }
            }

            // Don't GC files referenced by in-progress tx
            if (inProgressTxRange[0] != null) {
                for (int pendingTx=inProgressTxRange[0].getDataFileId(); pendingTx <= inProgressTxRange[1].getDataFileId(); pendingTx++) {
                    gcCandidateSet.remove(pendingTx);
                }
            }
            if (LOG.isTraceEnabled()) {
                LOG.trace(""gc candidates after in progress tx range:"" + Arrays.asList(inProgressTxRange) + "", "" + gcCandidateSet);
            }

            // Go through all the destinations to see if any of them can remove GC candidates.
            for (Entry<String, StoredDestination> entry : storedDestinations.entrySet()) {
                if( gcCandidateSet.isEmpty() ) {
                    break;
                }

                // Use a visitor to cut down the number of pages that we load
                entry.getValue().locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
                    int last=-1;
                    @Override
                    public boolean isInterestedInKeysBetween(Location first, Location second) {
                        if( first==null ) {
                            SortedSet<Integer> subset = gcCandidateSet.headSet(second.getDataFileId()+1);
                            if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
                                subset.remove(second.getDataFileId());
                            }
                            return !subset.isEmpty();
                        } else if( second==null ) {
                            SortedSet<Integer> subset = gcCandidateSet.tailSet(first.getDataFileId());
                            if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
                                subset.remove(first.getDataFileId());
                            }
                            return !subset.isEmpty();
                        } else {
                            SortedSet<Integer> subset = gcCandidateSet.subSet(first.getDataFileId(), second.getDataFileId()+1);
                            if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
                                subset.remove(first.getDataFileId());
                            }
                            if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
                                subset.remove(second.getDataFileId());
                            }
                            return !subset.isEmpty();
                        }
                    }

                    @Override
                    public void visit(List<Location> keys, List<Long> values) {
                        for (Location l : keys) {
                            int fileId = l.getDataFileId();
                            if( last != fileId ) {
                                gcCandidateSet.remove(fileId);
                                last = fileId;
                            }
                        }
                    }
                });

                // Durable Subscription
                if (entry.getValue().subLocations != null) {
                    Iterator<Entry<String, Location>> iter = entry.getValue().subLocations.iterator(tx);
                    while (iter.hasNext()) {
                        Entry<String, Location> subscription = iter.next();
                        int dataFileId = subscription.getValue().getDataFileId();

                        // Move subscription along if it has no outstanding messages that need ack'd
                        // and its in the last log file in the journal.
                        if (!gcCandidateSet.isEmpty() && gcCandidateSet.first() == dataFileId) {
                            final StoredDestination destination = entry.getValue();
                            final String subscriptionKey = subscription.getKey();
                            SequenceSet pendingAcks = destination.ackPositions.get(tx, subscriptionKey);

                            // When pending is size one that is the next message Id meaning there
                            // are no pending messages currently.
                            if (pendingAcks == null || pendingAcks.isEmpty() ||
                                (pendingAcks.size() == 1 && pendingAcks.getTail().range() == 1)) {

                                if (LOG.isTraceEnabled()) {
                                    LOG.trace(""Found candidate for rewrite: sub {} on {} from file {}"", subscriptionKey, entry.getKey(), dataFileId);
                                }

                                final KahaSubscriptionCommand kahaSub =
                                    destination.subscriptions.get(tx, subscriptionKey);
                                destination.subLocations.put(
                                    tx, subscriptionKey, checkpointSubscriptionCommand(kahaSub));

                                // Skips the remove from candidates if we rewrote the subscription
                                // in order to prevent duplicate subscription commands on recover.
                                // If another subscription is on the same file and isn't rewritten
                                // than it will remove the file from the set.
                                continue;
                            }
                        }

                        if (LOG.isTraceEnabled()) {
                            final StoredDestination destination = entry.getValue();
                            final String subscriptionKey = subscription.getKey();
                            final SequenceSet pendingAcks = destination.ackPositions.get(tx, subscriptionKey);
                            LOG.trace(""sub {} on {} in dataFile {} has pendingCount {}"", subscriptionKey, entry.getKey(), dataFileId, pendingAcks.rangeSize()-1);
                        }
                        gcCandidateSet.remove(dataFileId);
                    }
                }

                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after dest:"" + entry.getKey() + "", "" + gcCandidateSet);
                }
            }

            // check we are not deleting file with ack for in-use journal files
            if (LOG.isTraceEnabled()) {
                LOG.trace(""gc candidates: "" + gcCandidateSet);
                LOG.trace(""ackMessageFileMap: "" +  metadata.ackMessageFileMap);
            }

            boolean ackMessageFileMapMod = false;
            Iterator<Integer> candidates = gcCandidateSet.iterator();
            while (candidates.hasNext()) {
                Integer candidate = candidates.next();
                Set<Integer> referencedFileIds = metadata.ackMessageFileMap.get(candidate);
                if (referencedFileIds != null) {
                    for (Integer referencedFileId : referencedFileIds) {
                        if (completeFileSet.contains(referencedFileId) && !gcCandidateSet.contains(referencedFileId)) {
                            // active file that is not targeted for deletion is referenced so don't delete
                            candidates.remove();
                            break;
                        }
                    }
                    if (gcCandidateSet.contains(candidate)) {
                        ackMessageFileMapMod |= (metadata.ackMessageFileMap.remove(candidate) != null);
                        metadata.ackMessageFileMapDirtyFlag.lazySet(true);
                    } else {
                        if (LOG.isTraceEnabled()) {
                            LOG.trace(""not removing data file: "" + candidate
                                    + "" as contained ack(s) refer to referenced file: "" + referencedFileIds);
                        }
                    }
                }
            }

            if (!gcCandidateSet.isEmpty()) {
                LOG.debug(""Cleanup removing the data files: {}"", gcCandidateSet);
                for (Integer candidate : gcCandidateSet) {
                    for (Set<Integer> ackFiles : metadata.ackMessageFileMap.values()) {
                        ackMessageFileMapMod |= ackFiles.remove(candidate);
                        metadata.ackMessageFileMapDirtyFlag.lazySet(true);
                    }
                }
                if (ackMessageFileMapMod) {
                    checkpointUpdate(tx, false);
                }
            } else if (isEnableAckCompaction()) {
                if (++checkPointCyclesWithNoGC >= getCompactAcksAfterNoGC()) {
                    // First check length of journal to make sure it makes sense to even try.
                    //
                    // If there is only one journal file with Acks in it we don't need to move
                    // it since it won't be chained to any later logs.
                    //
                    // If the logs haven't grown since the last time then we need to compact
                    // otherwise there seems to still be room for growth and we don't need to incur
                    // the overhead.  Depending on configuration this check can be avoided and
                    // Ack compaction will run any time the store has not GC'd a journal file in
                    // the configured amount of cycles.
                    if (metadata.ackMessageFileMap.size() > 1 &&
                        (journalLogOnLastCompactionCheck == journal.getCurrentDataFileId() || isCompactAcksIgnoresStoreGrowth())) {

                        LOG.trace(""No files GC'd checking if threshold to ACK compaction has been met."");
                        try {
                            scheduler.execute(new AckCompactionRunner());
                        } catch (Exception ex) {
                            LOG.warn(""Error on queueing the Ack Compactor"", ex);
                        }
                    } else {
                        LOG.trace(""Journal activity detected, no Ack compaction scheduled."");
                    }

                    checkPointCyclesWithNoGC = 0;
                } else {
                    LOG.trace(""Not yet time to check for compaction: {} of {} cycles"",
                              checkPointCyclesWithNoGC, getCompactAcksAfterNoGC());
                }

                journalLogOnLastCompactionCheck = journal.getCurrentDataFileId();
            }
        }
        MDC.remove(""activemq.persistenceDir"");

        LOG.debug(""Checkpoint done."");
        return gcCandidateSet;
    }",,
activemq,19273,"LOG.debug(""Recovered durable sub:{} on connect"", subscription)",debug,https://github.com/apache/activemq/blob/main/activemq-mqtt/src/main/java/org/apache/activemq/transport/mqtt/strategy/AbstractMQTTSubscriptionStrategy.java/#L305,"protected List<SubscriptionInfo> lookupSubscription(String clientId) throws MQTTProtocolException {
        List<SubscriptionInfo> result = new ArrayList<SubscriptionInfo>();
        RegionBroker regionBroker;

        try {
            regionBroker = (RegionBroker) brokerService.getBroker().getAdaptor(RegionBroker.class);
        } catch (Exception e) {
            throw new MQTTProtocolException(""Error recovering durable subscriptions: "" + e.getMessage(), false, e);
        }

        final TopicRegion topicRegion = (TopicRegion) regionBroker.getTopicRegion();
        List<DurableTopicSubscription> subscriptions = topicRegion.lookupSubscriptions(clientId);
        if (subscriptions != null) {
            for (DurableTopicSubscription subscription : subscriptions) {
                
---------------Reference log start----------------
LOG.debug(""Recovered durable sub:{} on connect"", subscription)
---------------Reference log end----------------

                SubscriptionInfo info = new SubscriptionInfo();

                info.setDestination(subscription.getActiveMQDestination());
                info.setSubcriptionName(subscription.getSubscriptionKey().getSubscriptionName());
                info.setClientId(clientId);

                result.add(info);
            }
        }

        return result;
    }",,
activemq,18500,"LOG.warn(""no matching consumer {}, ignoring ack {}"", consumerExchange, ack)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransportConnection.java/#L587,"@Override
    public Response processMessageAck(MessageAck ack) throws Exception {
        ConsumerBrokerExchange consumerExchange = getConsumerBrokerExchange(ack.getConsumerId());
        if (consumerExchange != null) {
            broker.acknowledge(consumerExchange, ack);
        } else if (ack.isInTransaction()) {
            
---------------Reference log start----------------
LOG.warn(""no matching consumer {}, ignoring ack {}"", consumerExchange, ack)
---------------Reference log end----------------
        }
        return null;
    }",,
activemq,18787,"LOG.warn(""{} after purge of {} messages, message count stats report: {}"", getActiveMQDestination().getQualifiedName(), originalMessageCount, this.destinationStatistics.getMessages().getCount())",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Queue.java/#L1324,"public void purge() throws Exception {
        ConnectionContext c = createConnectionContext();
        List<MessageReference> list = null;
        try {
            sendLock.lock();
            long originalMessageCount = this.destinationStatistics.getMessages().getCount();
            do {
                doPageIn(true, false, getMaxPageSize());  // signal no expiry processing needed.
                pagedInMessagesLock.readLock().lock();
                try {
                    list = new ArrayList<MessageReference>(pagedInMessages.values());
                }finally {
                    pagedInMessagesLock.readLock().unlock();
                }

                for (MessageReference ref : list) {
                    try {
                        QueueMessageReference r = (QueueMessageReference) ref;
                        removeMessage(c, r);
                        messages.rollback(r.getMessageId());
                    } catch (IOException e) {
                    }
                }
                // don't spin/hang if stats are out and there is nothing left in the
                // store
            } while (!list.isEmpty() && this.destinationStatistics.getMessages().getCount() > 0);

            if (this.destinationStatistics.getMessages().getCount() > 0) {
                
---------------Reference log start----------------
LOG.warn(""{} after purge of {} messages, message count stats report: {}"", getActiveMQDestination().getQualifiedName(), originalMessageCount, this.destinationStatistics.getMessages().getCount())
---------------Reference log end----------------
            }
        } finally {
            sendLock.unlock();
        }
    }",,
activemq,19654,"LOG.debug(""I now think that the "" + serviceName + "" service has recovered."")",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/discovery/multicast/MulticastDiscoveryAgent.java/#L118,"public synchronized void updateHeartBeat() {
            lastHeartBeat = System.currentTimeMillis();

            // Consider that the broker recovery has succeeded if it has not
            // failed in 60 seconds.
            if (!failed && failureCount > 0 && (lastHeartBeat - recoveryTime) > 1000 * 60) {
                if (LOG.isDebugEnabled()) {
                    
---------------Reference log start----------------
LOG.debug(""I now think that the "" + serviceName + "" service has recovered."")
---------------Reference log end----------------
                }
                failureCount = 0;
                recoveryTime = 0;
            }
        }",,
activemq,19773,"LOG.debug(ignore.getMessage(), ignore)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/nio/SelectorWorker.java/#L149,"@Override
    public void run() {

        String origName = Thread.currentThread().getName();
        try {
            Thread.currentThread().setName(""Selector Worker: "" + id);
            while (!isReleased()) {

                processIoTasks();

                int count = selector.select(10);

                if (count == 0) {
                    continue;
                }

                // Get a java.util.Set containing the SelectionKey objects
                // for all channels that are ready for I/O.
                Set<SelectionKey> keys = selector.selectedKeys();

                for (Iterator<SelectionKey> i = keys.iterator(); i.hasNext();) {
                    final SelectionKey key = i.next();
                    i.remove();

                    final SelectorSelection s = (SelectorSelection) key.attachment();
                    try {
                        if (key.isValid()) {
                            key.interestOps(0);
                        }

                        // Kick off another thread to find newly selected keys
                        // while we process the
                        // currently selected keys
                        manager.getChannelExecutor().execute(new Runnable() {
                            @Override
                            public void run() {
                                try {
                                    s.onSelect();
                                    s.enable();
                                } catch (Throwable e) {
                                    s.onError(e);
                                }
                            }
                        });

                    } catch (Throwable e) {
                        s.onError(e);
                    }
                }
            }
        } catch (Throwable e) {
            // Notify all the selections that the error occurred.
            Set<SelectionKey> keys = selector.keys();
            for (Iterator<SelectionKey> i = keys.iterator(); i.hasNext();) {
                SelectionKey key = i.next();
                SelectorSelection s = (SelectorSelection) key.attachment();
                s.onError(e);
            }
        } finally {
            try {
                manager.onWorkerEmptyEvent(this);
                selector.close();
            } catch (IOException ignore) {
                
---------------Reference log start----------------
LOG.debug(ignore.getMessage(), ignore)
---------------Reference log end----------------
            }
            Thread.currentThread().setName(origName);
        }
    }",,
activemq,18629,"LOG.error(""Failed to start Apache ActiveMQ ({}, {})"", getBrokerName(), brokerId, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L625,"@Override
    public void start() throws Exception {
        if (stopped.get() || !started.compareAndSet(false, true)) {
            // lets just ignore redundant start() calls
            // as its way too easy to not be completely sure if start() has been
            // called or not with the gazillion of different configuration
            // mechanisms
            // throw new IllegalStateException(""Already started."");
            return;
        }

        setStartException(null);
        stopping.set(false);
        preShutdownHooksInvoked.set(false);
        startDate = new Date();
        MDC.put(""activemq.broker"", brokerName);

        try {
            checkMemorySystemUsageLimits();
            if (systemExitOnShutdown && useShutdownHook) {
                throw new ConfigurationException(""'useShutdownHook' property cannot be be used with 'systemExitOnShutdown', please turn it off (useShutdownHook=false)"");
            }
            processHelperProperties();
            if (isUseJmx()) {
                // need to remove MDC during starting JMX, as that would otherwise causes leaks, as spawned threads inheirt the MDC and
                // we cannot cleanup clear that during shutdown of the broker.
                MDC.remove(""activemq.broker"");
                try {
                    startManagementContext();
                    for (NetworkConnector connector : getNetworkConnectors()) {
                        registerNetworkConnectorMBean(connector);
                    }
                } finally {
                    MDC.put(""activemq.broker"", brokerName);
                }
            }

            // in jvm master slave, lets not publish over existing broker till we get the lock
            final BrokerRegistry brokerRegistry = BrokerRegistry.getInstance();
            if (brokerRegistry.lookup(getBrokerName()) == null) {
                brokerRegistry.bind(getBrokerName(), BrokerService.this);
            }
            startPersistenceAdapter(startAsync);
            startBroker(startAsync);
            brokerRegistry.bind(getBrokerName(), BrokerService.this);
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Failed to start Apache ActiveMQ ({}, {})"", getBrokerName(), brokerId, e)
---------------Reference log end----------------
            try {
                if (!stopped.get()) {
                    stop();
                }
            } catch (Exception ex) {
                LOG.warn(""Failed to stop broker after failure in start. This exception will be ignored"", ex);
            }
            throw e;
        } finally {
            MDC.remove(""activemq.broker"");
        }
    }",,
activemq,19548,"LOG.warn(""{} suppressing duplicate delivery on connection, poison acking: {}"", getConsumerId(), md)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQMessageConsumer.java/#L1486,"@Override
    public void dispatch(MessageDispatch md) {
        MessageListener listener = this.messageListener.get();
        try {
            clearMessagesInProgress();
            clearDeliveredList();
            synchronized (unconsumedMessages.getMutex()) {
                if (!unconsumedMessages.isClosed()) {
                    // deliverySequenceId non zero means previously queued dispatch
                    if (this.info.isBrowser() || md.getDeliverySequenceId() != 0l || !session.connection.isDuplicate(this, md.getMessage())) {
                        if (listener != null && unconsumedMessages.isRunning()) {
                            if (redeliveryExceeded(md)) {
                                poisonAck(md, ""listener dispatch["" + md.getRedeliveryCounter() + ""] to "" + getConsumerId() + "" exceeds redelivery policy limit:"" + redeliveryPolicy);
                                return;
                            }
                            ActiveMQMessage message = createActiveMQMessage(md);
                            beforeMessageIsConsumed(md);
                            try {
                                boolean expired = isConsumerExpiryCheckEnabled() && message.isExpired();
                                if (!expired) {
                                    listener.onMessage(message);
                                }
                                afterMessageIsConsumed(md, expired);
                            } catch (RuntimeException e) {
                                LOG.error(""{} Exception while processing message: {}"", getConsumerId(), md.getMessage().getMessageId(), e);
                                md.setRollbackCause(e);
                                if (isAutoAcknowledgeBatch() || isAutoAcknowledgeEach() || session.isIndividualAcknowledge()) {
                                    // schedual redelivery and possible dlq processing
                                    rollback();
                                } else {
                                    // Transacted or Client ack: Deliver the next message.
                                    afterMessageIsConsumed(md, false);
                                }
                            }
                        } else {
                            md.setDeliverySequenceId(-1); // skip duplicate check on subsequent queued delivery
                            if (md.getMessage() == null) {
                                // End of browse or pull request timeout.
                                unconsumedMessages.enqueue(md);
                            } else {
                                if (!consumeExpiredMessage(md)) {
                                    unconsumedMessages.enqueue(md);
                                    if (availableListener != null) {
                                        availableListener.onMessageAvailable(this);
                                    }
                                } else {
                                    beforeMessageIsConsumed(md);
                                    afterMessageIsConsumed(md, true);

                                    // Pull consumer needs to check if pull timed out and send
                                    // a new pull command if not.
                                    if (info.getCurrentPrefetchSize() == 0) {
                                        unconsumedMessages.enqueue(null);
                                    }
                                }
                            }
                        }
                    } else {
                        // deal with duplicate delivery
                        ConsumerId consumerWithPendingTransaction;
                        if (redeliveryExpectedInCurrentTransaction(md, true)) {
                            LOG.debug(""{} tracking transacted redelivery {}"", getConsumerId(), md.getMessage());
                            if (transactedIndividualAck) {
                                immediateIndividualTransactedAck(md);
                            } else {
                                session.sendAck(new MessageAck(md, MessageAck.DELIVERED_ACK_TYPE, 1));
                            }
                        } else if ((consumerWithPendingTransaction = redeliveryPendingInCompetingTransaction(md)) != null) {
                            LOG.warn(""{} delivering duplicate {}, pending transaction completion on {} will rollback"", getConsumerId(), md.getMessage(), consumerWithPendingTransaction);
                            session.getConnection().rollbackDuplicate(this, md.getMessage());
                            dispatch(md);
                        } else {
                            
---------------Reference log start----------------
LOG.warn(""{} suppressing duplicate delivery on connection, poison acking: {}"", getConsumerId(), md)
---------------Reference log end----------------
                            poisonAck(md, ""Suppressing duplicate delivery on connection, consumer "" + getConsumerId());
                        }
                    }
                }
            }
            if (++dispatchedCount % 1000 == 0) {
                dispatchedCount = 0;
                Thread.yield();
            }
        } catch (Exception e) {
            session.connection.onClientInternalException(e);
        }
    }",,
activemq,17866,"LOG.warn(""Exception occurred for client {} ({}) processing: {} -> {}"", connectionInfo.getClientId(), connectionInfo.getClientIp(), safeGetAction(command), exception.toString())",warn,https://github.com/apache/activemq/blob/main/activemq-stomp/src/main/java/org/apache/activemq/transport/stomp/ProtocolConverter.java/#L282,"protected void handleException(Throwable exception, StompFrame command) throws IOException {
        if (command == null) {
            LOG.warn(""Exception occurred while processing a command: {}"", exception.toString());
        } else {
            if (exception instanceof JMSException) {
                JMSException jmsException = (JMSException) exception;
                if (jmsException.getLinkedException() != null) {
                    LOG.warn(""Exception occurred for client {} ({}) processing: {} -> {} ({})"", connectionInfo.getClientId(), connectionInfo.getClientIp(), safeGetAction(command), exception.toString(), jmsException.getLinkedException().toString());
                } else {
                    LOG.warn(""Exception occurred for client {} ({}) processing: {} -> {}"", connectionInfo.getClientId(), connectionInfo.getClientIp(), safeGetAction(command), exception.toString());
                }
            } else {
                
---------------Reference log start----------------
LOG.warn(""Exception occurred for client {} ({}) processing: {} -> {}"", connectionInfo.getClientId(), connectionInfo.getClientIp(), safeGetAction(command), exception.toString())
---------------Reference log end----------------
            }
        }

        if (LOG.isDebugEnabled()) {
            LOG.debug(""Exception detail"", exception);
        }

        if (command != null && LOG.isTraceEnabled()) {
            LOG.trace(""Command that caused the error: {}"", command);
        }

        // Let the stomp client know about any protocol errors.
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        PrintWriter stream = new PrintWriter(new OutputStreamWriter(baos, ""UTF-8""));
        if (exception instanceof SecurityException || exception.getCause() instanceof SecurityException) {
            stream.write(exception.getLocalizedMessage());
        } else {
            exception.printStackTrace(stream);
        }
        stream.close();

        HashMap<String, String> headers = new HashMap<>();
        headers.put(Stomp.Headers.Error.MESSAGE, exception.getMessage());
        headers.put(Stomp.Headers.CONTENT_TYPE, ""text/plain"");

        if (command != null) {
            final String receiptId = command.getHeaders().get(Stomp.Headers.RECEIPT_REQUESTED);
            if (receiptId != null) {
                headers.put(Stomp.Headers.Response.RECEIPT_ID, receiptId);
            }
        }

        StompFrame errorMessage = new StompFrame(Stomp.Responses.ERROR, headers, baos.toByteArray());
        sendToStomp(errorMessage);
    }",,
activemq,19480,"LOG.warn(""Unknown command: "" + command)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/advisory/ProducerEventSource.java/#L100,"public void onMessage(Message message) {
        if (message instanceof ActiveMQMessage) {
            ActiveMQMessage activeMessage = (ActiveMQMessage)message;
            Object command = activeMessage.getDataStructure();
            int count = 0;
            if (command instanceof ProducerInfo) {
                count = producerCount.incrementAndGet();
                count = extractProducerCountFromMessage(message, count);
                fireProducerEvent(new ProducerStartedEvent(this, destination, (ProducerInfo)command, count));
            } else if (command instanceof RemoveInfo) {
                RemoveInfo removeInfo = (RemoveInfo)command;
                if (removeInfo.isProducerRemove()) {
                    count = producerCount.decrementAndGet();
                    count = extractProducerCountFromMessage(message, count);
                    fireProducerEvent(new ProducerStoppedEvent(this, destination, (ProducerId)removeInfo.getObjectId(), count));
                }
            } else {
                
---------------Reference log start----------------
LOG.warn(""Unknown command: "" + command)
---------------Reference log end----------------
            }
        } else {
            LOG.warn(""Unknown message type: "" + message + "". Message ignored"");
        }
    }",,
activemq,19497,"LOG.debug(""conn: "" + connectionState.getInfo().getConnectionId())",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/state/ConnectionStateTracker.java/#L201,"public void restore(Transport transport) throws IOException {
        // Restore the connections.
        for (Iterator<ConnectionState> iter = connectionStates.values().iterator(); iter.hasNext();) {
            ConnectionState connectionState = iter.next();
            connectionState.getInfo().setFailoverReconnect(true);
            if (LOG.isDebugEnabled()) {
                
---------------Reference log start----------------
LOG.debug(""conn: "" + connectionState.getInfo().getConnectionId())
---------------Reference log end----------------
            }
            transport.oneway(connectionState.getInfo());
            restoreTempDestinations(transport, connectionState);

            if (restoreSessions) {
                restoreSessions(transport, connectionState);
            }

            if (restoreTransaction) {
                restoreTransactions(transport, connectionState);
            }
        }

        // now flush messages and MessagePull commands.
        for (Command msg : messageCache.values()) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(""command: "" + (msg.isMessage() ? ((Message) msg).getMessageId() : msg));
            }
            transport.oneway(msg);
        }
    }",,
activemq,19250,"LOG.debug(""connector referenced removed for URI [{}], UUID[{}], remaining reference(s) [{}]"", connectorURI, uuid, referenceCount)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/LdapNetworkConnector.java/#L360,"protected synchronized void removeConnector(SearchResult result) throws Exception {
        String uuid = toUUID(result);
        if (!uuidMap.containsKey(uuid)) {
            LOG.warn(""connector not registered for UUID [{}]"", uuid);
            return;
        }

        URI connectorURI = uuidMap.get(uuid);
        if (!connectorMap.containsKey(connectorURI)) {
            LOG.warn(""connector not registered for URI [{}]"", connectorURI);
            return;
        }

        int referenceCount = referenceMap.get(connectorURI) - 1;
        referenceMap.put(connectorURI, referenceCount);
        uuidMap.remove(uuid);
        
---------------Reference log start----------------
LOG.debug(""connector referenced removed for URI [{}], UUID[{}], remaining reference(s) [{}]"", connectorURI, uuid, referenceCount)
---------------Reference log end----------------

        if (referenceCount > 0) {
            return;
        }

        NetworkConnector connector = connectorMap.remove(connectorURI);
        connector.stop();
        LOG.info(""connector removed with URI [{}]"", connectorURI);
    }",,
activemq,19818,"LOG.trace(""Created new connection: {}"", connection)",trace,https://github.com/apache/activemq/blob/main/activemq-jms-pool/src/main/java/org/apache/activemq/jms/pool/PooledConnectionFactory.java/#L110,"@Override
                    public PooledObject<ConnectionPool> makeObject(ConnectionKey connectionKey) throws Exception {
                        Connection delegate = createConnection(connectionKey);

                        ConnectionPool connection = createConnectionPool(delegate);
                        connection.setIdleTimeout(getIdleTimeout());
                        connection.setExpiryTimeout(getExpiryTimeout());
                        connection.setMaximumActiveSessionPerConnection(getMaximumActiveSessionPerConnection());
                        connection.setBlockIfSessionPoolIsFull(isBlockIfSessionPoolIsFull());
                        if (isBlockIfSessionPoolIsFull() && getBlockIfSessionPoolIsFullTimeout() > 0) {
                            connection.setBlockIfSessionPoolIsFullTimeout(getBlockIfSessionPoolIsFullTimeout());
                        }
                        connection.setUseAnonymousProducers(isUseAnonymousProducers());
                        connection.setReconnectOnException(isReconnectOnException());

                        
---------------Reference log start----------------
LOG.trace(""Created new connection: {}"", connection)
---------------Reference log end----------------

                        PooledConnectionFactory.this.mostRecentlyCreated.set(connection);

                        return new DefaultPooledObject<ConnectionPool>(connection);
                    }",,
activemq,18777,"LOG.warn(""Usage Manager Memory Limit ({}) reached on {}, size {}. Producers will be throttled to the rate at which messages are removed from this destination to prevent flooding it. See http://activemq.apache.org/producer-flow-control.html for more info."", memoryUsage.getLimit(), getActiveMQDestination().getQualifiedName(), destinationStatistics.getMessages().getCount())",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Queue.java/#L642,"@Override
    public void send(final ProducerBrokerExchange producerExchange, final Message message) throws Exception {
        final ConnectionContext context = producerExchange.getConnectionContext();
        // There is delay between the client sending it and it arriving at the
        // destination.. it may have expired.
        message.setRegionDestination(this);
        ProducerState state = producerExchange.getProducerState();
        if (state == null) {
            LOG.warn(""Send failed for: {}, missing producer state for: {}"", message, producerExchange);
            throw new JMSException(""Cannot send message to "" + getActiveMQDestination() + "" with invalid (null) producer state"");
        }
        final ProducerInfo producerInfo = producerExchange.getProducerState().getInfo();
        final boolean sendProducerAck = !message.isResponseRequired() && producerInfo.getWindowSize() > 0
                && !context.isInRecoveryMode();
        if (message.isExpired()) {
            // message not stored - or added to stats yet - so chuck here
            broker.getRoot().messageExpired(context, message, null);
            if (sendProducerAck) {
                ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message.getSize());
                context.getConnection().dispatchAsync(ack);
            }
            return;
        }
        if (memoryUsage.isFull()) {
            isFull(context, memoryUsage);
            fastProducer(context, producerInfo);
            if (isProducerFlowControl() && context.isProducerFlowControl()) {
                if (isFlowControlLogRequired()) {
                    
---------------Reference log start----------------
LOG.warn(""Usage Manager Memory Limit ({}) reached on {}, size {}. Producers will be throttled to the rate at which messages are removed from this destination to prevent flooding it. See http://activemq.apache.org/producer-flow-control.html for more info."", memoryUsage.getLimit(), getActiveMQDestination().getQualifiedName(), destinationStatistics.getMessages().getCount())
---------------Reference log end----------------
                } else {
                    LOG.debug(""Usage Manager Memory Limit ({}) reached on {}, size {}. Producers will be throttled to the rate at which messages are removed from this destination to prevent flooding it. See http://activemq.apache.org/producer-flow-control.html for more info."",
                            memoryUsage.getLimit(), getActiveMQDestination().getQualifiedName(), destinationStatistics.getMessages().getCount());
                }
                if (!context.isNetworkConnection() && systemUsage.isSendFailIfNoSpace()) {
                    ResourceAllocationException resourceAllocationException = sendMemAllocationException;
                    if (resourceAllocationException == null) {
                        synchronized (this) {
                            resourceAllocationException = sendMemAllocationException;
                            if (resourceAllocationException == null) {
                                sendMemAllocationException = resourceAllocationException = new ResourceAllocationException(""Usage Manager Memory Limit reached on ""
                                        + getActiveMQDestination().getQualifiedName() + "".""
                                        + "" See http://activemq.apache.org/producer-flow-control.html for more info"");
                            }
                        }
                    }
                    throw resourceAllocationException;
                }

                // We can avoid blocking due to low usage if the producer is
                // sending
                // a sync message or if it is using a producer window
                if (producerInfo.getWindowSize() > 0 || message.isResponseRequired()) {
                    // copy the exchange state since the context will be
                    // modified while we are waiting
                    // for space.
                    final ProducerBrokerExchange producerExchangeCopy = producerExchange.copy();
                    synchronized (messagesWaitingForSpace) {
                     // Start flow control timeout task
                        // Prevent trying to start it multiple times
                        if (!flowControlTimeoutTask.isAlive()) {
                            flowControlTimeoutTask.setName(getName()+"" Producer Flow Control Timeout Task"");
                            flowControlTimeoutTask.start();
                        }
                        messagesWaitingForSpace.put(message.getMessageId(), new Runnable() {
                            @Override
                            public void run() {

                                try {
                                    // While waiting for space to free up... the
                                    // transaction may be done
                                    if (message.isInTransaction()) {
                                        if (context.getTransaction() == null || context.getTransaction().getState() > IN_USE_STATE) {
                                            throw new JMSException(""Send transaction completed while waiting for space"");
                                        }
                                    }

                                    // the message may have expired.
                                    if (message.isExpired()) {
                                        LOG.error(""message expired waiting for space"");
                                        broker.messageExpired(context, message, null);
                                        destinationStatistics.getExpired().increment();
                                    } else {
                                        doMessageSend(producerExchangeCopy, message);
                                    }

                                    if (sendProducerAck) {
                                        ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message
                                                .getSize());
                                        context.getConnection().dispatchAsync(ack);
                                    } else {
                                        Response response = new Response();
                                        response.setCorrelationId(message.getCommandId());
                                        context.getConnection().dispatchAsync(response);
                                    }

                                } catch (Exception e) {
                                    if (!sendProducerAck && !context.isInRecoveryMode() && !brokerService.isStopping()) {
                                        ExceptionResponse response = new ExceptionResponse(e);
                                        response.setCorrelationId(message.getCommandId());
                                        context.getConnection().dispatchAsync(response);
                                    } else {
                                        LOG.debug(""unexpected exception on deferred send of: {}"", message, e);
                                    }
                                } finally {
                                    getDestinationStatistics().getBlockedSends().decrement();
                                    producerExchangeCopy.blockingOnFlowControl(false);
                                }
                            }
                        });

                        getDestinationStatistics().getBlockedSends().increment();
                        producerExchange.blockingOnFlowControl(true);
                        if (!context.isNetworkConnection() && systemUsage.getSendFailIfNoSpaceAfterTimeout() != 0) {
                            flowControlTimeoutMessages.add(new TimeoutMessage(message, context, systemUsage
                                    .getSendFailIfNoSpaceAfterTimeout()));
                        }

                        registerCallbackForNotFullNotification();
                        context.setDontSendReponse(true);
                        return;
                    }

                } else {

                    if (memoryUsage.isFull()) {
                        waitForSpace(context, producerExchange, memoryUsage, ""Usage Manager Memory Limit reached. Producer (""
                                + message.getProducerId() + "") stopped to prevent flooding ""
                                + getActiveMQDestination().getQualifiedName() + "".""
                                + "" See http://activemq.apache.org/producer-flow-control.html for more info"");
                    }

                    // The usage manager could have delayed us by the time
                    // we unblock the message could have expired..
                    if (message.isExpired()) {
                        LOG.debug(""Expired message: {}"", message);
                        broker.getRoot().messageExpired(context, message, null);
                        return;
                    }
                }
            }
        }
        doMessageSend(producerExchange, message);
        if (sendProducerAck) {
            ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message.getSize());
            context.getConnection().dispatchAsync(ack);
        }
    }",,
activemq,19714,"LOG.debug(""Stopped {}"", this)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/failover/FailoverTransport.java/#L382,"@Override
    public void stop() throws Exception {
        Transport transportToStop = null;
        List<Transport> backupsToStop = new ArrayList<Transport>(backups.size());

        try {
            synchronized (reconnectMutex) {
                if (LOG.isDebugEnabled()) {
                    
---------------Reference log start----------------
LOG.debug(""Stopped {}"", this)
---------------Reference log end----------------
                }
                if (!started) {
                    return;
                }
                started = false;
                disposed = true;

                if (connectedTransport.get() != null) {
                    transportToStop = connectedTransport.getAndSet(null);
                }
                reconnectMutex.notifyAll();
            }
            synchronized (sleepMutex) {
                sleepMutex.notifyAll();
            }
        } finally {
            reconnectTask.shutdown();
            reconnectTaskFactory.shutdownNow();
        }

        synchronized(backupMutex) {
            for (BackupTransport backup : backups) {
                backup.setDisposed(true);
                Transport transport = backup.getTransport();
                if (transport != null) {
                    transport.setTransportListener(disposedListener);
                    backupsToStop.add(transport);
                }
            }
            backups.clear();
        }
        for (Transport transport : backupsToStop) {
            try {
                LOG.trace(""Stopped backup: {}"", transport);
                disposeTransport(transport);
            } catch (Exception e) {
            }
        }
        if (transportToStop != null) {
            transportToStop.stop();
        }
    }",,
activemq,19470,"LOG.trace(""Run task done: {}"", task)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/thread/PooledTaskRunner.java/#L50,"@Override
            public void run() {
                runningThread = Thread.currentThread();
                try {
                    runTask();
                } finally {
                    
---------------Reference log start----------------
LOG.trace(""Run task done: {}"", task)
---------------Reference log end----------------
                    runningThread = null;
                }
            }",,
activemq,18780,"LOG.error(""message expired waiting for space"")",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Queue.java/#L693,"@Override
                            public void run() {

                                try {
                                    // While waiting for space to free up... the
                                    // transaction may be done
                                    if (message.isInTransaction()) {
                                        if (context.getTransaction() == null || context.getTransaction().getState() > IN_USE_STATE) {
                                            throw new JMSException(""Send transaction completed while waiting for space"");
                                        }
                                    }

                                    // the message may have expired.
                                    if (message.isExpired()) {
                                        
---------------Reference log start----------------
LOG.error(""message expired waiting for space"")
---------------Reference log end----------------
                                        broker.messageExpired(context, message, null);
                                        destinationStatistics.getExpired().increment();
                                    } else {
                                        doMessageSend(producerExchangeCopy, message);
                                    }

                                    if (sendProducerAck) {
                                        ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message
                                                .getSize());
                                        context.getConnection().dispatchAsync(ack);
                                    } else {
                                        Response response = new Response();
                                        response.setCorrelationId(message.getCommandId());
                                        context.getConnection().dispatchAsync(response);
                                    }

                                } catch (Exception e) {
                                    if (!sendProducerAck && !context.isInRecoveryMode() && !brokerService.isStopping()) {
                                        ExceptionResponse response = new ExceptionResponse(e);
                                        response.setCorrelationId(message.getCommandId());
                                        context.getConnection().dispatchAsync(response);
                                    } else {
                                        LOG.debug(""unexpected exception on deferred send of: {}"", message, e);
                                    }
                                } finally {
                                    getDestinationStatistics().getBlockedSends().decrement();
                                    producerExchangeCopy.blockingOnFlowControl(false);
                                }
                            }",,
activemq,19469,"LOG.trace(""Created thread[{}]: {}"", threadName, thread)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/thread/TaskRunnerFactory.java/#L206,"@Override
            public Thread newThread(Runnable runnable) {
                String threadName = name + ""-"" + id.incrementAndGet();
                Thread thread = new Thread(runnable, threadName);
                thread.setDaemon(daemon);
                thread.setPriority(priority);
                if (threadClassLoader != null) {
                    thread.setContextClassLoader(threadClassLoader);
                }
                thread.setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
                    @Override
                    public void uncaughtException(final Thread t, final Throwable e) {
                        LOG.error(""Error in thread '{}'"", t.getName(), e);
                    }
                });

                
---------------Reference log start----------------
LOG.trace(""Created thread[{}]: {}"", threadName, thread)
---------------Reference log end----------------
                return thread;
            }",,
activemq,19340,"log.debug(""Work completed: "" + event)",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ServerSessionImpl.java/#L148,"public void workCompleted(WorkEvent event) {
                    
---------------Reference log start----------------
log.debug(""Work completed: "" + event)
---------------Reference log end----------------
                }
                }",,
activemq,18723,"LOG.info(""Get Destinations: {}"", destinations)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/LoggingBrokerPlugin.java/#L355,"@Override
    public ActiveMQDestination[] getDestinations() throws Exception {
        ActiveMQDestination[] result = super.getDestinations();
        if (isLogAll() || isLogInternalEvents()) {
            if (result == null) {
                LOG.info(""Get Destinations returned empty list."");
            } else {
                StringBuffer destinations = new StringBuffer();
                for (ActiveMQDestination dest : result) {
                    destinations.append(destinations.length() > 0 ? "", "" : """");
                    destinations.append(dest.getPhysicalName());
                }
                
---------------Reference log start----------------
LOG.info(""Get Destinations: {}"", destinations)
---------------Reference log end----------------
            }
        }
        return result;
    }",,
activemq,18062,"LOG.trace(""gc candidates after removals check: {}"", gcCandidateSet)",trace,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/scheduler/JobSchedulerStoreImpl.java/#L434,"@Override
    protected void checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
        LOG.debug(""Job Scheduler Store Checkpoint started."");

        // reflect last update exclusive of current checkpoint
        Location lastUpdate = metaData.getLastUpdateLocation();
        metaData.setState(KahaDBMetaData.OPEN_STATE);
        tx.store(metaData.getPage(), metaDataMarshaller, true);
        pageFile.flush();

        if (cleanup) {
            final TreeSet<Integer> completeFileSet = new TreeSet<Integer>(journal.getFileMap().keySet());
            final TreeSet<Integer> gcCandidateSet = new TreeSet<Integer>(completeFileSet);

            LOG.trace(""Last update: {}, full gc candidates set: {}"", lastUpdate, gcCandidateSet);

            if (lastUpdate != null) {
                gcCandidateSet.remove(lastUpdate.getDataFileId());
            }

            this.metaData.getJournalRC().visit(tx, new BTreeVisitor<Integer, Integer>() {

                @Override
                public void visit(List<Integer> keys, List<Integer> values) {
                    for (Integer key : keys) {
                        if (gcCandidateSet.remove(key)) {
                            LOG.trace(""Removed referenced file: {} from GC set"", key);
                        }
                    }
                }

                @Override
                public boolean isInterestedInKeysBetween(Integer first, Integer second) {
                    return true;
                }
            });

            LOG.trace(""gc candidates after reference check: {}"", gcCandidateSet);

            // If there are GC candidates then check the remove command location to see
            // if any of them can go or if they must stay in order to ensure proper recover.
            //
            // A log containing any remove commands must be kept until all the logs with the
            // add commands for all the removed jobs have been dropped.
            if (!gcCandidateSet.isEmpty()) {
                Iterator<Entry<Integer, List<Integer>>> removals = metaData.getRemoveLocationTracker().iterator(tx);
                List<Integer> orphans = new ArrayList<Integer>();
                while (removals.hasNext()) {
                    boolean orphanedRemove = true;
                    Entry<Integer, List<Integer>> entry = removals.next();

                    // If this log is not a GC candidate then there's no need to do a check to rule it out
                    if (gcCandidateSet.contains(entry.getKey())) {
                        for (Integer addLocation : entry.getValue()) {
                            if (completeFileSet.contains(addLocation)) {
                                LOG.trace(""A remove in log {} has an add still in existance in {}."", entry.getKey(), addLocation);
                                orphanedRemove = false;
                                break;
                            }
                        }

                        // If it's not orphaned than we can't remove it, otherwise we
                        // stop tracking it it's log will get deleted on the next check.
                        if (!orphanedRemove) {
                            gcCandidateSet.remove(entry.getKey());
                        } else {
                            LOG.trace(""All removes in log {} are orphaned, file can be GC'd"", entry.getKey());
                            orphans.add(entry.getKey());
                        }
                    }
                }

                // Drop all orphaned removes from the tracker.
                for (Integer orphan : orphans) {
                    metaData.getRemoveLocationTracker().remove(tx, orphan);
                }
            }

            
---------------Reference log start----------------
LOG.trace(""gc candidates after removals check: {}"", gcCandidateSet)
---------------Reference log end----------------
            if (!gcCandidateSet.isEmpty()) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Cleanup removing the data files: "" + gcCandidateSet);
                }
                journal.removeDataFiles(gcCandidateSet);
            }
        }

        LOG.debug(""Job Scheduler Store Checkpoint complete."");
    }",,
activemq,19515,"LOG.warn(""Error shutting down thread pool: "" + executor + "". This exception will be ignored."", e)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQConnection.java/#L720,"@Override
    public void close() throws JMSException {
        try {
            // If we were running, lets stop first.
            if (!closed.get() && !transportFailed.get()) {
                // do not fail if already closed as according to JMS spec we must not
                // throw exception if already closed
                doStop(false);
            }

            synchronized (this) {
                if (!closed.get()) {
                    closing.set(true);

                    if (destinationSource != null) {
                        destinationSource.stop();
                        destinationSource = null;
                    }
                    if (advisoryConsumer != null) {
                        advisoryConsumer.dispose();
                        advisoryConsumer = null;
                    }

                    Scheduler scheduler = this.scheduler;
                    if (scheduler != null) {
                        try {
                            scheduler.stop();
                        } catch (Exception e) {
                            JMSException ex =  JMSExceptionSupport.create(e);
                            throw ex;
                        }
                    }

                    long lastDeliveredSequenceId = -1;
                    for (Iterator<ActiveMQSession> i = this.sessions.iterator(); i.hasNext();) {
                        ActiveMQSession s = i.next();
                        s.dispose();
                        lastDeliveredSequenceId = Math.max(lastDeliveredSequenceId, s.getLastDeliveredSequenceId());
                    }
                    for (Iterator<ActiveMQConnectionConsumer> i = this.connectionConsumers.iterator(); i.hasNext();) {
                        ActiveMQConnectionConsumer c = i.next();
                        c.dispose();
                    }

                    this.activeTempDestinations.clear();

                    try {
                        if (isConnectionInfoSentToBroker) {
                            // If we announced ourselves to the broker.. Try to let the broker
                            // know that the connection is being shutdown.
                            RemoveInfo removeCommand = info.createRemoveCommand();
                            removeCommand.setLastDeliveredSequenceId(lastDeliveredSequenceId);
                            try {
                                syncSendPacket(removeCommand, closeTimeout);
                            } catch (JMSException e) {
                                if (e.getCause() instanceof RequestTimedOutIOException) {
                                    // expected
                                } else {
                                    throw e;
                                }
                            }
                            doAsyncSendPacket(new ShutdownInfo());
                        }
                    } finally { // release anyway even if previous communication fails
                        started.set(false);

                        // TODO if we move the TaskRunnerFactory to the connection
                        // factory
                        // then we may need to call
                        // factory.onConnectionClose(this);
                        if (sessionTaskRunner != null) {
                            sessionTaskRunner.shutdown();
                        }
                        closed.set(true);
                        closing.set(false);
                    }
                }
            }
        } finally {
            try {
                if (executor != null) {
                    ThreadPoolUtils.shutdown(executor);
                }
            } catch (Throwable e) {
                
---------------Reference log start----------------
LOG.warn(""Error shutting down thread pool: "" + executor + "". This exception will be ignored."", e)
---------------Reference log end----------------
            }

            ServiceSupport.dispose(this.transport);

            factoryStats.removeConnection(this);
        }
    }",,
activemq,18390,"LOG.debug(""PUT to "" + url + "" failed with: "" + e)",debug,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/discovery/http/HTTPDiscoveryAgent.java/#L112,"synchronized private void doRegister(String service) {
        String url = registryURL;
        try {
            HttpPut method = new HttpPut(url);
            method.addHeader(""service"", service);
            ResponseHandler<String> handler = new BasicResponseHandler();
            String responseBody = httpClient.execute(method, handler);
            LOG.debug(""PUT to "" + url + "" got a "" + responseBody);
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.debug(""PUT to "" + url + "" failed with: "" + e)
---------------Reference log end----------------
        }
    }",,
activemq,19433,"LOG.trace(""applying props: "" + filterPasswords(properties) + "", to "" + instance.getClass().getSimpleName())",trace,https://github.com/apache/activemq/blob/main/activemq-runtime-config/src/main/java/org/apache/activemq/plugin/DefaultConfigurationProcessor.java/#L193,"protected <T> T fromDto(Object dto, T instance) {
        Properties properties = new Properties();
        IntrospectionSupport.getProperties(dto, properties, null);
        plugin.placeHolderUtil.filter(properties);
        
---------------Reference log start----------------
LOG.trace(""applying props: "" + filterPasswords(properties) + "", to "" + instance.getClass().getSimpleName())
---------------Reference log end----------------
        IntrospectionSupport.setProperties(instance, properties);

        // deal with nested elements
        for (Object nested : filter(dto, Object.class)) {
            String elementName = nested.getClass().getSimpleName();
            Method setter = JAXBUtils.findSetter(instance, elementName);
            if (setter != null) {
                List<Object> argument = new LinkedList<Object>();
                for (Object elementContent : filter(nested, Object.class)) {
                    argument.add(fromDto(elementContent, JAXBUtils.inferTargetObject(elementContent)));
                }
                try {
                    setter.invoke(instance, JAXBUtils.matchType(argument, setter.getParameterTypes()[0]));
                } catch (Exception e) {
                    plugin.info(""failed to invoke "" + setter + "" on "" + instance + "" with args "" + argument, e);
                }
            } else {
                plugin.info(""failed to find setter for "" + elementName + "" on :"" + instance);
            }
        }
        invokePostConstruct(instance);
        return instance;
    }",,
activemq,19307,"LOG.trace(""MQTT Snd PUBREC message:{} client:{} connection:{}"", command.messageId(), clientId, connectionInfo.getConnectionId())",trace,https://github.com/apache/activemq/blob/main/activemq-mqtt/src/main/java/org/apache/activemq/transport/mqtt/MQTTProtocolConverter.java/#L773,"@Override
                public void onResponse(MQTTProtocolConverter converter, Response response) throws IOException {
                    if (response.isException()) {
                        Throwable error = ((ExceptionResponse) response).getException();
                        LOG.warn(""Failed to send MQTT Publish: {}: {}"", command, error.getMessage());
                        LOG.trace(""Error trace: {}"", (Object)error);
                    }

                    switch (command.qos()) {
                        case AT_LEAST_ONCE:
                            PUBACK ack = new PUBACK();
                            ack.messageId(command.messageId());
                            LOG.trace(""MQTT Snd PUBACK message:{} client:{} connection:{}"",
                                      command.messageId(), clientId, connectionInfo.getConnectionId());
                            converter.getMQTTTransport().sendToMQTT(ack.encode());
                            break;
                        case EXACTLY_ONCE:
                            PUBREC req = new PUBREC();
                            req.messageId(command.messageId());
                            synchronized (publisherRecs) {
                                publisherRecs.put(command.messageId(), req);
                            }
                            
---------------Reference log start----------------
LOG.trace(""MQTT Snd PUBREC message:{} client:{} connection:{}"", command.messageId(), clientId, connectionInfo.getConnectionId())
---------------Reference log end----------------
                            converter.getMQTTTransport().sendToMQTT(req.encode());
                            break;
                        default:
                            break;
                    }
                }",,
activemq,19690,"LOG.debug(""Aborting read check...Not enough time elapsed since last read check."")",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/AbstractInactivityMonitor.java/#L128,"@Override
        public void run() {
            long now = System.currentTimeMillis();
            long elapsed = (now - lastRunTime);

            if (lastRunTime != 0) {
                LOG.debug(""{}ms elapsed since last read check."", elapsed);
            }

            // Perhaps the timer executed a read check late.. and then executes
            // the next read check on time which causes the time elapsed between
            // read checks to be small..

            // If less than 90% of the read check Time elapsed then abort this
            // read check.
            if (!allowReadCheck(elapsed)) {
                
---------------Reference log start----------------
LOG.debug(""Aborting read check...Not enough time elapsed since last read check."")
---------------Reference log end----------------
                return;
            }

            lastRunTime = now;
            readCheck();
        }",,
activemq,19653,"LOG.debug(""Registering service type: {} name: {} details: {}"", new Object[] { type, name, map })",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/discovery/zeroconf/ZeroconfDiscoveryAgent.java/#L208,"protected ServiceInfo createServiceInfo(String name, Map map) {
        int port = MapHelper.getInt(map, ""port"", 0);
        String type = getType();
        
---------------Reference log start----------------
LOG.debug(""Registering service type: {} name: {} details: {}"", new Object[] { type, name, map })
---------------Reference log end----------------
        return ServiceInfo.create(type, name + ""."" + type, port, weight, priority, """");
    }",,
activemq,19062,"LOG.error(""TransportLoggerControlMBean could not be registered, reason: "" + e, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/transport/TransportLoggerFactory.java/#L215,"private void createTransportLoggerControl(int port) {
         try {
             this.managementContext = new ManagementContext();
             this.managementContext.setConnectorPort(port);
             this.managementContext.start();
         } catch (Exception e) {
             LOG.error(""Management context could not be started, reason: "" + e, e);
         }

         try {
             this.objectName = new ObjectName(this.managementContext.getJmxDomainName()+"":""+ ""Type=TransportLoggerControl"");
             AnnotatedMBean.registerMBean(this.managementContext, new TransportLoggerControl(this.managementContext),this.objectName);

             this.transportLoggerControlCreated = true;

         } catch (Exception e) {
             
---------------Reference log start----------------
LOG.error(""TransportLoggerControlMBean could not be registered, reason: "" + e, e)
---------------Reference log end----------------
         }
     }",,
activemq,19836,"LOGGER.debug(""closing returned namedXAResource's connection: "" + ((ConnectionAndWrapperNamedXAResource) namedXaResource).connection)",debug,https://github.com/apache/activemq/blob/main/activemq-jms-pool/src/main/java/org/apache/activemq/jms/pool/GenericResourceManager.java/#L177,"@Override
                    public void returnNamedXAResource(NamedXAResource namedXaResource) {
                        if (namedXaResource instanceof ConnectionAndWrapperNamedXAResource) {
                            try {
                                
---------------Reference log start----------------
LOGGER.debug(""closing returned namedXAResource's connection: "" + ((ConnectionAndWrapperNamedXAResource) namedXaResource).connection)
---------------Reference log end----------------
                                ((ConnectionAndWrapperNamedXAResource)namedXaResource).connection.close();
                            } catch (Exception ignored) {
                                LOGGER.debug(""failed to close returned namedXAResource: "" + namedXaResource, ignored);
                            }
                        }
                    }",,
activemq,19624,"LOG.debug(""ignoring exception from after rollback on ended transaction: {}"", ignored, ignored)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/TransactionContext.java/#L555,"@Override
    public void rollback(Xid xid) throws XAException {

        if (LOG.isDebugEnabled()) {
            LOG.debug(""Rollback: "" + xid);
        }

        // We allow interleaving multiple transactions, so
        // we don't limit rollback to the associated xid.
        XATransactionId x;
        if (xid == null) {
            throw new XAException(XAException.XAER_PROTO);
        }
        if (equals(associatedXid, xid)) {
            // I think this can happen even without an end(xid) call. Need to
            // check spec.
            x = (XATransactionId)transactionId;
        } else {
            x = new XATransactionId(xid);
        }

        try {
            this.connection.checkClosedOrFailed();
            this.connection.ensureConnectionInfoSent();

            // Let the server know that the tx is rollback.
            TransactionInfo info = new TransactionInfo(getConnectionId(), x, TransactionInfo.ROLLBACK);
            this.connection.syncSendPacket(info);

            List<TransactionContext> l;
            synchronized(ENDED_XA_TRANSACTION_CONTEXTS) {
                l = ENDED_XA_TRANSACTION_CONTEXTS.remove(x);
            }
            // After rollback may be expensive and can deadlock, do it outside global synch block
            // No risk for concurrent updates as we own the list now
            if (l != null) {
                for (TransactionContext ctx : l) {
                    try {
                        ctx.afterRollback();
                    } catch (Exception ignored) {
                        
---------------Reference log start----------------
LOG.debug(""ignoring exception from after rollback on ended transaction: {}"", ignored, ignored)
---------------Reference log end----------------
                    }
                }                  
            }
        } catch (JMSException e) {
            throw toXAException(e);
        }
    }",,
activemq,19615,"LOG.info(""commit failed for transaction {}"", info.getTransactionId(), cause)",info,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/TransactionContext.java/#L340,"public void commit() throws JMSException {
        if (isInXATransaction()) {
            throw new TransactionInProgressException(""Cannot commit() if an XA transaction is already in progress "");
        }

        try {
            beforeEnd();
        } catch (JMSException e) {
            rollback();
            throw e;
        }

        if (transactionId != null && rollbackOnly) {
            final String message = ""Commit of "" + transactionId + ""  failed due to rollback only request; typically due to failover with pending acks"";
            try {
                rollback();
            } finally {
                LOG.warn(message);
                throw new TransactionRolledBackException(message);
            }
        }

        // Only send commit if the transaction was started.
        if (transactionId != null) {
            LOG.debug(""Commit: {} syncCount: {}"",
                transactionId, (synchronizations != null ? synchronizations.size() : 0));

            TransactionInfo info = new TransactionInfo(getConnectionId(), transactionId, TransactionInfo.COMMIT_ONE_PHASE);
            this.transactionId = null;
            // Notify the listener that the tx was committed back
            try {
                this.connection.syncSendPacket(info);
                if (localTransactionEventListener != null) {
                    localTransactionEventListener.commitEvent();
                }
                afterCommit();
            } catch (JMSException cause) {
                
---------------Reference log start----------------
LOG.info(""commit failed for transaction {}"", info.getTransactionId(), cause)
---------------Reference log end----------------
                if (localTransactionEventListener != null) {
                    localTransactionEventListener.rollbackEvent();
                }
                afterRollback();
                throw cause;
            }

        }
    }",,
activemq,19463,"LOG.warn(""Closed consumer on Command, "" + id)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQSession.java/#L2216,"protected void close(ConsumerId id) {
        for (Iterator<ActiveMQMessageConsumer> iter = consumers.iterator(); iter.hasNext();) {
            ActiveMQMessageConsumer c = iter.next();
            if (c.getConsumerId().equals(id)) {
                try {
                    c.close();
                } catch (JMSException e) {
                    LOG.warn(""Exception closing consumer"", e);
                }
                
---------------Reference log start----------------
LOG.warn(""Closed consumer on Command, "" + id)
---------------Reference log end----------------
                break;
            }
        }
    }",,
activemq,19047,"LOG.info(""Successfully restarted transports on "" + broker)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/util/DefaultIOExceptionHandler.java/#L128,"@Override
                                public void run() {
                                    try {
                                        allowIOResumption();
                                        while (hasLockOwnership() && isPersistenceAdapterDown()) {
                                            LOG.info(""waiting for broker persistence adapter checkpoint to succeed before restarting transports"");
                                            TimeUnit.MILLISECONDS.sleep(resumeCheckSleepPeriod);
                                        }
                                        if (hasLockOwnership()) {
                                            Map<ActiveMQDestination, Destination> destinations = ((RegionBroker)broker.getRegionBroker()).getDestinationMap();
                                            for (Destination destination : destinations.values()) {

                                                if (destination instanceof Queue) {
                                                    Queue queue = (Queue)destination;
                                                    if (queue.isResetNeeded()) {
                                                        queue.clearPendingMessages(0);
                                                    }
                                                }
                                            }
                                            broker.startAllConnectors();
                                            
---------------Reference log start----------------
LOG.info(""Successfully restarted transports on "" + broker)
---------------Reference log end----------------
                                        }
                                    } catch (Exception e) {
                                        LOG.warn(""Stopping "" + broker + "" due to failure restarting transports"", e);
                                        stopBroker(e);
                                    } finally {
                                        handlingException.compareAndSet(true, false);
                                    }
                                }",,
activemq,18407,"LOG.warn(""While waiting for StompSocket to be properly started, we got interrupted!! Should be okay, but you could see race conditions..."")",warn,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/ws/AbstractStompSocket.java/#L137,"protected void processStompFrame(String data) {
        if (!transportStartedAtLeastOnce()) {
            LOG.debug(""Waiting for StompSocket to be properly started..."");
            try {
                socketTransportStarted.await();
            } catch (InterruptedException e) {
                
---------------Reference log start----------------
LOG.warn(""While waiting for StompSocket to be properly started, we got interrupted!! Should be okay, but you could see race conditions..."")
---------------Reference log end----------------
            }
        }

        protocolLock.lock();
        try {
            if (data != null) {
                receiveCounter += data.length();

                if (data.equals(""\n"")) {
                    stompInactivityMonitor.onCommand(new KeepAliveInfo());
                } else {
                    StompFrame frame = (StompFrame)wireFormat.unmarshal(new ByteSequence(data.getBytes(""UTF-8"")));
                    frame.setTransportContext(getPeerCertificates());
                    protocolConverter.onStompCommand(frame);
                }
            }
        } catch (Exception e) {
            onException(IOExceptionSupport.create(e));
        } finally {
            protocolLock.unlock();
        }
    }",,
activemq,19061,"LOG.error(""Management context could not be started, reason: "" + e, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/transport/TransportLoggerFactory.java/#L205,"private void createTransportLoggerControl(int port) {
         try {
             this.managementContext = new ManagementContext();
             this.managementContext.setConnectorPort(port);
             this.managementContext.start();
         } catch (Exception e) {
             
---------------Reference log start----------------
LOG.error(""Management context could not be started, reason: "" + e, e)
---------------Reference log end----------------
         }

         try {
             this.objectName = new ObjectName(this.managementContext.getJmxDomainName()+"":""+ ""Type=TransportLoggerControl"");
             AnnotatedMBean.registerMBean(this.managementContext, new TransportLoggerControl(this.managementContext),this.objectName);

             this.transportLoggerControlCreated = true;

         } catch (Exception e) {
             LOG.error(""TransportLoggerControlMBean could not be registered, reason: "" + e, e);
         }
     }",,
activemq,18577,"LOG.warn(""Failed to call getPlatformMBeanServer() due to: "", e)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagementContext.java/#L504,"public MBeanServer findTigerMBeanServer() {
        String name = ""java.lang.management.ManagementFactory"";
        Class<?> type = loadClass(name, ManagementContext.class.getClassLoader());
        if (type != null) {
            try {
                Method method = type.getMethod(""getPlatformMBeanServer"", new Class[0]);
                if (method != null) {
                    Object answer = method.invoke(null, new Object[0]);
                    if (answer instanceof MBeanServer) {
                        if (createConnector) {
                            createConnector((MBeanServer)answer);
                        }
                        return (MBeanServer)answer;
                    } else {
                        LOG.warn(""Could not cast: {} into an MBeanServer. There must be some classloader strangeness in town"", answer);
                    }
                } else {
                    LOG.warn(""Method getPlatformMBeanServer() does not appear visible on type: {}"", type.getName());
                }
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.warn(""Failed to call getPlatformMBeanServer() due to: "", e)
---------------Reference log end----------------
            }
        } else {
            LOG.trace(""Class not found: {} so probably running on Java 1.4"", name);
        }
        return null;
    }",,
activemq,19169,"LOG.trace(""{}, bridging messages for static destination: {}"", configuration.getBrokerName(), dest)",trace,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L1400,"protected void setupStaticDestinations() {
        ActiveMQDestination[] dests = staticallyIncludedDestinations;
        if (dests != null) {
            for (ActiveMQDestination dest : dests) {
                if (isPermissableDestination(dest)) {
                    DemandSubscription sub = createDemandSubscription(dest, null);
                    if (sub != null) {
                        sub.setStaticallyIncluded(true);
                        try {
                            addSubscription(sub);
                        } catch (IOException e) {
                            LOG.error(""Failed to add static destination {}"", dest, e);
                        }
                        
---------------Reference log start----------------
LOG.trace(""{}, bridging messages for static destination: {}"", configuration.getBrokerName(), dest)
---------------Reference log end----------------
                    } else {
                        LOG.info(""{}, static destination excluded: {}, demand already exists"", configuration.getBrokerName(), dest);
                    }
                } else {
                    LOG.info(""{}, static destination excluded: {}"", configuration.getBrokerName(), dest);
                }
            }
        }
    }",,
activemq,18236,"LOG.trace(""onDelivery: Rejected state = {}, message poisoned."", state)",trace,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpSender.java/#L282,"@Override
    public void delivery(Delivery delivery) throws Exception {
        MessageDispatch md = (MessageDispatch) delivery.getContext();
        DeliveryState state = delivery.getRemoteState();

        if (state instanceof TransactionalState) {
            TransactionalState txState = (TransactionalState) state;
            LOG.trace(""onDelivery: TX delivery state = {}"", state);
            if (txState.getOutcome() != null) {
                Outcome outcome = txState.getOutcome();
                if (outcome instanceof Accepted) {
                    TransactionId txId = new LocalTransactionId(session.getConnection().getConnectionId(), toLong(txState.getTxnId()));

                    // Store the message sent in this TX we might need to re-send on rollback
                    // and we need to ACK it on commit.
                    session.enlist(txId);
                    dispatchedInTx.addFirst(delivery);

                    if (!delivery.remotelySettled()) {
                        TransactionalState txAccepted = new TransactionalState();
                        txAccepted.setOutcome(Accepted.getInstance());
                        txAccepted.setTxnId(txState.getTxnId());

                        delivery.disposition(txAccepted);
                    }
                }
            }
        } else {
            if (state instanceof Accepted) {
                LOG.trace(""onDelivery: accepted state = {}"", state);
                if (!delivery.remotelySettled()) {
                    delivery.disposition(new Accepted());
                }
                settle(delivery, MessageAck.INDIVIDUAL_ACK_TYPE);
            } else if (state instanceof Rejected) {
                // Rejection is a terminal outcome, we poison the message for dispatch to
                // the DLQ.  If a custom redelivery policy is used on the broker the message
                // can still be redelivered based on the configation of that policy.
                
---------------Reference log start----------------
LOG.trace(""onDelivery: Rejected state = {}, message poisoned."", state)
---------------Reference log end----------------
                settle(delivery, MessageAck.POISON_ACK_TYPE);
            } else if (state instanceof Released) {
                LOG.trace(""onDelivery: Released state = {}"", state);
                // re-deliver && don't increment the counter.
                settle(delivery, -1);
            } else if (state instanceof Modified) {
                Modified modified = (Modified) state;
                if (Boolean.TRUE.equals(modified.getDeliveryFailed())) {
                    // increment delivery counter..
                    md.setRedeliveryCounter(md.getRedeliveryCounter() + 1);
                }
                LOG.trace(""onDelivery: Modified state = {}, delivery count now {}"", state, md.getRedeliveryCounter());
                byte ackType = -1;
                Boolean undeliverableHere = modified.getUndeliverableHere();
                if (undeliverableHere != null && undeliverableHere) {
                    // receiver does not want the message..
                    // perhaps we should DLQ it?
                    ackType = MessageAck.POISON_ACK_TYPE;
                }
                settle(delivery, ackType);
            }
        }

        pumpOutbound();
    }",,
activemq,18451,"LOG.debug(""ignored exception"", e)",debug,https://github.com/apache/activemq/blob/main/activemq-partition/src/main/java/org/apache/activemq/partition/ZKClient.java/#L77,"@Override
    public void close() {
        if (_stateChangeDispatcher != null) {
            _stateChangeDispatcher.end();
            try {
                _stateChangeDispatcher.join(1000);
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.debug(""ignored exception"", e)
---------------Reference log end----------------
            }
        }
        synchronized(_lock) {
            if (_zk != null) {
                try {
                    changeState(State.NONE);
                    _zk.close();
                    Thread th = getSendThread();
                    if (th != null) {
                        th.join(1000);
                    }
                    _zk = null;
                } catch (Exception e) {
                    LOG.debug(""ignored exception"", e);
                }
            }
        }
    }",,
activemq,18884,"LOG.warn(runtimeException.getLocalizedMessage(), runtimeException)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/RegionBroker.java/#L665,"@Override
    public void preProcessDispatch(final MessageDispatch messageDispatch) {
        final Message message = messageDispatch.getMessage();
        if (message != null) {
            long endTime = System.currentTimeMillis();
            message.setBrokerOutTime(endTime);
            if (getBrokerService().isEnableStatistics()) {
                long totalTime = endTime - message.getBrokerInTime();
                ((Destination) message.getRegionDestination()).getDestinationStatistics().getProcessTime().addTime(totalTime);
            }
            if (((BaseDestination) message.getRegionDestination()).isPersistJMSRedelivered() && !message.isRedelivered()) {
                final int originalValue = message.getRedeliveryCounter();
                message.incrementRedeliveryCounter();
                try {
                    if (message.isPersistent()) {
                        ((BaseDestination) message.getRegionDestination()).getMessageStore().updateMessage(message);
                    }
                    messageDispatch.setTransmitCallback(new TransmitCallback() {
                        // dispatch is considered a delivery, so update sub state post dispatch otherwise
                        // on a disconnect/reconnect cached messages will not reflect initial delivery attempt
                        final TransmitCallback delegate = messageDispatch.getTransmitCallback();
                        @Override
                        public void onSuccess() {
                            message.incrementRedeliveryCounter();
                            if (delegate != null) {
                                delegate.onSuccess();
                            }
                        }

                        @Override
                        public void onFailure() {
                            if (delegate != null) {
                                delegate.onFailure();
                            }
                        }
                    });
                } catch (IOException error) {
                    RuntimeException runtimeException = new RuntimeException(""Failed to persist JMSRedeliveryFlag on "" + message.getMessageId() + "" in "" + message.getDestination(), error);
                    
---------------Reference log start----------------
LOG.warn(runtimeException.getLocalizedMessage(), runtimeException)
---------------Reference log end----------------
                    throw runtimeException;
                } finally {
                    message.setRedeliveryCounter(originalValue);
                }
            }
        }
    }",,
activemq,19673,"LOG.debug(""Reconnecting disabled: stopped"")",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/discovery/simple/SimpleDiscoveryAgent.java/#L176,"@Override
                public void run() {
                    SimpleDiscoveryEvent event = new SimpleDiscoveryEvent(sevent);

                    // We detect a failed connection attempt because the service
                    // fails right away.
                    if (event.connectTime + minConnectTime > System.currentTimeMillis()) {
                        LOG.debug(""Failure occurred soon after the discovery event was generated.  It will be classified as a connection failure: {}"", event);

                        event.connectFailures++;

                        if (maxReconnectAttempts > 0 && event.connectFailures >= maxReconnectAttempts) {
                            LOG.warn(""Reconnect attempts exceeded {} tries.  Reconnecting has been disabled for: {}"", maxReconnectAttempts, event);
                            return;
                        }

                        if (!useExponentialBackOff || event.reconnectDelay == -1) {
                            event.reconnectDelay = initialReconnectDelay;
                        } else {
                            // Exponential increment of reconnect delay.
                            event.reconnectDelay *= backOffMultiplier;
                            if (event.reconnectDelay > maxReconnectDelay) {
                                event.reconnectDelay = maxReconnectDelay;
                            }
                        }

                        doReconnectDelay(event);

                    } else {
                        LOG.trace(""Failure occurred to long after the discovery event was generated.  "" +
                                  ""It will not be classified as a connection failure: {}"", event);
                        event.connectFailures = 0;
                        event.reconnectDelay = initialReconnectDelay;

                        doReconnectDelay(event);
                    }

                    if (!running.get()) {
                        
---------------Reference log start----------------
LOG.debug(""Reconnecting disabled: stopped"")
---------------Reference log end----------------
                        return;
                    }

                    event.connectTime = System.currentTimeMillis();
                    event.failed.set(false);
                    listener.onServiceAdd(event);
                }",,
activemq,18934,"LOG.error(""Failed to recover this message {}"", message, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Topic.java/#L324,"@Override
                    public boolean recoverMessage(Message message) throws Exception {
                        message.setRegionDestination(Topic.this);
                        try {
                            msgContext.setMessageReference(message);
                            if (subscription.matches(message, msgContext)) {
                                subscription.add(message);
                            }
                        } catch (IOException e) {
                            
---------------Reference log start----------------
LOG.error(""Failed to recover this message {}"", message, e)
---------------Reference log end----------------
                        }
                        return true;
                    }",,
activemq,19306,"LOG.trace(""MQTT Snd PUBACK message:{} client:{} connection:{}"", command.messageId(), clientId, connectionInfo.getConnectionId())",trace,https://github.com/apache/activemq/blob/main/activemq-mqtt/src/main/java/org/apache/activemq/transport/mqtt/MQTTProtocolConverter.java/#L763,"@Override
                public void onResponse(MQTTProtocolConverter converter, Response response) throws IOException {
                    if (response.isException()) {
                        Throwable error = ((ExceptionResponse) response).getException();
                        LOG.warn(""Failed to send MQTT Publish: {}: {}"", command, error.getMessage());
                        LOG.trace(""Error trace: {}"", (Object)error);
                    }

                    switch (command.qos()) {
                        case AT_LEAST_ONCE:
                            PUBACK ack = new PUBACK();
                            ack.messageId(command.messageId());
                            
---------------Reference log start----------------
LOG.trace(""MQTT Snd PUBACK message:{} client:{} connection:{}"", command.messageId(), clientId, connectionInfo.getConnectionId())
---------------Reference log end----------------
                            converter.getMQTTTransport().sendToMQTT(ack.encode());
                            break;
                        case EXACTLY_ONCE:
                            PUBREC req = new PUBREC();
                            req.messageId(command.messageId());
                            synchronized (publisherRecs) {
                                publisherRecs.put(command.messageId(), req);
                            }
                            LOG.trace(""MQTT Snd PUBREC message:{} client:{} connection:{}"",
                                      command.messageId(), clientId, connectionInfo.getConnectionId());
                            converter.getMQTTTransport().sendToMQTT(req.encode());
                            break;
                        default:
                            break;
                    }
                }",,
activemq,18617,"LOG.warn(""Failed to create object name to unregister {}"", transaction, e)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedRegionBroker.java/#L815,"public void unregister(XATransaction transaction) {
        try {
            ObjectName objectName = BrokerMBeanSupport.createXATransactionName(brokerObjectName, transaction);
            if (registeredMBeans.remove(objectName)) {
                try {
                    managementContext.unregisterMBean(objectName);
                } catch (Throwable e) {
                    LOG.warn(""Failed to unregister MBean {}"", objectName);
                    LOG.debug(""Failure reason: "", e);
                }
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.warn(""Failed to create object name to unregister {}"", transaction, e)
---------------Reference log end----------------
        }
    }",,
activemq,19138,"LOG.warn(""Error processing BrokerSubscriptionInfo: {}"", e.getMessage(), e)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L784,"@Override
                        public void run() {
                            try {
                                staticDestinationsLatch.await();
                                //Make sure after the countDown of staticDestinationsLatch we aren't stopping
                                if (!disposed.get()) {
                                    BrokerSubscriptionInfo subInfo = brokerSubscriptionInfo;
                                    LOG.debug(""Received Remote BrokerSubscriptionInfo on {} from {}"",
                                            brokerService.getBrokerName(), subInfo.getBrokerName());

                                    if (configuration.isSyncDurableSubs() && configuration.isConduitSubscriptions()
                                            && !configuration.isDynamicOnly()) {
                                        if (started.get()) {
                                            if (subInfo.getSubscriptionInfos() != null) {
                                                for (ConsumerInfo info : subInfo.getSubscriptionInfos()) {
                                                    //re-add any process any non-NC consumers that match the
                                                    //dynamicallyIncludedDestinations list
                                                    //Also re-add network consumers that are not part of this direct
                                                    //bridge (proxy of proxy bridges)
                                                    if((info.getSubscriptionName() == null || !isDirectBridgeConsumer(info)) &&
                                                            NetworkBridgeUtils.matchesDestinations(dynamicallyIncludedDestinations, info.getDestination())) {
                                                        serviceRemoteConsumerAdvisory(info);
                                                    }
                                                }
                                            }

                                            //After re-added, clean up any empty durables
                                            for (Iterator<DemandSubscription> i = subscriptionMapByLocalId.values().iterator(); i.hasNext(); ) {
                                                DemandSubscription ds = i.next();
                                                if (NetworkBridgeUtils.matchesDestinations(dynamicallyIncludedDestinations, ds.getLocalInfo().getDestination())) {
                                                    cleanupDurableSub(ds, i);
                                                }
                                            }
                                        }
                                    }
                                }
                            } catch (Exception e) {
                                
---------------Reference log start----------------
LOG.warn(""Error processing BrokerSubscriptionInfo: {}"", e.getMessage(), e)
---------------Reference log end----------------
                                LOG.debug(e.getMessage(), e);
                            }
                        }",,
activemq,19697,"LOG.trace(""A receive is in progress, skipping read check."")",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/AbstractInactivityMonitor.java/#L237,"final void readCheck() {
        int currentCounter = next.getReceiveCounter();
        int previousCounter = lastReceiveCounter.getAndSet(currentCounter);
        if (inReceive.get() || currentCounter != previousCounter) {
            
---------------Reference log start----------------
LOG.trace(""A receive is in progress, skipping read check."")
---------------Reference log end----------------
            return;
        }
        if (!commandReceived.get() && monitorStarted.get() && !ASYNC_TASKS.isShutdown()) {
            LOG.debug(""No message received since last read check for {}. Throwing InactivityIOException."", this);

            try {
                ASYNC_TASKS.execute(new Runnable() {
                    @Override
                    public void run() {
                        LOG.debug(""Running {}"", this);
                        onException(new InactivityIOException(""Channel was inactive for too (>"" + readCheckTime + "") long: "" + next.getRemoteAddress()));
                    }

                    @Override
                    public String toString() {
                        return ""ReadCheck["" + getRemoteAddress() + ""]"";
                    };
                });
            } catch (RejectedExecutionException ex) {
                if (!ASYNC_TASKS.isShutdown()) {
                    LOG.warn(""Async read check was rejected from the executor: "", ex);
                }
            }
        } else {
            if (LOG.isTraceEnabled()) {
                LOG.trace(""Message received since last read check, resetting flag: {}"", this);
            }
        }
        commandReceived.set(false);
    }",,
activemq,18605,"LOG.debug(""Failure reason: "", e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedRegionBroker.java/#L468,"protected void unregisterSubscription(ObjectName key, boolean addToInactive) throws Exception {
        queueSubscribers.remove(key);
        topicSubscribers.remove(key);
        temporaryQueueSubscribers.remove(key);
        temporaryTopicSubscribers.remove(key);
        if (registeredMBeans.remove(key)) {
            try {
                managementContext.unregisterMBean(key);
            } catch (Throwable e) {
                LOG.warn(""Failed to unregister MBean {}"", key);
                
---------------Reference log start----------------
LOG.debug(""Failure reason: "", e)
---------------Reference log end----------------
            }
        }
        DurableSubscriptionView view = (DurableSubscriptionView)durableTopicSubscribers.remove(key);
        if (view != null) {
            // need to put this back in the inactive list
            SubscriptionKey subscriptionKey = new SubscriptionKey(view.getClientId(), view.getSubscriptionName());
            if (addToInactive) {
                SubscriptionInfo info = new SubscriptionInfo();
                info.setClientId(subscriptionKey.getClientId());
                info.setSubscriptionName(subscriptionKey.getSubscriptionName());
                info.setDestination(new ActiveMQTopic(view.getDestinationName()));
                info.setSelector(view.getSelector());
                addInactiveSubscription(subscriptionKey, info, (brokerService.isKeepDurableSubsActive() ? view.subscription : null));
            }
        }
    }",,
activemq,18930,"LOG.error(""Failed to create message group Factory "", e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/policy/PolicyEntry.java/#L516,"public MessageGroupMapFactory getMessageGroupMapFactory() {
        if (messageGroupMapFactory == null) {
            try {
            messageGroupMapFactory = GroupFactoryFinder.createMessageGroupMapFactory(getMessageGroupMapFactoryType());
            }catch(Exception e){
                
---------------Reference log start----------------
LOG.error(""Failed to create message group Factory "", e)
---------------Reference log end----------------
            }
        }
        return messageGroupMapFactory;
    }",,
activemq,18620,"LOG.error(""Failed to checkpoint persistence adapter on gc request"", e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/BrokerView.java/#L105,"@Override
    public void gc() throws Exception {
        brokerService.getBroker().gc();
        try {
            brokerService.getPersistenceAdapter().checkpoint(true);
        } catch (IOException e) {
            
---------------Reference log start----------------
LOG.error(""Failed to checkpoint persistence adapter on gc request"", e)
---------------Reference log end----------------
        }
    }",,
activemq,17776,"LOG.info(getLeaseHolderId() + "" diff adjust from db: "" + result + "", db time: "" + timestamp)",info,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/LeaseDatabaseLocker.java/#L146,"protected long determineTimeDifference(Connection connection) throws SQLException {
        try (PreparedStatement statement = connection.prepareStatement(getStatements().getCurrentDateTime());
             ResultSet resultSet = statement.executeQuery()) {
            long result = 0l;
            if (resultSet.next()) {
                Timestamp timestamp = resultSet.getTimestamp(1);
                long diff = System.currentTimeMillis() - timestamp.getTime();
                if (Math.abs(diff) > maxAllowableDiffFromDBTime) {
                    // off by more than maxAllowableDiffFromDBTime so lets adjust
                    result = (-diff);
                }
                
---------------Reference log start----------------
LOG.info(getLeaseHolderId() + "" diff adjust from db: "" + result + "", db time: "" + timestamp)
---------------Reference log end----------------
            }
            return result;
        }
    }",,
activemq,18590,"LOG.error(""Failed to unregister subscription {}"", sub, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedRegionBroker.java/#L307,"public void unregisterSubscription(Subscription sub) {
        ObjectName name = subscriptionMap.remove(sub);
        if (name != null) {
            try {
                SubscriptionKey subscriptionKey = new SubscriptionKey(sub.getContext().getClientId(), sub.getConsumerInfo().getSubscriptionName());
                ObjectName inactiveName = subscriptionKeys.remove(subscriptionKey);
                if (inactiveName != null) {
                    inactiveDurableTopicSubscribers.remove(inactiveName);
                    managementContext.unregisterMBean(inactiveName);
                }
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.error(""Failed to unregister subscription {}"", sub, e)
---------------Reference log end----------------
            }
        }
    }",,
activemq,19792,"LOG.debug(""Caught exception closing socket "" + socket + "". This exception will be ignored."", e)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/tcp/TcpTransport.java/#L571,"@Override
                    public void run() {
                        LOG.trace(""Closing socket {}"", socket);
                        try {
                            socket.close();
                            LOG.debug(""Closed socket {}"", socket);
                        } catch (IOException e) {
                            if (LOG.isDebugEnabled()) {
                                
---------------Reference log start----------------
LOG.debug(""Caught exception closing socket "" + socket + "". This exception will be ignored."", e)
---------------Reference log end----------------
                            }
                        } finally {
                            latch.countDown();
                        }
                    }",,
activemq,18032,"LOG.warn(""Failed during replay of legacy store: "", e)",warn,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/scheduler/legacy/LegacyStoreReplayer.java/#L122,"public void startReplay(JobSchedulerStoreImpl targetStore) throws IOException {
        checkLoaded();

        if (targetStore == null) {
            throw new IOException(""Cannot replay to a null store"");
        }

        try {
            Set<String> schedulers = store.getJobSchedulerNames();
            if (!schedulers.isEmpty()) {

                for (String name : schedulers) {
                    LegacyJobSchedulerImpl scheduler = store.getJobScheduler(name);
                    LOG.info(""Replay of legacy store {} starting."", name);
                    replayScheduler(scheduler, targetStore);
                }
            }

            LOG.info(""Replay of legacy store complate."");
        } catch (IOException ioe) {
            LOG.warn(""Failed during replay of legacy store: "", ioe);
            throw ioe;
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.warn(""Failed during replay of legacy store: "", e)
---------------Reference log end----------------
            throw new IOException(e);
        }
    }",,
activemq,18149,"LOG.info(""Creating queue: {}"", destName)",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/JmsProducerClient.java/#L334,"@Override
    protected Destination createTemporaryDestination(String destName) throws JMSException {
        String simpleName = getSimpleName(destName);
        byte destinationType = getDestinationType(destName);

        // when we produce to temp destinations, we publish to them as
        // though they were normal queues or topics
        if (destinationType == ActiveMQDestination.TEMP_QUEUE_TYPE) {
            
---------------Reference log start----------------
LOG.info(""Creating queue: {}"", destName)
---------------Reference log end----------------
            return getSession().createQueue(simpleName);
        } else if (destinationType == ActiveMQDestination.TEMP_TOPIC_TYPE) {
            LOG.info(""Creating topic: {}"", destName);
            return getSession().createTopic(simpleName);
        } else {
            throw new IllegalArgumentException(""Unrecognized destination type: "" + destinationType);
        }
    }",,
activemq,19496,"LOG.trace(""removing tracked message: "" + eldest.getKey())",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/state/ConnectionStateTracker.java/#L87,"@Override
        protected boolean removeEldestEntry(Map.Entry<Object,Command> eldest) {
            boolean result = currentCacheSize > maxCacheSize;
            if (result) {
                if (eldest.getValue() instanceof Message) {
                    currentCacheSize -= ((Message)eldest.getValue()).getSize();
                } else if (eldest.getValue() instanceof MessagePull) {
                    currentCacheSize -= MESSAGE_PULL_SIZE;
                }
                if (LOG.isTraceEnabled()) {
                    
---------------Reference log start----------------
LOG.trace(""removing tracked message: "" + eldest.getKey())
---------------Reference log end----------------
                }
            }
            return result;
        }",,
activemq,19476,"LOG.trace(""Run task done: {}"", task)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/thread/DedicatedTaskRunner.java/#L44,"@Override
            public void run() {
                try {
                    runTask();
                } finally {
                    
---------------Reference log start----------------
LOG.trace(""Run task done: {}"", task)
---------------Reference log end----------------
                }
            }",,
activemq,19239,"LOG.info(""searching for network connectors..."")",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/LdapNetworkConnector.java/#L245,"@Override
    public void start() throws Exception {
        LOG.info(""connecting..."");
        Hashtable<String, String> env = new Hashtable<String, String>();
        env.put(Context.INITIAL_CONTEXT_FACTORY, ""com.sun.jndi.ldap.LdapCtxFactory"");
        this.ldapURI = getUri();
        LOG.debug(""    URI [{}]"", this.ldapURI);
        env.put(Context.PROVIDER_URL, this.ldapURI.toString());
        if (anonymousAuthentication) {
            LOG.debug(""    login credentials [anonymous]"");
            env.put(Context.SECURITY_AUTHENTICATION, ""none"");
        } else {
            LOG.debug(""    login credentials [{}:******]"", user);
            if (user != null && !"""".equals(user)) {
                env.put(Context.SECURITY_PRINCIPAL, user);
            } else {
                throw new Exception(""Empty username is not allowed"");
            }
            if (password != null && !"""".equals(password)) {
                env.put(Context.SECURITY_CREDENTIALS, password);
            } else {
                throw new Exception(""Empty password is not allowed"");
            }
        }
        boolean isConnected = false;
        while (!isConnected) {
            try {
                context = new InitialDirContext(env);
                isConnected = true;
            } catch (CommunicationException err) {
                if (failover) {
                    this.ldapURI = getUri();
                    LOG.error(""connection error [{}], failover connection to [{}]"", env.get(Context.PROVIDER_URL), this.ldapURI.toString());
                    env.put(Context.PROVIDER_URL, this.ldapURI.toString());
                    Thread.sleep(curReconnectDelay);
                    curReconnectDelay = Math.min(curReconnectDelay * 2, maxReconnectDelay);
                } else {
                    throw err;
                }
            }
        }

        // add connectors from search results
        
---------------Reference log start----------------
LOG.info(""searching for network connectors..."")
---------------Reference log end----------------
        LOG.debug(""    base   [{}]"", base);
        LOG.debug(""    filter [{}]"", searchFilter);
        LOG.debug(""    scope  [{}]"", searchControls.getSearchScope());
        NamingEnumeration<SearchResult> results = context.search(base, searchFilter, searchControls);
        while (results.hasMore()) {
            addConnector(results.next());
        }

        // register persistent search event listener
        if (searchEventListener) {
            LOG.info(""registering persistent search listener..."");
            EventDirContext eventContext = (EventDirContext) context.lookup("""");
            eventContext.addNamingListener(base, searchFilter, searchControls, this);
        } else { // otherwise close context (i.e. connection as it is no longer needed)
            context.close();
        }
    }",,
activemq,18982,"LOG.warn(""We cannot send an advisory message for a durable sub removal when we don't know about the durable sub"")",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/advisory/AdvisoryBroker.java/#L399,"@Override
    public void removeSubscription(ConnectionContext context, RemoveSubscriptionInfo info) throws Exception {
        SubscriptionKey key = new SubscriptionKey(context.getClientId(), info.getSubscriptionName());

        RegionBroker regionBroker = null;
        if (next instanceof RegionBroker) {
            regionBroker = (RegionBroker) next;
        } else {
            BrokerService service = next.getBrokerService();
            regionBroker = (RegionBroker) service.getRegionBroker();
        }

        if (regionBroker == null) {
            LOG.warn(""Cannot locate a RegionBroker instance to pass along the removeSubscription call"");
            throw new IllegalStateException(""No RegionBroker found."");
        }

        DurableTopicSubscription sub = ((TopicRegion) regionBroker.getTopicRegion()).getDurableSubscription(key);

        super.removeSubscription(context, info);

        if (sub == null) {
            
---------------Reference log start----------------
LOG.warn(""We cannot send an advisory message for a durable sub removal when we don't know about the durable sub"")
---------------Reference log end----------------
            return;
        }

        ActiveMQDestination dest = sub.getConsumerInfo().getDestination();

        // Don't advise advisory topics.
        if (!AdvisorySupport.isAdvisoryTopic(dest)) {
            ActiveMQTopic topic = AdvisorySupport.getConsumerAdvisoryTopic(dest);
            fireConsumerAdvisory(context, dest, topic, info);
        }

    }",,
activemq,18193,"LOG.info(""End of wait for "" + end + "" millis and received: "" + getMessageCount() + "" messages"")",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-memtest-maven-plugin/src/main/java/org/apache/activemq/tool/MemMessageIdList.java/#L144,"public void waitForMessagesToArrive(int messageCount) {
        LOG.info(""Waiting for "" + messageCount + "" message(s) to arrive"");

        long start = System.currentTimeMillis();

        for (int i = 0; i < messageCount; i++) {
            try {
                if (hasReceivedMessages(messageCount)) {
                    break;
                }
                long duration = System.currentTimeMillis() - start;
                if (duration >= maximumDuration) {
                    break;
                }
                synchronized (semaphore) {
                    semaphore.wait(maximumDuration - duration);
                }
            } catch (InterruptedException e) {
                LOG.info(""Caught: "" + e);
            }
        }
        long end = System.currentTimeMillis() - start;

        
---------------Reference log start----------------
LOG.info(""End of wait for "" + end + "" millis and received: "" + getMessageCount() + "" messages"")
---------------Reference log end----------------
    }
    }",,
activemq,17898,"LOG.error(""["" + sdEntry.getKey() + ""] references corrupt locations: "" + matches)",error,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L1006,"protected void recoverIndex(Transaction tx) throws IOException {
        long start = System.currentTimeMillis();
        // It is possible index updates got applied before the journal updates..
        // in that case we need to removed references to messages that are not in the journal
        final Location lastAppendLocation = journal.getLastAppendLocation();
        long undoCounter=0;

        // Go through all the destinations to see if they have messages past the lastAppendLocation
        for (String key : storedDestinations.keySet()) {
            StoredDestination sd = storedDestinations.get(key);

            final ArrayList<Long> matches = new ArrayList<>();
            // Find all the Locations that are >= than the last Append Location.
            sd.locationIndex.visit(tx, new BTreeVisitor.GTEVisitor<Location, Long>(lastAppendLocation) {
                @Override
                protected void matched(Location key, Long value) {
                    matches.add(value);
                }
            });

            for (Long sequenceId : matches) {
                MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
                if (keys != null) {
                    sd.locationIndex.remove(tx, keys.location);
                    sd.messageIdIndex.remove(tx, keys.messageId);
                    metadata.producerSequenceIdTracker.rollback(keys.messageId);
                    undoCounter++;
                    decrementAndSubSizeToStoreStat(tx, key, sd, keys.location.getSize());
                    // TODO: do we need to modify the ack positions for the pub sub case?
                }
            }
        }

        if (undoCounter > 0) {
            // The rolledback operations are basically in flight journal writes.  To avoid getting
            // these the end user should do sync writes to the journal.
            if (LOG.isInfoEnabled()) {
                long end = System.currentTimeMillis();
                LOG.info(""Rolled back "" + undoCounter + "" messages from the index in "" + ((end - start) / 1000.0f) + "" seconds."");
            }
        }

        undoCounter = 0;
        start = System.currentTimeMillis();

        // Lets be extra paranoid here and verify that all the datafiles being referenced
        // by the indexes still exists.

        final SequenceSet ss = new SequenceSet();
        for (StoredDestination sd : storedDestinations.values()) {
            // Use a visitor to cut down the number of pages that we load
            sd.locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
                int last=-1;

                @Override
                public boolean isInterestedInKeysBetween(Location first, Location second) {
                    if( first==null ) {
                        return !ss.contains(0, second.getDataFileId());
                    } else if( second==null ) {
                        return true;
                    } else {
                        return !ss.contains(first.getDataFileId(), second.getDataFileId());
                    }
                }

                @Override
                public void visit(List<Location> keys, List<Long> values) {
                    for (Location l : keys) {
                        int fileId = l.getDataFileId();
                        if( last != fileId ) {
                            ss.add(fileId);
                            last = fileId;
                        }
                    }
                }

            });
        }
        HashSet<Integer> missingJournalFiles = new HashSet<>();
        while (!ss.isEmpty()) {
            missingJournalFiles.add((int) ss.removeFirst());
        }

        for (Entry<Integer, Set<Integer>> entry : metadata.ackMessageFileMap.entrySet()) {
            missingJournalFiles.add(entry.getKey());
            for (Integer i : entry.getValue()) {
                missingJournalFiles.add(i);
            }
        }

        missingJournalFiles.removeAll(journal.getFileMap().keySet());

        if (!missingJournalFiles.isEmpty()) {
            LOG.warn(""Some journal files are missing: "" + missingJournalFiles);
        }

        ArrayList<BTreeVisitor.Predicate<Location>> knownCorruption = new ArrayList<>();
        ArrayList<BTreeVisitor.Predicate<Location>> missingPredicates = new ArrayList<>();
        for (Integer missing : missingJournalFiles) {
            missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(missing, 0), new Location(missing + 1, 0)));
        }

        if (checkForCorruptJournalFiles) {
            Collection<DataFile> dataFiles = journal.getFileMap().values();
            for (DataFile dataFile : dataFiles) {
                int id = dataFile.getDataFileId();
                // eof to next file id
                missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, dataFile.getLength()), new Location(id + 1, 0)));
                Sequence seq = dataFile.getCorruptedBlocks().getHead();
                while (seq != null) {
                    BTreeVisitor.BetweenVisitor<Location, Long> visitor =
                        new BTreeVisitor.BetweenVisitor<>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast() + 1));
                    missingPredicates.add(visitor);
                    knownCorruption.add(visitor);
                    seq = seq.getNext();
                }
            }
        }

        if (!missingPredicates.isEmpty()) {
            for (Entry<String, StoredDestination> sdEntry : storedDestinations.entrySet()) {
                final StoredDestination sd = sdEntry.getValue();
                final LinkedHashMap<Long, Location> matches = new LinkedHashMap<>();
                sd.locationIndex.visit(tx, new BTreeVisitor.OrVisitor<Location, Long>(missingPredicates) {
                    @Override
                    protected void matched(Location key, Long value) {
                        matches.put(value, key);
                    }
                });

                // If some message references are affected by the missing data files...
                if (!matches.isEmpty()) {

                    // We either 'gracefully' recover dropping the missing messages or
                    // we error out.
                    if( ignoreMissingJournalfiles ) {
                        // Update the index to remove the references to the missing data
                        for (Long sequenceId : matches.keySet()) {
                            MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
                            sd.locationIndex.remove(tx, keys.location);
                            sd.messageIdIndex.remove(tx, keys.messageId);
                            LOG.info(""["" + sdEntry.getKey() + ""] dropped: "" + keys.messageId + "" at corrupt location: "" + keys.location);
                            undoCounter++;
                            decrementAndSubSizeToStoreStat(tx, sdEntry.getKey(), sdEntry.getValue(), keys.location.getSize());
                            // TODO: do we need to modify the ack positions for the pub sub case?
                        }
                    } else {
                        
---------------Reference log start----------------
LOG.error(""["" + sdEntry.getKey() + ""] references corrupt locations: "" + matches)
---------------Reference log end----------------
                        throw new IOException(""Detected missing/corrupt journal files referenced by:["" + sdEntry.getKey() + ""] "" +matches.size()+"" messages affected."");
                    }
                }
            }
        }

        if (!ignoreMissingJournalfiles) {
            if (!knownCorruption.isEmpty()) {
                LOG.error(""Detected corrupt journal files. "" + knownCorruption);
                throw new IOException(""Detected corrupt journal files. "" + knownCorruption);
            }

            if (!missingJournalFiles.isEmpty()) {
                LOG.error(""Detected missing journal files. "" + missingJournalFiles);
                throw new IOException(""Detected missing journal files. "" + missingJournalFiles);
            }
        }

        if (undoCounter > 0) {
            // The rolledback operations are basically in flight journal writes.  To avoid getting these the end user
            // should do sync writes to the journal.
            if (LOG.isInfoEnabled()) {
                long end = System.currentTimeMillis();
                LOG.info(""Detected missing/corrupt journal files.  Dropped "" + undoCounter + "" messages from the index in "" + ((end - start) / 1000.0f) + "" seconds."");
            }
        }
    }",,
activemq,17881,"LOG.trace(""Writing trace command to trigger journal sync"")",trace,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L434,"@Override
        public void run() {
            try {
                // Decide on cleanup vs full checkpoint here.
                if (opened.get()) {
                    long now = System.currentTimeMillis();
                    if (journal.isJournalDiskSyncPeriodic() &&
                            journalDiskSyncInterval > 0 && (now - lastSync >= journalDiskSyncInterval)) {
                        Location currentUpdate = lastAsyncJournalUpdate.get();
                        if (currentUpdate != null && !currentUpdate.equals(lastAsyncUpdate)) {
                            lastAsyncUpdate = currentUpdate;
                            if (LOG.isTraceEnabled()) {
                                
---------------Reference log start----------------
LOG.trace(""Writing trace command to trigger journal sync"")
---------------Reference log end----------------
                            }
                            store(new KahaTraceCommand(), true, null, null);
                        }
                        lastSync = now;
                    }
                    if (cleanupInterval > 0 && (now - lastCleanup >= cleanupInterval)) {
                        checkpointCleanup(true);
                        lastCleanup = now;
                        lastCheckpoint = now;
                    } else if (checkpointInterval > 0 && (now - lastCheckpoint >= checkpointInterval)) {
                        checkpointCleanup(false);
                        lastCheckpoint = now;
                    }
                }
            } catch (IOException ioe) {
                LOG.error(""Checkpoint failed"", ioe);
                brokerService.handleIOException(ioe);
            } catch (Throwable e) {
                LOG.error(""Checkpoint failed"", e);
                brokerService.handleIOException(IOExceptionSupport.create(e));
            }
        }",,
activemq,18771,"LOG.error(""Failed to add message to cursor"", e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Queue.java/#L322,"@Override
        public boolean recoverMessage(Message message) {
            recoveredAccumulator++;
            if ((recoveredAccumulator % 10000) == 0) {
                LOG.info(""cursor for {} has recovered {} messages. {}% complete"",
                        getActiveMQDestination().getQualifiedName(), recoveredAccumulator,
                        Integer.valueOf((int) (recoveredAccumulator * 100 / totalMessageCount)));
            }
            // Message could have expired while it was being
            // loaded..
            message.setRegionDestination(Queue.this);
            if (message.isExpired() && broker.isExpired(message)) {
                toExpire.add(message);
                return true;
            }
            if (hasSpace()) {
                messagesLock.writeLock().lock();
                try {
                    try {
                        messages.addMessageLast(message);
                    } catch (Exception e) {
                        
---------------Reference log start----------------
LOG.error(""Failed to add message to cursor"", e)
---------------Reference log end----------------
                    }
                } finally {
                    messagesLock.writeLock().unlock();
                }
                destinationStatistics.getMessages().increment();
                return true;
            }
            return false;
        }",,
activemq,18805,"LOG.debug(""Duplicate message {} from cursor, removing from store"", ref.getMessage())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Queue.java/#L2101,"private PendingList doPageInForDispatch(boolean force, boolean processExpired, int maxPageSize) throws Exception {
        List<QueueMessageReference> result = null;
        PendingList resultList = null;

        int toPageIn = maxPageSize;
        messagesLock.readLock().lock();
        try {
            toPageIn = Math.min(toPageIn, messages.size());
        } finally {
            messagesLock.readLock().unlock();
        }
        int pagedInPendingSize = 0;
        pagedInPendingDispatchLock.readLock().lock();
        try {
            pagedInPendingSize = dispatchPendingList.size();
        } finally {
            pagedInPendingDispatchLock.readLock().unlock();
        }
        if (isLazyDispatch() && !force) {
            // Only page in the minimum number of messages which can be
            // dispatched immediately.
            toPageIn = Math.min(toPageIn, getConsumerMessageCountBeforeFull());
        }

        if (LOG.isDebugEnabled()) {
            LOG.debug(""{} toPageIn: {}, force:{}, Inflight: {}, pagedInMessages.size {}, pagedInPendingDispatch.size {}, enqueueCount: {}, dequeueCount: {}, memUsage:{}, maxPageSize:{}"",
                    this,
                    toPageIn,
                    force,
                    destinationStatistics.getInflight().getCount(),
                    pagedInMessages.size(),
                    pagedInPendingSize,
                    destinationStatistics.getEnqueues().getCount(),
                    destinationStatistics.getDequeues().getCount(),
                    getMemoryUsage().getUsage(),
                    maxPageSize);
        }

        if (toPageIn > 0 && (force || (haveRealConsumer() && pagedInPendingSize < maxPageSize))) {
            int count = 0;
            result = new ArrayList<QueueMessageReference>(toPageIn);
            messagesLock.writeLock().lock();
            try {
                try {
                    messages.setMaxBatchSize(toPageIn);
                    messages.reset();
                    while (count < toPageIn && messages.hasNext()) {
                        MessageReference node = messages.next();
                        messages.remove();

                        QueueMessageReference ref = createMessageReference(node.getMessage());
                        if (processExpired && ref.isExpired()) {
                            if (broker.isExpired(ref)) {
                                messageExpired(createConnectionContext(), ref);
                            } else {
                                ref.decrementReferenceCount();
                            }
                        } else {
                            result.add(ref);
                            count++;
                        }
                    }
                } finally {
                    messages.release();
                }
            } finally {
                messagesLock.writeLock().unlock();
            }

            if (count > 0) {
                // Only add new messages, not already pagedIn to avoid multiple
                // dispatch attempts
                pagedInMessagesLock.writeLock().lock();
                try {
                    if (isPrioritizedMessages()) {
                        resultList = new PrioritizedPendingList();
                    } else {
                        resultList = new OrderedPendingList();
                    }
                    for (QueueMessageReference ref : result) {
                        if (!pagedInMessages.contains(ref)) {
                            pagedInMessages.addMessageLast(ref);
                            resultList.addMessageLast(ref);
                        } else {
                            ref.decrementReferenceCount();
                            // store should have trapped duplicate in it's index, or cursor audit trapped insert
                            // or producerBrokerExchange suppressed send.
                            // note: jdbc store will not trap unacked messages as a duplicate b/c it gives each message a unique sequence id
                            LOG.warn(""{}, duplicate message {} - {} from cursor, is cursor audit disabled or too constrained? Redirecting to dlq"", this, ref.getMessageId(), ref.getMessage().getMessageId().getFutureOrSequenceLong());
                            if (store != null) {
                                ConnectionContext connectionContext = createConnectionContext();
                                dropMessage(ref);
                                if (gotToTheStore(ref.getMessage())) {
                                    
---------------Reference log start----------------
LOG.debug(""Duplicate message {} from cursor, removing from store"", ref.getMessage())
---------------Reference log end----------------
                                    store.removeMessage(connectionContext, new MessageAck(ref.getMessage(), MessageAck.POISON_ACK_TYPE, 1));
                                }
                                broker.getRoot().sendToDeadLetterQueue(connectionContext, ref.getMessage(), null, new Throwable(""duplicate paged in from cursor for "" + destination));
                            }
                        }
                    }
                } finally {
                    pagedInMessagesLock.writeLock().unlock();
                }
            } else if (!messages.hasSpace()) {
                if (isFlowControlLogRequired()) {
                    LOG.warn(""{} cursor blocked, no space available to page in messages; usage: {}"", this, this.systemUsage.getMemoryUsage());
                } else {
                    LOG.debug(""{} cursor blocked, no space available to page in messages; usage: {}"", this, this.systemUsage.getMemoryUsage());
                }
            }
        }

        // Avoid return null list, if condition is not validated
        return resultList != null ? resultList : new OrderedPendingList();
    }",,
activemq,19259,"LOG.debug(""connector reference renamed for URI [{}], Old UUID [{}], New UUID [{}]"", connectorURI, uuidOld, uuidNew)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/LdapNetworkConnector.java/#L437,"@Override
    public void objectRenamed(NamingEvent event) {
        LOG.debug(""entry renamed"");
        // XXX: getNameInNamespace method does not seem to work properly,
        // but getName seems to provide the result we want
        String uuidOld = event.getOldBinding().getName();
        String uuidNew = event.getNewBinding().getName();
        URI connectorURI = uuidMap.remove(uuidOld);
        uuidMap.put(uuidNew, connectorURI);
        
---------------Reference log start----------------
LOG.debug(""connector reference renamed for URI [{}], Old UUID [{}], New UUID [{}]"", connectorURI, uuidOld, uuidNew)
---------------Reference log end----------------
    }
    }",,
activemq,19531,"LOG.debug(""Failed to send remove command: "" + e, e)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/AdvisoryConsumer.java/#L59,"public synchronized void dispose() {
        if (!closed) {
            try {
                this.connection.asyncSendPacket(info.createRemoveCommand());
            } catch (JMSException e) {
                
---------------Reference log start----------------
LOG.debug(""Failed to send remove command: "" + e, e)
---------------Reference log end----------------
            }
            this.connection.removeDispatcher(info.getConsumerId());
            closed = true;
        }
    }",,
activemq,18887,"LOG.debug(""Dead Letter message with no DLQ strategy in place, message id: {}, destination: {}"", message.getMessageId(), message.getDestination())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/RegionBroker.java/#L814,"@Override
    public boolean sendToDeadLetterQueue(ConnectionContext context, MessageReference node, Subscription subscription, Throwable poisonCause) {
        try {
            if (node != null) {
                Message message = node.getMessage();
                if (message != null && node.getRegionDestination() != null) {
                    DeadLetterStrategy deadLetterStrategy = ((Destination) node.getRegionDestination()).getDeadLetterStrategy();
                    if (deadLetterStrategy != null) {
                        if (deadLetterStrategy.isSendToDeadLetterQueue(message)) {
                            ActiveMQDestination deadLetterDestination = deadLetterStrategy.getDeadLetterQueueFor(message, subscription);
                            // Prevent a DLQ loop where same message is sent from a DLQ back to itself
                            if (deadLetterDestination.equals(message.getDestination())) {
                                LOG.debug(""Not re-adding to DLQ: {}, dest: {}"", message.getMessageId(), message.getDestination());
                                return false;
                            }

                            // message may be inflight to other subscriptions so do not modify
                            message = message.copy();
                            long dlqExpiration = deadLetterStrategy.getExpiration();
                            if (dlqExpiration > 0) {
                                dlqExpiration += System.currentTimeMillis();
                            } else {
                                stampAsExpired(message);
                            }
                            message.setExpiration(dlqExpiration);
                            if (!message.isPersistent()) {
                                message.setPersistent(true);
                                message.setProperty(""originalDeliveryMode"", ""NON_PERSISTENT"");
                            }
                            if (poisonCause != null) {
                                message.setProperty(ActiveMQMessage.DLQ_DELIVERY_FAILURE_CAUSE_PROPERTY,
                                        poisonCause.toString());
                            }
                            // The original destination and transaction id do
                            // not get filled when the message is first sent,
                            // it is only populated if the message is routed to
                            // another destination like the DLQ
                            ConnectionContext adminContext = context;
                            if (context.getSecurityContext() == null || !context.getSecurityContext().isBrokerContext()) {
                                adminContext = BrokerSupport.getConnectionContext(this);
                            }
                            addDestination(adminContext, deadLetterDestination, false).getActiveMQDestination().setDLQ(true);
                            BrokerSupport.resendNoCopy(adminContext, message, deadLetterDestination);
                            return true;
                        }
                    } else {
                        
---------------Reference log start----------------
LOG.debug(""Dead Letter message with no DLQ strategy in place, message id: {}, destination: {}"", message.getMessageId(), message.getDestination())
---------------Reference log end----------------
                    }
                }
            }
        } catch (Exception e) {
            LOG.warn(""Caught an exception sending to DLQ: {}"", node, e);
        }

        return false;
    }",,
activemq,18818,"LOG.debug(""Discarding expired message {}"", reference)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/cursors/FilePendingMessageCursor.java/#L488,"private void discardExpiredMessage(MessageReference reference) {
        
---------------Reference log start----------------
LOG.debug(""Discarding expired message {}"", reference)
---------------Reference log end----------------
        if (reference.isExpired() && broker.isExpired(reference)) {
            ConnectionContext context = new ConnectionContext();
            context.setBroker(broker);
            ((Destination)reference.getRegionDestination()).messageExpired(context, null, new IndirectMessageReference(reference.getMessage()));
        }
    }",,
activemq,19589,"LOG.error(String.format(""Could not set property %s on %s"", name, target), e)",error,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/util/IntrospectionSupport.java/#L191,"public static boolean setProperty(Object target, String name, Object value) {
        try {
            Class<?> clazz = target.getClass();
            if (target instanceof SSLServerSocket) {
                // overcome illegal access issues with internal implementation class
                clazz = SSLServerSocket.class;
            }
            Method setter = findSetterMethod(clazz, name);
            if (setter == null) {
                return false;
            }

            // JDK 11: class or setter might not be publicly accessible
            setter.setAccessible(true);

            // If the type is null or it matches the needed type, just use the
            // value directly
            if (value == null || value.getClass() == setter.getParameterTypes()[0]) {
                setter.invoke(target, value);
            } else {
                // We need to convert it
                setter.invoke(target, convert(value, setter.getParameterTypes()[0]));
            }
            return true;
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(String.format(""Could not set property %s on %s"", name, target), e)
---------------Reference log end----------------
            return false;
        }
    }",,
activemq,19675,"LOG.debug(""Reconnecting disabled: stopped"")",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/discovery/simple/SimpleDiscoveryAgent.java/#L192,"protected void doReconnectDelay(SimpleDiscoveryEvent event) {
        synchronized (sleepMutex) {
            try {
                if (!running.get()) {
                    
---------------Reference log start----------------
LOG.debug(""Reconnecting disabled: stopped"")
---------------Reference log end----------------
                    return;
                }

                LOG.debug(""Waiting {}ms before attempting to reconnect."", event.reconnectDelay);
                sleepMutex.wait(event.reconnectDelay);
            } catch (InterruptedException ie) {
                LOG.debug(""Reconnecting disabled: "", ie);
                Thread.currentThread().interrupt();
                return;
            }
        }
    }",,
activemq,17820,"LOG.debug(""Sleeping for "" + lockAcquireSleepInterval + "" milli(s) before trying again to get the lock..."")",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/adapter/TransactDatabaseLocker.java/#L86,"@Override
    public void doStart() throws Exception {

        LOG.info(""Attempting to acquire the exclusive lock to become the Master broker"");
        PreparedStatement statement = null;
        while (true) {
            try {
                connection = dataSource.getConnection();
                connection.setAutoCommit(false);
                String sql = getStatements().getLockCreateStatement();
                statement = connection.prepareStatement(sql);
                if (statement.getMetaData() != null) {
                    ResultSet rs = statement.executeQuery();
                    // if not already locked the statement below blocks until lock acquired
                    rs.next();
                } else {
                    statement.execute();
                }
                break;
            } catch (Exception e) {
                if (isStopping()) {
                    throw new Exception(""Cannot start broker as being asked to shut down. Interrupted attempt to acquire lock: "" + e, e);
                }

                if (exceptionHandler != null) {
                    try {
                        exceptionHandler.handle(e);
                    } catch (Throwable handlerException) {
                        LOG.error(""The exception handler "" + exceptionHandler.getClass().getCanonicalName() + "" threw this exception: "" + handlerException
                                + "" while trying to handle this excpetion: "" + e, handlerException);
                    }

                } else {
                    LOG.error(""Failed to acquire lock: "" + e, e);
                }
            } finally {

                if (null != statement) {
                    try {
                        statement.close();
                    } catch (SQLException e1) {
                        LOG.warn(""Caught while closing statement: "" + e1, e1);
                    }
                    statement = null;
                }
            }

            
---------------Reference log start----------------
LOG.debug(""Sleeping for "" + lockAcquireSleepInterval + "" milli(s) before trying again to get the lock..."")
---------------Reference log end----------------
            try {
            	Thread.sleep(lockAcquireSleepInterval);
            } catch (InterruptedException ie) {
            	LOG.warn(""Master lock retry sleep interrupted"", ie);
            }
        }

        LOG.info(""Becoming the master on dataSource: "" + dataSource);
    }",,
activemq,19782,"LOG.debug(""Unexpected runtime exception: "" + e2, e2)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/TransportSupport.java/#L100,"public void onException(IOException e) {
        if (transportListener != null) {
            try {
                transportListener.onException(e);
            } catch (RuntimeException e2) {
                // Handle any unexpected runtime exceptions by debug logging
                // them.
                
---------------Reference log start----------------
LOG.debug(""Unexpected runtime exception: "" + e2, e2)
---------------Reference log end----------------
            }
        }
    }",,
activemq,18103,"LOG.warn(""Failed to aquire lock"", e)",warn,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/KahaDBStore.java/#L1679,"@Override
        public void aquireLocks() {
            if (this.locked.compareAndSet(false, true)) {
                try {
                    globalTopicSemaphore.acquire();
                    store.acquireLocalAsyncLock();
                    message.incrementReferenceCount();
                } catch (InterruptedException e) {
                    
---------------Reference log start----------------
LOG.warn(""Failed to aquire lock"", e)
---------------Reference log end----------------
                }
            }
        }",,
activemq,18586,"LOG.error(""Failed to register destination {}"", destName, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedRegionBroker.java/#L176,"public void register(ActiveMQDestination destName, Destination destination) {
        // TODO refactor to allow views for custom destinations
        try {
            ObjectName objectName = BrokerMBeanSupport.createDestinationName(brokerObjectName, destName);
            DestinationView view;
            if (destination instanceof Queue) {
                view = new QueueView(this, (Queue)destination);
            } else if (destination instanceof Topic) {
                view = new TopicView(this, (Topic)destination);
            } else {
                view = null;
                LOG.warn(""JMX View is not supported for custom destination {}"", destination);
            }
            if (view != null) {
                registerDestination(objectName, destName, view);
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Failed to register destination {}"", destName, e)
---------------Reference log end----------------
        }
    }",,
activemq,18138,"LOG.info(""Starting to publish "" + messageCount + "" messages from file "" + client.getMsgFileName())",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/JmsProducerClient.java/#L94,"public void sendCountBasedMessages(long messageCount) throws JMSException {
        // Parse through different ways to send messages
        // Avoided putting the condition inside the loop to prevent effect on performance
        Destination[] dest = createDestinations(destCount);

        // Create a producer, if none is created.
        if (getJmsProducer() == null) {
            if (dest.length == 1) {
                createJmsProducer(dest[0]);
            } else {
                createJmsProducer();
            }
        }
        try {
            getConnection().start();
            if (client.getMsgFileName() != null) {
                
---------------Reference log start----------------
LOG.info(""Starting to publish "" + messageCount + "" messages from file "" + client.getMsgFileName())
---------------Reference log end----------------
            } else {
                LOG.info(""Starting to publish "" +
                    messageCount +
                    "" messages of size "" +
                    client.getMessageSize() +
                    "" byte(s).""
                );
            }

            // Send one type of message only, avoiding the creation of different messages on sending
            if (!client.isCreateNewMsg()) {
                // Create only a single message
                createJmsTextMessage();

                // Send to more than one actual destination
                if (dest.length > 1) {
                    for (int i = 0; i < messageCount; i++) {
                        for (int j = 0; j < dest.length; j++) {
                            getJmsProducer().send(dest[j], getJmsTextMessage());
                            incThroughput();
                            sleep();
                            commitTxIfNecessary();
                        }
                    }
                    // Send to only one actual destination
                } else {
                    for (int i = 0; i < messageCount; i++) {
                        getJmsProducer().send(getJmsTextMessage());
                        incThroughput();
                        sleep();
                        commitTxIfNecessary();
                    }
                }

                // Send different type of messages using indexing to identify each one.
                // Message size will vary. Definitely slower, since messages properties
                // will be set individually each send.
            } else {
                // Send to more than one actual destination
                if (dest.length > 1) {
                    for (int i = 0; i < messageCount; i++) {
                        for (int j = 0; j < dest.length; j++) {
                            getJmsProducer().send(dest[j], createJmsTextMessage(""Text Message ["" + i + ""]""));
                            incThroughput();
                            sleep();
                            commitTxIfNecessary();
                        }
                    }

                    // Send to only one actual destination
                } else {
                    for (int i = 0; i < messageCount; i++) {
                        getJmsProducer().send(createJmsTextMessage(""Text Message ["" + i + ""]""));
                        incThroughput();
                        sleep();
                        commitTxIfNecessary();
                    }
                }
            }
        } finally {
            LOG.info(""Finished sending"");
            getConnection().close();
        }
    }",,
activemq,18466,"LOG.debug(""No partition target found for connection: "" + monitor.context.getConnectionId())",debug,https://github.com/apache/activemq/blob/main/activemq-partition/src/main/java/org/apache/activemq/partition/PartitionBroker.java/#L132,"protected void checkTarget(ConnectionMonitor monitor) {

        // can we find a preferred target for the connection?
        Target targetDTO = pickBestBroker(monitor);
        if( targetDTO == null || targetDTO.ids==null) {
            
---------------Reference log start----------------
LOG.debug(""No partition target found for connection: "" + monitor.context.getConnectionId())
---------------Reference log end----------------
            return;
        }

        // Are we one the the targets?
        if( targetDTO.ids.contains(getBrokerName()) ) {
            LOG.debug(""We are a partition target for connection: ""+monitor.context.getConnectionId());
            return;
        }

        // Then we need to move the connection over.
        String connectionString = getConnectionString(targetDTO.ids);
        if( connectionString==null ) {
            LOG.debug(""Could not convert to partition targets to connection string: "" + targetDTO.ids);
            return;
        }

        LOG.info(""Redirecting connection to: "" + connectionString);
        TransportConnection connection = (TransportConnection)monitor.context.getConnection();
        ConnectionControl cc = new ConnectionControl();
        cc.setConnectedBrokers(connectionString);
        cc.setRebalanceConnection(true);
        connection.dispatchAsync(cc);
    }",,
activemq,19099,"LOG.debug(""{} on {} from {} removed {}"", configuration.getBrokerName(), localBroker, remoteBrokerName, ds)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/ConduitBridge.java/#L130,"@Override
    protected void removeDemandSubscription(ConsumerId id) throws IOException {
        List<DemandSubscription> tmpList = new ArrayList<DemandSubscription>();

        for (DemandSubscription ds : subscriptionMapByLocalId.values()) {
            if (ds.remove(id)) {
                LOG.debug(""{} on {} from {} removed interest for: {} from {}"",
                        configuration.getBrokerName(), localBroker, remoteBrokerName, id, ds);
            }
            if (ds.isEmpty()) {
                tmpList.add(ds);
            }
        }

        for (DemandSubscription ds : tmpList) {
            removeSubscription(ds);
            
---------------Reference log start----------------
LOG.debug(""{} on {} from {} removed {}"", configuration.getBrokerName(), localBroker, remoteBrokerName, ds)
---------------Reference log end----------------
        }
    }",,
activemq,19350,"log.debug(""{} Run finished"", this)",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ServerSessionImpl.java/#L204,"public void run() {
        log.debug(""{} Running"", this);
        currentBatchSize = 0;
        while (true) {
            log.debug(""{} run loop"", this);
            try {
                InboundContextSupport.register(this);
                if (session.isClosed()) {
                    stale = true;
                } else if (session.isRunning() ) {
                    session.run();
                } else {
                    log.debug(""JMS Session {} with unconsumed {} is no longer running (maybe due to loss of connection?), marking ServerSession as stale"", session, session.getUnconsumedMessages().size());
                    stale = true;
                }
            } catch (Throwable e) {
                stale = true;
                if ( log.isDebugEnabled() ) {
                    log.debug(""Endpoint {} failed to process message."", this, e);
                } else if ( log.isInfoEnabled() ) {
                    log.info(""Endpoint {} failed to process message. Reason: "" + e.getMessage(), this);
                }
            } finally {
                InboundContextSupport.unregister(this);
                log.debug(""run loop end"");
                synchronized (runControlMutex) {
                    // This endpoint may have gone stale due to error
                    if (stale) {
                        log.debug(""Session {} stale, removing from pool"", this);
                        runningFlag = false;
                        pool.removeFromPool(this);
                        break;
                    }
                    if (!session.hasUncomsumedMessages()) {
                        runningFlag = false;
                        log.debug(""Session {} has no unconsumed message, returning to pool"", this);
                        pool.returnToPool(this);
                        break;
                    } else {
                        log.debug(""Session {} has more work to do b/c of unconsumed"", this);
                    }
                }
            }
        }
        
---------------Reference log start----------------
log.debug(""{} Run finished"", this)
---------------Reference log end----------------
    }
    }",,
activemq,19113,"LOG.debug(""Caught exception sending shutdown"", e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L315,"@Override
                        public void run() {
                            try {
                                serialExecutor.shutdown();
                                if (!serialExecutor.awaitTermination(5, TimeUnit.SECONDS)) {
                                    List<Runnable> pendingTasks = serialExecutor.shutdownNow();
                                    LOG.info(""pending tasks on stop {}"", pendingTasks);
                                }
                                //Shutdown the syncExecutor, call countDown to make sure a thread can
                                //terminate if it is waiting
                                staticDestinationsLatch.countDown();
                                syncExecutor.shutdown();
                                if (!syncExecutor.awaitTermination(5, TimeUnit.SECONDS)) {
                                    List<Runnable> pendingTasks = syncExecutor.shutdownNow();
                                    LOG.info(""pending tasks on stop {}"", pendingTasks);
                                }
                                localBroker.oneway(new ShutdownInfo());
                                remoteBroker.oneway(new ShutdownInfo());
                            } catch (Throwable e) {
                                
---------------Reference log start----------------
LOG.debug(""Caught exception sending shutdown"", e)
---------------Reference log end----------------
                            } finally {
                                sendShutdown.countDown();
                            }

                        }",,
activemq,18937,"LOG.warn(""Waiting for space to send transacted message - transaction elements = {} need more space to commit. Message = {}"", size, message)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Topic.java/#L472,"@Override
    public void send(final ProducerBrokerExchange producerExchange, final Message message) throws Exception {
        final ConnectionContext context = producerExchange.getConnectionContext();

        final ProducerInfo producerInfo = producerExchange.getProducerState().getInfo();
        producerExchange.incrementSend();
        final boolean sendProducerAck = !message.isResponseRequired() && producerInfo.getWindowSize() > 0
                && !context.isInRecoveryMode();

        message.setRegionDestination(this);

        // There is delay between the client sending it and it arriving at the
        // destination.. it may have expired.
        if (message.isExpired()) {
            broker.messageExpired(context, message, null);
            getDestinationStatistics().getExpired().increment();
            if (sendProducerAck) {
                ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message.getSize());
                context.getConnection().dispatchAsync(ack);
            }
            return;
        }

        if (memoryUsage.isFull()) {
            isFull(context, memoryUsage);
            fastProducer(context, producerInfo);

            if (isProducerFlowControl() && context.isProducerFlowControl()) {

                if (isFlowControlLogRequired()) {
                    LOG.warn(""{}, Usage Manager memory limit reached {}. Producers will be throttled to the rate at which messages are removed from this destination to prevent flooding it. See http://activemq.apache.org/producer-flow-control.html for more info."",
                            getActiveMQDestination().getQualifiedName(), memoryUsage.getLimit());
                } else {
                    LOG.debug(""{}, Usage Manager memory limit reached {}. Producers will be throttled to the rate at which messages are removed from this destination to prevent flooding it. See http://activemq.apache.org/producer-flow-control.html for more info."",
                            getActiveMQDestination().getQualifiedName(), memoryUsage.getLimit());
                }

                if (!context.isNetworkConnection() && systemUsage.isSendFailIfNoSpace()) {
                    throw new javax.jms.ResourceAllocationException(""Usage Manager memory limit (""
                            + memoryUsage.getLimit() + "") reached. Rejecting send for producer ("" + message.getProducerId()
                            + "") to prevent flooding "" + getActiveMQDestination().getQualifiedName() + "".""
                            + "" See http://activemq.apache.org/producer-flow-control.html for more info"");
                }

                // We can avoid blocking due to low usage if the producer is sending a sync message or
                // if it is using a producer window
                if (producerInfo.getWindowSize() > 0 || message.isResponseRequired()) {
                    synchronized (messagesWaitingForSpace) {
                        messagesWaitingForSpace.add(new Runnable() {
                            @Override
                            public void run() {
                                try {

                                    // While waiting for space to free up...
                                    // the transaction may be done
                                    if (message.isInTransaction()) {
                                        if (context.getTransaction() == null || context.getTransaction().getState() > IN_USE_STATE) {
                                            throw new JMSException(""Send transaction completed while waiting for space"");
                                        }
                                    }

                                    // the message may have expired.
                                    if (message.isExpired()) {
                                        broker.messageExpired(context, message, null);
                                        getDestinationStatistics().getExpired().increment();
                                    } else {
                                        doMessageSend(producerExchange, message);
                                    }

                                    if (sendProducerAck) {
                                        ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message
                                                .getSize());
                                        context.getConnection().dispatchAsync(ack);
                                    } else {
                                        Response response = new Response();
                                        response.setCorrelationId(message.getCommandId());
                                        context.getConnection().dispatchAsync(response);
                                    }

                                } catch (Exception e) {
                                    if (!sendProducerAck && !context.isInRecoveryMode()) {
                                        ExceptionResponse response = new ExceptionResponse(e);
                                        response.setCorrelationId(message.getCommandId());
                                        context.getConnection().dispatchAsync(response);
                                    }
                                }
                            }
                        });

                        registerCallbackForNotFullNotification();
                        context.setDontSendReponse(true);
                        return;
                    }

                } else {
                    // Producer flow control cannot be used, so we have do the flow control
                    // at the broker by blocking this thread until there is space available.

                    if (memoryUsage.isFull()) {
                        if (context.isInTransaction()) {

                            int count = 0;
                            while (!memoryUsage.waitForSpace(1000)) {
                                if (context.getStopping().get()) {
                                    throw new IOException(""Connection closed, send aborted."");
                                }
                                if (count > 2 && context.isInTransaction()) {
                                    count = 0;
                                    int size = context.getTransaction().size();
                                    
---------------Reference log start----------------
LOG.warn(""Waiting for space to send transacted message - transaction elements = {} need more space to commit. Message = {}"", size, message)
---------------Reference log end----------------
                                }
                                count++;
                            }
                        } else {
                            waitForSpace(
                                    context,
                                    producerExchange,
                                    memoryUsage,
                                    ""Usage Manager Memory Usage limit reached. Stopping producer (""
                                            + message.getProducerId()
                                            + "") to prevent flooding ""
                                            + getActiveMQDestination().getQualifiedName()
                                            + "".""
                                            + "" See http://activemq.apache.org/producer-flow-control.html for more info"");
                        }
                    }

                    // The usage manager could have delayed us by the time
                    // we unblock the message could have expired..
                    if (message.isExpired()) {
                        getDestinationStatistics().getExpired().increment();
                        LOG.debug(""Expired message: {}"", message);
                        return;
                    }
                }
            }
        }

        doMessageSend(producerExchange, message);
        messageDelivered(context, message);
        if (sendProducerAck) {
            ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message.getSize());
            context.getConnection().dispatchAsync(ack);
        }
    }",,
activemq,19468,"LOG.error(""Error in thread '{}'"", t.getName(), e)",error,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/thread/TaskRunnerFactory.java/#L202,"@Override
                    public void uncaughtException(final Thread t, final Throwable e) {
                        
---------------Reference log start----------------
LOG.error(""Error in thread '{}'"", t.getName(), e)
---------------Reference log end----------------
                    }
                    }",,
activemq,19443,"LOG.debug(getName() + "": usage change from: "" + oldPercentUsage + ""% of available memory, to: "" + newPercentUsage + ""% of available memory"")",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/usage/Usage.java/#L289,"private void fireEvent(final int oldPercentUsage, final int newPercentUsage) {
        if (debug) {
            
---------------Reference log start----------------
LOG.debug(getName() + "": usage change from: "" + oldPercentUsage + ""% of available memory, to: "" + newPercentUsage + ""% of available memory"")
---------------Reference log end----------------
        }
        if (started.get()) {
            // Switching from being full to not being full..
            if (oldPercentUsage >= 100 && newPercentUsage < 100) {
                waitForSpaceCondition.signalAll();
                if (!callbacks.isEmpty()) {
                    for (Runnable callback : callbacks) {
                        getExecutor().execute(callback);
                    }
                    callbacks.clear();
                }
            }
            if (!listeners.isEmpty()) {
                // Let the listeners know on a separate thread
                Runnable listenerNotifier = new Runnable() {
                    @Override
                    public void run() {
                        for (UsageListener listener : listeners) {
                            listener.onUsageChanged(Usage.this, oldPercentUsage, newPercentUsage);
                        }
                    }
                };
                if (started.get()) {
                    getExecutor().execute(listenerNotifier);
                } else {
                    LOG.warn(""Not notifying memory usage change to listeners on shutdown"");
                }
            }
        }
    }",,
activemq,19423,"LOG.debug(""Connection could not be created:"", e)",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ActiveMQConnectionFactory.java/#L101,"private Connection createConnection(ActiveMQConnectionRequestInfo connectionRequestInfo) throws JMSException {
        try {
            if (connectionRequestInfo.isUseInboundSessionEnabled()) {
                return new InboundConnectionProxy();
            }
            if (manager == null) {
                throw new JMSException(""No JCA ConnectionManager configured! Either enable UseInboundSessionEnabled or get your JCA container to configure one."");
            }

            return (Connection)manager.allocateConnection(factory, connectionRequestInfo);
        } catch (ResourceException e) {
            // Throw the root cause if it was a JMSException..
            if (e.getCause() instanceof JMSException) {
                throw (JMSException)e.getCause();
            }
            
---------------Reference log start----------------
LOG.debug(""Connection could not be created:"", e)
---------------Reference log end----------------
            JMSException jmsException = new JMSException(e.getMessage());
            jmsException.setLinkedException(e);
            throw jmsException;
        }
    }",,
activemq,17993,"LOG.debug(""Discarded data file: {}"", dataFile)",debug,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/disk/journal/Journal.java/#L838,"private void forceRemoveDataFile(DataFile dataFile) throws IOException {
        accessorPool.disposeDataFileAccessors(dataFile);
        totalLength.addAndGet(-dataFile.getLength());
        if (archiveDataLogs) {
            File directoryArchive = getDirectoryArchive();
            if (directoryArchive.exists()) {
                LOG.debug(""Archive directory exists: {}"", directoryArchive);
            } else {
                if (directoryArchive.isAbsolute())
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Archive directory [{}] does not exist - creating it now"",
                            directoryArchive.getAbsolutePath());
                }
                IOHelper.mkdirs(directoryArchive);
            }
            LOG.debug(""Moving data file {} to {} "", dataFile, directoryArchive.getCanonicalPath());
            dataFile.move(directoryArchive);
            LOG.debug(""Successfully moved data file"");
        } else {
            LOG.debug(""Deleting data file: {}"", dataFile);
            if (dataFile.delete()) {
                
---------------Reference log start----------------
LOG.debug(""Discarded data file: {}"", dataFile)
---------------Reference log end----------------
            } else {
                LOG.warn(""Failed to discard data file : {}"", dataFile.getFile());
            }
        }
        if (dataFileRemovedListener != null) {
            dataFileRemovedListener.fileRemoved(dataFile);
        }
    }",,
activemq,18462,"LOG.info(""Exiting recovery mode."")",info,https://github.com/apache/activemq/blob/main/activemq-partition/src/main/java/org/apache/activemq/partition/ZKClient.java/#L403,"@Override
        public void run() {
            LOG.info(""Entering recovery mode"");
            synchronized (_lock) {
                try {
                    int count = 0;
                    while (_state == ZKClient.State.NONE) {
                        try {
                            count++;
                            LOG.warn(""Recovery mode: trying to reconnect to zookeeper [{}]"", count);
                            ZKClient.this.connect();
                        } catch (Throwable e) {
                            LOG.warn(""Recovery mode: reconnect attempt failed [{}]... waiting for {}"", count, _reconnectTimeout, e);
                            try {
                                _lock.wait(_reconnectTimeout.getDurationInMilliseconds());
                            } catch (InterruptedException e1) {
                                throw new RuntimeException(""Recovery mode: wait interrupted... bailing out"", e1);
                            }
                        }
                    }
                } finally {
                    _expiredSessionRecovery = null;
                    
---------------Reference log start----------------
LOG.info(""Exiting recovery mode."")
---------------Reference log end----------------
                }
            }
        }",,
activemq,18303,"LOG.warn(""Error receiving message "" + e.getMessage() + "". This exception is ignored."", e)",warn,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/AjaxListener.java/#L78,"@Override
    public synchronized void onMessageAvailable(MessageConsumer consumer) {
        LOG.debug(""Message for consumer: {} continuation: {}"", consumer, continuation);

        if (continuation != null) {
            try {
                Message message = consumer.receive(10);
                LOG.debug(""message is "" + message);
                if (message != null) {
                    if (!continuation.isResumed()) {
                        LOG.debug(""Resuming suspended continuation {}"", continuation);
                        continuation.setAttribute(""undelivered_message"", new UndeliveredAjaxMessage(message, consumer));
                        continuation.resume();
                    } else {
                        LOG.debug(""Message available, but continuation is already resumed. Buffer for next time."");
                        bufferMessageForDelivery(message, consumer);
                    }
                }
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.warn(""Error receiving message "" + e.getMessage() + "". This exception is ignored."", e)
---------------Reference log end----------------
            }

        } else if (System.currentTimeMillis() - lastAccess > 2 * this.maximumReadTimeout) {
            new Thread() {
                @Override
                public void run() {
                    LOG.debug(""Closing consumers on client: {}"", client);
                    client.closeConsumers();
                }
            }.start();
        } else {
            try {
                Message message = consumer.receive(10);
                bufferMessageForDelivery(message, consumer);
            } catch (Exception e) {
                LOG.warn(""Error receiving message "" + e.getMessage() + "". This exception is ignored."", e);
            }
        }
    }",,
activemq,19397,"log.debug(this + "", setting [useSessionArgs] to: "" + useSessionArgs)",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ActiveMQConnectionSupport.java/#L497,"public void setUseSessionArgs(Boolean useSessionArgs) {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(this + "", setting [useSessionArgs] to: "" + useSessionArgs)
---------------Reference log end----------------
        }
        info.setUseSessionArgs(useSessionArgs);
    }",,
activemq,18941,"LOG.warn(""After clear of pending, failed to dispatch to: {}, for: {}, pending: {}, exception: {}"", durableTopicSubscription, destination, durableTopicSubscription.pending, exception)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Topic.java/#L897,"private void clearPendingAndDispatch(DurableTopicSubscription durableTopicSubscription) {
        synchronized (durableTopicSubscription.pendingLock) {
            durableTopicSubscription.pending.clear();
            try {
                durableTopicSubscription.dispatchPending();
            } catch (IOException exception) {
                
---------------Reference log start----------------
LOG.warn(""After clear of pending, failed to dispatch to: {}, for: {}, pending: {}, exception: {}"", durableTopicSubscription, destination, durableTopicSubscription.pending, exception)
---------------Reference log end----------------
            }
        }
    }",,
activemq,17996,"LOG.debug(""Moving data file {} to {} "", dataFile, directoryArchive.getCanonicalPath())",debug,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/disk/journal/Journal.java/#L832,"private void forceRemoveDataFile(DataFile dataFile) throws IOException {
        accessorPool.disposeDataFileAccessors(dataFile);
        totalLength.addAndGet(-dataFile.getLength());
        if (archiveDataLogs) {
            File directoryArchive = getDirectoryArchive();
            if (directoryArchive.exists()) {
                LOG.debug(""Archive directory exists: {}"", directoryArchive);
            } else {
                if (directoryArchive.isAbsolute())
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Archive directory [{}] does not exist - creating it now"",
                            directoryArchive.getAbsolutePath());
                }
                IOHelper.mkdirs(directoryArchive);
            }
            
---------------Reference log start----------------
LOG.debug(""Moving data file {} to {} "", dataFile, directoryArchive.getCanonicalPath())
---------------Reference log end----------------
            dataFile.move(directoryArchive);
            LOG.debug(""Successfully moved data file"");
        } else {
            LOG.debug(""Deleting data file: {}"", dataFile);
            if (dataFile.delete()) {
                LOG.debug(""Discarded data file: {}"", dataFile);
            } else {
                LOG.warn(""Failed to discard data file : {}"", dataFile.getFile());
            }
        }
        if (dataFileRemovedListener != null) {
            dataFileRemovedListener.fileRemoved(dataFile);
        }
    }",,
activemq,18165,"log.debug(""Ramp down end"")",debug,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/sampler/AbstractPerformanceSampler.java/#L207,"@Override
    public void run() {
        try {
            log.debug(""Ramp up start"");
            onRampUpStart();
            if (perfEventListener != null) {
                perfEventListener.onRampUpStart(this);
            }

            if (rampUpTime > 0) {
                try {
                    Thread.sleep(rampUpTime);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }

            log.debug(""Sampler start"");
            onSamplerStart();
            if (perfEventListener != null) {
                perfEventListener.onSamplerStart(this);
            }

            sample();

            log.debug(""Sampler end"");
            onSamplerEnd();
            if (perfEventListener != null) {
                perfEventListener.onSamplerEnd(this);
            }

            if (rampDownTime > 0) {
                try {
                    Thread.sleep(rampDownTime);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }

            
---------------Reference log start----------------
log.debug(""Ramp down end"")
---------------Reference log end----------------
            onRampDownEnd();
            if (perfEventListener != null) {
                perfEventListener.onRampDownEnd(this);
            }
        } finally {
            completionLatch.countDown();
        }
    }",,
activemq,18258,"LOG.trace(""Server: Received from client: {} bytes"", frame.getLength())",trace,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpConnection.java/#L372,"@SuppressWarnings(""deprecation"")
    @Override
    public void onAMQPData(Object command) throws Exception {
        Buffer frame;
        if (command.getClass() == AmqpHeader.class) {
            AmqpHeader header = (AmqpHeader) command;

            if (amqpWireFormat.isHeaderValid(header, authenticator != null)) {
                LOG.trace(""Connection from an AMQP v1.0 client initiated. {}"", header);
            } else {
                LOG.warn(""Connection attempt from non AMQP v1.0 client. {}"", header);
                AmqpHeader reply = amqpWireFormat.getMinimallySupportedHeader();
                amqpTransport.sendToAmqp(reply.getBuffer());
                handleException(new AmqpProtocolException(
                    ""Connection from client using unsupported AMQP attempted"", true));
            }

            switch (header.getProtocolId()) {
                case 0:
                    authenticator = null;
                    break; // nothing to do..
                case 3: // Client will be using SASL for auth..
                    authenticator = new AmqpAuthenticator(amqpTransport, protonTransport.sasl(), brokerService);
                    break;
                default:
            }
            frame = header.getBuffer();
        } else {
            frame = (Buffer) command;
        }

        if (protonTransport.isClosed()) {
            LOG.debug(""Ignoring incoming AMQP data, transport is closed."");
            return;
        }

        
---------------Reference log start----------------
LOG.trace(""Server: Received from client: {} bytes"", frame.getLength())
---------------Reference log end----------------

        while (frame.length > 0) {
            try {
                int count = protonTransport.input(frame.data, frame.offset, frame.length);
                frame.moveHead(count);
            } catch (Throwable e) {
                handleException(new AmqpProtocolException(""Could not decode AMQP frame: "" + frame, true, e));
                return;
            }

            if (authenticator != null) {
                processSaslExchange();
            } else {
                processProtonEvents();
            }
        }
    }",,
activemq,18942,"log.debug(""Creating DOT file at: {}"", file)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/view/DotFileInterceptorSupport.java/#L43,"protected void generateFile() throws Exception {
        
---------------Reference log start----------------
log.debug(""Creating DOT file at: {}"", file)
---------------Reference log end----------------
        PrintWriter writer = new PrintWriter(new FileWriter(file));
        try {
            generateFile(writer);
        } finally {
            writer.close();
        }
    }",,
activemq,19699,"LOG.debug(""No message received since last read check for {}. Throwing InactivityIOException."", this)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/AbstractInactivityMonitor.java/#L241,"final void readCheck() {
        int currentCounter = next.getReceiveCounter();
        int previousCounter = lastReceiveCounter.getAndSet(currentCounter);
        if (inReceive.get() || currentCounter != previousCounter) {
            LOG.trace(""A receive is in progress, skipping read check."");
            return;
        }
        if (!commandReceived.get() && monitorStarted.get() && !ASYNC_TASKS.isShutdown()) {
            
---------------Reference log start----------------
LOG.debug(""No message received since last read check for {}. Throwing InactivityIOException."", this)
---------------Reference log end----------------

            try {
                ASYNC_TASKS.execute(new Runnable() {
                    @Override
                    public void run() {
                        LOG.debug(""Running {}"", this);
                        onException(new InactivityIOException(""Channel was inactive for too (>"" + readCheckTime + "") long: "" + next.getRemoteAddress()));
                    }

                    @Override
                    public String toString() {
                        return ""ReadCheck["" + getRemoteAddress() + ""]"";
                    };
                });
            } catch (RejectedExecutionException ex) {
                if (!ASYNC_TASKS.isShutdown()) {
                    LOG.warn(""Async read check was rejected from the executor: "", ex);
                }
            }
        } else {
            if (LOG.isTraceEnabled()) {
                LOG.trace(""Message received since last read check, resetting flag: {}"", this);
            }
        }
        commandReceived.set(false);
    }",,
activemq,17772,"LOG.warn(getLeaseHolderId() + "" lease acquire failure: "" + e, e)",warn,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/LeaseDatabaseLocker.java/#L86,"public void doStart() throws Exception {

        if (lockAcquireSleepInterval < lockable.getLockKeepAlivePeriod()) {
            LOG.warn(""LockableService keep alive period: "" + lockable.getLockKeepAlivePeriod()
                    + "", which renews the lease, is greater than lockAcquireSleepInterval: "" + lockAcquireSleepInterval
                    + "", the lease duration. These values will allow the lease to expire."");
        }

        LOG.info(getLeaseHolderId() + "" attempting to acquire exclusive lease to become the master"");
        String sql = getStatements().getLeaseObtainStatement();
        LOG.debug(getLeaseHolderId() + "" locking Query is ""+sql);

        long now = 0l;
        while (!isStopping()) {
            Connection connection = null;
            PreparedStatement statement = null;
            try {
                connection = getConnection();
                initTimeDiff(connection);

                statement = connection.prepareStatement(sql);
                setQueryTimeout(statement);

                now = System.currentTimeMillis() + diffFromCurrentTime;
                statement.setString(1, getLeaseHolderId());
                statement.setLong(2, now + lockAcquireSleepInterval);
                statement.setLong(3, now);

                int result = statement.executeUpdate();
                if (result == 1) {
                    // we got the lease, verify we still have it
                    if (keepAlive()) {
                        break;
                    }
                }

                reportLeasOwnerShipAndDuration(connection);

            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.warn(getLeaseHolderId() + "" lease acquire failure: "" + e, e)
---------------Reference log end----------------
                if (isStopping()) {
                    throw new Exception(
                            ""Cannot start broker as being asked to shut down. ""
                                    + ""Interrupted attempt to acquire lock: ""
                                    + e, e);
                }
                if (handleStartException) {
                    throw e;
                }
            } finally {
                close(statement);
                close(connection);
            }

            LOG.debug(getLeaseHolderId() + "" failed to acquire lease.  Sleeping for "" + lockAcquireSleepInterval + "" milli(s) before trying again..."");
            TimeUnit.MILLISECONDS.sleep(lockAcquireSleepInterval);
        }
        if (isStopping()) {
            throw new RuntimeException(getLeaseHolderId() + "" failing lease acquire due to stop"");
        }

        LOG.info(getLeaseHolderId() + "", becoming master with lease expiry "" + new Date(now + lockAcquireSleepInterval) + "" on dataSource: "" + dataSource);
    }",,
activemq,18838,"LOG.error(""Failed to determine if store is empty"", e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/cursors/TopicStorePrefetch.java/#L131,"@Override
    protected synchronized boolean isStoreEmpty() {
        try {
            return this.store.isEmpty();
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Failed to determine if store is empty"", e)
---------------Reference log end----------------
            throw new RuntimeException(e);
        }
    }",,
activemq,19730,"LOG.debug(""Caught an exception stopping existing transport for rebalance"", e)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/failover/FailoverTransport.java/#L959,"final boolean doReconnect() {
        Exception failure = null;
        synchronized (reconnectMutex) {
            List<URI> connectList = null;
            // First ensure we are up to date.
            doUpdateURIsFromDisk();

            if (disposed || connectionFailure != null) {
                reconnectMutex.notifyAll();
            }
            if ((connectedTransport.get() != null && !doRebalance && !priorityBackupAvailable) || disposed || connectionFailure != null) {
                return false;
            } else {
                connectList = getConnectList();
                if (connectList.isEmpty()) {
                    failure = new IOException(""No uris available to connect to."");
                } else {
                    if (doRebalance) {
                        if (connectedToPriority || compareURIs(connectList.get(0), connectedTransportURI)) {
                            // already connected to first in the list, no need to rebalance
                            doRebalance = false;
                            return false;
                        } else {
                            LOG.debug(""Doing rebalance from: {} to {}"", connectedTransportURI, connectList);

                            try {
                                Transport transport = this.connectedTransport.getAndSet(null);
                                if (transport != null) {
                                    disposeTransport(transport);
                                }
                            } catch (Exception e) {
                                
---------------Reference log start----------------
LOG.debug(""Caught an exception stopping existing transport for rebalance"", e)
---------------Reference log end----------------
                            }
                        }
                        doRebalance = false;
                    }

                    resetReconnectDelay();

                    Transport transport = null;
                    URI uri = null;

                    // If we have a backup already waiting lets try it.
                    synchronized (backupMutex) {
                        if ((priorityBackup || backup) && !backups.isEmpty()) {
                            ArrayList<BackupTransport> l = new ArrayList<BackupTransport>(backups);
                            if (randomize) {
                                Collections.shuffle(l);
                            }
                            BackupTransport bt = l.remove(0);
                            backups.remove(bt);
                            transport = bt.getTransport();
                            uri = bt.getUri();
                            processCommand(bt.getBrokerInfo());
                            if (priorityBackup && priorityBackupAvailable) {
                                Transport old = this.connectedTransport.getAndSet(null);
                                if (old != null) {
                                    disposeTransport(old);
                                }
                                priorityBackupAvailable = false;
                            }
                        }
                    }

                    // When there was no backup and we are reconnecting for the first time
                    // we honor the initialReconnectDelay before trying a new connection, after
                    // this normal reconnect delay happens following a failed attempt.
                    if (transport == null && !firstConnection && connectFailures == 0 && initialReconnectDelay > 0 && !disposed) {
                        // reconnectDelay will be equal to initialReconnectDelay since we are on
                        // the first connect attempt after we had a working connection, doDelay
                        // will apply updates to move to the next reconnectDelay value based on
                        // configuration.
                        doDelay();
                    }

                    Iterator<URI> iter = connectList.iterator();
                    while ((transport != null || iter.hasNext()) && (connectedTransport.get() == null && !disposed)) {

                        try {
                            SslContext.setCurrentSslContext(brokerSslContext);

                            // We could be starting with a backup and if so we wait to grab a
                            // URI from the pool until next time around.
                            if (transport == null) {
                                uri = addExtraQueryOptions(iter.next());
                                transport = TransportFactory.compositeConnect(uri);
                            }

                            LOG.debug(""Attempting {}th connect to: {}"", connectFailures, uri);

                            transport.setTransportListener(createTransportListener(transport));
                            transport.start();

                            if (started && !firstConnection) {
                                restoreTransport(transport);
                            }

                            LOG.debug(""Connection established"");

                            reconnectDelay = initialReconnectDelay;
                            connectedTransportURI = uri;
                            connectedTransport.set(transport);
                            connectedToPriority = isPriority(connectedTransportURI);
                            reconnectMutex.notifyAll();
                            connectFailures = 0;

                            // Make sure on initial startup, that the transportListener
                            // has been initialized for this instance.
                            synchronized (listenerMutex) {
                                if (transportListener == null) {
                                    try {
                                        // if it isn't set after 2secs - it probably never will be
                                        listenerMutex.wait(2000);
                                    } catch (InterruptedException ex) {
                                    }
                                }
                            }

                            if (transportListener != null) {
                                transportListener.transportResumed();
                            } else {
                                LOG.debug(""transport resumed by transport listener not set"");
                            }

                            if (firstConnection) {
                                firstConnection = false;
                                LOG.info(""Successfully connected to {}"", uri);
                            } else {
                                LOG.info(""Successfully reconnected to {}"", uri);
                            }

                            return false;
                        } catch (Exception e) {
                            failure = e;
                            LOG.debug(""Connect fail to: {}, reason: {}"", uri, e);
                            if (transport != null) {
                                try {
                                    transport.stop();
                                    transport = null;
                                } catch (Exception ee) {
                                    LOG.debug(""Stop of failed transport: {} failed with reason: {}"", transport, ee);
                                }
                            }
                        } finally {
                            SslContext.setCurrentSslContext(null);
                        }
                    }
                }
            }

            int reconnectLimit = calculateReconnectAttemptLimit();

            connectFailures++;
            if (reconnectLimit != INFINITE && connectFailures >= reconnectLimit) {
                LOG.error(""Failed to connect to {} after: {} attempt(s)"", connectList, connectFailures);
                connectionFailure = failure;

                // Make sure on initial startup, that the transportListener has been
                // initialized for this instance.
                synchronized (listenerMutex) {
                    if (transportListener == null) {
                        try {
                            listenerMutex.wait(2000);
                        } catch (InterruptedException ex) {
                        }
                    }
                }

                propagateFailureToExceptionListener(connectionFailure);
                return false;
            }

            int warnInterval = getWarnAfterReconnectAttempts();
            if (warnInterval > 0 && (connectFailures == 1 || (connectFailures % warnInterval) == 0)) {
                LOG.warn(""Failed to connect to {} after: {} attempt(s) with {}, continuing to retry."",
                         connectList, connectFailures, (failure == null ? ""?"" : failure.getLocalizedMessage()));
            }
        }

        if (!disposed) {
            doDelay();
        }

        return !disposed;
    }",,
activemq,19780,"LOG.debug(""Processing replay command: "" + command)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/reliable/ReliableTransport.java/#L286,"protected void replayCommands(ReplayCommand command) {
        try {
            if (replayer == null) {
                onException(new IOException(""Cannot replay commands. No replayer property configured""));
            }
            if (LOG.isDebugEnabled()) {
                
---------------Reference log start----------------
LOG.debug(""Processing replay command: "" + command)
---------------Reference log end----------------
            }
            getReplayBuffer().replayMessages(command.getFirstNakNumber(), command.getLastNakNumber(), replayer);

            // TODO we could proactively remove ack'd stuff from the replay
            // buffer
            // if we only have a single client talking to us
        } catch (IOException e) {
            onException(e);
        }
    }",,
activemq,18648,"LOG.debug(""Failed to read URI to build transportURIsAsMap"", e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L1385,"public Map<String, String> getTransportConnectorURIsAsMap() {
        Map<String, String> answer = new HashMap<>();
        for (TransportConnector connector : transportConnectors) {
            try {
                URI uri = connector.getConnectUri();
                if (uri != null) {
                    String scheme = uri.getScheme();
                    if (scheme != null) {
                        answer.put(scheme.toLowerCase(Locale.ENGLISH), uri.toString());
                    }
                }
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.debug(""Failed to read URI to build transportURIsAsMap"", e)
---------------Reference log end----------------
            }
        }
        return answer;
    }",,
activemq,19050,"LOG.info(""Stopping "" + broker + "" due to exception, "" + exception, exception)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/util/DefaultIOExceptionHandler.java/#L179,"private void stopBroker(Exception exception) {
        
---------------Reference log start----------------
LOG.info(""Stopping "" + broker + "" due to exception, "" + exception, exception)
---------------Reference log end----------------
        new Thread(""IOExceptionHandler: stopping "" + broker) {
            @Override
            public void run() {
                try {
                    if( broker.isRestartAllowed() ) {
                        broker.requestRestart();
                    }
                    broker.setSystemExitOnShutdown(isSystemExitOnShutdown());
                    broker.stop();
                } catch (Exception e) {
                    LOG.warn(""Failure occurred while stopping broker"", e);
                }
            }
        }.start();
    }",,
activemq,17841,"LOG.debug(""Could not get JDBC connection for checkpoint: "" + e, e)",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/JDBCPersistenceAdapter.java/#L717,"@Override
    public void checkpoint(boolean sync) throws IOException {
        // by pass TransactionContext to avoid IO Exception handler
        Connection connection = null;
        try {
            connection = getDataSource().getConnection();
            if (!connection.isValid(10)) {
                throw new IOException(""isValid(10) failed for: "" + connection);
            }
        } catch (SQLException e) {
            
---------------Reference log start----------------
LOG.debug(""Could not get JDBC connection for checkpoint: "" + e, e)
---------------Reference log end----------------
            throw IOExceptionSupport.create(e);
        } finally {
            if (connection != null) {
                try {
                    connection.close();
                } catch (Throwable ignored) {
                }
            }
        }
    }",,
activemq,18972,LOG.error(e.toString()),error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/security/LDAPAuthorizationMap.java/#L383,"protected Set<GroupPrincipal> getACLs(ActiveMQDestination destination, String roleBase, String roleAttribute) {
        try {
            context = open();
        } catch (NamingException e) {
            
---------------Reference log start----------------
LOG.error(e.toString())
---------------Reference log end----------------
            return new HashSet<GroupPrincipal>();
        }



        String destinationBase = """";
        SearchControls constraints = new SearchControls();
        if (AdvisorySupport.isAdvisoryTopic(destination) && useAdvisorySearchBase) {
            destinationBase = advisorySearchBase;
        } else {
            if ((destination.getDestinationType() & ActiveMQDestination.QUEUE_TYPE) == ActiveMQDestination.QUEUE_TYPE) {
                destinationBase = queueSearchMatchingFormat.format(new String[]{destination.getPhysicalName()});
                if (queueSearchSubtreeBool) {
                    constraints.setSearchScope(SearchControls.SUBTREE_SCOPE);
                } else {
                    constraints.setSearchScope(SearchControls.ONELEVEL_SCOPE);
                }
            }
            if ((destination.getDestinationType() & ActiveMQDestination.TOPIC_TYPE) == ActiveMQDestination.TOPIC_TYPE) {
                destinationBase = topicSearchMatchingFormat.format(new String[]{destination.getPhysicalName()});
                if (topicSearchSubtreeBool) {
                    constraints.setSearchScope(SearchControls.SUBTREE_SCOPE);
                } else {
                    constraints.setSearchScope(SearchControls.ONELEVEL_SCOPE);
                }
            }
        }

        constraints.setReturningAttributes(new String[] {roleAttribute});

        return getACLs(destinationBase, constraints, roleBase, roleAttribute);
    }",,
activemq,19503,"LOG.debug(""tx remove replayed producer :"" + producerState.getInfo())",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/state/ConnectionStateTracker.java/#L265,"private void restoreTransactions(Transport transport, ConnectionState connectionState) throws IOException {
        Vector<TransactionInfo> toRollback = new Vector<>();
        for (TransactionState transactionState : connectionState.getTransactionStates()) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(""tx: "" + transactionState.getId());
            }

            // rollback any completed transactions - no way to know if commit got there
            // or if reply went missing
            //
            if (!transactionState.getCommands().isEmpty()) {
                Command lastCommand = transactionState.getCommands().get(transactionState.getCommands().size() - 1);
                if (lastCommand instanceof TransactionInfo) {
                    TransactionInfo transactionInfo = (TransactionInfo) lastCommand;
                    if (transactionInfo.getType() == TransactionInfo.COMMIT_ONE_PHASE) {
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""rolling back potentially completed tx: "" + transactionState.getId());
                        }
                        toRollback.add(transactionInfo);
                        continue;
                    }
                }
            }

            // replay short lived producers that may have been involved in the transaction
            for (ProducerState producerState : transactionState.getProducerStates().values()) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""tx replay producer :"" + producerState.getInfo());
                }
                transport.oneway(producerState.getInfo());
            }

            for (Command command : transactionState.getCommands()) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""tx replay: "" + command);
                }
                transport.oneway(command);
            }

            for (ProducerState producerState : transactionState.getProducerStates().values()) {
                if (LOG.isDebugEnabled()) {
                    
---------------Reference log start----------------
LOG.debug(""tx remove replayed producer :"" + producerState.getInfo())
---------------Reference log end----------------
                }
                transport.oneway(producerState.getInfo().createRemoveCommand());
            }
        }

        for (TransactionInfo command: toRollback) {
            // respond to the outstanding commit
            ExceptionResponse response = new ExceptionResponse();
            response.setException(new TransactionRolledBackException(""Transaction completion in doubt due to failover. Forcing rollback of "" + command.getTransactionId()));
            response.setCorrelationId(command.getCommandId());
            transport.getTransportListener().onCommand(response);
        }
    }",,
activemq,19166,"LOG.info(""{}, static destination excluded: {}"", configuration.getBrokerName(), dest)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L1405,"protected void setupStaticDestinations() {
        ActiveMQDestination[] dests = staticallyIncludedDestinations;
        if (dests != null) {
            for (ActiveMQDestination dest : dests) {
                if (isPermissableDestination(dest)) {
                    DemandSubscription sub = createDemandSubscription(dest, null);
                    if (sub != null) {
                        sub.setStaticallyIncluded(true);
                        try {
                            addSubscription(sub);
                        } catch (IOException e) {
                            LOG.error(""Failed to add static destination {}"", dest, e);
                        }
                        LOG.trace(""{}, bridging messages for static destination: {}"", configuration.getBrokerName(), dest);
                    } else {
                        LOG.info(""{}, static destination excluded: {}, demand already exists"", configuration.getBrokerName(), dest);
                    }
                } else {
                    
---------------Reference log start----------------
LOG.info(""{}, static destination excluded: {}"", configuration.getBrokerName(), dest)
---------------Reference log end----------------
                }
            }
        }
    }",,
activemq,18758,"LOG.debug(""recovered prepared transaction: {}"", transaction.getTransactionId())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransactionBroker.java/#L108,"public void recover(XATransactionId xid, Message[] addedMessages, MessageAck[] aks) {
                    try {
                        beginTransaction(context, xid);
                        XATransaction transaction = (XATransaction) getTransaction(context, xid, false);
                        for (int i = 0; i < addedMessages.length; i++) {
                            forceDestinationWakeupOnCompletion(context, transaction, addedMessages[i].getDestination(), addedMessages[i]);
                        }
                        for (int i = 0; i < aks.length; i++) {
                            forceDestinationWakeupOnCompletion(context, transaction, aks[i].getDestination(), aks[i]);
                        }
                        transaction.setState(Transaction.PREPARED_STATE);
                        registerMBean(transaction);
                        
---------------Reference log start----------------
LOG.debug(""recovered prepared transaction: {}"", transaction.getTransactionId())
---------------Reference log end----------------
                    } catch (Throwable e) {
                        throw new WrappedException(e);
                    }
                }",,
activemq,18811,"LOG.error(""Failed to get current cursor "", e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/cursors/StoreDurableSubscriberCursor.java/#L254,"@Override
    public synchronized boolean hasNext() {
        boolean result = true;
        if (result) {
            try {
                currentCursor = getNextCursor();
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.error(""Failed to get current cursor "", e)
---------------Reference log end----------------
                throw new RuntimeException(e);
            }
            result = currentCursor != null ? currentCursor.hasNext() : false;
        }
        return result;
    }",,
activemq,17833,"LOG.info(""Using a separate dataSource for locking: "" + lockDataSource)",info,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/JDBCPersistenceAdapter.java/#L434,"public void setLockDataSource(DataSource dataSource) {
        this.lockDataSource = dataSource;
        
---------------Reference log start----------------
LOG.info(""Using a separate dataSource for locking: "" + lockDataSource)
---------------Reference log end----------------
    }
    }",,
activemq,18173,"LOG.info(""Temporary topic created: {}"", temporaryTopic.getTopicName())",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/AbstractJmsClient.java/#L264,"protected Destination createTemporaryDestination(String destName) throws JMSException {
        byte destinationType = getDestinationType(destName);

        if (destinationType == ActiveMQDestination.TEMP_QUEUE_TYPE) {
            LOG.warn(""Creating temporary queue. Requested name ({}) ignored."", destName);
            TemporaryQueue temporaryQueue = getSession().createTemporaryQueue();
            LOG.info(""Temporary queue created: {}"", temporaryQueue.getQueueName());
            return temporaryQueue;
        } else if (destinationType == ActiveMQDestination.TEMP_TOPIC_TYPE) {
            LOG.warn(""Creating temporary topic. Requested name ({}) ignored."", destName);
            TemporaryTopic temporaryTopic = getSession().createTemporaryTopic();
            
---------------Reference log start----------------
LOG.info(""Temporary topic created: {}"", temporaryTopic.getTopicName())
---------------Reference log end----------------
            return temporaryTopic;
        } else {
            throw new IllegalArgumentException(""Unrecognized destination type: "" + destinationType);
        }
    }",,
activemq,19231,"LOG.debug(""Start failure exception: "", e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DiscoveryNetworkConnector.java/#L170,"@Override
    public void onServiceAdd(DiscoveryEvent event) {
        // Ignore events once we start stopping.
        if (serviceSupport.isStopped() || serviceSupport.isStopping()) {
            return;
        }
        String url = event.getServiceName();
        if (url != null) {
            URI uri;
            try {
                uri = new URI(url);
            } catch (URISyntaxException e) {
                LOG.warn(""Could not connect to remote URI: {} due to bad URI syntax: "", url, e);
                return;
            }

            if (localURI.equals(uri)) {
                LOG.debug(""not connecting loopback: {}"", uri);
                return;
            }

            if (connectionFilter != null && !connectionFilter.connectTo(uri)) {
                LOG.debug(""connectionFilter disallows connection to: {}"", uri);
                return;
            }

            // Should we try to connect to that URI?
            if (activeEvents.putIfAbsent(uri, event) != null) {
                LOG.debug(""Discovery agent generated a duplicate onServiceAdd event for: {}"", uri);
                return;
            }

            URI connectUri = uri;
            try {
                connectUri = URISupport.applyParameters(connectUri, parameters, DISCOVERED_OPTION_PREFIX);
            } catch (URISyntaxException e) {
                LOG.warn(""could not apply query parameters: {} to: {}"",parameters, connectUri, e);
            }

            LOG.info(""Establishing network connection from {} to {}"", localURI, connectUri);

            Transport remoteTransport;
            Transport localTransport;
            try {
                // Allows the transport to access the broker's ssl configuration.
                if (getSslContext() != null) {
                    SslContext.setCurrentSslContext(getSslContext());
                } else {
                    SslContext.setCurrentSslContext(getBrokerService().getSslContext());
                }
                try {
                    remoteTransport = TransportFactory.connect(connectUri);
                } catch (Exception e) {
                    LOG.warn(""Could not connect to remote URI: {}: {}"", connectUri, e.getMessage());
                    LOG.debug(""Connection failure exception: "", e);
                    try {
                        discoveryAgent.serviceFailed(event);
                    } catch (IOException e1) {
                        LOG.debug(""Failure while handling create remote transport failure event: {}"", e1.getMessage(), e1);
                    }
                    return;
                }
                try {
                    localTransport = createLocalTransport();
                } catch (Exception e) {
                    ServiceSupport.dispose(remoteTransport);
                    LOG.warn(""Could not connect to local URI: {}: {}"", localURI, e.getMessage());
                    LOG.debug(""Connection failure exception: "", e);

                    try {
                        discoveryAgent.serviceFailed(event);
                    } catch (IOException e1) {
                        LOG.debug(""Failure while handling create local transport failure event: {}"", e1.getMessage(), e1);
                    }
                    return;
                }
            } finally {
                SslContext.setCurrentSslContext(null);
            }
            NetworkBridge bridge = createBridge(localTransport, remoteTransport, event);
            try {
                synchronized (bridges) {
                    bridges.put(uri, bridge);
                }
                bridge.start();
            } catch (Exception e) {
                ServiceSupport.dispose(localTransport);
                ServiceSupport.dispose(remoteTransport);
                LOG.warn(""Could not start network bridge between: {} and: {} due to: {}"", localURI, uri, e.getMessage());
                
---------------Reference log start----------------
LOG.debug(""Start failure exception: "", e)
---------------Reference log end----------------
                try {
                    // Will remove bridge and active event.
                    discoveryAgent.serviceFailed(event);
                } catch (IOException e1) {
                    LOG.debug(""Discovery agent failure while handling failure event: {}"", e1.getMessage(), e1);
                }
            }
        }
    }",,
activemq,18335,"LOG.debug(""sending final available messages"")",debug,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/MessageListenerServlet.java/#L417,"protected void doMessages(AjaxWebClient client, HttpServletRequest request, HttpServletResponse response) throws JMSException, IOException {

        int messages = 0;
        // This is a poll for any messages

        long timeout = getReadTimeout(request);
        if (LOG.isDebugEnabled()) {
            LOG.debug(""doMessage timeout="" + timeout);
        }

        // this is non-null if we're resuming the continuation.
        // attributes set in AjaxListener
        UndeliveredAjaxMessage undelivered_message = null;
        Message message = null;
        undelivered_message = (UndeliveredAjaxMessage)request.getAttribute(""undelivered_message"");
        if( undelivered_message != null ) {
            message = undelivered_message.getMessage();
        }

        synchronized (client) {

            List<MessageConsumer> consumers = client.getConsumers();
            MessageAvailableConsumer consumer = null;
            if( undelivered_message != null ) {
                consumer = (MessageAvailableConsumer)undelivered_message.getConsumer();
            }

            if (message == null) {
                // Look for a message that is ready to go
                for (int i = 0; message == null && i < consumers.size(); i++) {
                    consumer = (MessageAvailableConsumer)consumers.get(i);
                    if (consumer.getAvailableListener() == null) {
                        continue;
                    }

                    // Look for any available messages
                    message = consumer.receive(10);
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""received "" + message + "" from "" + consumer);
                    }
                }
            }

            // prepare the response
            response.setContentType(""text/xml"");
            response.setHeader(""Cache-Control"", ""no-cache"");

            if (message == null && client.getListener().getUndeliveredMessages().size() == 0) {
                Continuation continuation = ContinuationSupport.getContinuation(request);

                // Add a listener to the continuation to make sure it actually
                // will expire (seems like a bug in Jetty Servlet 3 continuations,
                // see https://issues.apache.org/jira/browse/AMQ-3447
                continuation.addContinuationListener(new ContinuationListener() {
                    @Override
                    public void onTimeout(Continuation cont) {
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Continuation "" + cont.toString() + "" expired."");
                        }
                    }

                    @Override
                    public void onComplete(Continuation cont) {
                        if (LOG.isDebugEnabled()) {
                           LOG.debug(""Continuation "" + cont.toString() + "" completed."");
                        }
                    }
                });

                if (continuation.isExpired()) {
                    response.setStatus(HttpServletResponse.SC_OK);
                    StringWriter swriter = new StringWriter();
                    PrintWriter writer = new PrintWriter(swriter);
                    writer.println(""<ajax-response>"");
                    writer.print(""</ajax-response>"");

                    writer.flush();
                    String m = swriter.toString();
                    response.getWriter().println(m);

                    return;
                }

                continuation.setTimeout(timeout);
                continuation.suspend();
                LOG.debug( ""Suspending continuation "" + continuation );

                // Fetch the listeners
                AjaxListener listener = client.getListener();
                listener.access();

                // register this continuation with our listener.
                listener.setContinuation(continuation);

                return;
            }

            StringWriter swriter = new StringWriter();
            PrintWriter writer = new PrintWriter(swriter);

            Map<MessageAvailableConsumer, String> consumerIdMap = client.getIdMap();
            Map<MessageAvailableConsumer, String> consumerDestinationNameMap = client.getDestinationNameMap();
            response.setStatus(HttpServletResponse.SC_OK);
            writer.println(""<ajax-response>"");

            // Send any message we already have
            if (message != null) {
                String id = consumerIdMap.get(consumer);
                String destinationName = consumerDestinationNameMap.get(consumer);
                LOG.debug( ""sending pre-existing message"" );
                writeMessageResponse(writer, message, id, destinationName);

                messages++;
            }

            // send messages buffered while continuation was unavailable.
            LinkedList<UndeliveredAjaxMessage> undeliveredMessages = ((AjaxListener)consumer.getAvailableListener()).getUndeliveredMessages();
            LOG.debug(""Send "" + undeliveredMessages.size() + "" unconsumed messages"");
            synchronized( undeliveredMessages ) {
                for (Iterator<UndeliveredAjaxMessage> it = undeliveredMessages.iterator(); it.hasNext();) {
                    messages++;
                    UndeliveredAjaxMessage undelivered = it.next();
                    Message msg = undelivered.getMessage();
                    consumer = (MessageAvailableConsumer)undelivered.getConsumer();
                    String id = consumerIdMap.get(consumer);
                    String destinationName = consumerDestinationNameMap.get(consumer);
                    LOG.debug( ""sending undelivered/buffered messages"" );
                    LOG.debug( ""msg:"" +msg+ "", id:"" +id+ "", destinationName:"" +destinationName);
                    writeMessageResponse(writer, msg, id, destinationName);
                    it.remove();
                    if (messages >= maximumMessages) {
                        break;
                    }
                }
            }

            // Send the rest of the messages
            for (int i = 0; i < consumers.size() && messages < maximumMessages; i++) {
                consumer = (MessageAvailableConsumer)consumers.get(i);
                if (consumer.getAvailableListener() == null) {
                    continue;
                }

                // Look for any available messages
                while (messages < maximumMessages) {
                    message = consumer.receiveNoWait();
                    if (message == null) {
                        break;
                    }
                    messages++;
                    String id = consumerIdMap.get(consumer);
                    String destinationName = consumerDestinationNameMap.get(consumer);
                    
---------------Reference log start----------------
LOG.debug(""sending final available messages"")
---------------Reference log end----------------
                    writeMessageResponse(writer, message, id, destinationName);
                }
            }

            writer.print(""</ajax-response>"");

            writer.flush();
            String m = swriter.toString();
            response.getWriter().println(m);
        }
    }",,
activemq,19594,"LOG.info(threadName + "" Elapsed time in milli second : "" + (tEnd - tStart) + "" milli seconds"")",info,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/util/ProducerThread.java/#L94,"public void run() {
        MessageProducer producer = null;
        String threadName = Thread.currentThread().getName();
        try {
            producer = session.createProducer(destination);
            producer.setDeliveryMode(persistent ? DeliveryMode.PERSISTENT : DeliveryMode.NON_PERSISTENT);
            producer.setTimeToLive(msgTTL);
            initPayLoad();
            running = true;

            LOG.info(threadName +  "" Started to calculate elapsed time ...\n"");
            long tStart = System.currentTimeMillis();

            if (runIndefinitely) {
                while (running) {
                    synchronized (this) {
                        paused.await();
                    }
                    sendMessage(producer, threadName);
                    sentCount.incrementAndGet();
                }
            }else{
                for (sentCount.set(0); sentCount.get() < messageCount && running; sentCount.incrementAndGet()) {
                    synchronized (this) {
                        paused.await();
                    }
                    sendMessage(producer, threadName);
                }
            }

            LOG.info(threadName + "" Produced: "" + this.getSentCount() + "" messages"");
            long tEnd = System.currentTimeMillis();
            long elapsed = (tEnd - tStart) / 1000;
            LOG.info(threadName + "" Elapsed time in second : "" + elapsed + "" s"");
            
---------------Reference log start----------------
LOG.info(threadName + "" Elapsed time in milli second : "" + (tEnd - tStart) + "" milli seconds"")
---------------Reference log end----------------

        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            if (finished != null) {
                finished.countDown();
            }
            if (producer != null) {
                try {
                    producer.close();
                } catch (JMSException e) {
                    e.printStackTrace();
                }
            }
        }
    }",,
activemq,19493,"LOG.trace(""ConsumerInfo advisory all ready routed once through target broker ("" + networkBrokerId + ""), path: "" + Arrays.toString(info.getBrokerPath()) + "" - ignoring: "" + message)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/command/NetworkBridgeFilter.java/#L121,"protected boolean matchesForwardingFilter(Message message, MessageEvaluationContext mec) {

        if (contains(message.getBrokerPath(), networkBrokerId)) {
            if (LOG.isTraceEnabled()) {
                LOG.trace(""Message all ready routed once through target broker (""
                        + networkBrokerId + ""), path: ""
                        + Arrays.toString(message.getBrokerPath()) + "" - ignoring: "" + message);
            }
            return false;
        }

        int hops = message.getBrokerPath() == null ? 0 : message.getBrokerPath().length;

        if (messageTTL > -1 && hops >= messageTTL) {
            if (LOG.isTraceEnabled()) {
                LOG.trace(""Message restricted to "" + messageTTL + "" network hops ignoring: "" + message);
            }
            return false;
        }

        if (message.isAdvisory()) {
            if (consumerInfo != null && consumerInfo.isNetworkSubscription() && isAdvisoryInterpretedByNetworkBridge(message)) {
                // they will be interpreted by the bridge leading to dup commands
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""not propagating advisory to network sub: "" + consumerInfo.getConsumerId() + "", message: ""+ message);
                }
                return false;
            } else if ( message.getDataStructure() != null && message.getDataStructure().getDataStructureType() == CommandTypes.CONSUMER_INFO) {
                ConsumerInfo info = (ConsumerInfo)message.getDataStructure();
                hops = info.getBrokerPath() == null ? 0 : info.getBrokerPath().length;
                if (consumerTTL > -1 && hops >= consumerTTL) {
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(""ConsumerInfo advisory restricted to "" + consumerTTL + "" network hops ignoring: "" + message);
                    }
                    return false;
                }

                if (contains(info.getBrokerPath(), networkBrokerId)) {
                    
---------------Reference log start----------------
LOG.trace(""ConsumerInfo advisory all ready routed once through target broker ("" + networkBrokerId + ""), path: "" + Arrays.toString(info.getBrokerPath()) + "" - ignoring: "" + message)
---------------Reference log end----------------
                    return false;
                }
            }
        }
        return true;
    }",,
activemq,19453,"LOG.trace(""beforeEnd ack {}"", ack)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQSession.java/#L957,"@Override
                            public void beforeEnd() throws Exception {
                                // validate our consumer so we don't push stale acks that get ignored
                                if (ack.getTransactionId().isXATransaction() && !connection.hasDispatcher(ack.getConsumerId())) {
                                    LOG.debug(""forcing rollback - {} consumer no longer active on {}"", ack, connection);
                                    throw new TransactionRolledBackException(""consumer "" + ack.getConsumerId() + "" no longer active on "" + connection);
                                }
                                
---------------Reference log start----------------
LOG.trace(""beforeEnd ack {}"", ack)
---------------Reference log end----------------
                                sendAck(ack);
                            }",,
activemq,17938,"LOG.trace(""Error loading command during ack forward: {}"", nextLocation)",trace,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L2195,"private void forwardAllAcks(Integer journalToRead, Set<Integer> journalLogsReferenced) throws IllegalStateException, IOException {
        LOG.trace(""Attempting to move all acks in journal:{} to the front. Referenced files:{}"", journalToRead, journalLogsReferenced);

        DataFile forwardsFile = journal.reserveDataFile();
        forwardsFile.setTypeCode(COMPACTED_JOURNAL_FILE);
        LOG.trace(""Reserved file for forwarded acks: {}"", forwardsFile);

        Map<Integer, Set<Integer>> updatedAckLocations = new HashMap<>();

        try (TargetedDataFileAppender appender = new TargetedDataFileAppender(journal, forwardsFile);) {
            KahaRewrittenDataFileCommand compactionMarker = new KahaRewrittenDataFileCommand();
            compactionMarker.setSourceDataFileId(journalToRead);
            compactionMarker.setRewriteType(forwardsFile.getTypeCode());

            ByteSequence payload = toByteSequence(compactionMarker);
            appender.storeItem(payload, Journal.USER_RECORD_TYPE, false);
            LOG.trace(""Marked ack rewrites file as replacing file: {}"", journalToRead);

            final Location limit = new Location(journalToRead + 1, 0);
            Location nextLocation = getNextLocationForAckForward(new Location(journalToRead, 0), limit);
            while (nextLocation != null) {
                JournalCommand<?> command = null;
                try {
                    command = load(nextLocation);
                } catch (IOException ex) {
                    
---------------Reference log start----------------
LOG.trace(""Error loading command during ack forward: {}"", nextLocation)
---------------Reference log end----------------
                }

                if (shouldForward(command)) {
                    payload = toByteSequence(command);
                    Location location = appender.storeItem(payload, Journal.USER_RECORD_TYPE, false);
                    updatedAckLocations.put(location.getDataFileId(), journalLogsReferenced);
                }

                nextLocation = getNextLocationForAckForward(nextLocation, limit);
            }
        }

        LOG.trace(""ACKS forwarded, updates for ack locations: {}"", updatedAckLocations);

        // Lock index while we update the ackMessageFileMap.
        indexLock.writeLock().lock();

        // Update the ack map with the new locations of the acks
        for (Entry<Integer, Set<Integer>> entry : updatedAckLocations.entrySet()) {
            Set<Integer> referenceFileIds = metadata.ackMessageFileMap.get(entry.getKey());
            if (referenceFileIds == null) {
                referenceFileIds = new HashSet<>();
                referenceFileIds.addAll(entry.getValue());
                metadata.ackMessageFileMap.put(entry.getKey(), referenceFileIds);
                metadata.ackMessageFileMapDirtyFlag.lazySet(true);
            } else {
                referenceFileIds.addAll(entry.getValue());
            }
        }

        // remove the old location data from the ack map so that the old journal log file can
        // be removed on next GC.
        metadata.ackMessageFileMap.remove(journalToRead);
        metadata.ackMessageFileMapDirtyFlag.lazySet(true);

        indexLock.writeLock().unlock();

        LOG.trace(""ACK File Map following updates: {}"", metadata.ackMessageFileMap);
    }",,
activemq,19265,"LOG.warn(""Failed to register "" + destination, e)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/MBeanBridgeDestination.java/#L75,"public void onOutboundMessage(Message message) {
        ActiveMQDestination destination = message.getDestination();
        NetworkDestinationContainer networkDestinationContainer;

        if ((networkDestinationContainer = outboundDestinationViewMap.get(destination)) == null) {
            ObjectName bridgeObjectName = bridge.getMbeanObjectName();
            try {
                ObjectName objectName = BrokerMBeanSupport.createNetworkOutBoundDestinationObjectName(bridgeObjectName, destination);
                NetworkDestinationView networkDestinationView = new NetworkDestinationView(networkBridgeView, destination.getPhysicalName());
                AnnotatedMBean.registerMBean(brokerService.getManagementContext(), networkDestinationView, objectName);

                networkDestinationContainer = new NetworkDestinationContainer(networkDestinationView, objectName);
                outboundDestinationViewMap.put(destination, networkDestinationContainer);
                networkDestinationView.messageSent();
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.warn(""Failed to register "" + destination, e)
---------------Reference log end----------------
            }
        } else {
            networkDestinationContainer.view.messageSent();
        }
    }",,
activemq,18063,"LOG.debug(""Cleanup removing the data files: "" + gcCandidateSet)",debug,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/scheduler/JobSchedulerStoreImpl.java/#L437,"@Override
    protected void checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
        LOG.debug(""Job Scheduler Store Checkpoint started."");

        // reflect last update exclusive of current checkpoint
        Location lastUpdate = metaData.getLastUpdateLocation();
        metaData.setState(KahaDBMetaData.OPEN_STATE);
        tx.store(metaData.getPage(), metaDataMarshaller, true);
        pageFile.flush();

        if (cleanup) {
            final TreeSet<Integer> completeFileSet = new TreeSet<Integer>(journal.getFileMap().keySet());
            final TreeSet<Integer> gcCandidateSet = new TreeSet<Integer>(completeFileSet);

            LOG.trace(""Last update: {}, full gc candidates set: {}"", lastUpdate, gcCandidateSet);

            if (lastUpdate != null) {
                gcCandidateSet.remove(lastUpdate.getDataFileId());
            }

            this.metaData.getJournalRC().visit(tx, new BTreeVisitor<Integer, Integer>() {

                @Override
                public void visit(List<Integer> keys, List<Integer> values) {
                    for (Integer key : keys) {
                        if (gcCandidateSet.remove(key)) {
                            LOG.trace(""Removed referenced file: {} from GC set"", key);
                        }
                    }
                }

                @Override
                public boolean isInterestedInKeysBetween(Integer first, Integer second) {
                    return true;
                }
            });

            LOG.trace(""gc candidates after reference check: {}"", gcCandidateSet);

            // If there are GC candidates then check the remove command location to see
            // if any of them can go or if they must stay in order to ensure proper recover.
            //
            // A log containing any remove commands must be kept until all the logs with the
            // add commands for all the removed jobs have been dropped.
            if (!gcCandidateSet.isEmpty()) {
                Iterator<Entry<Integer, List<Integer>>> removals = metaData.getRemoveLocationTracker().iterator(tx);
                List<Integer> orphans = new ArrayList<Integer>();
                while (removals.hasNext()) {
                    boolean orphanedRemove = true;
                    Entry<Integer, List<Integer>> entry = removals.next();

                    // If this log is not a GC candidate then there's no need to do a check to rule it out
                    if (gcCandidateSet.contains(entry.getKey())) {
                        for (Integer addLocation : entry.getValue()) {
                            if (completeFileSet.contains(addLocation)) {
                                LOG.trace(""A remove in log {} has an add still in existance in {}."", entry.getKey(), addLocation);
                                orphanedRemove = false;
                                break;
                            }
                        }

                        // If it's not orphaned than we can't remove it, otherwise we
                        // stop tracking it it's log will get deleted on the next check.
                        if (!orphanedRemove) {
                            gcCandidateSet.remove(entry.getKey());
                        } else {
                            LOG.trace(""All removes in log {} are orphaned, file can be GC'd"", entry.getKey());
                            orphans.add(entry.getKey());
                        }
                    }
                }

                // Drop all orphaned removes from the tracker.
                for (Integer orphan : orphans) {
                    metaData.getRemoveLocationTracker().remove(tx, orphan);
                }
            }

            LOG.trace(""gc candidates after removals check: {}"", gcCandidateSet);
            if (!gcCandidateSet.isEmpty()) {
                if (LOG.isDebugEnabled()) {
                    
---------------Reference log start----------------
LOG.debug(""Cleanup removing the data files: "" + gcCandidateSet)
---------------Reference log end----------------
                }
                journal.removeDataFiles(gcCandidateSet);
            }
        }

        LOG.debug(""Job Scheduler Store Checkpoint complete."");
    }",,
activemq,18316,"LOG.debug(""POST client="" + client + "" session="" + request.getSession().getId() + "" clientId="" + request.getParameter(""clientId"") + "" info="" + request.getPathInfo() + "" contentType="" + request.getContentType())",debug,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/MessageListenerServlet.java/#L128,"@Override
    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {

        // lets turn the HTTP post into a JMS Message
        AjaxWebClient client = getAjaxWebClient( request );
        String messageIds = """";

        synchronized (client) {

            if (LOG.isDebugEnabled()) {
                
---------------Reference log start----------------
LOG.debug(""POST client="" + client + "" session="" + request.getSession().getId() + "" clientId="" + request.getParameter(""clientId"") + "" info="" + request.getPathInfo() + "" contentType="" + request.getContentType())
---------------Reference log end----------------
                // dump(request.getParameterMap());
            }

            int messages = 0;

            // loop until no more messages
            while (true) {
                // Get the message parameters. Multiple messages are encoded
                // with more compact parameter names.
                String destinationName = request.getParameter(messages == 0 ? ""destination"" : (""d"" + messages));

                if (destinationName == null) {
                    destinationName = request.getHeader(""destination"");
                }

                String message = request.getParameter(messages == 0 ? ""message"" : (""m"" + messages));
                String type = request.getParameter(messages == 0 ? ""type"" : (""t"" + messages));

                if (destinationName == null || message == null || type == null) {
                    break;
                }

                try {
                    Destination destination = getDestination(client, request, destinationName);

                    if (LOG.isDebugEnabled()) {
                        LOG.debug(messages + "" destination="" + destinationName + "" message="" + message + "" type="" + type);
                        LOG.debug(destination + "" is a "" + destination.getClass().getName());
                    }

                    messages++;

                    if (""listen"".equals(type)) {
                        AjaxListener listener = client.getListener();
                        Map<MessageAvailableConsumer, String> consumerIdMap = client.getIdMap();
                        Map<MessageAvailableConsumer, String> consumerDestinationNameMap = client.getDestinationNameMap();
                        client.closeConsumer(destination); // drop any existing
                        // consumer.
                        MessageAvailableConsumer consumer = (MessageAvailableConsumer)client.getConsumer(destination, request.getHeader(WebClient.selectorName));

                        consumer.setAvailableListener(listener);
                        consumerIdMap.put(consumer, message);
                        consumerDestinationNameMap.put(consumer, destinationName);
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Subscribed: "" + consumer + "" to "" + destination + "" id="" + message);
                        }
                    } else if (""unlisten"".equals(type)) {
                        Map<MessageAvailableConsumer, String> consumerIdMap = client.getIdMap();
                        Map<MessageAvailableConsumer, String> consumerDestinationNameMap = client.getDestinationNameMap();
                        MessageAvailableConsumer consumer = (MessageAvailableConsumer)client.getConsumer(destination, request.getHeader(WebClient.selectorName));

                        consumer.setAvailableListener(null);
                        consumerIdMap.remove(consumer);
                        consumerDestinationNameMap.remove(consumer);
                        client.closeConsumer(destination);
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Unsubscribed: "" + consumer);
                        }
                    } else if (""send"".equals(type)) {
                        TextMessage text = client.getSession().createTextMessage(message);
                        appendParametersToMessage(request, text);

                        client.send(destination, text);
                        messageIds += text.getJMSMessageID() + ""\n"";
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Sent "" + message + "" to "" + destination);
                        }
                    } else {
                        LOG.warn(""unknown type "" + type);
                    }

                } catch (JMSException e) {
                    LOG.warn(""jms"", e);
                }
            }
        }

        if (""true"".equals(request.getParameter(""poll""))) {
            try {
                // TODO return message IDs
                doMessages(client, request, response);
            } catch (JMSException e) {
                throw new ServletException(""JMS problem: "" + e, e);
            }
        } else {
            // handle simple POST of a message
            if (request.getContentLength() != 0 && (request.getContentType() == null || !request.getContentType().toLowerCase().startsWith(""application/x-www-form-urlencoded""))) {
                try {
                    Destination destination = getDestination(client, request);
                    String body = getPostedMessageBody(request);
                    TextMessage message = client.getSession().createTextMessage(body);
                    appendParametersToMessage(request, message);

                    client.send(destination, message);
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Sent to destination: "" + destination + "" body: "" + body);
                    }
                    messageIds += message.getJMSMessageID() + ""\n"";
                } catch (JMSException e) {
                    throw new ServletException(e);
                }
            }

            response.setContentType(""text/plain"");
            response.setHeader(""Cache-Control"", ""no-cache"");
            response.getWriter().print(messageIds);
        }
    }",,
activemq,18935,"LOG.debug(""{}, Usage Manager memory limit reached {}. Producers will be throttled to the rate at which messages are removed from this destination to prevent flooding it. See http://activemq.apache.org/producer-flow-control.html for more info."", getActiveMQDestination().getQualifiedName(), memoryUsage.getLimit())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Topic.java/#L396,"@Override
    public void send(final ProducerBrokerExchange producerExchange, final Message message) throws Exception {
        final ConnectionContext context = producerExchange.getConnectionContext();

        final ProducerInfo producerInfo = producerExchange.getProducerState().getInfo();
        producerExchange.incrementSend();
        final boolean sendProducerAck = !message.isResponseRequired() && producerInfo.getWindowSize() > 0
                && !context.isInRecoveryMode();

        message.setRegionDestination(this);

        // There is delay between the client sending it and it arriving at the
        // destination.. it may have expired.
        if (message.isExpired()) {
            broker.messageExpired(context, message, null);
            getDestinationStatistics().getExpired().increment();
            if (sendProducerAck) {
                ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message.getSize());
                context.getConnection().dispatchAsync(ack);
            }
            return;
        }

        if (memoryUsage.isFull()) {
            isFull(context, memoryUsage);
            fastProducer(context, producerInfo);

            if (isProducerFlowControl() && context.isProducerFlowControl()) {

                if (isFlowControlLogRequired()) {
                    LOG.warn(""{}, Usage Manager memory limit reached {}. Producers will be throttled to the rate at which messages are removed from this destination to prevent flooding it. See http://activemq.apache.org/producer-flow-control.html for more info."",
                            getActiveMQDestination().getQualifiedName(), memoryUsage.getLimit());
                } else {
                    
---------------Reference log start----------------
LOG.debug(""{}, Usage Manager memory limit reached {}. Producers will be throttled to the rate at which messages are removed from this destination to prevent flooding it. See http://activemq.apache.org/producer-flow-control.html for more info."", getActiveMQDestination().getQualifiedName(), memoryUsage.getLimit())
---------------Reference log end----------------
                }

                if (!context.isNetworkConnection() && systemUsage.isSendFailIfNoSpace()) {
                    throw new javax.jms.ResourceAllocationException(""Usage Manager memory limit (""
                            + memoryUsage.getLimit() + "") reached. Rejecting send for producer ("" + message.getProducerId()
                            + "") to prevent flooding "" + getActiveMQDestination().getQualifiedName() + "".""
                            + "" See http://activemq.apache.org/producer-flow-control.html for more info"");
                }

                // We can avoid blocking due to low usage if the producer is sending a sync message or
                // if it is using a producer window
                if (producerInfo.getWindowSize() > 0 || message.isResponseRequired()) {
                    synchronized (messagesWaitingForSpace) {
                        messagesWaitingForSpace.add(new Runnable() {
                            @Override
                            public void run() {
                                try {

                                    // While waiting for space to free up...
                                    // the transaction may be done
                                    if (message.isInTransaction()) {
                                        if (context.getTransaction() == null || context.getTransaction().getState() > IN_USE_STATE) {
                                            throw new JMSException(""Send transaction completed while waiting for space"");
                                        }
                                    }

                                    // the message may have expired.
                                    if (message.isExpired()) {
                                        broker.messageExpired(context, message, null);
                                        getDestinationStatistics().getExpired().increment();
                                    } else {
                                        doMessageSend(producerExchange, message);
                                    }

                                    if (sendProducerAck) {
                                        ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message
                                                .getSize());
                                        context.getConnection().dispatchAsync(ack);
                                    } else {
                                        Response response = new Response();
                                        response.setCorrelationId(message.getCommandId());
                                        context.getConnection().dispatchAsync(response);
                                    }

                                } catch (Exception e) {
                                    if (!sendProducerAck && !context.isInRecoveryMode()) {
                                        ExceptionResponse response = new ExceptionResponse(e);
                                        response.setCorrelationId(message.getCommandId());
                                        context.getConnection().dispatchAsync(response);
                                    }
                                }
                            }
                        });

                        registerCallbackForNotFullNotification();
                        context.setDontSendReponse(true);
                        return;
                    }

                } else {
                    // Producer flow control cannot be used, so we have do the flow control
                    // at the broker by blocking this thread until there is space available.

                    if (memoryUsage.isFull()) {
                        if (context.isInTransaction()) {

                            int count = 0;
                            while (!memoryUsage.waitForSpace(1000)) {
                                if (context.getStopping().get()) {
                                    throw new IOException(""Connection closed, send aborted."");
                                }
                                if (count > 2 && context.isInTransaction()) {
                                    count = 0;
                                    int size = context.getTransaction().size();
                                    LOG.warn(""Waiting for space to send transacted message - transaction elements = {} need more space to commit. Message = {}"", size, message);
                                }
                                count++;
                            }
                        } else {
                            waitForSpace(
                                    context,
                                    producerExchange,
                                    memoryUsage,
                                    ""Usage Manager Memory Usage limit reached. Stopping producer (""
                                            + message.getProducerId()
                                            + "") to prevent flooding ""
                                            + getActiveMQDestination().getQualifiedName()
                                            + "".""
                                            + "" See http://activemq.apache.org/producer-flow-control.html for more info"");
                        }
                    }

                    // The usage manager could have delayed us by the time
                    // we unblock the message could have expired..
                    if (message.isExpired()) {
                        getDestinationStatistics().getExpired().increment();
                        LOG.debug(""Expired message: {}"", message);
                        return;
                    }
                }
            }
        }

        doMessageSend(producerExchange, message);
        messageDelivered(context, message);
        if (sendProducerAck) {
            ProducerAck ack = new ProducerAck(producerInfo.getProducerId(), message.getSize());
            context.getConnection().dispatchAsync(ack);
        }
    }",,
activemq,18239,"LOG.trace(""Sending commit Ack to ActiveMQ: {}"", pendingTxAck)",trace,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpSender.java/#L319,"@Override
    public void commit(LocalTransactionId txnId) throws Exception {
        if (!dispatchedInTx.isEmpty()) {
            for (final Delivery delivery : dispatchedInTx) {
                MessageDispatch dispatch = (MessageDispatch) delivery.getContext();

                MessageAck pendingTxAck = new MessageAck(dispatch, MessageAck.INDIVIDUAL_ACK_TYPE, 1);
                pendingTxAck.setFirstMessageId(dispatch.getMessage().getMessageId());
                pendingTxAck.setTransactionId(txnId);

                
---------------Reference log start----------------
LOG.trace(""Sending commit Ack to ActiveMQ: {}"", pendingTxAck)
---------------Reference log end----------------

                sendToActiveMQ(pendingTxAck, new ResponseHandler() {
                    @Override
                    public void onResponse(AmqpProtocolConverter converter, Response response) throws IOException {
                        if (response.isException()) {
                            Throwable exception = ((ExceptionResponse) response).getException();
                            exception.printStackTrace();
                            getEndpoint().close();
                        } else {
                            delivery.settle();
                        }
                        session.pumpProtonToSocket();
                    }
                });
            }

            dispatchedInTx.clear();
        }
    }",,
activemq,19723,"LOG.error(""Failed to parse URI: {}"", u)",error,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/failover/FailoverTransport.java/#L771,"public void add(boolean rebalance, String u) {
        try {
            URI newURI = new URI(u);
            if (contains(newURI) == false) {
                uris.add(newURI);
                reconnect(rebalance);
            }

        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Failed to parse URI: {}"", u)
---------------Reference log end----------------
        }
    }",,
activemq,19555,"LOG.debug(""Caught exception while cancelling old optimized ack task"", e)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQMessageConsumer.java/#L1649,"public void setOptimizedAckScheduledAckInterval(long optimizedAckScheduledAckInterval) throws JMSException {
        this.optimizedAckScheduledAckInterval = optimizedAckScheduledAckInterval;

        if (this.optimizedAckTask != null) {
            try {
                this.session.connection.getScheduler().cancel(optimizedAckTask);
            } catch (JMSException e) {
                
---------------Reference log start----------------
LOG.debug(""Caught exception while cancelling old optimized ack task"", e)
---------------Reference log end----------------
                throw e;
            }
            this.optimizedAckTask = null;
        }

        // Should we periodically send out all outstanding acks.
        if (this.optimizeAcknowledge && this.optimizedAckScheduledAckInterval > 0) {
            this.optimizedAckTask = new Runnable() {

                @Override
                public void run() {
                    try {
                        if (optimizeAcknowledge && !unconsumedMessages.isClosed()) {
                            LOG.info(""Consumer:{} is performing scheduled delivery of outstanding optimized Acks"", info.getConsumerId());
                            deliverAcks();
                        }
                    } catch (Exception e) {
                        LOG.debug(""Optimized Ack Task caught exception during ack"", e);
                    }
                }
            };

            try {
                this.session.connection.getScheduler().executePeriodically(optimizedAckTask, optimizedAckScheduledAckInterval);
            } catch (JMSException e) {
                LOG.debug(""Caught exception while scheduling new optimized ack task"", e);
                throw e;
            }
        }
    }",,
activemq,18410,"LOG.debug(""Waiting for WebSocket to be properly started..."")",debug,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/ws/WSTransportProxy.java/#L184,"@Override
    public void onWebSocketText(String data) {
        if (!transportStartedAtLeastOnce()) {
            
---------------Reference log start----------------
LOG.debug(""Waiting for WebSocket to be properly started..."")
---------------Reference log end----------------
            try {
                socketTransportStarted.await();
            } catch (InterruptedException e) {
                LOG.warn(""While waiting for WebSocket to be properly started, we got interrupted!! Should be okay, but you could see race conditions..."");
            }
        }

        protocolLock.lock();
        try {
            wsTransport.onWebSocketText(data);
        } catch (Exception e) {
            onException(IOExceptionSupport.create(e));
        } finally {
            protocolLock.unlock();
        }
    }",,
activemq,17736,"LOG.debug(""Journalled message remove for: "" + ack.getLastMessageId() + "", at: "" + location)",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/journal/JournalMessageStore.java/#L172,"public void removeMessage(ConnectionContext context, final MessageAck ack) throws IOException {
        final boolean debug = LOG.isDebugEnabled();
        JournalQueueAck remove = new JournalQueueAck();
        remove.setDestination(destination);
        remove.setMessageAck(ack);

        final RecordLocation location = peristenceAdapter.writeCommand(remove, ack.isResponseRequired());
        if (!context.isInTransaction()) {
            if (debug) {
                
---------------Reference log start----------------
LOG.debug(""Journalled message remove for: "" + ack.getLastMessageId() + "", at: "" + location)
---------------Reference log end----------------
            }
            removeMessage(ack, location);
        } else {
            if (debug) {
                LOG.debug(""Journalled transacted message remove for: "" + ack.getLastMessageId() + "", at: "" + location);
            }
            synchronized (this) {
                inFlightTxLocations.add(location);
            }
            transactionStore.removeMessage(this, ack, location);
            context.getTransaction().addSynchronization(new Synchronization() {
                public void afterCommit() throws Exception {
                    if (debug) {
                        LOG.debug(""Transacted message remove commit for: "" + ack.getLastMessageId() + "", at: "" + location);
                    }
                    synchronized (JournalMessageStore.this) {
                        inFlightTxLocations.remove(location);
                        removeMessage(ack, location);
                    }
                }

                public void afterRollback() throws Exception {
                    if (debug) {
                        LOG.debug(""Transacted message remove rollback for: "" + ack.getLastMessageId() + "", at: "" + location);
                    }
                    synchronized (JournalMessageStore.this) {
                        inFlightTxLocations.remove(location);
                    }
                }
            });

        }
    }",,
activemq,18691,"LOG.trace(""JobScheduler rescheduling job[{}] to fire at: {}"", job.getJobId(), JobSupport.getDateTime(nextExecutionTime))",trace,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/scheduler/memory/InMemoryJobScheduler.java/#L281,"private void doReschedule(InMemoryJob job, long nextExecutionTime) {
        job.setNextTime(nextExecutionTime);
        job.incrementExecutionCount();
        if (!job.isCron()) {
            job.decrementRepeatCount();
        }

        
---------------Reference log start----------------
LOG.trace(""JobScheduler rescheduling job[{}] to fire at: {}"", job.getJobId(), JobSupport.getDateTime(nextExecutionTime))
---------------Reference log end----------------

        lock.writeLock().lock();
        try {
            ScheduledTask task = jobs.get(nextExecutionTime);
            if (task == null) {
                task = new ScheduledTask(nextExecutionTime);
                task.add(job);
                jobs.put(task.getExecutionTime(), task);
                timer.schedule(task, new Date(task.getExecutionTime()));
            } else {
                task.add(job);
            }
        } finally {
            lock.writeLock().unlock();
        }
    }",,
activemq,19077,"log.debug(""$$ SENDREQ: "" + CustomLogWriter.commandToString(command))",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/transport/logwriters/CustomLogWriter.java/#L52,"public void logRequest (Logger log, Object command) {
        
---------------Reference log start----------------
log.debug(""$$ SENDREQ: "" + CustomLogWriter.commandToString(command))
---------------Reference log end----------------
    }
    }",,
activemq,18292,"LOG.debug(""Couldn't find "" + BROKER_URL_INIT_PARAM + "" param, trying to find a broker embedded in a local VM"")",debug,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/WebClient.java/#L276,"protected static synchronized void initConnectionFactory(ServletContext servletContext) {
        if (factory == null) {
            factory = (ActiveMQConnectionFactory)servletContext.getAttribute(CONNECTION_FACTORY_ATTRIBUTE);
        }
        if (factory == null) {
            String brokerURL = getInitParameter(servletContext, BROKER_URL_INIT_PARAM);


            if (brokerURL == null) {
                
---------------Reference log start----------------
LOG.debug(""Couldn't find "" + BROKER_URL_INIT_PARAM + "" param, trying to find a broker embedded in a local VM"")
---------------Reference log end----------------
                BrokerService broker = BrokerRegistry.getInstance().findFirst();
                if (broker == null) {
                    throw new IllegalStateException(""missing brokerURL (specified via "" + BROKER_URL_INIT_PARAM + "" init-Param) or embedded broker"");
                } else {
                    brokerURL = ""vm://"" + broker.getBrokerName();
                }
            }

            LOG.debug(""Using broker URL: "" + brokerURL);
            String username = getInitParameter(servletContext, USERNAME_INIT_PARAM);
            String password = getInitParameter(servletContext, PASSWORD_INIT_PARAM);
            ActiveMQConnectionFactory amqfactory = new ActiveMQConnectionFactory(username, password, brokerURL);

            // Set prefetch policy for factory
            if (servletContext.getInitParameter(CONNECTION_FACTORY_PREFETCH_PARAM) != null) {
                int prefetch = Integer.valueOf(getInitParameter(servletContext, CONNECTION_FACTORY_PREFETCH_PARAM)).intValue();
                amqfactory.getPrefetchPolicy().setAll(prefetch);
            }

            // Set optimize acknowledge setting
            if (servletContext.getInitParameter(CONNECTION_FACTORY_OPTIMIZE_ACK_PARAM) != null) {
                boolean optimizeAck = Boolean.valueOf(getInitParameter(servletContext, CONNECTION_FACTORY_OPTIMIZE_ACK_PARAM)).booleanValue();
                amqfactory.setOptimizeAcknowledge(optimizeAck);
            }

            factory = amqfactory;

            servletContext.setAttribute(CONNECTION_FACTORY_ATTRIBUTE, factory);
        }
    }",,
activemq,18546,"LOG.warn(""cannot resolve subscription matching name: {}"", consumerToAbort)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/AbortSlowConsumerStrategyView.java/#L86,"public void abortConsumer(ObjectName consumerToAbort) {
        Subscription sub = broker.getSubscriber(consumerToAbort);
        if (sub != null) {
            LOG.info(""aborting consumer via jmx: {}"", sub.getConsumerInfo().getConsumerId());
            strategy.abortConsumer(sub, false);
        } else {
            
---------------Reference log start----------------
LOG.warn(""cannot resolve subscription matching name: {}"", consumerToAbort)
---------------Reference log end----------------
        }

    }",,
activemq,18244,"LOG.trace(""Sender:[{}] browse done."", getEndpoint().getName())",trace,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpSender.java/#L456,"public void pumpOutbound() throws Exception {
        while (!isClosed()) {
            while (currentBuffer != null) {
                int sent = getEndpoint().send(currentBuffer.data, currentBuffer.offset, currentBuffer.length);
                if (sent > 0) {
                    currentBuffer.moveHead(sent);
                    if (currentBuffer.length == 0) {
                        if (presettle) {
                            settle(currentDelivery, MessageAck.INDIVIDUAL_ACK_TYPE);
                        } else {
                            getEndpoint().advance();
                        }
                        currentBuffer = null;
                        currentDelivery = null;
                        logicalDeliveryCount++;
                    }
                } else {
                    return;
                }
            }

            if (outbound.isEmpty()) {
                return;
            }

            final MessageDispatch md = outbound.removeFirst();
            try {

                ActiveMQMessage temp = null;
                if (md.getMessage() != null) {
                    temp = (ActiveMQMessage) md.getMessage().copy();
                }

                final ActiveMQMessage jms = temp;
                if (jms == null) {
                    
---------------Reference log start----------------
LOG.trace(""Sender:[{}] browse done."", getEndpoint().getName())
---------------Reference log end----------------
                    // It's the end of browse signal in response to a MessagePull
                    getEndpoint().drained();
                    draining = false;
                    currentCreditRequest = 0;
                    logicalDeliveryCount = 0;
                } else {
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(""Sender:[{}] msgId={} draining={}, drain={}, credit={}, remoteCredit={}, queued={}"",
                                  getEndpoint().getName(), jms.getJMSMessageID(), draining, getEndpoint().getDrain(),
                                  getEndpoint().getCredit(), getEndpoint().getRemoteCredit(), getEndpoint().getQueued());
                    }

                    if (draining && getEndpoint().getCredit() == 0) {
                        LOG.trace(""Sender:[{}] browse complete."", getEndpoint().getName());
                        getEndpoint().drained();
                        draining = false;
                        currentCreditRequest = 0;
                        logicalDeliveryCount = 0;
                    }

                    jms.setRedeliveryCounter(md.getRedeliveryCounter());
                    jms.setReadOnlyBody(true);
                    final EncodedMessage amqp = outboundTransformer.transform(jms);
                    if (amqp != null && amqp.getLength() > 0) {
                        currentBuffer = new Buffer(amqp.getArray(), amqp.getArrayOffset(), amqp.getLength());
                        if (presettle) {
                            currentDelivery = getEndpoint().delivery(EMPTY_BYTE_ARRAY, 0, 0);
                        } else {
                            final byte[] tag = tagCache.getNextTag();
                            currentDelivery = getEndpoint().delivery(tag, 0, tag.length);
                        }
                        currentDelivery.setContext(md);
                        currentDelivery.setMessageFormat((int) amqp.getMessageFormat());
                    } else {
                        // TODO: message could not be generated what now?
                    }
                }
            } catch (Exception e) {
                LOG.warn(""Error detected while flushing outbound messages: {}"", e.getMessage());
            }
        }
    }",,
activemq,19036,"LOG.error(""Unable to persist selector cache"", ex)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/plugin/SubQueueSelectorCacheBroker.java/#L242,"private void persistCache() {
        LOG.debug(""Persisting selector cache...."");
        try {
            FileOutputStream fos = new FileOutputStream(persistFile);
            try {
                ObjectOutputStream out = new ObjectOutputStream(fos);
                try {
                    out.writeObject(subSelectorCache);
                } finally {
                    out.flush();
                    out.close();
                }
            } catch (IOException ex) {
                
---------------Reference log start----------------
LOG.error(""Unable to persist selector cache"", ex)
---------------Reference log end----------------
            } finally {
                fos.close();
            }
        } catch (IOException ex) {
            LOG.error(""Unable to access file[{}]"", persistFile, ex);
        }
    }",,
activemq,19264,"LOG.warn(""demand sub interrupted or timedout while waiting for outstanding responses, expect potentially {} duplicate forwards"", this.dispatched.get())",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandSubscription.java/#L136,"public void waitForCompletion() {
        if (dispatched.get() > 0) {
            LOG.debug(""Waiting for completion for sub: {}, dispatched: {}"", localInfo.getConsumerId(), this.dispatched.get());
            activeWaiter.set(true);
            if (dispatched.get() > 0) {
                synchronized (activeWaiter) {
                    try {
                        activeWaiter.wait(TimeUnit.SECONDS.toMillis(30));
                    } catch (InterruptedException ignored) {
                    }
                }
                if (this.dispatched.get() > 0) {
                    
---------------Reference log start----------------
LOG.warn(""demand sub interrupted or timedout while waiting for outstanding responses, expect potentially {} duplicate forwards"", this.dispatched.get())
---------------Reference log end----------------
                }
            }
        }
    }",,
activemq,18184,"log.info(""Starting embedded ActiveMQ broker: {}"", this.getBrokerName())",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-junit/src/main/java/org/apache/activemq/junit/EmbeddedActiveMQBroker.java/#L168,"@Override
    protected void before() throws Throwable {
        
---------------Reference log start----------------
log.info(""Starting embedded ActiveMQ broker: {}"", this.getBrokerName())
---------------Reference log end----------------

        this.start();

        super.before();
    }",,
activemq,18512,"TRANSPORTLOG.debug(""Unexpected exception on asyncDispatch, command of type: {}"", command.getDataStructureType(), e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransportConnection.java/#L990,"protected void processDispatch(Command command) throws IOException {
        MessageDispatch messageDispatch = (MessageDispatch) (command.isMessageDispatch() ? command : null);
        try {
            if (!stopping.get()) {
                if (messageDispatch != null) {
                    try {
                        broker.preProcessDispatch(messageDispatch);
                    } catch (RuntimeException convertToIO) {
                        throw new IOException(convertToIO);
                    }
                }
                dispatch(command);
            }
        } catch (IOException e) {
            if (messageDispatch != null) {
                TransmitCallback sub = messageDispatch.getTransmitCallback();
                broker.postProcessDispatch(messageDispatch);
                if (sub != null) {
                    sub.onFailure();
                }
                messageDispatch = null;
                throw e;
            } else {
                if (TRANSPORTLOG.isDebugEnabled()) {
                    
---------------Reference log start----------------
TRANSPORTLOG.debug(""Unexpected exception on asyncDispatch, command of type: {}"", command.getDataStructureType(), e)
---------------Reference log end----------------
                }
            }
        } finally {
            if (messageDispatch != null) {
                TransmitCallback sub = messageDispatch.getTransmitCallback();
                broker.postProcessDispatch(messageDispatch);
                if (sub != null) {
                    sub.onSuccess();
                }
            }
        }
    }",,
activemq,19796,"LOG.warn(""run()"", ex)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/tcp/TcpTransportServer.java/#L408,"private void doRunWithServerSocketChannel(final ServerSocketChannel channel) {
        try {
            channel.configureBlocking(false);
            final Selector selector = Selector.open();

            try {
                channel.register(selector, SelectionKey.OP_ACCEPT);
            } catch (ClosedChannelException ex) {
                try {
                    selector.close();
                } catch (IOException ignore) {}

                throw ex;
            }

            // Update object instance for later cleanup.
            this.selector = selector;

            while (!isStopped()) {
                int count = selector.select(10);

                if (count == 0) {
                    continue;
                }

                Set<SelectionKey> keys = selector.selectedKeys();

                for (Iterator<SelectionKey> i = keys.iterator(); i.hasNext(); ) {
                    final SelectionKey key = i.next();
                    if (key.isAcceptable()) {
                        try {
                            SocketChannel sc = channel.accept();
                            if (sc != null) {
                                if (isStopped() || getAcceptListener() == null) {
                                    sc.close();
                                } else {
                                    if (useQueueForAccept) {
                                        socketQueue.put(sc.socket());
                                    } else {
                                        handleSocket(sc.socket());
                                    }
                                }
                            }

                        } catch (SocketTimeoutException ste) {
                            // expect this to happen
                        } catch (Exception e) {
                            e.printStackTrace();
                            if (!isStopping()) {
                                onAcceptError(e);
                            } else if (!isStopped()) {
                                LOG.warn(""run()"", e);
                                onAcceptError(e);
                            }
                        }
                    }
                    i.remove();
                }
            }
        } catch (IOException ex) {
            if (!isStopping()) {
                onAcceptError(ex);
            } else if (!isStopped()) {
                
---------------Reference log start----------------
LOG.warn(""run()"", ex)
---------------Reference log end----------------
                onAcceptError(ex);
            }
        }
    }",,
activemq,19241,"LOG.debug(""    filter [{}]"", searchFilter)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/LdapNetworkConnector.java/#L247,"@Override
    public void start() throws Exception {
        LOG.info(""connecting..."");
        Hashtable<String, String> env = new Hashtable<String, String>();
        env.put(Context.INITIAL_CONTEXT_FACTORY, ""com.sun.jndi.ldap.LdapCtxFactory"");
        this.ldapURI = getUri();
        LOG.debug(""    URI [{}]"", this.ldapURI);
        env.put(Context.PROVIDER_URL, this.ldapURI.toString());
        if (anonymousAuthentication) {
            LOG.debug(""    login credentials [anonymous]"");
            env.put(Context.SECURITY_AUTHENTICATION, ""none"");
        } else {
            LOG.debug(""    login credentials [{}:******]"", user);
            if (user != null && !"""".equals(user)) {
                env.put(Context.SECURITY_PRINCIPAL, user);
            } else {
                throw new Exception(""Empty username is not allowed"");
            }
            if (password != null && !"""".equals(password)) {
                env.put(Context.SECURITY_CREDENTIALS, password);
            } else {
                throw new Exception(""Empty password is not allowed"");
            }
        }
        boolean isConnected = false;
        while (!isConnected) {
            try {
                context = new InitialDirContext(env);
                isConnected = true;
            } catch (CommunicationException err) {
                if (failover) {
                    this.ldapURI = getUri();
                    LOG.error(""connection error [{}], failover connection to [{}]"", env.get(Context.PROVIDER_URL), this.ldapURI.toString());
                    env.put(Context.PROVIDER_URL, this.ldapURI.toString());
                    Thread.sleep(curReconnectDelay);
                    curReconnectDelay = Math.min(curReconnectDelay * 2, maxReconnectDelay);
                } else {
                    throw err;
                }
            }
        }

        // add connectors from search results
        LOG.info(""searching for network connectors..."");
        LOG.debug(""    base   [{}]"", base);
        
---------------Reference log start----------------
LOG.debug(""    filter [{}]"", searchFilter)
---------------Reference log end----------------
        LOG.debug(""    scope  [{}]"", searchControls.getSearchScope());
        NamingEnumeration<SearchResult> results = context.search(base, searchFilter, searchControls);
        while (results.hasMore()) {
            addConnector(results.next());
        }

        // register persistent search event listener
        if (searchEventListener) {
            LOG.info(""registering persistent search listener..."");
            EventDirContext eventContext = (EventDirContext) context.lookup("""");
            eventContext.addNamingListener(base, searchFilter, searchControls, this);
        } else { // otherwise close context (i.e. connection as it is no longer needed)
            context.close();
        }
    }",,
activemq,18083,"LOG.info(""delivering rollback outcome to store for tid: "" + txid)",info,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MultiKahaDBTransactionStore.java/#L495,"@Override
    public synchronized void recover(final TransactionRecoveryListener listener) throws IOException {

        for (final PersistenceAdapter adapter : multiKahaDBPersistenceAdapter.adapters) {
            adapter.createTransactionStore().recover(new TransactionRecoveryListener() {
                @Override
                public void recover(XATransactionId xid, Message[] addedMessages, MessageAck[] acks) {
                    try {
                        getTx(xid).trackStore(adapter.createTransactionStore(), xid);
                    } catch (IOException e) {
                        LOG.error(""Failed to access transaction store: "" + adapter + "" for prepared xa tid: "" + xid, e);
                    }
                    listener.recover(xid, addedMessages, acks);
                }
            });
        }

        boolean recoveryWorkPending = false;
        try {
            Broker broker = multiKahaDBPersistenceAdapter.getBrokerService().getBroker();
            // force completion of local xa
            for (TransactionId txid : broker.getPreparedTransactions(null)) {
                if (multiKahaDBPersistenceAdapter.isLocalXid(txid)) {
                    recoveryWorkPending = true;
                    if (corruptJournalDetected.get()) {
                        // not having a record is meaningless once our tx store is corrupt; we need a heuristic decision
                        LOG.warn(""Pending multi store local transaction {} requires manual heuristic outcome via JMX"", txid);
                        logSomeContext(txid);
                    } else {
                        try {
                            if (pendingCommit.keySet().contains(txid)) {
                                // we recorded the commit outcome, finish the job
                                LOG.info(""delivering pending commit outcome for tid: "" + txid);
                                broker.commitTransaction(null, txid, false);
                            } else {
                                // we have not record an outcome, and would have reported a commit failure, so we must rollback
                                
---------------Reference log start----------------
LOG.info(""delivering rollback outcome to store for tid: "" + txid)
---------------Reference log end----------------
                                broker.forgetTransaction(null, txid);
                            }
                            persistCompletion(txid);
                        } catch (Exception ex) {
                            LOG.error(""failed to deliver pending outcome for tid: "" + txid, ex);
                        }
                    }
                }
            }
        } catch (Exception e) {
            LOG.error(""failed to resolve pending local transactions"", e);
        }
        // can we ignore corruption and resume
        if (corruptJournalDetected.get() && !recoveryWorkPending) {
            // move to new write file, gc will cleanup
            journal.rotateWriteFile();
            loaded();
            corruptJournalDetected.set(false);
            LOG.info(""No heuristics outcome pending after corrupt tx store detection, auto resolving"");
        }
    }",,
activemq,19746,"LOG.warn(""Caught in: "" + this + "" while closing: "" + e2 + "". Now Closed"", e2)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/udp/UdpTransport.java/#L157,"@Override
    public void run() {
        LOG.trace(""Consumer thread starting for: "" + toString());
        while (!isStopped()) {
            try {
                Command command = commandChannel.read();
                doConsume(command);
            } catch (AsynchronousCloseException e) {
                // DatagramChannel closed
                try {
                    stop();
                } catch (Exception e2) {
                    
---------------Reference log start----------------
LOG.warn(""Caught in: "" + this + "" while closing: "" + e2 + "". Now Closed"", e2)
---------------Reference log end----------------
                }
            } catch (SocketException e) {
                // DatagramSocket closed
                LOG.debug(""Socket closed: "" + e, e);
                try {
                    stop();
                } catch (Exception e2) {
                    LOG.warn(""Caught in: "" + this + "" while closing: "" + e2 + "". Now Closed"", e2);
                }
            } catch (EOFException e) {
                // DataInputStream closed
                LOG.debug(""Socket closed: "" + e, e);
                try {
                    stop();
                } catch (Exception e2) {
                    LOG.warn(""Caught in: "" + this + "" while closing: "" + e2 + "". Now Closed"", e2);
                }
            } catch (Exception e) {
                try {
                    stop();
                } catch (Exception e2) {
                    LOG.warn(""Caught in: "" + this + "" while closing: "" + e2 + "". Now Closed"", e2);
                }
                if (e instanceof IOException) {
                    onException((IOException)e);
                } else {
                    LOG.error(""Caught: "" + e, e);
                    e.printStackTrace();
                }
            }
        }
    }",,
activemq,19631,"LOG.debug(""recover({})"", flag)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/TransactionContext.java/#L682,"@Override
    public Xid[] recover(int flag) throws XAException {
        
---------------Reference log start----------------
LOG.debug(""recover({})"", flag)
---------------Reference log end----------------
        XATransactionId[] answer;

        if (XAResource.TMNOFLAGS == flag) {
            // signal next in cursor scan, which for us is always the end b/c we don't maintain any cursor state
            // allows looping scan to complete
            answer = new XATransactionId[0];
        } else {
            TransactionInfo info = new TransactionInfo(getConnectionId(), null, TransactionInfo.RECOVER);
            try {
                this.connection.checkClosedOrFailed();
                this.connection.ensureConnectionInfoSent();

                DataArrayResponse receipt = (DataArrayResponse) this.connection.syncSendPacket(info);
                DataStructure[] data = receipt.getData();
                if (data instanceof XATransactionId[]) {
                    answer = (XATransactionId[]) data;
                } else {
                    answer = new XATransactionId[data.length];
                    System.arraycopy(data, 0, answer, 0, data.length);
                }
            } catch (JMSException e) {
                throw toXAException(e);
            }
        }
        LOG.debug(""recover({})={}"", flag, answer);
        return answer;
    }",,
activemq,18148,"LOG.info(""Creating topic: {}"", destName)",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/JmsProducerClient.java/#L337,"@Override
    protected Destination createTemporaryDestination(String destName) throws JMSException {
        String simpleName = getSimpleName(destName);
        byte destinationType = getDestinationType(destName);

        // when we produce to temp destinations, we publish to them as
        // though they were normal queues or topics
        if (destinationType == ActiveMQDestination.TEMP_QUEUE_TYPE) {
            LOG.info(""Creating queue: {}"", destName);
            return getSession().createQueue(simpleName);
        } else if (destinationType == ActiveMQDestination.TEMP_TOPIC_TYPE) {
            
---------------Reference log start----------------
LOG.info(""Creating topic: {}"", destName)
---------------Reference log end----------------
            return getSession().createTopic(simpleName);
        } else {
            throw new IllegalArgumentException(""Unrecognized destination type: "" + destinationType);
        }
    }",,
activemq,19520,"LOG.error(""Caught an exception trying to create a JMSException for "" + er.getException(), e)",error,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQConnection.java/#L1406,"public Response syncSendPacket(Command command, int timeout) throws JMSException {
        if (isClosed()) {
            throw new ConnectionClosedException();
        } else {

            try {
                Response response = (Response)(timeout > 0
                        ? this.transport.request(command, timeout)
                        : this.transport.request(command));
                if (response.isException()) {
                    ExceptionResponse er = (ExceptionResponse)response;
                    if (er.getException() instanceof JMSException) {
                        throw (JMSException)er.getException();
                    } else {
                        if (isClosed() || closing.get()) {
                            LOG.debug(""Received an exception but connection is closing"");
                        }
                        JMSException jmsEx = null;
                        try {
                            jmsEx = JMSExceptionSupport.create(er.getException());
                        } catch(Throwable e) {
                            
---------------Reference log start----------------
LOG.error(""Caught an exception trying to create a JMSException for "" + er.getException(), e)
---------------Reference log end----------------
                        }
                        if (er.getException() instanceof SecurityException && command instanceof ConnectionInfo){
                            try {
                                forceCloseOnSecurityException(er.getException());
                            } catch (Throwable t) {
                                // We throw the original error from the ExceptionResponse instead.
                            }
                        }
                        if (jmsEx != null) {
                            throw jmsEx;
                        }
                    }
                }
                return response;
            } catch (IOException e) {
                throw JMSExceptionSupport.create(e);
            }
        }
    }",,
activemq,19489,"LOG.warn(""No consumerCount header available on the message: "" + message)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/advisory/ConsumerEventSource.java/#L123,"protected int extractConsumerCountFromMessage(Message message, int count) {
        try {
            Object value = message.getObjectProperty(""consumerCount"");
            if (value instanceof Number) {
                Number n = (Number)value;
                return n.intValue();
            }
            
---------------Reference log start----------------
LOG.warn(""No consumerCount header available on the message: "" + message)
---------------Reference log end----------------
        } catch (Exception e) {
            LOG.warn(""Failed to extract consumerCount from message: "" + message + "".Reason: "" + e, e);
        }
        return count;
    }",,
activemq,18471,"LOG.error(""Error stopping {}"", tc, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransportStatusDetector.java/#L93,"protected void doCollection(TransportConnection tc) {
        LOG.warn(""found a blocked client - stopping: {}"", tc);
        try {
            tc.stop();
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Error stopping {}"", tc, e)
---------------Reference log end----------------
        }
    }",,
activemq,19716,"LOG.error(""Failed to parse broker address: "" + str, e)",error,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/failover/FailoverTransport.java/#L564,"public void setPriorityURIs(String priorityURIs) {
        StringTokenizer tokenizer = new StringTokenizer(priorityURIs, "","");
        while (tokenizer.hasMoreTokens()) {
            String str = tokenizer.nextToken();
            try {
                URI uri = new URI(str);
                priorityList.add(uri);
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.error(""Failed to parse broker address: "" + str, e)
---------------Reference log end----------------
            }
        }
    }",,
activemq,18402,"LOG.info(""Listening for connections at {}"", getConnectURI())",info,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/ws/WSTransportServer.java/#L117,"@Override
    protected void doStart() throws Exception {
        createServer();

        if (connector == null) {
            connector = socketConnectorFactory.createConnector(server);
        }

        for(ConnectionFactory cf  : connector.getConnectionFactories()) {
            if(HttpConnectionFactory.class.isAssignableFrom(cf.getClass())) {
                HttpConnectionFactory.class.cast(cf).getHttpConfiguration().setSendServerVersion(false);
            }
        }

        URI boundTo = bind();

        ServletContextHandler contextHandler =
                new ServletContextHandler(server, ""/"", ServletContextHandler.SECURITY);

        ServletHolder holder = new ServletHolder();

        //AMQ-6182 - disabling trace by default
        configureTraceMethod((ConstraintSecurityHandler) contextHandler.getSecurityHandler(),
                httpOptions.isEnableTrace());

        Map<String, Object> webSocketOptions = IntrospectionSupport.extractProperties(transportOptions, ""websocket."");
        for(Map.Entry<String,Object> webSocketEntry : webSocketOptions.entrySet()) {
            Object value = webSocketEntry.getValue();
            if (value != null) {
                holder.setInitParameter(webSocketEntry.getKey(), value.toString());
            }
        }

        holder.setServlet(createWSServlet());
        contextHandler.addServlet(holder, ""/"");

        contextHandler.setAttribute(""acceptListener"", getAcceptListener());

        server.start();

        // Update the Connect To URI with our actual location in case the configured port
        // was set to zero so that we report the actual port we are listening on.

        int port = getConnectorLocalPort();
        if (port == -1) {
            port = boundTo.getPort();
        }

        setConnectURI(new URI(boundTo.getScheme(),
                              boundTo.getUserInfo(),
                              boundTo.getHost(),
                              port,
                              boundTo.getPath(),
                              boundTo.getQuery(),
                              boundTo.getFragment()));

        
---------------Reference log start----------------
LOG.info(""Listening for connections at {}"", getConnectURI())
---------------Reference log end----------------
    }
    }",,
activemq,18792,"LOG.debug(""{} ms elapsed. Starting dispatch."", timeBeforeDispatchStarts)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/Queue.java/#L1695,"@Override
    public boolean iterate() {
        MDC.put(""activemq.destination"", getName());
        boolean pageInMoreMessages = false;
        synchronized (iteratingMutex) {

            // If optimize dispatch is on or this is a slave this method could be called recursively
            // we set this state value to short-circuit wakeup in those cases to avoid that as it
            // could lead to errors.
            iterationRunning = true;

            // do early to allow dispatch of these waiting messages
            synchronized (messagesWaitingForSpace) {
                Iterator<Runnable> it = messagesWaitingForSpace.values().iterator();
                while (it.hasNext()) {
                    if (!memoryUsage.isFull()) {
                        Runnable op = it.next();
                        it.remove();
                        op.run();
                    } else {
                        registerCallbackForNotFullNotification();
                        break;
                    }
                }
            }

            if (firstConsumer) {
                firstConsumer = false;
                try {
                    if (consumersBeforeDispatchStarts > 0) {
                        int timeout = 1000; // wait one second by default if
                                            // consumer count isn't reached
                        if (timeBeforeDispatchStarts > 0) {
                            timeout = timeBeforeDispatchStarts;
                        }
                        if (consumersBeforeStartsLatch.await(timeout, TimeUnit.MILLISECONDS)) {
                            LOG.debug(""{} consumers subscribed. Starting dispatch."", consumers.size());
                        } else {
                            LOG.debug(""{} ms elapsed and {} consumers subscribed. Starting dispatch."", timeout, consumers.size());
                        }
                    }
                    if (timeBeforeDispatchStarts > 0 && consumersBeforeDispatchStarts <= 0) {
                        iteratingMutex.wait(timeBeforeDispatchStarts);
                        
---------------Reference log start----------------
LOG.debug(""{} ms elapsed. Starting dispatch."", timeBeforeDispatchStarts)
---------------Reference log end----------------
                    }
                } catch (Exception e) {
                    LOG.error(e.toString());
                }
            }

            messagesLock.readLock().lock();
            try{
                pageInMoreMessages |= !messages.isEmpty();
            } finally {
                messagesLock.readLock().unlock();
            }

            pagedInPendingDispatchLock.readLock().lock();
            try {
                pageInMoreMessages |= !dispatchPendingList.isEmpty();
            } finally {
                pagedInPendingDispatchLock.readLock().unlock();
            }

            boolean hasBrowsers = !browserSubscriptions.isEmpty();

            if (pageInMoreMessages || hasBrowsers || !dispatchPendingList.hasRedeliveries()) {
                try {
                    pageInMessages(hasBrowsers && getMaxBrowsePageSize() > 0, getMaxPageSize());
                } catch (Throwable e) {
                    LOG.error(""Failed to page in more queue messages "", e);
                }
            }

            if (hasBrowsers) {
                PendingList messagesInMemory = isPrioritizedMessages() ?
                        new PrioritizedPendingList() : new OrderedPendingList();
                pagedInMessagesLock.readLock().lock();
                try {
                    messagesInMemory.addAll(pagedInMessages);
                } finally {
                    pagedInMessagesLock.readLock().unlock();
                }

                Iterator<QueueBrowserSubscription> browsers = browserSubscriptions.iterator();
                while (browsers.hasNext()) {
                    QueueBrowserSubscription browser = browsers.next();
                    try {
                        MessageEvaluationContext msgContext = new NonCachedMessageEvaluationContext();
                        msgContext.setDestination(destination);

                        LOG.debug(""dispatch to browser: {}, already dispatched/paged count: {}"", browser, messagesInMemory.size());
                        boolean added = false;
                        for (MessageReference node : messagesInMemory) {
                            if (!((QueueMessageReference)node).isAcked() && !browser.isDuplicate(node.getMessageId()) && !browser.atMax()) {
                                msgContext.setMessageReference(node);
                                if (browser.matches(node, msgContext)) {
                                    browser.add(node);
                                    added = true;
                                }
                            }
                        }
                        // are we done browsing? no new messages paged
                        if (!added || browser.atMax()) {
                            browser.decrementQueueRef();
                            browsers.remove();
                        } else {
                            wakeup();
                        }
                    } catch (Exception e) {
                        LOG.warn(""exception on dispatch to browser: {}"", browser, e);
                    }
                }
            }

            if (pendingWakeups.get() > 0) {
                pendingWakeups.decrementAndGet();
            }
            MDC.remove(""activemq.destination"");
            iterationRunning = false;

            return pendingWakeups.get() > 0;
        }
    }",,
activemq,19173,"LOG.debug(""{} Ignoring duplicate subscription from {}, sub: {} is duplicate by network subscription with equal or higher network priority: {}, networkConsumerIds: {}"", configuration.getBrokerName(), remoteBrokerName, candidateInfo, existingSub, existingSub.getConsumerInfo().getNetworkConsumerIds())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L1490,"private boolean hasLowerPriority(Subscription existingSub, ConsumerInfo candidateInfo) {
        boolean suppress = false;

        if (existingSub.getConsumerInfo().getPriority() >= candidateInfo.getPriority()) {
            
---------------Reference log start----------------
LOG.debug(""{} Ignoring duplicate subscription from {}, sub: {} is duplicate by network subscription with equal or higher network priority: {}, networkConsumerIds: {}"", configuration.getBrokerName(), remoteBrokerName, candidateInfo, existingSub, existingSub.getConsumerInfo().getNetworkConsumerIds())
---------------Reference log end----------------
            suppress = true;
        } else {
            // remove the existing lower priority duplicate and allow this candidate
            try {
                removeDuplicateSubscription(existingSub);

                LOG.debug(""{} Replacing duplicate subscription {} with sub from {}, which has a higher priority, new sub: {}, networkConsumerIds: {}"",
                        configuration.getBrokerName(), existingSub.getConsumerInfo(), remoteBrokerName, candidateInfo, candidateInfo.getNetworkConsumerIds());
            } catch (IOException e) {
                LOG.error(""Failed to remove duplicated sub as a result of sub with higher priority, sub: {}"", existingSub, e);
            }
        }
        return suppress;
    }",,
activemq,19201,"LOG.info(""Created replyTo bridge for {}"", replyToProducerQueue)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/jms/SimpleJmsQueueConnector.java/#L434,"@Override
    protected Destination createReplyToBridge(Destination destination, Connection replyToProducerConnection,
                                              Connection replyToConsumerConnection) {
        Queue replyToProducerQueue = (Queue)destination;
        boolean isInbound = replyToProducerConnection.equals(localConnection.get());

        if (isInbound) {
            InboundQueueBridge bridge = (InboundQueueBridge)replyToBridges.get(replyToProducerQueue);
            if (bridge == null) {
                bridge = new InboundQueueBridge() {
                    @Override
                    protected Destination processReplyToDestination(Destination destination) {
                        return null;
                    }
                };
                try {
                    QueueSession replyToConsumerSession = ((QueueConnection)replyToConsumerConnection)
                        .createQueueSession(false, Session.AUTO_ACKNOWLEDGE);
                    Queue replyToConsumerQueue = replyToConsumerSession.createTemporaryQueue();
                    replyToConsumerSession.close();
                    bridge.setConsumerQueue(replyToConsumerQueue);
                    bridge.setProducerQueue(replyToProducerQueue);
                    bridge.setProducerConnection((QueueConnection)replyToProducerConnection);
                    bridge.setConsumerConnection((QueueConnection)replyToConsumerConnection);
                    bridge.setDoHandleReplyTo(false);
                    if (bridge.getJmsMessageConvertor() == null) {
                        bridge.setJmsMessageConvertor(getInboundMessageConvertor());
                    }
                    bridge.setJmsConnector(this);
                    bridge.start();
                    LOG.info(""Created replyTo bridge for {}"", replyToProducerQueue);
                } catch (Exception e) {
                    LOG.error(""Failed to create replyTo bridge for queue: {}"", replyToProducerQueue, e);
                    return null;
                }
                replyToBridges.put(replyToProducerQueue, bridge);
            }
            return bridge.getConsumerQueue();
        } else {
            OutboundQueueBridge bridge = (OutboundQueueBridge)replyToBridges.get(replyToProducerQueue);
            if (bridge == null) {
                bridge = new OutboundQueueBridge() {
                    @Override
                    protected Destination processReplyToDestination(Destination destination) {
                        return null;
                    }
                };
                try {
                    QueueSession replyToConsumerSession = ((QueueConnection)replyToConsumerConnection)
                        .createQueueSession(false, Session.AUTO_ACKNOWLEDGE);
                    Queue replyToConsumerQueue = replyToConsumerSession.createTemporaryQueue();
                    replyToConsumerSession.close();
                    bridge.setConsumerQueue(replyToConsumerQueue);
                    bridge.setProducerQueue(replyToProducerQueue);
                    bridge.setProducerConnection((QueueConnection)replyToProducerConnection);
                    bridge.setConsumerConnection((QueueConnection)replyToConsumerConnection);
                    bridge.setDoHandleReplyTo(false);
                    if (bridge.getJmsMessageConvertor() == null) {
                        bridge.setJmsMessageConvertor(getOutboundMessageConvertor());
                    }
                    bridge.setJmsConnector(this);
                    bridge.start();
                    
---------------Reference log start----------------
LOG.info(""Created replyTo bridge for {}"", replyToProducerQueue)
---------------Reference log end----------------
                } catch (Exception e) {
                    LOG.error(""Failed to create replyTo bridge for queue: {}"", replyToProducerQueue, e);
                    return null;
                }
                replyToBridges.put(replyToProducerQueue, bridge);
            }
            return bridge.getConsumerQueue();
        }
    }",,
activemq,18684,"LOG.info(""{}: {} (blocking for: {}s)"", usage, logMessage, (now - start) / 1000)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/scheduler/SchedulerBroker.java/#L302,"@Override
    public void send(ProducerBrokerExchange producerExchange, final Message messageSend) throws Exception {
        ConnectionContext context = producerExchange.getConnectionContext();

        final String jobId = (String) messageSend.getProperty(ScheduledMessage.AMQ_SCHEDULED_ID);
        final Object cronValue = messageSend.getProperty(ScheduledMessage.AMQ_SCHEDULED_CRON);
        final Object periodValue = messageSend.getProperty(ScheduledMessage.AMQ_SCHEDULED_PERIOD);
        final Object delayValue = messageSend.getProperty(ScheduledMessage.AMQ_SCHEDULED_DELAY);

        String physicalName = messageSend.getDestination().getPhysicalName();
        boolean schedularManage = physicalName.regionMatches(true, 0, ScheduledMessage.AMQ_SCHEDULER_MANAGEMENT_DESTINATION, 0,
            ScheduledMessage.AMQ_SCHEDULER_MANAGEMENT_DESTINATION.length());

        if (schedularManage == true) {

            JobScheduler scheduler = getInternalScheduler();
            ActiveMQDestination replyTo = messageSend.getReplyTo();

            String action = (String) messageSend.getProperty(ScheduledMessage.AMQ_SCHEDULER_ACTION);

            if (action != null) {

                Object startTime = messageSend.getProperty(ScheduledMessage.AMQ_SCHEDULER_ACTION_START_TIME);
                Object endTime = messageSend.getProperty(ScheduledMessage.AMQ_SCHEDULER_ACTION_END_TIME);

                if (replyTo != null && action.equals(ScheduledMessage.AMQ_SCHEDULER_ACTION_BROWSE)) {

                    if (startTime != null && endTime != null) {

                        long start = (Long) TypeConversionSupport.convert(startTime, Long.class);
                        long finish = (Long) TypeConversionSupport.convert(endTime, Long.class);

                        for (Job job : scheduler.getAllJobs(start, finish)) {
                            sendScheduledJob(producerExchange.getConnectionContext(), job, replyTo);
                        }
                    } else {
                        for (Job job : scheduler.getAllJobs()) {
                            sendScheduledJob(producerExchange.getConnectionContext(), job, replyTo);
                        }
                    }
                }
                if (jobId != null && action.equals(ScheduledMessage.AMQ_SCHEDULER_ACTION_REMOVE)) {
                    scheduler.remove(jobId);
                } else if (action.equals(ScheduledMessage.AMQ_SCHEDULER_ACTION_REMOVEALL)) {

                    if (startTime != null && endTime != null) {

                        long start = (Long) TypeConversionSupport.convert(startTime, Long.class);
                        long finish = (Long) TypeConversionSupport.convert(endTime, Long.class);

                        scheduler.removeAllJobs(start, finish);
                    } else {
                        scheduler.removeAllJobs();
                    }
                }
            }

        } else if ((cronValue != null || periodValue != null || delayValue != null) && jobId == null) {

            // Check for room in the job scheduler store
            if (systemUsage.getJobSchedulerUsage() != null) {
                JobSchedulerUsage usage = systemUsage.getJobSchedulerUsage();
                if (usage.isFull()) {
                    final String logMessage = ""Job Scheduler Store is Full ("" +
                        usage.getPercentUsage() + ""% of "" + usage.getLimit() +
                        ""). Stopping producer ("" + messageSend.getProducerId() +
                        "") to prevent flooding of the job scheduler store."" +
                        "" See http://activemq.apache.org/producer-flow-control.html for more info"";

                    long start = System.currentTimeMillis();
                    long nextWarn = start;
                    while (!usage.waitForSpace(1000)) {
                        if (context.getStopping().get()) {
                            throw new IOException(""Connection closed, send aborted."");
                        }

                        long now = System.currentTimeMillis();
                        if (now >= nextWarn) {
                            
---------------Reference log start----------------
LOG.info(""{}: {} (blocking for: {}s)"", usage, logMessage, (now - start) / 1000)
---------------Reference log end----------------
                            nextWarn = now + 30000l;
                        }
                    }
                }
            }

            if (context.isInTransaction()) {
                context.getTransaction().addSynchronization(new Synchronization() {
                    @Override
                    public void afterCommit() throws Exception {
                        doSchedule(messageSend, cronValue, periodValue, delayValue);
                    }
                });
            } else {
                doSchedule(messageSend, cronValue, periodValue, delayValue);
            }
        } else {
            super.send(producerExchange, messageSend);
        }
    }",,
activemq,18653,"LOG.error(""Temporary Store limit {} mb, whilst the max journal file size for the temporary store is {} mb, the temp store will not accept any data when used."", (storeLimit / (1024 * 1024)), (maxJournalFileSize / (1024 * 1024)))",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L2047,"protected void checkTmpStoreUsageLimits() throws Exception {
        final SystemUsage usage = getSystemUsage();

        File tmpDir = getTmpDataDirectory();

        if (tmpDir != null) {
            checkUsageLimit(tmpDir, usage.getTempUsage(), usage.getTempUsage().getPercentLimit());

            if (isPersistent()) {
                long maxJournalFileSize;

                PListStore store = usage.getTempUsage().getStore();
                if (store != null && store instanceof JournaledStore) {
                    maxJournalFileSize = ((JournaledStore) store).getJournalMaxFileLength();
                } else {
                    maxJournalFileSize = DEFAULT_MAX_FILE_LENGTH;
                }
                long storeLimit = usage.getTempUsage().getLimit();

                if (storeLimit > 0 && storeLimit < maxJournalFileSize) {
                    
---------------Reference log start----------------
LOG.error(""Temporary Store limit {} mb, whilst the max journal file size for the temporary store is {} mb, the temp store will not accept any data when used."", (storeLimit / (1024 * 1024)), (maxJournalFileSize / (1024 * 1024)))
---------------Reference log end----------------
                }
            }
        }
    }",,
activemq,18251,"LOG.trace(""Performing connection:{} keep-alive processing"", amqpTransport.getRemoteAddress())",trace,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpConnection.java/#L254,"@Override
    public long keepAlive() throws IOException {
        long rescheduleAt = 0l;

        
---------------Reference log start----------------
LOG.trace(""Performing connection:{} keep-alive processing"", amqpTransport.getRemoteAddress())
---------------Reference log end----------------

        if (protonConnection.getLocalState() != EndpointState.CLOSED) {
            // Using nano time since it is not related to the wall clock, which may change
            long now = TimeUnit.NANOSECONDS.toMillis(System.nanoTime());
            long deadline = protonTransport.tick(now);
            pumpProtonToSocket();
            if (protonTransport.isClosed()) {
                LOG.debug(""Transport closed after inactivity check."");
                throw new InactivityIOException(""Channel was inactive for too long"");
            } else {
                if(deadline != 0) {
                    // caller treats 0 as no-work, ensure value is at least 1 as there was a deadline
                    rescheduleAt = Math.max(deadline - now, 1);
                }
            }
        }

        LOG.trace(""Connection:{} keep alive processing done, next update in {} milliseconds."",
                  amqpTransport.getRemoteAddress(), rescheduleAt);

        return rescheduleAt;
    }",,
activemq,18231,"LOG.trace(""Flow: credit 0 for sub:"" + subscription)",trace,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpSender.java/#L220,"@Override
    public void flow() throws Exception {
        Link endpoint = getEndpoint();
        if (LOG.isTraceEnabled()) {
            LOG.trace(""Flow: draining={}, drain={} credit={}, currentCredit={}, senderDeliveryCount={} - Sub={}"",
                    draining, endpoint.getDrain(),
                    endpoint.getCredit(), currentCreditRequest, logicalDeliveryCount, subscription);
        }

        final int endpointCredit = endpoint.getCredit();
        if (endpoint.getDrain() && !draining) {

            if (endpointCredit > 0) {
                draining = true;

                // Now request dispatch of the drain amount, we request immediate
                // timeout and an completion message regardless so that we can know
                // when we should marked the link as drained.
                MessagePull pullRequest = new MessagePull();
                pullRequest.setConsumerId(getConsumerId());
                pullRequest.setDestination(getDestination());
                pullRequest.setTimeout(-1);
                pullRequest.setAlwaysSignalDone(true);
                pullRequest.setQuantity(endpointCredit);

                LOG.trace(""Pull case -> consumer pull request quantity = {}"", endpointCredit);

                sendToActiveMQ(pullRequest);
            } else {
                LOG.trace(""Pull case -> sending any Queued messages and marking drained"");

                pumpOutbound();
                getEndpoint().drained();
                session.pumpProtonToSocket();
                currentCreditRequest = 0;
                logicalDeliveryCount = 0;
            }
        } else if (endpointCredit >= 0) {

            if (endpointCredit == 0 && currentCreditRequest != 0) {
                prefetchExtension.set(0);
                currentCreditRequest = 0;
                logicalDeliveryCount = 0;
                
---------------Reference log start----------------
LOG.trace(""Flow: credit 0 for sub:"" + subscription)
---------------Reference log end----------------
            } else {
                int deltaToAdd = endpointCredit;
                int logicalCredit = currentCreditRequest - logicalDeliveryCount;
                if (logicalCredit > 0) {
                    deltaToAdd -= logicalCredit;
                } else {
                    // reset delivery counter - dispatch from broker concurrent with credit=0
                    // flow can go negative
                    logicalDeliveryCount = 0;
                }

                if (deltaToAdd > 0) {
                    currentCreditRequest = prefetchExtension.addAndGet(deltaToAdd);
                    subscription.wakeupDestinationsForDispatch();
                    // force dispatch of matched/pending for topics (pending messages accumulate
                    // in the sub and are dispatched on update of prefetch)
                    subscription.setPrefetchSize(0);
                    LOG.trace(""Flow: credit addition of {} for sub {}"", deltaToAdd, subscription);
                }
            }
        }
    }",,
activemq,18540,"LOG.warn(""Failed to unregister MBean {}"", name)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedTransportConnection.java/#L109,"protected void unregisterMBean(ObjectName name) {
        if (name != null) {
            try {
                managementContext.unregisterMBean(name);
            } catch (Throwable e) {
                
---------------Reference log start----------------
LOG.warn(""Failed to unregister MBean {}"", name)
---------------Reference log end----------------
                LOG.debug(""Failure reason: "", e);
            }
        }
    }",,
activemq,19281,"LOG.warn(""Failed to send frame "" + frame, e)",warn,https://github.com/apache/activemq/blob/main/activemq-mqtt/src/main/java/org/apache/activemq/transport/mqtt/MQTTProtocolConverter.java/#L187,"void sendToMQTT(MQTTFrame frame) {
        try {
            mqttTransport.sendToMQTT(frame);
        } catch (IOException e) {
            
---------------Reference log start----------------
LOG.warn(""Failed to send frame "" + frame, e)
---------------Reference log end----------------
        }
    }",,
activemq,18893,"LOG.warn(""{}: has twice its prefetch limit pending, without an ack; it appears to be slow{}"", toString(), (remoteAddr != null) ? "": "" + remoteAddr : """")",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/TopicSubscription.java/#L123,"@Override
    public void add(MessageReference node) throws Exception {
        if (isDuplicate(node)) {
            return;
        }
        // Lets use an indirect reference so that we can associate a unique
        // locator /w the message.
        node = new IndirectMessageReference(node.getMessage());
        getSubscriptionStatistics().getEnqueues().increment();
        synchronized (matchedListMutex) {
            // if this subscriber is already discarding a message, we don't want to add
            // any more messages to it as those messages can only be advisories generated in the process,
            // which can trigger the recursive call loop
            if (discarding) return;

            if (!isFull() && matched.isEmpty()) {
                // if maximumPendingMessages is set we will only discard messages which
                // have not been dispatched (i.e. we allow the prefetch buffer to be filled)
                dispatch(node);
                setSlowConsumer(false);
            } else {
                if (info.getPrefetchSize() > 1 && matched.size() > info.getPrefetchSize()) {
                    // Slow consumers should log and set their state as such.
                    if (!isSlowConsumer()) {
                        String remoteAddr = null;
                        if (context != null && context.getConnection() != null) {
                            remoteAddr = context.getConnection().getRemoteAddress();
                        }
                        
---------------Reference log start----------------
LOG.warn(""{}: has twice its prefetch limit pending, without an ack; it appears to be slow{}"", toString(), (remoteAddr != null) ? "": "" + remoteAddr : """")
---------------Reference log end----------------
                        setSlowConsumer(true);
                        for (Destination dest: destinations) {
                            dest.slowConsumer(getContext(), this);
                        }
                    }
                }
                if (maximumPendingMessages != 0) {
                    boolean warnedAboutWait = false;
                    while (active) {
                        while (matched.isFull()) {
                            if (getContext().getStopping().get()) {
                                LOG.warn(""{}: stopped waiting for space in pendingMessage cursor for: {}"", toString(), node.getMessageId());
                                getSubscriptionStatistics().getEnqueues().decrement();
                                return;
                            }
                            if (!warnedAboutWait) {
                                LOG.info(""{}: Pending message cursor [{}] is full, temp usage ({}%) or memory usage ({}%) limit reached, blocking message add() pending the release of resources."",
                                        toString(),
                                        matched,
                                        matched.getSystemUsage().getTempUsage().getPercentUsage(),
                                        matched.getSystemUsage().getMemoryUsage().getPercentUsage());
                                warnedAboutWait = true;
                            }
                            matchedListMutex.wait(20);
                        }
                        // Temporary storage could be full - so just try to add the message
                        // see https://issues.apache.org/activemq/browse/AMQ-2475
                        if (matched.tryAddMessageLast(node, 10)) {
                            break;
                        }
                    }
                    if (maximumPendingMessages > 0) {
                        // calculate the high water mark from which point we
                        // will eagerly evict expired messages
                        int max = messageEvictionStrategy.getEvictExpiredMessagesHighWatermark();
                        if (maximumPendingMessages > 0 && maximumPendingMessages < max) {
                            max = maximumPendingMessages;
                        }
                        if (!matched.isEmpty() && matched.size() > max) {
                            removeExpiredMessages();
                        }
                        // lets discard old messages as we are a slow consumer
                        while (!matched.isEmpty() && matched.size() > maximumPendingMessages) {
                            int pageInSize = matched.size() - maximumPendingMessages;
                            // only page in a 1000 at a time - else we could blow the memory
                            pageInSize = Math.max(1000, pageInSize);
                            LinkedList<MessageReference> list = null;
                            MessageReference[] oldMessages=null;
                            synchronized(matched){
                                list = matched.pageInList(pageInSize);
                                oldMessages = messageEvictionStrategy.evictMessages(list);
                                for (MessageReference ref : list) {
                                    ref.decrementReferenceCount();
                                }
                            }
                            int messagesToEvict = 0;
                            if (oldMessages != null){
                                messagesToEvict = oldMessages.length;
                                for (int i = 0; i < messagesToEvict; i++) {
                                    MessageReference oldMessage = oldMessages[i];
                                    discard(oldMessage);
                                }
                            }
                            // lets avoid an infinite loop if we are given a bad eviction strategy
                            // for a bad strategy lets just not evict
                            if (messagesToEvict == 0) {
                                LOG.warn(""No messages to evict returned for {} from eviction strategy: {} out of {} candidates"",
                                        destination, messageEvictionStrategy, list.size());
                                break;
                            }
                        }
                    }
                    dispatchMatched();
                }
            }
        }
    }",,
activemq,19315,"LOG.debug(""Peer Identity has been verified\n"")",debug,https://github.com/apache/activemq/blob/main/activemq-mqtt/src/main/java/org/apache/activemq/transport/mqtt/MQTTTransportFilter.java/#L177,"@Override
    public X509Certificate[] getPeerCertificates() {
        X509Certificate[] peerCerts = null;
        if (next instanceof SslTransport) {
            peerCerts = ((SslTransport) next).getPeerCertificates();
        }
        if (next instanceof  NIOSSLTransport) {
            peerCerts = ((NIOSSLTransport)next).getPeerCertificates();
        }
        if (trace && peerCerts != null) {
            
---------------Reference log start----------------
LOG.debug(""Peer Identity has been verified\n"")
---------------Reference log end----------------
        }
        return peerCerts;
    }",,
activemq,18889,"LOG.error(""Trying to get Root Broker"", e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/RegionBroker.java/#L830,"@Override
    public Broker getRoot() {
        try {
            return getBrokerService().getBroker();
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Trying to get Root Broker"", e)
---------------Reference log end----------------
            throw new RuntimeException(""The broker from the BrokerService should not throw an exception"", e);
        }
    }",,
activemq,18114,"LOG.info(""Created performance report: "" + xmlFile.getAbsolutePath())",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/reports/XmlFilePerfReportWriter.java/#L162,"protected void writeToXml() {
        try {
            xmlFile = createXmlFile();
            xmlFileWriter = new PrintWriter(new FileOutputStream(xmlFile));
            writeXmlHeader();
            writeXmlTestSettings();
            writeXmlLogFile();
            writeXmlPerfSummary();
            writeXmlFooter();
            xmlFileWriter.close();

            
---------------Reference log start----------------
LOG.info(""Created performance report: "" + xmlFile.getAbsolutePath())
---------------Reference log end----------------
        } catch (Exception e) {
            e.printStackTrace();
        }
    }",,
activemq,19115,"LOG.info(""pending tasks on stop {}"", pendingTasks)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L310,"@Override
                        public void run() {
                            try {
                                serialExecutor.shutdown();
                                if (!serialExecutor.awaitTermination(5, TimeUnit.SECONDS)) {
                                    List<Runnable> pendingTasks = serialExecutor.shutdownNow();
                                    LOG.info(""pending tasks on stop {}"", pendingTasks);
                                }
                                //Shutdown the syncExecutor, call countDown to make sure a thread can
                                //terminate if it is waiting
                                staticDestinationsLatch.countDown();
                                syncExecutor.shutdown();
                                if (!syncExecutor.awaitTermination(5, TimeUnit.SECONDS)) {
                                    List<Runnable> pendingTasks = syncExecutor.shutdownNow();
                                    
---------------Reference log start----------------
LOG.info(""pending tasks on stop {}"", pendingTasks)
---------------Reference log end----------------
                                }
                                localBroker.oneway(new ShutdownInfo());
                                remoteBroker.oneway(new ShutdownInfo());
                            } catch (Throwable e) {
                                LOG.debug(""Caught exception sending shutdown"", e);
                            } finally {
                                sendShutdown.countDown();
                            }

                        }",,
activemq,17962,"LOG.debug(""Resizing done.  New bins start at: "" + metadata.binPageId)",debug,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/disk/index/HashIndex.java/#L346,"private void resize(Transaction tx, final int newSize) throws IOException {
        LOG.debug(""Resizing to: ""+newSize);
        
        int resizeCapacity = newSize;
        long resizePageId = tx.allocate(resizeCapacity).getPageId();

        // In Phase 1 we copy the data to the new bins..
        // Initialize the bins..
        for (int i = 0; i < resizeCapacity; i++) {
            long pageId = resizePageId + i;
            clearBinAtPage(tx, pageId);
        }

        metadata.binsActive = 0;
        // Copy the data from the old bins to the new bins.
        for (int i = 0; i < metadata.binCapacity; i++) {
            
            HashBin<Key,Value> bin = getBin(tx, i);
            for (Map.Entry<Key, Value> entry : bin.getAll(tx).entrySet()) {
                HashBin<Key,Value> resizeBin = getBin(tx, entry.getKey(), resizePageId, resizeCapacity);
                resizeBin.put(entry.getKey(), entry.getValue());
                store(tx, resizeBin);
                if( resizeBin.size() == 1) {
                    metadata.binsActive++;
                }
            }
        }
        
        // In phase 2 we free the old bins and switch the the new bins.
        tx.free(metadata.binPageId, metadata.binCapacity);
        
        metadata.binCapacity = resizeCapacity;
        metadata.binPageId = resizePageId;
        metadata.state = OPEN_STATE;
        tx.store(metadata.page, metadataMarshaller, true);
        calcThresholds();

        
---------------Reference log start----------------
LOG.debug(""Resizing done.  New bins start at: "" + metadata.binPageId)
---------------Reference log end----------------
        resizeCapacity=0;
        resizePageId=0;
    }",,
activemq,18924,"LOG.info(""idle sub: {} is no longer slow"", subscriber.getConsumerInfo().getConsumerId())",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/policy/AbortSlowAckConsumerStrategy.java/#L126,"private void updateSlowConsumersList(List<Subscription> subscribers) {
        for (Subscription subscriber : subscribers) {
            if (isIgnoreNetworkSubscriptions() && subscriber.getConsumerInfo().isNetworkSubscription()) {
                if (slowConsumers.remove(subscriber) != null) {
                    LOG.info(""network sub: {} is no longer slow"", subscriber.getConsumerInfo().getConsumerId());
                }
                continue;
            }

            if (isIgnoreIdleConsumers() && subscriber.getDispatchedQueueSize() == 0) {
                // Not considered Idle so ensure its cleared from the list
                if (slowConsumers.remove(subscriber) != null) {
                    
---------------Reference log start----------------
LOG.info(""idle sub: {} is no longer slow"", subscriber.getConsumerInfo().getConsumerId())
---------------Reference log end----------------
                }
                continue;
            }

            long lastAckTime = subscriber.getTimeOfLastMessageAck();
            long timeDelta = System.currentTimeMillis() - lastAckTime;

            if (timeDelta > maxTimeSinceLastAck) {
                if (!slowConsumers.containsKey(subscriber)) {
                    LOG.debug(""sub: {} is now slow"", subscriber.getConsumerInfo().getConsumerId());
                    SlowConsumerEntry entry = new SlowConsumerEntry(subscriber.getContext());
                    entry.mark(); // mark consumer on first run
                    if (subscriber instanceof AbstractSubscription) {
                        AbstractSubscription abstractSubscription = (AbstractSubscription) subscriber;
                        if (!abstractSubscription.isSlowConsumer()) {
                            abstractSubscription.setSlowConsumer(true);
                            for (Destination destination: abstractSubscription.getDestinations()) {
                               destination.slowConsumer(broker.getAdminConnectionContext(), abstractSubscription);
                            }
                        }
                    }
                    slowConsumers.put(subscriber, entry);
                } else if (getMaxSlowCount() > 0) {
                    slowConsumers.get(subscriber).slow();
                }
            } else {
                if (slowConsumers.remove(subscriber) != null) {
                    LOG.info(""sub: {} is no longer slow"", subscriber.getConsumerInfo().getConsumerId());
                }
            }
        }
    }",,
activemq,18363,"log.debug(""  filter: "" + filter)",debug,https://github.com/apache/activemq/blob/main/activemq-jaas/src/main/java/org/apache/activemq/jaas/LDAPLoginModule.java/#L371,"protected List<String> getRoles(DirContext context, String dn, String username, List<String> currentRoles) throws NamingException {
        List<String> list = currentRoles;
        MessageFormat roleSearchMatchingFormat;
        boolean roleSearchSubtreeBool;
        boolean expandRolesBool;
        roleSearchMatchingFormat = new MessageFormat(getLDAPPropertyValue(ROLE_SEARCH_MATCHING));
        roleSearchSubtreeBool = Boolean.valueOf(getLDAPPropertyValue(ROLE_SEARCH_SUBTREE)).booleanValue();
        expandRolesBool = Boolean.valueOf(getLDAPPropertyValue(EXPAND_ROLES)).booleanValue();
        
        if (list == null) {
            list = new ArrayList<String>();
        }
        if (!isLoginPropertySet(ROLE_NAME)) {
            return list;
        }
        String filter = roleSearchMatchingFormat.format(new String[] {
            doRFC2254Encoding(dn), doRFC2254Encoding(username)
        });

        SearchControls constraints = new SearchControls();
        if (roleSearchSubtreeBool) {
            constraints.setSearchScope(SearchControls.SUBTREE_SCOPE);
        } else {
            constraints.setSearchScope(SearchControls.ONELEVEL_SCOPE);
        }
        if (log.isDebugEnabled()) {
            log.debug(""Get user roles."");
            log.debug(""Looking for the user roles in LDAP with "");
            log.debug(""  base DN: "" + getLDAPPropertyValue(ROLE_BASE));
            
---------------Reference log start----------------
log.debug(""  filter: "" + filter)
---------------Reference log end----------------
        }
        HashSet<String> haveSeenNames = new HashSet<String>();
        Queue<String> pendingNameExpansion = new LinkedList<String>();
        NamingEnumeration<SearchResult> results = context.search(getLDAPPropertyValue(ROLE_BASE), filter, constraints);
        while (results.hasMore()) {
            SearchResult result = results.next();
            Attributes attrs = result.getAttributes();
            if (expandRolesBool) {
                haveSeenNames.add(result.getNameInNamespace());
                pendingNameExpansion.add(result.getNameInNamespace());
            }
            if (attrs == null) {
                continue;
            }
            list = addAttributeValues(getLDAPPropertyValue(ROLE_NAME), attrs, list);
        }
        if (expandRolesBool) {
            MessageFormat expandRolesMatchingFormat = new MessageFormat(getLDAPPropertyValue(EXPAND_ROLES_MATCHING));
            while (!pendingNameExpansion.isEmpty()) {
                String name = pendingNameExpansion.remove();
                filter = expandRolesMatchingFormat.format(new String[]{name});
                results = context.search(getLDAPPropertyValue(ROLE_BASE), filter, constraints);
                while (results.hasMore()) {
                    SearchResult result = results.next();
                    name = result.getNameInNamespace();
                    if (!haveSeenNames.contains(name)) {
                        Attributes attrs = result.getAttributes();
                        list = addAttributeValues(getLDAPPropertyValue(ROLE_NAME), attrs, list);
                        haveSeenNames.add(name);
                        pendingNameExpansion.add(name);
                    }
                }
            }
        }
        return list;
    }",,
activemq,19725,"LOG.debug(""Waking up reconnect task"")",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/failover/FailoverTransport.java/#L781,"public void reconnect(boolean rebalance) {
        synchronized (reconnectMutex) {
            if (started) {
                if (rebalance) {
                    doRebalance = true;
                }
                
---------------Reference log start----------------
LOG.debug(""Waking up reconnect task"")
---------------Reference log end----------------
                try {
                    reconnectTask.wakeup();
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
            } else {
                LOG.debug(""Reconnect was triggered but transport is not started yet. Wait for start to connect the transport."");
            }
        }
    }",,
activemq,19530,"LOG.debug(""notified failover transport ("" + failoverTransport + "") of pending interruption processing for: "" + this.getConnectionInfo().getConnectionId())",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQConnection.java/#L2361,"private void signalInterruptionProcessingNeeded() {
        FailoverTransport failoverTransport = transport.narrow(FailoverTransport.class);
        if (failoverTransport != null) {
            failoverTransport.getStateTracker().transportInterrupted(this.getConnectionInfo().getConnectionId());
            if (LOG.isDebugEnabled()) {
                
---------------Reference log start----------------
LOG.debug(""notified failover transport ("" + failoverTransport + "") of pending interruption processing for: "" + this.getConnectionInfo().getConnectionId())
---------------Reference log end----------------
            }
        }
    }",,
activemq,17845,"LOG.debug(""Executing SQL: "" + createStatements[i])",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/AbstractJDBCLocker.java/#L117,"@Override
    public void preStart() {
        if (createTablesOnStartup) {

            String[] createStatements = getStatements().getCreateLockSchemaStatements();

            Connection connection = null;
            Statement statement = null;
            try {
                connection = getConnection();
                statement = connection.createStatement();
                setQueryTimeout(statement);

                for (int i = 0; i < createStatements.length; i++) {
                    
---------------Reference log start----------------
LOG.debug(""Executing SQL: "" + createStatements[i])
---------------Reference log end----------------
                    try {
                        statement.execute(createStatements[i]);
                    } catch (SQLException e) {
                        LOG.info(""Could not create lock tables; they could already exist."" + "" Failure was: ""
                                + createStatements[i] + "" Message: "" + e.getMessage() + "" SQLState: "" + e.getSQLState()
                                + "" Vendor code: "" + e.getErrorCode());
                    }
                }
            } catch (SQLException e) {
                LOG.warn(""Could not create lock tables; Failure Message: "" + e.getMessage() + "" SQLState: "" + e.getSQLState()
                        + "" Vendor code: "" + e.getErrorCode(), e);
            } finally {
                close(statement);
                close(connection);
            }
        }
    }",,
activemq,18673,"LOG.info(""No IOExceptionHandler registered, ignoring IO exception"", exception)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L2752,"public void handleIOException(IOException exception) {
        if (ioExceptionHandler != null) {
            ioExceptionHandler.handle(exception);
         } else {
            
---------------Reference log start----------------
LOG.info(""No IOExceptionHandler registered, ignoring IO exception"", exception)
---------------Reference log end----------------
         }
    }",,
activemq,19568,"LOG.trace(""Shutdown of ExecutorService: {} is shutdown: {} and terminated: {}."", new Object[] { executorService, executorService.isShutdown(), executorService.isTerminated() })",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/util/ThreadPoolUtils.java/#L57,"public static List<Runnable> shutdownNow(ExecutorService executorService) {
        List<Runnable> answer = null;
        if (!executorService.isShutdown()) {
            LOG.debug(""Forcing shutdown of ExecutorService: {}"", executorService);
            answer = executorService.shutdownNow();
            if (LOG.isTraceEnabled()) {
                
---------------Reference log start----------------
LOG.trace(""Shutdown of ExecutorService: {} is shutdown: {} and terminated: {}."", new Object[] { executorService, executorService.isShutdown(), executorService.isTerminated() })
---------------Reference log end----------------
            }
        }

        return answer;
    }",,
activemq,19105,"LOG.info(""Error with pending local brokerInfo on: {} ({})"", localBroker, error.getMessage())",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L225,"@Override
                public void onException(IOException error) {
                    if (!futureLocalBrokerInfo.isDone()) {
                        
---------------Reference log start----------------
LOG.info(""Error with pending local brokerInfo on: {} ({})"", localBroker, error.getMessage())
---------------Reference log end----------------
                        LOG.debug(""Peer error: "", error);
                        futureLocalBrokerInfo.cancel(true);
                        return;
                    }
                    serviceLocalException(error);
                }",,
activemq,19816,"LOG.trace(""Ignoring exception on invalidateObject as discarding session: "" + e, e)",trace,https://github.com/apache/activemq/blob/main/activemq-jms-pool/src/main/java/org/apache/activemq/jms/pool/PooledSession.java/#L149,"@Override
    public void close() throws JMSException {
        if (ignoreClose) {
            return;
        }

        if (closed.compareAndSet(false, true)) {
            boolean invalidate = false;
            try {
                // lets reset the session
                getInternalSession().setMessageListener(null);

                // Close any consumers and browsers that may have been created.
                for (Iterator<MessageConsumer> iter = consumers.iterator(); iter.hasNext();) {
                    MessageConsumer consumer = iter.next();
                    consumer.close();
                }

                for (Iterator<QueueBrowser> iter = browsers.iterator(); iter.hasNext();) {
                    QueueBrowser browser = iter.next();
                    browser.close();
                }

                if (transactional && !isXa) {
                    try {
                        getInternalSession().rollback();
                    } catch (JMSException e) {
                        invalidate = true;
                        LOG.warn(""Caught exception trying rollback() when putting session back into the pool, will invalidate. "" + e, e);
                    }
                }
            } catch (JMSException ex) {
                invalidate = true;
                LOG.warn(""Caught exception trying close() when putting session back into the pool, will invalidate. "" + ex, ex);
            } finally {
                consumers.clear();
                browsers.clear();
                for (PooledSessionEventListener listener : this.sessionEventListeners) {
                    listener.onSessionClosed(this);
                }
                sessionEventListeners.clear();
            }

            if (invalidate) {
                // lets close the session and not put the session back into the pool
                // instead invalidate it so the pool can create a new one on demand.
                if (sessionHolder != null) {
                    try {
                        sessionHolder.close();
                    } catch (JMSException e1) {
                        LOG.trace(""Ignoring exception on close as discarding session: "" + e1, e1);
                    }
                }
                try {
                    sessionPool.invalidateObject(key, sessionHolder);
                } catch (Exception e) {
                    
---------------Reference log start----------------
LOG.trace(""Ignoring exception on invalidateObject as discarding session: "" + e, e)
---------------Reference log end----------------
                }
            } else {
                try {
                    sessionPool.returnObject(key, sessionHolder);
                } catch (Exception e) {
                    javax.jms.IllegalStateException illegalStateException = new javax.jms.IllegalStateException(e.toString());
                    illegalStateException.initCause(e);
                    throw illegalStateException;
                }
            }

            sessionHolder = null;
        }
    }",,
activemq,19830,"LOGGER.info(""Resource manager is unrecoverable due to missing classes: "" + e)",info,https://github.com/apache/activemq/blob/main/activemq-jms-pool/src/main/java/org/apache/activemq/jms/pool/GenericResourceManager.java/#L81,"public void recoverResource() {
        try {
            if (!Recovery.recover(this)) {
                LOGGER.info(""Resource manager is unrecoverable"");
            }
        } catch (NoClassDefFoundError e) {
            
---------------Reference log start----------------
LOGGER.info(""Resource manager is unrecoverable due to missing classes: "" + e)
---------------Reference log end----------------
        } catch (Throwable e) {
            LOGGER.warn(""Error while recovering resource manager"", e);
        }
    }",,
activemq,19692,"LOG.trace(""Send in progress. Skipping write check."")",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/AbstractInactivityMonitor.java/#L184,"final void writeCheck() {
        if (inSend.get()) {
            
---------------Reference log start----------------
LOG.trace(""Send in progress. Skipping write check."")
---------------Reference log end----------------
            return;
        }

        if (!commandSent.get() && useKeepAlive && monitorStarted.get() && !ASYNC_TASKS.isShutdown()) {
            LOG.trace(""{} no message sent since last write check, sending a KeepAliveInfo"", this);

            try {
                ASYNC_TASKS.execute(new Runnable() {
                    @Override
                    public void run() {
                        LOG.debug(""Running {}"", this);
                        if (monitorStarted.get()) {
                            try {
                                // If we can't get the lock it means another
                                // write beat us into the
                                // send and we don't need to heart beat now.
                                if (sendLock.writeLock().tryLock()) {
                                    KeepAliveInfo info = new KeepAliveInfo();
                                    info.setResponseRequired(keepAliveResponseRequired);
                                    doOnewaySend(info);
                                }
                            } catch (IOException e) {
                                onException(e);
                            } finally {
                                if (sendLock.writeLock().isHeldByCurrentThread()) {
                                    sendLock.writeLock().unlock();
                                }
                            }
                        }
                    }

                    @Override
                    public String toString() {
                        return ""WriteCheck["" + getRemoteAddress() + ""]"";
                    };
                });
            } catch (RejectedExecutionException ex) {
                if (!ASYNC_TASKS.isShutdown()) {
                    LOG.warn(""Async write check was rejected from the executor: "", ex);
                }
            }
        } else {
            LOG.trace(""{} message sent since last write check, resetting flag."", this);
        }

        commandSent.set(false);
    }",,
activemq,18621,"LOG.debug(""Failed to read URI to build transport connectors map"", e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/BrokerView.java/#L480,"@Override
    public Map<String, String> getTransportConnectors() {
        Map<String, String> answer = new HashMap<String, String>();
        try {
            for (TransportConnector connector : brokerService.getTransportConnectors()) {
                answer.put(connector.getName(), connector.getConnectUri().toString());
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.debug(""Failed to read URI to build transport connectors map"", e)
---------------Reference log end----------------
        }
        return answer;
    }",,
activemq,19737,"LOG.info(""Successfully connected to {}"", uri)",info,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/failover/FailoverTransport.java/#L1054,"final boolean doReconnect() {
        Exception failure = null;
        synchronized (reconnectMutex) {
            List<URI> connectList = null;
            // First ensure we are up to date.
            doUpdateURIsFromDisk();

            if (disposed || connectionFailure != null) {
                reconnectMutex.notifyAll();
            }
            if ((connectedTransport.get() != null && !doRebalance && !priorityBackupAvailable) || disposed || connectionFailure != null) {
                return false;
            } else {
                connectList = getConnectList();
                if (connectList.isEmpty()) {
                    failure = new IOException(""No uris available to connect to."");
                } else {
                    if (doRebalance) {
                        if (connectedToPriority || compareURIs(connectList.get(0), connectedTransportURI)) {
                            // already connected to first in the list, no need to rebalance
                            doRebalance = false;
                            return false;
                        } else {
                            LOG.debug(""Doing rebalance from: {} to {}"", connectedTransportURI, connectList);

                            try {
                                Transport transport = this.connectedTransport.getAndSet(null);
                                if (transport != null) {
                                    disposeTransport(transport);
                                }
                            } catch (Exception e) {
                                LOG.debug(""Caught an exception stopping existing transport for rebalance"", e);
                            }
                        }
                        doRebalance = false;
                    }

                    resetReconnectDelay();

                    Transport transport = null;
                    URI uri = null;

                    // If we have a backup already waiting lets try it.
                    synchronized (backupMutex) {
                        if ((priorityBackup || backup) && !backups.isEmpty()) {
                            ArrayList<BackupTransport> l = new ArrayList<BackupTransport>(backups);
                            if (randomize) {
                                Collections.shuffle(l);
                            }
                            BackupTransport bt = l.remove(0);
                            backups.remove(bt);
                            transport = bt.getTransport();
                            uri = bt.getUri();
                            processCommand(bt.getBrokerInfo());
                            if (priorityBackup && priorityBackupAvailable) {
                                Transport old = this.connectedTransport.getAndSet(null);
                                if (old != null) {
                                    disposeTransport(old);
                                }
                                priorityBackupAvailable = false;
                            }
                        }
                    }

                    // When there was no backup and we are reconnecting for the first time
                    // we honor the initialReconnectDelay before trying a new connection, after
                    // this normal reconnect delay happens following a failed attempt.
                    if (transport == null && !firstConnection && connectFailures == 0 && initialReconnectDelay > 0 && !disposed) {
                        // reconnectDelay will be equal to initialReconnectDelay since we are on
                        // the first connect attempt after we had a working connection, doDelay
                        // will apply updates to move to the next reconnectDelay value based on
                        // configuration.
                        doDelay();
                    }

                    Iterator<URI> iter = connectList.iterator();
                    while ((transport != null || iter.hasNext()) && (connectedTransport.get() == null && !disposed)) {

                        try {
                            SslContext.setCurrentSslContext(brokerSslContext);

                            // We could be starting with a backup and if so we wait to grab a
                            // URI from the pool until next time around.
                            if (transport == null) {
                                uri = addExtraQueryOptions(iter.next());
                                transport = TransportFactory.compositeConnect(uri);
                            }

                            LOG.debug(""Attempting {}th connect to: {}"", connectFailures, uri);

                            transport.setTransportListener(createTransportListener(transport));
                            transport.start();

                            if (started && !firstConnection) {
                                restoreTransport(transport);
                            }

                            LOG.debug(""Connection established"");

                            reconnectDelay = initialReconnectDelay;
                            connectedTransportURI = uri;
                            connectedTransport.set(transport);
                            connectedToPriority = isPriority(connectedTransportURI);
                            reconnectMutex.notifyAll();
                            connectFailures = 0;

                            // Make sure on initial startup, that the transportListener
                            // has been initialized for this instance.
                            synchronized (listenerMutex) {
                                if (transportListener == null) {
                                    try {
                                        // if it isn't set after 2secs - it probably never will be
                                        listenerMutex.wait(2000);
                                    } catch (InterruptedException ex) {
                                    }
                                }
                            }

                            if (transportListener != null) {
                                transportListener.transportResumed();
                            } else {
                                LOG.debug(""transport resumed by transport listener not set"");
                            }

                            if (firstConnection) {
                                firstConnection = false;
                                
---------------Reference log start----------------
LOG.info(""Successfully connected to {}"", uri)
---------------Reference log end----------------
                            } else {
                                LOG.info(""Successfully reconnected to {}"", uri);
                            }

                            return false;
                        } catch (Exception e) {
                            failure = e;
                            LOG.debug(""Connect fail to: {}, reason: {}"", uri, e);
                            if (transport != null) {
                                try {
                                    transport.stop();
                                    transport = null;
                                } catch (Exception ee) {
                                    LOG.debug(""Stop of failed transport: {} failed with reason: {}"", transport, ee);
                                }
                            }
                        } finally {
                            SslContext.setCurrentSslContext(null);
                        }
                    }
                }
            }

            int reconnectLimit = calculateReconnectAttemptLimit();

            connectFailures++;
            if (reconnectLimit != INFINITE && connectFailures >= reconnectLimit) {
                LOG.error(""Failed to connect to {} after: {} attempt(s)"", connectList, connectFailures);
                connectionFailure = failure;

                // Make sure on initial startup, that the transportListener has been
                // initialized for this instance.
                synchronized (listenerMutex) {
                    if (transportListener == null) {
                        try {
                            listenerMutex.wait(2000);
                        } catch (InterruptedException ex) {
                        }
                    }
                }

                propagateFailureToExceptionListener(connectionFailure);
                return false;
            }

            int warnInterval = getWarnAfterReconnectAttempts();
            if (warnInterval > 0 && (connectFailures == 1 || (connectFailures % warnInterval) == 0)) {
                LOG.warn(""Failed to connect to {} after: {} attempt(s) with {}, continuing to retry."",
                         connectList, connectFailures, (failure == null ? ""?"" : failure.getLocalizedMessage()));
            }
        }

        if (!disposed) {
            doDelay();
        }

        return !disposed;
    }",,
activemq,18600,"LOG.debug(""Failure reason: "", e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedRegionBroker.java/#L404,"protected void unregisterProducer(ObjectName key) throws Exception {
        queueProducers.remove(key);
        topicProducers.remove(key);
        temporaryQueueProducers.remove(key);
        temporaryTopicProducers.remove(key);
        dynamicDestinationProducers.remove(key);
        if (registeredMBeans.remove(key)) {
            try {
                managementContext.unregisterMBean(key);
            } catch (Throwable e) {
                LOG.warn(""Failed to unregister MBean {}"", key);
                
---------------Reference log start----------------
LOG.debug(""Failure reason: "", e)
---------------Reference log end----------------
            }
        }
    }",,
activemq,17883,"LOG.debug(""Index load failure"", t)",debug,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L467,"public void open() throws IOException {
        if( opened.compareAndSet(false, true) ) {
            getJournal().start();
            try {
                loadPageFile();
            } catch (Throwable t) {
                LOG.warn(""Index corrupted. Recovering the index through journal replay. Cause:"" + t);
                if (LOG.isDebugEnabled()) {
                    
---------------Reference log start----------------
LOG.debug(""Index load failure"", t)
---------------Reference log end----------------
                }
                // try to recover index
                try {
                    pageFile.unload();
                } catch (Exception ignore) {}
                if (archiveCorruptedIndex) {
                    pageFile.archive();
                } else {
                    pageFile.delete();
                }
                metadata = createMetadata();
                //The metadata was recreated after a detect corruption so we need to
                //reconfigure anything that was configured on the old metadata on startup
                configureMetadata();
                pageFile = null;
                loadPageFile();
            }
            recover();
            startCheckpoint();
        }
    }",,
activemq,17899,"LOG.info(""["" + sdEntry.getKey() + ""] dropped: "" + keys.messageId + "" at corrupt location: "" + keys.location)",info,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L1000,"protected void recoverIndex(Transaction tx) throws IOException {
        long start = System.currentTimeMillis();
        // It is possible index updates got applied before the journal updates..
        // in that case we need to removed references to messages that are not in the journal
        final Location lastAppendLocation = journal.getLastAppendLocation();
        long undoCounter=0;

        // Go through all the destinations to see if they have messages past the lastAppendLocation
        for (String key : storedDestinations.keySet()) {
            StoredDestination sd = storedDestinations.get(key);

            final ArrayList<Long> matches = new ArrayList<>();
            // Find all the Locations that are >= than the last Append Location.
            sd.locationIndex.visit(tx, new BTreeVisitor.GTEVisitor<Location, Long>(lastAppendLocation) {
                @Override
                protected void matched(Location key, Long value) {
                    matches.add(value);
                }
            });

            for (Long sequenceId : matches) {
                MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
                if (keys != null) {
                    sd.locationIndex.remove(tx, keys.location);
                    sd.messageIdIndex.remove(tx, keys.messageId);
                    metadata.producerSequenceIdTracker.rollback(keys.messageId);
                    undoCounter++;
                    decrementAndSubSizeToStoreStat(tx, key, sd, keys.location.getSize());
                    // TODO: do we need to modify the ack positions for the pub sub case?
                }
            }
        }

        if (undoCounter > 0) {
            // The rolledback operations are basically in flight journal writes.  To avoid getting
            // these the end user should do sync writes to the journal.
            if (LOG.isInfoEnabled()) {
                long end = System.currentTimeMillis();
                LOG.info(""Rolled back "" + undoCounter + "" messages from the index in "" + ((end - start) / 1000.0f) + "" seconds."");
            }
        }

        undoCounter = 0;
        start = System.currentTimeMillis();

        // Lets be extra paranoid here and verify that all the datafiles being referenced
        // by the indexes still exists.

        final SequenceSet ss = new SequenceSet();
        for (StoredDestination sd : storedDestinations.values()) {
            // Use a visitor to cut down the number of pages that we load
            sd.locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
                int last=-1;

                @Override
                public boolean isInterestedInKeysBetween(Location first, Location second) {
                    if( first==null ) {
                        return !ss.contains(0, second.getDataFileId());
                    } else if( second==null ) {
                        return true;
                    } else {
                        return !ss.contains(first.getDataFileId(), second.getDataFileId());
                    }
                }

                @Override
                public void visit(List<Location> keys, List<Long> values) {
                    for (Location l : keys) {
                        int fileId = l.getDataFileId();
                        if( last != fileId ) {
                            ss.add(fileId);
                            last = fileId;
                        }
                    }
                }

            });
        }
        HashSet<Integer> missingJournalFiles = new HashSet<>();
        while (!ss.isEmpty()) {
            missingJournalFiles.add((int) ss.removeFirst());
        }

        for (Entry<Integer, Set<Integer>> entry : metadata.ackMessageFileMap.entrySet()) {
            missingJournalFiles.add(entry.getKey());
            for (Integer i : entry.getValue()) {
                missingJournalFiles.add(i);
            }
        }

        missingJournalFiles.removeAll(journal.getFileMap().keySet());

        if (!missingJournalFiles.isEmpty()) {
            LOG.warn(""Some journal files are missing: "" + missingJournalFiles);
        }

        ArrayList<BTreeVisitor.Predicate<Location>> knownCorruption = new ArrayList<>();
        ArrayList<BTreeVisitor.Predicate<Location>> missingPredicates = new ArrayList<>();
        for (Integer missing : missingJournalFiles) {
            missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(missing, 0), new Location(missing + 1, 0)));
        }

        if (checkForCorruptJournalFiles) {
            Collection<DataFile> dataFiles = journal.getFileMap().values();
            for (DataFile dataFile : dataFiles) {
                int id = dataFile.getDataFileId();
                // eof to next file id
                missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, dataFile.getLength()), new Location(id + 1, 0)));
                Sequence seq = dataFile.getCorruptedBlocks().getHead();
                while (seq != null) {
                    BTreeVisitor.BetweenVisitor<Location, Long> visitor =
                        new BTreeVisitor.BetweenVisitor<>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast() + 1));
                    missingPredicates.add(visitor);
                    knownCorruption.add(visitor);
                    seq = seq.getNext();
                }
            }
        }

        if (!missingPredicates.isEmpty()) {
            for (Entry<String, StoredDestination> sdEntry : storedDestinations.entrySet()) {
                final StoredDestination sd = sdEntry.getValue();
                final LinkedHashMap<Long, Location> matches = new LinkedHashMap<>();
                sd.locationIndex.visit(tx, new BTreeVisitor.OrVisitor<Location, Long>(missingPredicates) {
                    @Override
                    protected void matched(Location key, Long value) {
                        matches.put(value, key);
                    }
                });

                // If some message references are affected by the missing data files...
                if (!matches.isEmpty()) {

                    // We either 'gracefully' recover dropping the missing messages or
                    // we error out.
                    if( ignoreMissingJournalfiles ) {
                        // Update the index to remove the references to the missing data
                        for (Long sequenceId : matches.keySet()) {
                            MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
                            sd.locationIndex.remove(tx, keys.location);
                            sd.messageIdIndex.remove(tx, keys.messageId);
                            
---------------Reference log start----------------
LOG.info(""["" + sdEntry.getKey() + ""] dropped: "" + keys.messageId + "" at corrupt location: "" + keys.location)
---------------Reference log end----------------
                            undoCounter++;
                            decrementAndSubSizeToStoreStat(tx, sdEntry.getKey(), sdEntry.getValue(), keys.location.getSize());
                            // TODO: do we need to modify the ack positions for the pub sub case?
                        }
                    } else {
                        LOG.error(""["" + sdEntry.getKey() + ""] references corrupt locations: "" + matches);
                        throw new IOException(""Detected missing/corrupt journal files referenced by:["" + sdEntry.getKey() + ""] "" +matches.size()+"" messages affected."");
                    }
                }
            }
        }

        if (!ignoreMissingJournalfiles) {
            if (!knownCorruption.isEmpty()) {
                LOG.error(""Detected corrupt journal files. "" + knownCorruption);
                throw new IOException(""Detected corrupt journal files. "" + knownCorruption);
            }

            if (!missingJournalFiles.isEmpty()) {
                LOG.error(""Detected missing journal files. "" + missingJournalFiles);
                throw new IOException(""Detected missing journal files. "" + missingJournalFiles);
            }
        }

        if (undoCounter > 0) {
            // The rolledback operations are basically in flight journal writes.  To avoid getting these the end user
            // should do sync writes to the journal.
            if (LOG.isInfoEnabled()) {
                long end = System.currentTimeMillis();
                LOG.info(""Detected missing/corrupt journal files.  Dropped "" + undoCounter + "" messages from the index in "" + ((end - start) / 1000.0f) + "" seconds."");
            }
        }
    }",,
activemq,18754,"LOG.error(toThrow.toString(), exception)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/RedeliveryPlugin.java/#L166,"@Override
    public boolean sendToDeadLetterQueue(ConnectionContext context, MessageReference messageReference, Subscription subscription, Throwable poisonCause) {
        if (messageReference.isExpired() || (poisonCause != null && poisonCause.getMessage() != null && poisonCause.getMessage().contains(DUPLICATE_FROM_STORE_MSG_PREFIX))) {
            // there are three uses of  sendToDeadLetterQueue, we are only interested in valid messages
            return super.sendToDeadLetterQueue(context, messageReference, subscription, poisonCause);
        } else {
            try {
                Destination regionDestination = (Destination) messageReference.getRegionDestination();
                final RedeliveryPolicy redeliveryPolicy = redeliveryPolicyMap.getEntryFor(regionDestination.getActiveMQDestination());
                if (redeliveryPolicy != null) {
                    final int maximumRedeliveries = redeliveryPolicy.getMaximumRedeliveries();
                    int redeliveryCount = messageReference.getRedeliveryCounter();
                    if (RedeliveryPolicy.NO_MAXIMUM_REDELIVERIES == maximumRedeliveries || redeliveryCount < maximumRedeliveries) {

                        long delay = redeliveryPolicy.getInitialRedeliveryDelay();
                        for (int i = 0; i < redeliveryCount; i++) {
                            delay = redeliveryPolicy.getNextRedeliveryDelay(delay);
                        }

                        scheduleRedelivery(context, messageReference, delay, ++redeliveryCount);
                    } else if (isSendToDlqIfMaxRetriesExceeded()) {
                        return super.sendToDeadLetterQueue(context, messageReference, subscription, poisonCause);
                    } else {
                        LOG.debug(""Discarding message that exceeds max redelivery count({}), {}"", maximumRedeliveries, messageReference.getMessageId());
                    }
                } else if (isFallbackToDeadLetter()) {
                    return super.sendToDeadLetterQueue(context, messageReference, subscription, poisonCause);
                } else {
                    LOG.debug(""Ignoring dlq request for: {}, RedeliveryPolicy not found (and no fallback) for: {}"", messageReference.getMessageId(), regionDestination.getActiveMQDestination());
                }

                return false;
            } catch (Exception exception) {
                // abort the ack, will be effective if client use transactions or individual ack with sync send
                RuntimeException toThrow =  new RuntimeException(""Failed to schedule redelivery for: "" + messageReference.getMessageId(), exception);
                
---------------Reference log start----------------
LOG.error(toThrow.toString(), exception)
---------------Reference log end----------------
                throw toThrow;
            }
        }
    }",,
activemq,19194,"LOG.info(""Created replyTo bridge for {}"", replyToProducerTopic)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/jms/SimpleJmsTopicConnector.java/#L433,"@Override
    protected Destination createReplyToBridge(Destination destination, Connection replyToProducerConnection,
                                              Connection replyToConsumerConnection) {
        Topic replyToProducerTopic = (Topic)destination;
        boolean isInbound = replyToProducerConnection.equals(localConnection.get());

        if (isInbound) {
            InboundTopicBridge bridge = (InboundTopicBridge)replyToBridges.get(replyToProducerTopic);
            if (bridge == null) {
                bridge = new InboundTopicBridge() {
                    @Override
                    protected Destination processReplyToDestination(Destination destination) {
                        return null;
                    }
                };
                try {
                    TopicSession replyToConsumerSession = ((TopicConnection)replyToConsumerConnection)
                        .createTopicSession(false, Session.AUTO_ACKNOWLEDGE);
                    Topic replyToConsumerTopic = replyToConsumerSession.createTemporaryTopic();
                    replyToConsumerSession.close();
                    bridge.setConsumerTopic(replyToConsumerTopic);
                    bridge.setProducerTopic(replyToProducerTopic);
                    bridge.setProducerConnection((TopicConnection)replyToProducerConnection);
                    bridge.setConsumerConnection((TopicConnection)replyToConsumerConnection);
                    bridge.setDoHandleReplyTo(false);
                    if (bridge.getJmsMessageConvertor() == null) {
                        bridge.setJmsMessageConvertor(getInboundMessageConvertor());
                    }
                    bridge.setJmsConnector(this);
                    bridge.start();
                    LOG.info(""Created replyTo bridge for {}"", replyToProducerTopic);
                } catch (Exception e) {
                    LOG.error(""Failed to create replyTo bridge for topic: {}"", replyToProducerTopic, e);
                    return null;
                }
                replyToBridges.put(replyToProducerTopic, bridge);
            }
            return bridge.getConsumerTopic();
        } else {
            OutboundTopicBridge bridge = (OutboundTopicBridge)replyToBridges.get(replyToProducerTopic);
            if (bridge == null) {
                bridge = new OutboundTopicBridge() {
                    @Override
                    protected Destination processReplyToDestination(Destination destination) {
                        return null;
                    }
                };
                try {
                    TopicSession replyToConsumerSession = ((TopicConnection)replyToConsumerConnection)
                        .createTopicSession(false, Session.AUTO_ACKNOWLEDGE);
                    Topic replyToConsumerTopic = replyToConsumerSession.createTemporaryTopic();
                    replyToConsumerSession.close();
                    bridge.setConsumerTopic(replyToConsumerTopic);
                    bridge.setProducerTopic(replyToProducerTopic);
                    bridge.setProducerConnection((TopicConnection)replyToProducerConnection);
                    bridge.setConsumerConnection((TopicConnection)replyToConsumerConnection);
                    bridge.setDoHandleReplyTo(false);
                    if (bridge.getJmsMessageConvertor() == null) {
                        bridge.setJmsMessageConvertor(getOutboundMessageConvertor());
                    }
                    bridge.setJmsConnector(this);
                    bridge.start();
                    
---------------Reference log start----------------
LOG.info(""Created replyTo bridge for {}"", replyToProducerTopic)
---------------Reference log end----------------
                } catch (Exception e) {
                    LOG.error(""Failed to create replyTo bridge for topic: {}"", replyToProducerTopic, e);
                    return null;
                }
                replyToBridges.put(replyToProducerTopic, bridge);
            }
            return bridge.getConsumerTopic();
        }
    }",,
activemq,18714,"LOG.info(""Removing Producer: {}"", info)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/LoggingBrokerPlugin.java/#L258,"@Override
    public void removeProducer(ConnectionContext context, ProducerInfo info) throws Exception {
        if (isLogAll() || isLogProducerEvents()) {
            
---------------Reference log start----------------
LOG.info(""Removing Producer: {}"", info)
---------------Reference log end----------------
        }
        super.removeProducer(context, info);
    }",,
activemq,18987,"LOG.debug(""Virtual destination removed: {}"", virtualDestination)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/advisory/AdvisoryBroker.java/#L680,"@Override
    public void virtualDestinationRemoved(ConnectionContext context,
            VirtualDestination virtualDestination) {
        super.virtualDestinationRemoved(context, virtualDestination);

        if (virtualDestinations.remove(virtualDestination)) {
            
---------------Reference log start----------------
LOG.debug(""Virtual destination removed: {}"", virtualDestination)
---------------Reference log end----------------
            try {
                consumersLock.readLock().lock();
                try {
                    // remove the demand created by the addition of the virtual destination
                    if (getBrokerService().isUseVirtualDestSubsOnCreation()) {
                        if (!AdvisorySupport.isAdvisoryTopic(virtualDestination.getVirtualDestination())) {
                            for (ConsumerInfo info : virtualDestinationConsumers.keySet()) {
                                //find all consumers for this virtual destination
                                if (virtualDestinationConsumers.get(info).equals(virtualDestination)) {
                                    fireVirtualDestinationRemoveAdvisory(context, info);

                                    //check consumers created for the existence of a destination to see if they
                                    //match the consumerinfo and clean up
                                    for (VirtualConsumerPair activeMQDest : brokerConsumerDests.keySet()) {
                                        ConsumerInfo i = brokerConsumerDests.get(activeMQDest);
                                        if (info.equals(i) && brokerConsumerDests.remove(activeMQDest) != null) {
                                            LOG.debug(""Virtual consumer pair removed: {} for consumer: {} "", activeMQDest, i);
                                        }
                                    }
                                }

                            }
                        }
                    }
                } finally {
                    consumersLock.readLock().unlock();
                }
            } catch (Exception e) {
                handleFireFailure(""virtualDestinationAdded"", e);
            }
        }
    }",,
activemq,19254,"LOG.debug(""entry added"")",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/LdapNetworkConnector.java/#L404,"@Override
    public void objectAdded(NamingEvent event) {
        
---------------Reference log start----------------
LOG.debug(""entry added"")
---------------Reference log end----------------
        try {
            addConnector((SearchResult) event.getNewBinding());
        } catch (Exception err) {
            LOG.error(""ERR: caught unexpected exception"", err);
        }
    }",,
activemq,19526,"LOG.debug(""Sending message: "" + msg)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQConnection.java/#L2226,"void send(ActiveMQDestination destination, ActiveMQMessage msg, MessageId messageId, int deliveryMode, int priority, long timeToLive, boolean async) throws JMSException {
        checkClosedOrFailed();

        if (destination.isTemporary() && isDeleted(destination)) {
            throw new JMSException(""Cannot publish to a deleted Destination: "" + destination);
        }

        msg.setJMSDestination(destination);
        msg.setJMSDeliveryMode(deliveryMode);
        long expiration = 0L;

        if (!isDisableTimeStampsByDefault()) {
            long timeStamp = System.currentTimeMillis();
            msg.setJMSTimestamp(timeStamp);
            if (timeToLive > 0) {
                expiration = timeToLive + timeStamp;
            }
        }

        msg.setJMSExpiration(expiration);
        msg.setJMSPriority(priority);
        msg.setJMSRedelivered(false);
        msg.setMessageId(messageId);
        msg.onSend();
        msg.setProducerId(msg.getMessageId().getProducerId());

        if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""Sending message: "" + msg)
---------------Reference log end----------------
        }

        if (async) {
            asyncSendPacket(msg);
        } else {
            syncSendPacket(msg);
        }
    }",,
activemq,19302,"LOG.debug(""Exception detail"", exception)",debug,https://github.com/apache/activemq/blob/main/activemq-mqtt/src/main/java/org/apache/activemq/transport/mqtt/MQTTProtocolConverter.java/#L725,"void handleException(Throwable exception, MQTTFrame command) {
        LOG.warn(""Exception occurred processing: \n"" + command + "": "" + exception.toString());
        
---------------Reference log start----------------
LOG.debug(""Exception detail"", exception)
---------------Reference log end----------------

        if (connected.get() && connectionInfo != null) {
            connected.set(false);
            sendToActiveMQ(connectionInfo.createRemoveCommand(), null);
        }
        stopTransport();
    }",,
activemq,17775,"LOG.debug(getLeaseHolderId() + "" Lease held by "" + resultSet.getString(1) + "" till "" + new Date(resultSet.getLong(2)))",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/LeaseDatabaseLocker.java/#L117,"private void reportLeasOwnerShipAndDuration(Connection connection) throws SQLException {
        PreparedStatement statement = null;
        try {
            statement = connection.prepareStatement(getStatements().getLeaseOwnerStatement());
            ResultSet resultSet = statement.executeQuery();
            while (resultSet.next()) {
                
---------------Reference log start----------------
LOG.debug(getLeaseHolderId() + "" Lease held by "" + resultSet.getString(1) + "" till "" + new Date(resultSet.getLong(2)))
---------------Reference log end----------------
            }
        } finally {
            close(statement);
        }
    }",,
activemq,19820,"LOG.trace(""Destroying connection: {}"", connection)",trace,https://github.com/apache/activemq/blob/main/activemq-jms-pool/src/main/java/org/apache/activemq/jms/pool/PooledConnectionFactory.java/#L121,"@Override
                    public void destroyObject(ConnectionKey connectionKey, PooledObject<ConnectionPool> pooledObject) throws Exception {
                        ConnectionPool connection = pooledObject.getObject();
                        try {
                            
---------------Reference log start----------------
LOG.trace(""Destroying connection: {}"", connection)
---------------Reference log end----------------
                            connection.close();
                        } catch (Exception e) {
                            LOG.warn(""Close connection failed for connection: "" + connection + "". This exception will be ignored."",e);
                        }
                    }",,
activemq,19023,"LOG.warn(""JMX is enabled, but when installing the VirtualDestinationSelectorCache, couldn't install the JMX mbeans. Continuing without installing the mbeans."")",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/plugin/SubQueueSelectorCacheBroker.java/#L109,"private void enableJmx() {
        BrokerService broker = getBrokerService();
        if (broker.isUseJmx()) {
            VirtualDestinationSelectorCacheView view = new VirtualDestinationSelectorCacheView(this);
            try {
                objectName = BrokerMBeanSupport.createVirtualDestinationSelectorCacheName(broker.getBrokerObjectName(), ""plugin"", ""virtualDestinationCache"");
                LOG.trace(""virtualDestinationCacheSelector mbean name; "" + objectName.toString());
                AnnotatedMBean.registerMBean(broker.getManagementContext(), view, objectName);
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.warn(""JMX is enabled, but when installing the VirtualDestinationSelectorCache, couldn't install the JMX mbeans. Continuing without installing the mbeans."")
---------------Reference log end----------------
            }
        }
    }",,
activemq,19341,"log.debug(""{} Running"", this)",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ServerSessionImpl.java/#L161,"public void run() {
        
---------------Reference log start----------------
log.debug(""{} Running"", this)
---------------Reference log end----------------
        currentBatchSize = 0;
        while (true) {
            log.debug(""{} run loop"", this);
            try {
                InboundContextSupport.register(this);
                if (session.isClosed()) {
                    stale = true;
                } else if (session.isRunning() ) {
                    session.run();
                } else {
                    log.debug(""JMS Session {} with unconsumed {} is no longer running (maybe due to loss of connection?), marking ServerSession as stale"", session, session.getUnconsumedMessages().size());
                    stale = true;
                }
            } catch (Throwable e) {
                stale = true;
                if ( log.isDebugEnabled() ) {
                    log.debug(""Endpoint {} failed to process message."", this, e);
                } else if ( log.isInfoEnabled() ) {
                    log.info(""Endpoint {} failed to process message. Reason: "" + e.getMessage(), this);
                }
            } finally {
                InboundContextSupport.unregister(this);
                log.debug(""run loop end"");
                synchronized (runControlMutex) {
                    // This endpoint may have gone stale due to error
                    if (stale) {
                        log.debug(""Session {} stale, removing from pool"", this);
                        runningFlag = false;
                        pool.removeFromPool(this);
                        break;
                    }
                    if (!session.hasUncomsumedMessages()) {
                        runningFlag = false;
                        log.debug(""Session {} has no unconsumed message, returning to pool"", this);
                        pool.returnToPool(this);
                        break;
                    } else {
                        log.debug(""Session {} has more work to do b/c of unconsumed"", this);
                    }
                }
            }
        }
        log.debug(""{} Run finished"", this);
    }",,
activemq,18599,"LOG.warn(""Failed to unregister MBean {}"", key)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedRegionBroker.java/#L403,"protected void unregisterProducer(ObjectName key) throws Exception {
        queueProducers.remove(key);
        topicProducers.remove(key);
        temporaryQueueProducers.remove(key);
        temporaryTopicProducers.remove(key);
        dynamicDestinationProducers.remove(key);
        if (registeredMBeans.remove(key)) {
            try {
                managementContext.unregisterMBean(key);
            } catch (Throwable e) {
                
---------------Reference log start----------------
LOG.warn(""Failed to unregister MBean {}"", key)
---------------Reference log end----------------
                LOG.debug(""Failure reason: "", e);
            }
        }
    }",,
activemq,18831,"LOG.debug(""{} unexpected exception verifying exception state of future"", this, unexpected)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/cursors/AbstractStoreCursor.java/#L373,"private void pruneLastCached() {
        for (Iterator<MessageId> it = pendingCachedIds.iterator(); it.hasNext(); ) {
            MessageId candidate = it.next();
            final Object futureOrLong = candidate.getFutureOrSequenceLong();
            if (futureOrLong instanceof Future) {
                Future future = (Future) futureOrLong;
                if (future.isDone()) {
                    if (future.isCancelled()) {
                        it.remove();
                    } else {
                        // check for exception, we may be seeing old state
                        try {
                            future.get(0, TimeUnit.SECONDS);
                            // stale; if we get a result next prune will see Long
                        } catch (ExecutionException expected) {
                            it.remove();
                        } catch (Exception unexpected) {
                            
---------------Reference log start----------------
LOG.debug(""{} unexpected exception verifying exception state of future"", this, unexpected)
---------------Reference log end----------------
                        }
                    }
                } else {
                    // we don't want to wait for work to complete
                    break;
                }
            } else {
                // complete
                setLastCachedId(ASYNC_ADD, candidate);

                // keep lock step with sync adds while order is preserved
                if (lastCachedIds[SYNC_ADD] != null) {
                    long next = 1 + (Long)lastCachedIds[SYNC_ADD].getFutureOrSequenceLong();
                    if (Long.compare((Long)futureOrLong, next) == 0) {
                        setLastCachedId(SYNC_ADD, candidate);
                    }
                }
                it.remove();
            }
        }
    }",,
activemq,18038,"LOG.debug(""Process reschedule command for job {} non-existent executime time {}."", command.getJobId(), command.getExecutionTime())",debug,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/scheduler/JobSchedulerImpl.java/#L393,"protected void process(final Transaction tx, final KahaRescheduleJobCommand command, Location location) throws IOException {
        JobLocation result = null;
        final List<JobLocation> current = this.index.remove(tx, command.getExecutionTime());
        if (current != null) {
            for (int i = 0; i < current.size(); i++) {
                JobLocation jl = current.get(i);
                if (jl.getJobId().equals(command.getJobId())) {
                    current.remove(i);
                    if (!current.isEmpty()) {
                        this.index.put(tx, command.getExecutionTime(), current);
                    }
                    result = jl;
                    break;
                }
            }
        } else {
            
---------------Reference log start----------------
LOG.debug(""Process reschedule command for job {} non-existent executime time {}."", command.getJobId(), command.getExecutionTime())
---------------Reference log end----------------
        }

        if (result != null) {
            Location previousUpdate = result.getLastUpdate();

            List<JobLocation> target = null;
            result.setNextTime(command.getNextExecutionTime());
            result.setLastUpdate(location);
            result.setRescheduledCount(command.getRescheduledCount());
            if (!result.isCron() && result.getRepeat() > 0) {
                result.setRepeat(result.getRepeat() - 1);
            }
            if (this.index.containsKey(tx, command.getNextExecutionTime())) {
                target = this.index.remove(tx, command.getNextExecutionTime());
            }
            if (target == null) {
                target = new ArrayList<>();
            }
            target.add(result);

            // Track the location of the last reschedule command and release the log file
            // reference for the previous one if there was one.
            this.store.incrementJournalCount(tx, location);
            if (previousUpdate != null) {
                this.store.decrementJournalCount(tx, previousUpdate);
            }

            this.index.put(tx, command.getNextExecutionTime(), target);
            this.scheduleTime.newJob();
        } else {
            LOG.debug(""Process reschedule command for non-scheduled job {} at executime time {}."",
                      command.getJobId(), command.getExecutionTime());
        }
    }",,
activemq,19628,"LOG.debug(""failed to firing afterRollback callbacks commit failure, txid: {}, context: {}"", x, ctx, ignored)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/TransactionContext.java/#L625,"@Override
    public void commit(Xid xid, boolean onePhase) throws XAException {

        LOG.debug(""Commit: {}, onePhase={}"", xid, onePhase);

        // We allow interleaving multiple transactions, so
        // we don't limit commit to the associated xid.
        XATransactionId x;
        if (xid == null || (equals(associatedXid, xid))) {
            // should never happen, end(xid,TMSUCCESS) must have been previously
            // called
            throw new XAException(XAException.XAER_PROTO);
        } else {
            x = new XATransactionId(xid);
        }

        if (rollbackOnly) {
             LOG.warn(""commit of: "" + x + "" failed because it was marked rollback only; typically due to failover with pending acks"");
             throw new XAException(XAException.XA_RBINTEGRITY);
         }

        try {
            this.connection.checkClosedOrFailed();
            this.connection.ensureConnectionInfoSent();

            // Notify the server that the tx was committed back
            TransactionInfo info = new TransactionInfo(getConnectionId(), x, onePhase ? TransactionInfo.COMMIT_ONE_PHASE : TransactionInfo.COMMIT_TWO_PHASE);

            this.connection.syncSendPacket(info);

            List<TransactionContext> l;
            synchronized(ENDED_XA_TRANSACTION_CONTEXTS) {
                l = ENDED_XA_TRANSACTION_CONTEXTS.remove(x);
            }
            // After commit may be expensive and can deadlock, do it outside global synch block
            // No risk for concurrent updates as we own the list now
            if (l != null) {
                for (TransactionContext ctx : l) {
                    try {
                        ctx.afterCommit();
                    } catch (Exception ignored) {
                        LOG.debug(""ignoring exception from after completion on ended transaction: {}"", ignored, ignored);
                    }
                }
            }

        } catch (JMSException e) {
            LOG.warn(""commit of: "" + x + "" failed with: "" + e, e);
            if (onePhase) {
                List<TransactionContext> l;
                synchronized(ENDED_XA_TRANSACTION_CONTEXTS) {
                    l = ENDED_XA_TRANSACTION_CONTEXTS.remove(x);
                }
                // After rollback may be expensive and can deadlock, do it outside global synch block
                // No risk for concurrent updates as we own the list now
                if (l != null) {
                    for (TransactionContext ctx : l) {
                        try {
                            ctx.afterRollback();
                        } catch (Throwable ignored) {
                            
---------------Reference log start----------------
LOG.debug(""failed to firing afterRollback callbacks commit failure, txid: {}, context: {}"", x, ctx, ignored)
---------------Reference log end----------------
                        }
                    }
                }
            }
            throw toXAException(e);
        }
    }",,
activemq,17728,"LOG.debug(""Journalled transacted message add for: "" + id + "", at: "" + location)",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/journal/JournalMessageStore.java/#L107,"public void addMessage(final ConnectionContext context, final Message message) throws IOException {

        final MessageId id = message.getMessageId();

        final boolean debug = LOG.isDebugEnabled();
        message.incrementReferenceCount();

        final RecordLocation location = peristenceAdapter.writeCommand(message, message.isResponseRequired());
        if (!context.isInTransaction()) {
            if (debug) {
                LOG.debug(""Journalled message add for: "" + id + "", at: "" + location);
            }
            addMessage(context, message, location);
        } else {
            if (debug) {
                
---------------Reference log start----------------
LOG.debug(""Journalled transacted message add for: "" + id + "", at: "" + location)
---------------Reference log end----------------
            }
            synchronized (this) {
                inFlightTxLocations.add(location);
            }
            transactionStore.addMessage(this, message, location);
            context.getTransaction().addSynchronization(new Synchronization() {
                public void afterCommit() throws Exception {
                    if (debug) {
                        LOG.debug(""Transacted message add commit for: "" + id + "", at: "" + location);
                    }
                    synchronized (JournalMessageStore.this) {
                        inFlightTxLocations.remove(location);
                        addMessage(context, message, location);
                    }
                }

                public void afterRollback() throws Exception {
                    if (debug) {
                        LOG.debug(""Transacted message add rollback for: "" + id + "", at: "" + location);
                    }
                    synchronized (JournalMessageStore.this) {
                        inFlightTxLocations.remove(location);
                    }
                    message.decrementReferenceCount();
                }
            });
        }
    }",,
activemq,19510,"LOG.debug(""restored recovering consumer: "" + control.getConsumerId() + "" with: "" + control.getPrefetch())",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/state/ConnectionStateTracker.java/#L750,"public void connectionInterruptProcessingComplete(Transport transport, ConnectionId connectionId) {
        ConnectionState connectionState = connectionStates.get(connectionId);
        if (connectionState != null) {
            connectionState.setConnectionInterruptProcessingComplete(true);
            Map<ConsumerId, ConsumerInfo> stalledConsumers = connectionState.getRecoveringPullConsumers();
            for (Entry<ConsumerId, ConsumerInfo> entry: stalledConsumers.entrySet()) {
                ConsumerControl control = new ConsumerControl();
                control.setConsumerId(entry.getKey());
                control.setPrefetch(entry.getValue().getPrefetchSize());
                control.setDestination(entry.getValue().getDestination());
                try {
                    if (LOG.isDebugEnabled()) {
                        
---------------Reference log start----------------
LOG.debug(""restored recovering consumer: "" + control.getConsumerId() + "" with: "" + control.getPrefetch())
---------------Reference log end----------------
                    }
                    transport.oneway(control);
                } catch (Exception ex) {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Failed to submit control for consumer: "" + control.getConsumerId()
                                + "" with: "" + control.getPrefetch(), ex);
                    }
                }
            }
            stalledConsumers.clear();
        }
    }",,
activemq,18498,"LOG.debug(""on async exception, force rollback of transaction for: {}"", command, e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransportConnection.java/#L383,"private void forceRollbackOnlyOnFailedAsyncTransactionOp(Throwable e, Command command) {
        if (brokerService.isRollbackOnlyOnAsyncException() && !(e instanceof IOException) && isInTransaction(command)) {
            Transaction transaction = getActiveTransaction(command);
            if (transaction != null && !transaction.isRollbackOnly()) {
                
---------------Reference log start----------------
LOG.debug(""on async exception, force rollback of transaction for: {}"", command, e)
---------------Reference log end----------------
                transaction.setRollbackOnly(e);
            }
        }
    }",,
activemq,19227,"LOG.warn(""Could not connect to local URI: {}: {}"", localURI, e.getMessage())",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DiscoveryNetworkConnector.java/#L147,"@Override
    public void onServiceAdd(DiscoveryEvent event) {
        // Ignore events once we start stopping.
        if (serviceSupport.isStopped() || serviceSupport.isStopping()) {
            return;
        }
        String url = event.getServiceName();
        if (url != null) {
            URI uri;
            try {
                uri = new URI(url);
            } catch (URISyntaxException e) {
                LOG.warn(""Could not connect to remote URI: {} due to bad URI syntax: "", url, e);
                return;
            }

            if (localURI.equals(uri)) {
                LOG.debug(""not connecting loopback: {}"", uri);
                return;
            }

            if (connectionFilter != null && !connectionFilter.connectTo(uri)) {
                LOG.debug(""connectionFilter disallows connection to: {}"", uri);
                return;
            }

            // Should we try to connect to that URI?
            if (activeEvents.putIfAbsent(uri, event) != null) {
                LOG.debug(""Discovery agent generated a duplicate onServiceAdd event for: {}"", uri);
                return;
            }

            URI connectUri = uri;
            try {
                connectUri = URISupport.applyParameters(connectUri, parameters, DISCOVERED_OPTION_PREFIX);
            } catch (URISyntaxException e) {
                LOG.warn(""could not apply query parameters: {} to: {}"",parameters, connectUri, e);
            }

            LOG.info(""Establishing network connection from {} to {}"", localURI, connectUri);

            Transport remoteTransport;
            Transport localTransport;
            try {
                // Allows the transport to access the broker's ssl configuration.
                if (getSslContext() != null) {
                    SslContext.setCurrentSslContext(getSslContext());
                } else {
                    SslContext.setCurrentSslContext(getBrokerService().getSslContext());
                }
                try {
                    remoteTransport = TransportFactory.connect(connectUri);
                } catch (Exception e) {
                    LOG.warn(""Could not connect to remote URI: {}: {}"", connectUri, e.getMessage());
                    LOG.debug(""Connection failure exception: "", e);
                    try {
                        discoveryAgent.serviceFailed(event);
                    } catch (IOException e1) {
                        LOG.debug(""Failure while handling create remote transport failure event: {}"", e1.getMessage(), e1);
                    }
                    return;
                }
                try {
                    localTransport = createLocalTransport();
                } catch (Exception e) {
                    ServiceSupport.dispose(remoteTransport);
                    
---------------Reference log start----------------
LOG.warn(""Could not connect to local URI: {}: {}"", localURI, e.getMessage())
---------------Reference log end----------------
                    LOG.debug(""Connection failure exception: "", e);

                    try {
                        discoveryAgent.serviceFailed(event);
                    } catch (IOException e1) {
                        LOG.debug(""Failure while handling create local transport failure event: {}"", e1.getMessage(), e1);
                    }
                    return;
                }
            } finally {
                SslContext.setCurrentSslContext(null);
            }
            NetworkBridge bridge = createBridge(localTransport, remoteTransport, event);
            try {
                synchronized (bridges) {
                    bridges.put(uri, bridge);
                }
                bridge.start();
            } catch (Exception e) {
                ServiceSupport.dispose(localTransport);
                ServiceSupport.dispose(remoteTransport);
                LOG.warn(""Could not start network bridge between: {} and: {} due to: {}"", localURI, uri, e.getMessage());
                LOG.debug(""Start failure exception: "", e);
                try {
                    // Will remove bridge and active event.
                    discoveryAgent.serviceFailed(event);
                } catch (IOException e1) {
                    LOG.debug(""Discovery agent failure while handling failure event: {}"", e1.getMessage(), e1);
                }
            }
        }
    }",,
activemq,19726,"LOG.debug(""urlList connectionList:{}, from: {}"", l, uniqueUris)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/failover/FailoverTransport.java/#L818,"private List<URI> getConnectList() {
        // updated have precedence
        LinkedHashSet<URI> uniqueUris = new LinkedHashSet<URI>(updated);
        uniqueUris.addAll(uris);

        boolean removed = false;
        if (failedConnectTransportURI != null) {
            removed = uniqueUris.remove(failedConnectTransportURI);
        }

        ArrayList<URI> l = new ArrayList<URI>(uniqueUris);
        if (randomize) {
            // Randomly, reorder the list by random swapping
            for (int i = 0; i < l.size(); i++) {
                // meed parenthesis due other JDKs (see AMQ-4826)
                int p = ((int) (Math.random() * 100)) % l.size();
                URI t = l.get(p);
                l.set(p, l.get(i));
                l.set(i, t);
            }
        }
        if (removed) {
            l.add(failedConnectTransportURI);
        }

        
---------------Reference log start----------------
LOG.debug(""urlList connectionList:{}, from: {}"", l, uniqueUris)
---------------Reference log end----------------

        return l;
    }",,
activemq,18677,"LOG.error(""Failed to start Scheduler"", e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L2842,"public synchronized Scheduler getScheduler() {
        if (this.scheduler==null) {
            this.scheduler = new Scheduler(""ActiveMQ Broker[""+getBrokerName()+""] Scheduler"");
            try {
                this.scheduler.start();
            } catch (Exception e) {
               
---------------Reference log start----------------
LOG.error(""Failed to start Scheduler"", e)
---------------Reference log end----------------
            }
        }
        return this.scheduler;
    }",,
activemq,19487,"LOG.warn(""Unknown command: "" + command)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/advisory/ConsumerEventSource.java/#L104,"public void onMessage(Message message) {
        if (message instanceof ActiveMQMessage) {
            ActiveMQMessage activeMessage = (ActiveMQMessage)message;
            Object command = activeMessage.getDataStructure();
            int count = 0;
            if (command instanceof ConsumerInfo) {
                count = consumerCount.incrementAndGet();
                count = extractConsumerCountFromMessage(message, count);
                fireConsumerEvent(new ConsumerStartedEvent(this, destination, (ConsumerInfo)command, count));
            } else if (command instanceof RemoveInfo) {
                RemoveInfo removeInfo = (RemoveInfo)command;
                if (removeInfo.isConsumerRemove()) {
                    count = consumerCount.decrementAndGet();
                    count = extractConsumerCountFromMessage(message, count);
                    fireConsumerEvent(new ConsumerStoppedEvent(this, destination, (ConsumerId)removeInfo.getObjectId(), count));
                }
            } else {
                
---------------Reference log start----------------
LOG.warn(""Unknown command: "" + command)
---------------Reference log end----------------
            }
        } else {
            LOG.warn(""Unknown message type: "" + message + "". Message ignored"");
        }
    }",,
activemq,17795,"LOG.error(""Failed to update database lock: "" + e, e)",error,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/DefaultDatabaseLocker.java/#L169,"public boolean keepAlive() throws IOException {
        boolean result = false;
        try {
            lockUpdateStatement = connection.prepareStatement(getStatements().getLockUpdateStatement());
            lockUpdateStatement.setLong(1, System.currentTimeMillis());
            setQueryTimeout(lockUpdateStatement);
            int rows = lockUpdateStatement.executeUpdate();
            if (rows == 1) {
                result=true;
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Failed to update database lock: "" + e, e)
---------------Reference log end----------------
        } finally {
            if (lockUpdateStatement != null) {
                try {
                    lockUpdateStatement.close();
                } catch (SQLException e) {
                    LOG.error(""Failed to close statement"",e);
                }
                lockUpdateStatement = null;
            }
        }
        return result;
    }",,
activemq,19458,"LOG.trace(""Exceeded redelivery with count: {}, Ack: {}"", redeliveryCounter, ack)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQSession.java/#L992,"@Override
                            public void afterRollback() throws Exception {
                                if (LOG.isTraceEnabled()) {
                                    LOG.trace(""afterRollback {}"", ack, new Throwable(""here""));
                                }
                                // ensure we don't filter this as a duplicate
                                connection.rollbackDuplicate(ActiveMQSession.this, md.getMessage());

                                // don't redeliver if we have been interrupted b/c the broker will redeliver on reconnect
                                if (clearRequestsCounter.get() > clearRequestCount) {
                                    LOG.debug(""No redelivery of {} on rollback of {} due to failover of {}"", md, ack.getTransactionId(), connection.getTransport());
                                    return;
                                }

                                // validate our consumer so we don't push stale acks that get ignored or redeliver what will be redispatched
                                if (ack.getTransactionId().isXATransaction() && !connection.hasDispatcher(ack.getConsumerId())) {
                                    LOG.debug(""No local redelivery of {} on rollback of {} because consumer is no longer active on {}"", md, ack.getTransactionId(), connection.getTransport());
                                    return;
                                }

                                RedeliveryPolicy redeliveryPolicy = connection.getRedeliveryPolicy();
                                int redeliveryCounter = md.getMessage().getRedeliveryCounter();
                                if (redeliveryPolicy.getMaximumRedeliveries() != RedeliveryPolicy.NO_MAXIMUM_REDELIVERIES
                                        && redeliveryCounter >= redeliveryPolicy.getMaximumRedeliveries()) {
                                    // We need to NACK the messages so that they get
                                    // sent to the
                                    // DLQ.
                                    // Acknowledge the last message.
                                    MessageAck ack = new MessageAck(md, MessageAck.POISON_ACK_TYPE, 1);
                                    ack.setFirstMessageId(md.getMessage().getMessageId());
                                    ack.setPoisonCause(new Throwable(""Exceeded ra redelivery policy limit:"" + redeliveryPolicy));
                                    
---------------Reference log start----------------
LOG.trace(""Exceeded redelivery with count: {}, Ack: {}"", redeliveryCounter, ack)
---------------Reference log end----------------
                                    asyncSendPacket(ack);

                                } else {

                                    MessageAck ack = new MessageAck(md, MessageAck.REDELIVERED_ACK_TYPE, 1);
                                    ack.setFirstMessageId(md.getMessage().getMessageId());
                                    asyncSendPacket(ack);

                                    // Figure out how long we should wait to resend
                                    // this message.
                                    long redeliveryDelay = redeliveryPolicy.getInitialRedeliveryDelay();
                                    for (int i = 0; i < redeliveryCounter; i++) {
                                        redeliveryDelay = redeliveryPolicy.getNextRedeliveryDelay(redeliveryDelay);
                                    }

                                    /*
                                    * If we are a non blocking delivery then we need to stop the executor to avoid more
                                    * messages being delivered, once the message is redelivered we can restart it.
                                    * */
                                    if (!connection.isNonBlockingRedelivery()) {
                                        LOG.debug(""Blocking session until re-delivery..."");
                                        executor.stop();
                                    }

                                    connection.getScheduler().executeAfterDelay(new Runnable() {

                                        @Override
                                        public void run() {
                                            /*
                                            * wait for the first delivery to be complete, i.e. after delivery has been called.
                                            * */
                                            synchronized (redeliveryGuard) {
                                                /*
                                                * If its non blocking then we can just dispatch in a new session.
                                                * */
                                                if (connection.isNonBlockingRedelivery()) {
                                                    ((ActiveMQDispatcher) md.getConsumer()).dispatch(md);
                                                } else {
                                                    /*
                                                    * If there has been an error thrown during afterDelivery then the
                                                    * endpoint will be marked as dead so redelivery will fail (and eventually
                                                    * the session marked as stale), in this case we can only call dispatch
                                                    * which will create a new session with a new endpoint.
                                                    * */
                                                    if (afterDeliveryError.get()) {
                                                        ((ActiveMQDispatcher) md.getConsumer()).dispatch(md);
                                                    } else {
                                                        executor.executeFirst(md);
                                                        executor.start();
                                                    }
                                                }
                                            }
                                        }
                                    }, redeliveryDelay);
                                }
                                md.getMessage().onMessageRolledBack();
                            }",,
activemq,19032,"LOG.debug(""Reading selector cache...."")",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/plugin/SubQueueSelectorCacheBroker.java/#L200,"@SuppressWarnings(""unchecked"")
    private void readCache() {
        if (persistFile != null && persistFile.exists()) {
            try {
                try (FileInputStream fis = new FileInputStream(persistFile);) {
                    ObjectInputStream in = new SubSelectorClassObjectInputStream(fis);
                    try {
                        
---------------Reference log start----------------
LOG.debug(""Reading selector cache...."")
---------------Reference log end----------------
                        subSelectorCache = (ConcurrentHashMap<String, Set<String>>) in.readObject();

                        if (LOG.isDebugEnabled()) {
                            final StringBuilder sb = new StringBuilder();
                            sb.append(""Selector cache data loaded from: "").append(persistFile.getAbsolutePath()).append(""\n"");
                            sb.append(""The following entries were loaded from the cache file: \n"");

                            subSelectorCache.forEach((k,v) -> {
                                sb.append(""\t"").append(k).append("": "").append(v).append(""\n"");
                            });

                            LOG.debug(sb.toString());
                        }
                    } catch (ClassNotFoundException ex) {
                        LOG.error(""Invalid selector cache data found. Please remove file."", ex);
                    } finally {
                        in.close();
                    }
                }
            } catch (IOException ex) {
                LOG.error(""Unable to read persisted selector cache...it will be ignored!"", ex);
            }
        }
    }",,
activemq,18756,"LOG.debug(""Discarding message that exceeds max redelivery count({}), {}"", maximumRedeliveries, messageReference.getMessageId())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/RedeliveryPlugin.java/#L154,"@Override
    public boolean sendToDeadLetterQueue(ConnectionContext context, MessageReference messageReference, Subscription subscription, Throwable poisonCause) {
        if (messageReference.isExpired() || (poisonCause != null && poisonCause.getMessage() != null && poisonCause.getMessage().contains(DUPLICATE_FROM_STORE_MSG_PREFIX))) {
            // there are three uses of  sendToDeadLetterQueue, we are only interested in valid messages
            return super.sendToDeadLetterQueue(context, messageReference, subscription, poisonCause);
        } else {
            try {
                Destination regionDestination = (Destination) messageReference.getRegionDestination();
                final RedeliveryPolicy redeliveryPolicy = redeliveryPolicyMap.getEntryFor(regionDestination.getActiveMQDestination());
                if (redeliveryPolicy != null) {
                    final int maximumRedeliveries = redeliveryPolicy.getMaximumRedeliveries();
                    int redeliveryCount = messageReference.getRedeliveryCounter();
                    if (RedeliveryPolicy.NO_MAXIMUM_REDELIVERIES == maximumRedeliveries || redeliveryCount < maximumRedeliveries) {

                        long delay = redeliveryPolicy.getInitialRedeliveryDelay();
                        for (int i = 0; i < redeliveryCount; i++) {
                            delay = redeliveryPolicy.getNextRedeliveryDelay(delay);
                        }

                        scheduleRedelivery(context, messageReference, delay, ++redeliveryCount);
                    } else if (isSendToDlqIfMaxRetriesExceeded()) {
                        return super.sendToDeadLetterQueue(context, messageReference, subscription, poisonCause);
                    } else {
                        
---------------Reference log start----------------
LOG.debug(""Discarding message that exceeds max redelivery count({}), {}"", maximumRedeliveries, messageReference.getMessageId())
---------------Reference log end----------------
                    }
                } else if (isFallbackToDeadLetter()) {
                    return super.sendToDeadLetterQueue(context, messageReference, subscription, poisonCause);
                } else {
                    LOG.debug(""Ignoring dlq request for: {}, RedeliveryPolicy not found (and no fallback) for: {}"", messageReference.getMessageId(), regionDestination.getActiveMQDestination());
                }

                return false;
            } catch (Exception exception) {
                // abort the ack, will be effective if client use transactions or individual ack with sync send
                RuntimeException toThrow =  new RuntimeException(""Failed to schedule redelivery for: "" + messageReference.getMessageId(), exception);
                LOG.error(toThrow.toString(), exception);
                throw toThrow;
            }
        }
    }",,
activemq,18711,"LOG.info(""Preparing transaction: {}"", xid.getTransactionKey())",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/LoggingBrokerPlugin.java/#L234,"@Override
    public int prepareTransaction(ConnectionContext context, TransactionId xid) throws Exception {
        if (isLogAll() || isLogTransactionEvents()) {
            
---------------Reference log start----------------
LOG.info(""Preparing transaction: {}"", xid.getTransactionKey())
---------------Reference log end----------------
        }
        return super.prepareTransaction(context, xid);
    }",,
activemq,18865,"LOG.warn(""Ack for non existent subscription, ack: {}"", ack)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/AbstractRegion.java/#L525,"@Override
    public void acknowledge(ConsumerBrokerExchange consumerExchange, MessageAck ack) throws Exception {
        Subscription sub = consumerExchange.getSubscription();
        if (sub == null) {
            sub = subscriptions.get(ack.getConsumerId());
            if (sub == null) {
                if (!consumerExchange.getConnectionContext().isInRecoveryMode()) {
                    
---------------Reference log start----------------
LOG.warn(""Ack for non existent subscription, ack: {}"", ack)
---------------Reference log end----------------
                    throw new IllegalArgumentException(""The subscription does not exist: "" + ack.getConsumerId());
                } else {
                    LOG.debug(""Ack for non existent subscription in recovery, ack: {}"", ack);
                    return;
                }
            }
            consumerExchange.setSubscription(sub);
        }
        sub.acknowledge(consumerExchange.getConnectionContext(), ack);
    }",,
activemq,19466,"LOG.trace(""Execute[{}] runnable: {}"", name, runnable)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/thread/TaskRunnerFactory.java/#L170,"public void execute(Runnable runnable, String name) {
        init();
        
---------------Reference log start----------------
LOG.trace(""Execute[{}] runnable: {}"", name, runnable)
---------------Reference log end----------------
        ExecutorService executor = executorRef.get();
        if (executor != null) {
            executor.execute(runnable);
        } else {
            doExecuteNewThread(runnable, name);
        }
    }",,
activemq,18094,"LOG.trace(""updating: "" + message.getMessageId() + "" with deliveryCount: "" + message.getRedeliveryCounter())",trace,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/KahaDBStore.java/#L591,"@Override
        public void updateMessage(Message message) throws IOException {
            if (LOG.isTraceEnabled()) {
                
---------------Reference log start----------------
LOG.trace(""updating: "" + message.getMessageId() + "" with deliveryCount: "" + message.getRedeliveryCounter())
---------------Reference log end----------------
            }
            KahaUpdateMessageCommand updateMessageCommand = new KahaUpdateMessageCommand();
            KahaAddMessageCommand command = new KahaAddMessageCommand();
            command.setDestination(dest);
            command.setMessageId(message.getMessageId().toProducerKey());
            command.setPriority(message.getPriority());
            command.setPrioritySupported(prioritizedMessages);
            org.apache.activemq.util.ByteSequence packet = wireFormat.marshal(message);
            command.setMessage(new Buffer(packet.getData(), packet.getOffset(), packet.getLength()));
            updateMessageCommand.setMessage(command);
            store(updateMessageCommand, isEnableJournalDiskSyncs(), null, null);
        }",,
activemq,19057,"LOG.warn(""Error processing virtualDestinationSubs for BrokerSubscriptionInfo"")",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/util/NetworkBridgeUtils.java/#L91,"public static BrokerSubscriptionInfo getBrokerSubscriptionInfo(final BrokerService brokerService,
            final NetworkBridgeConfiguration config) {

        RegionBroker regionBroker = (RegionBroker) brokerService.getRegionBroker();
        TopicRegion topicRegion = (TopicRegion) regionBroker.getTopicRegion();
        Set<ConsumerInfo> subscriptionInfos = new HashSet<>();

        //Add all durable subscriptions to the set that match the network config
        //which currently is just the dynamicallyIncludedDestinations list
        for (SubscriptionKey key : topicRegion.getDurableSubscriptions().keySet()) {
            DurableTopicSubscription sub = topicRegion.getDurableSubscriptions().get(key);
            if (sub != null && NetworkBridgeUtils.matchesNetworkConfig(config, sub.getConsumerInfo().getDestination())) {
                ConsumerInfo ci = sub.getConsumerInfo().copy();
                ci.setClientId(key.getClientId());
                subscriptionInfos.add(ci);
            }
        }

        //We also need to iterate over all normal subscriptions and check if they are part of
        //any dynamicallyIncludedDestination that is configured with forceDurable to be true
        //over the network bridge.  If forceDurable is true then we want to add the consumer to the set
        for (Subscription sub : topicRegion.getSubscriptions().values()) {
            if (sub != null && NetworkBridgeUtils.isForcedDurable(sub.getConsumerInfo(),
                    config.getDynamicallyIncludedDestinations())) {
                subscriptionInfos.add(sub.getConsumerInfo().copy());
            }
        }

        try {
            //Lastly, if isUseVirtualDestSubs is configured on this broker (to fire advisories) and
            //configured on the network connector (to listen to advisories) then also add any virtual
            //dest subscription to the set if forceDurable is true for its destination
            AdvisoryBroker ab = (AdvisoryBroker) brokerService.getBroker().getAdaptor(AdvisoryBroker.class);
            if (ab != null && brokerService.isUseVirtualDestSubs() && config.isUseVirtualDestSubs()) {
                for (ConsumerInfo info : ab.getVirtualDestinationConsumers().keySet()) {
                    if (NetworkBridgeUtils.isForcedDurable(info, config.getDynamicallyIncludedDestinations())) {
                        subscriptionInfos.add(info.copy());
                    }
                }
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.warn(""Error processing virtualDestinationSubs for BrokerSubscriptionInfo"")
---------------Reference log end----------------
            LOG.debug(""Error processing virtualDestinationSubs for BrokerSubscriptionInfo"", e);
        }
        BrokerSubscriptionInfo bsi = new BrokerSubscriptionInfo(brokerService.getBrokerName());
        bsi.setSubscriptionInfos(subscriptionInfos.toArray(new ConsumerInfo[0]));
        return bsi;
    }",,
activemq,19066,"LOG.warn(""Could not accept connection {}: {} ({})"", (in.getRemoteAddress() == null ? """" : ""from "" + in.getRemoteAddress()), error.getMessage(), TransportConnector.getRootCause(error).getMessage())",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/transport/auto/nio/AutoNIOSSLTransportServer.java/#L126,"@Override
            public void run() {
                try {
                    in.start();
                } catch (Exception error) {
                    
---------------Reference log start----------------
LOG.warn(""Could not accept connection {}: {} ({})"", (in.getRemoteAddress() == null ? """" : ""from "" + in.getRemoteAddress()), error.getMessage(), TransportConnector.getRootCause(error).getMessage())
---------------Reference log end----------------
                    throw new IllegalStateException(""Could not complete Transport start"", error);
                }

                int attempts = 0;
                do {
                    if(attempts > 0) {
                        try {
                            //increase sleep period each attempt to prevent high cpu usage
                            //if the client is hung and not sending bytes
                            int sleep = attempts >= 1024 ? 1024 : 4 * attempts;
                            Thread.sleep(sleep);
                        } catch (InterruptedException e) {
                            break;
                        }
                    }
                    //In the future it might be better to register a nonblocking selector
                    //to be told when bytes are ready
                    in.serviceRead();
                    attempts++;
                } while(in.getReadSize().get() < 8 && !Thread.interrupted());
            }",,
activemq,19767,"LOG.warn(""Request for buffer: "" + commandId + "" is no longer present"")",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/udp/CommandDatagramChannel.java/#L253,"public void sendBuffer(int commandId, Object buffer) throws IOException {
        if (buffer != null) {
            ByteBuffer writeBuffer = (ByteBuffer)buffer;
            sendWriteBuffer(commandId, getReplayAddress(), writeBuffer, true);
        } else {
            if (LOG.isWarnEnabled()) {
                
---------------Reference log start----------------
LOG.warn(""Request for buffer: "" + commandId + "" is no longer present"")
---------------Reference log end----------------
            }
        }
    }",,
activemq,18960,"LOG.error(""Policy not applied!  Error parsing DN for object removal for removal of {}"", result.getName(), e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/security/SimpleCachedLDAPAuthorizationMap.java/#L835,"public void objectRemoved(NamingEvent namingEvent, DestinationType destinationType, PermissionType permissionType) {
        LOG.debug(""Removing object: {}"", namingEvent.getOldBinding());
        Binding result = namingEvent.getOldBinding();

        try {
            DefaultAuthorizationMap map = this.map.get();
            LdapName name = new LdapName(result.getName());
            AuthorizationEntry entry = getEntry(map, name, destinationType);
            applyAcl(entry, permissionType, new HashSet<Object>());
        } catch (InvalidNameException e) {
            
---------------Reference log start----------------
LOG.error(""Policy not applied!  Error parsing DN for object removal for removal of {}"", result.getName(), e)
---------------Reference log end----------------
        } catch (Exception e) {
            LOG.error(""Policy not applied!  Error processing object removal for removal of {}"", result.getName(), e);
        }
    }",,
activemq,18056,"LOG.debug(""Job Scheduler Store Checkpoint started."")",debug,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/scheduler/JobSchedulerStoreImpl.java/#L358,"@Override
    protected void checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
        
---------------Reference log start----------------
LOG.debug(""Job Scheduler Store Checkpoint started."")
---------------Reference log end----------------

        // reflect last update exclusive of current checkpoint
        Location lastUpdate = metaData.getLastUpdateLocation();
        metaData.setState(KahaDBMetaData.OPEN_STATE);
        tx.store(metaData.getPage(), metaDataMarshaller, true);
        pageFile.flush();

        if (cleanup) {
            final TreeSet<Integer> completeFileSet = new TreeSet<Integer>(journal.getFileMap().keySet());
            final TreeSet<Integer> gcCandidateSet = new TreeSet<Integer>(completeFileSet);

            LOG.trace(""Last update: {}, full gc candidates set: {}"", lastUpdate, gcCandidateSet);

            if (lastUpdate != null) {
                gcCandidateSet.remove(lastUpdate.getDataFileId());
            }

            this.metaData.getJournalRC().visit(tx, new BTreeVisitor<Integer, Integer>() {

                @Override
                public void visit(List<Integer> keys, List<Integer> values) {
                    for (Integer key : keys) {
                        if (gcCandidateSet.remove(key)) {
                            LOG.trace(""Removed referenced file: {} from GC set"", key);
                        }
                    }
                }

                @Override
                public boolean isInterestedInKeysBetween(Integer first, Integer second) {
                    return true;
                }
            });

            LOG.trace(""gc candidates after reference check: {}"", gcCandidateSet);

            // If there are GC candidates then check the remove command location to see
            // if any of them can go or if they must stay in order to ensure proper recover.
            //
            // A log containing any remove commands must be kept until all the logs with the
            // add commands for all the removed jobs have been dropped.
            if (!gcCandidateSet.isEmpty()) {
                Iterator<Entry<Integer, List<Integer>>> removals = metaData.getRemoveLocationTracker().iterator(tx);
                List<Integer> orphans = new ArrayList<Integer>();
                while (removals.hasNext()) {
                    boolean orphanedRemove = true;
                    Entry<Integer, List<Integer>> entry = removals.next();

                    // If this log is not a GC candidate then there's no need to do a check to rule it out
                    if (gcCandidateSet.contains(entry.getKey())) {
                        for (Integer addLocation : entry.getValue()) {
                            if (completeFileSet.contains(addLocation)) {
                                LOG.trace(""A remove in log {} has an add still in existance in {}."", entry.getKey(), addLocation);
                                orphanedRemove = false;
                                break;
                            }
                        }

                        // If it's not orphaned than we can't remove it, otherwise we
                        // stop tracking it it's log will get deleted on the next check.
                        if (!orphanedRemove) {
                            gcCandidateSet.remove(entry.getKey());
                        } else {
                            LOG.trace(""All removes in log {} are orphaned, file can be GC'd"", entry.getKey());
                            orphans.add(entry.getKey());
                        }
                    }
                }

                // Drop all orphaned removes from the tracker.
                for (Integer orphan : orphans) {
                    metaData.getRemoveLocationTracker().remove(tx, orphan);
                }
            }

            LOG.trace(""gc candidates after removals check: {}"", gcCandidateSet);
            if (!gcCandidateSet.isEmpty()) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Cleanup removing the data files: "" + gcCandidateSet);
                }
                journal.removeDataFiles(gcCandidateSet);
            }
        }

        LOG.debug(""Job Scheduler Store Checkpoint complete."");
    }",,
activemq,18326,"LOG.debug(""doMessage timeout="" + timeout)",debug,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/MessageListenerServlet.java/#L272,"protected void doMessages(AjaxWebClient client, HttpServletRequest request, HttpServletResponse response) throws JMSException, IOException {

        int messages = 0;
        // This is a poll for any messages

        long timeout = getReadTimeout(request);
        if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""doMessage timeout="" + timeout)
---------------Reference log end----------------
        }

        // this is non-null if we're resuming the continuation.
        // attributes set in AjaxListener
        UndeliveredAjaxMessage undelivered_message = null;
        Message message = null;
        undelivered_message = (UndeliveredAjaxMessage)request.getAttribute(""undelivered_message"");
        if( undelivered_message != null ) {
            message = undelivered_message.getMessage();
        }

        synchronized (client) {

            List<MessageConsumer> consumers = client.getConsumers();
            MessageAvailableConsumer consumer = null;
            if( undelivered_message != null ) {
                consumer = (MessageAvailableConsumer)undelivered_message.getConsumer();
            }

            if (message == null) {
                // Look for a message that is ready to go
                for (int i = 0; message == null && i < consumers.size(); i++) {
                    consumer = (MessageAvailableConsumer)consumers.get(i);
                    if (consumer.getAvailableListener() == null) {
                        continue;
                    }

                    // Look for any available messages
                    message = consumer.receive(10);
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""received "" + message + "" from "" + consumer);
                    }
                }
            }

            // prepare the response
            response.setContentType(""text/xml"");
            response.setHeader(""Cache-Control"", ""no-cache"");

            if (message == null && client.getListener().getUndeliveredMessages().size() == 0) {
                Continuation continuation = ContinuationSupport.getContinuation(request);

                // Add a listener to the continuation to make sure it actually
                // will expire (seems like a bug in Jetty Servlet 3 continuations,
                // see https://issues.apache.org/jira/browse/AMQ-3447
                continuation.addContinuationListener(new ContinuationListener() {
                    @Override
                    public void onTimeout(Continuation cont) {
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Continuation "" + cont.toString() + "" expired."");
                        }
                    }

                    @Override
                    public void onComplete(Continuation cont) {
                        if (LOG.isDebugEnabled()) {
                           LOG.debug(""Continuation "" + cont.toString() + "" completed."");
                        }
                    }
                });

                if (continuation.isExpired()) {
                    response.setStatus(HttpServletResponse.SC_OK);
                    StringWriter swriter = new StringWriter();
                    PrintWriter writer = new PrintWriter(swriter);
                    writer.println(""<ajax-response>"");
                    writer.print(""</ajax-response>"");

                    writer.flush();
                    String m = swriter.toString();
                    response.getWriter().println(m);

                    return;
                }

                continuation.setTimeout(timeout);
                continuation.suspend();
                LOG.debug( ""Suspending continuation "" + continuation );

                // Fetch the listeners
                AjaxListener listener = client.getListener();
                listener.access();

                // register this continuation with our listener.
                listener.setContinuation(continuation);

                return;
            }

            StringWriter swriter = new StringWriter();
            PrintWriter writer = new PrintWriter(swriter);

            Map<MessageAvailableConsumer, String> consumerIdMap = client.getIdMap();
            Map<MessageAvailableConsumer, String> consumerDestinationNameMap = client.getDestinationNameMap();
            response.setStatus(HttpServletResponse.SC_OK);
            writer.println(""<ajax-response>"");

            // Send any message we already have
            if (message != null) {
                String id = consumerIdMap.get(consumer);
                String destinationName = consumerDestinationNameMap.get(consumer);
                LOG.debug( ""sending pre-existing message"" );
                writeMessageResponse(writer, message, id, destinationName);

                messages++;
            }

            // send messages buffered while continuation was unavailable.
            LinkedList<UndeliveredAjaxMessage> undeliveredMessages = ((AjaxListener)consumer.getAvailableListener()).getUndeliveredMessages();
            LOG.debug(""Send "" + undeliveredMessages.size() + "" unconsumed messages"");
            synchronized( undeliveredMessages ) {
                for (Iterator<UndeliveredAjaxMessage> it = undeliveredMessages.iterator(); it.hasNext();) {
                    messages++;
                    UndeliveredAjaxMessage undelivered = it.next();
                    Message msg = undelivered.getMessage();
                    consumer = (MessageAvailableConsumer)undelivered.getConsumer();
                    String id = consumerIdMap.get(consumer);
                    String destinationName = consumerDestinationNameMap.get(consumer);
                    LOG.debug( ""sending undelivered/buffered messages"" );
                    LOG.debug( ""msg:"" +msg+ "", id:"" +id+ "", destinationName:"" +destinationName);
                    writeMessageResponse(writer, msg, id, destinationName);
                    it.remove();
                    if (messages >= maximumMessages) {
                        break;
                    }
                }
            }

            // Send the rest of the messages
            for (int i = 0; i < consumers.size() && messages < maximumMessages; i++) {
                consumer = (MessageAvailableConsumer)consumers.get(i);
                if (consumer.getAvailableListener() == null) {
                    continue;
                }

                // Look for any available messages
                while (messages < maximumMessages) {
                    message = consumer.receiveNoWait();
                    if (message == null) {
                        break;
                    }
                    messages++;
                    String id = consumerIdMap.get(consumer);
                    String destinationName = consumerDestinationNameMap.get(consumer);
                    LOG.debug( ""sending final available messages"" );
                    writeMessageResponse(writer, message, id, destinationName);
                }
            }

            writer.print(""</ajax-response>"");

            writer.flush();
            String m = swriter.toString();
            response.getWriter().println(m);
        }
    }",,
activemq,18830,"LOG.trace(""no set batch from async:"" + candidate.getFutureOrSequenceLong() + "" >= than current: "" + currentAdd.getMessageId().getFutureOrSequenceLong() + "", "" + this)",trace,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/cursors/AbstractStoreCursor.java/#L327,"private void syncWithStore(Message currentAdd) throws Exception {
        pruneLastCached();
        for (ListIterator<MessageId> it = pendingCachedIds.listIterator(pendingCachedIds.size()); it.hasPrevious(); ) {
            MessageId lastPending = it.previous();
            Object futureOrLong = lastPending.getFutureOrSequenceLong();
            if (futureOrLong instanceof Future) {
                Future future = (Future) futureOrLong;
                if (future.isCancelled()) {
                    continue;
                }
                try {
                    future.get(5, TimeUnit.SECONDS);
                    setLastCachedId(ASYNC_ADD, lastPending);
                } catch (CancellationException ok) {
                    continue;
                } catch (TimeoutException potentialDeadlock) {
                    LOG.debug(""{} timed out waiting for async add"", this, potentialDeadlock);
                } catch (Exception worstCaseWeReplay) {
                    LOG.debug(""{} exception waiting for async add"", this, worstCaseWeReplay);
                }
            } else {
                setLastCachedId(ASYNC_ADD, lastPending);
            }
            break;
        }

        MessageId candidate = lastCachedIds[ASYNC_ADD];
        if (candidate != null) {
            // ensure we don't skip current possibly sync add b/c we waited on the future
            if (!isAsync(currentAdd) && Long.compare(((Long) currentAdd.getMessageId().getFutureOrSequenceLong()), ((Long) lastCachedIds[ASYNC_ADD].getFutureOrSequenceLong())) < 0) {
                if (LOG.isTraceEnabled()) {
                    
---------------Reference log start----------------
LOG.trace(""no set batch from async:"" + candidate.getFutureOrSequenceLong() + "" >= than current: "" + currentAdd.getMessageId().getFutureOrSequenceLong() + "", "" + this)
---------------Reference log end----------------
                }
                candidate = null;
            }
        }
        if (candidate == null) {
            candidate = lastCachedIds[SYNC_ADD];
        }
        if (candidate != null) {
            setBatch(candidate);
        }
        // cleanup
        lastCachedIds[SYNC_ADD] = lastCachedIds[ASYNC_ADD] = null;
        pendingCachedIds.clear();
    }",,
activemq,18313,"LOG.debug(""destination uri="" + uri)",debug,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/MessageServletSupport.java/#L305,"protected Destination getDestinationFromURI(WebClient client, HttpServletRequest request) throws JMSException {
        String uri = request.getPathInfo();
        if (uri == null) {
            return null;
        }

        // replace URI separator with JMS destination separator
        if (uri.startsWith(""/"")) {
            uri = uri.substring(1);
            if (uri.length() == 0) {
                return null;
            }
        }

        uri = uri.replace('/', '.');
        
---------------Reference log start----------------
LOG.debug(""destination uri="" + uri)
---------------Reference log end----------------
        return getDestination(client, request, uri);
    }",,
activemq,19199,"LOG.info(""failed to forward message on attempt: {} reason: {} message: {}"", attempt, e, message)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/jms/DestinationBridge.java/#L152,"@Override
    public void onMessage(Message message) {

        int attempt = 0;
        final int maxRetries = jmsConnector.getReconnectionPolicy().getMaxSendRetries();

        while (started.get() && message != null && (maxRetries == ReconnectionPolicy.INFINITE || attempt <= maxRetries)) {

            try {

                if (attempt++ > 0) {
                    try {
                        Thread.sleep(jmsConnector.getReconnectionPolicy().getNextDelay(attempt));
                    } catch(InterruptedException e) {
                        break;
                    }
                }

                Message converted;
                if (jmsMessageConvertor != null) {
                    if (doHandleReplyTo) {
                        Destination replyTo = message.getJMSReplyTo();
                        if (replyTo != null) {
                            converted = jmsMessageConvertor.convert(message, processReplyToDestination(replyTo));
                        } else {
                            converted = jmsMessageConvertor.convert(message);
                        }
                    } else {
                        message.setJMSReplyTo(null);
                        converted = jmsMessageConvertor.convert(message);
                    }
                } else {
                    // The Producer side is not up or not yet configured, retry.
                    continue;
                }

                try {
                    sendMessage(converted);
                } catch(Exception e) {
                    jmsConnector.handleConnectionFailure(getConnectionForProducer());
                    continue;
                }

                try {
                    message.acknowledge();
                } catch(Exception e) {
                    jmsConnector.handleConnectionFailure(getConnnectionForConsumer());
                    continue;
                }

                // if we got here then it made it out and was ack'd
                return;

            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.info(""failed to forward message on attempt: {} reason: {} message: {}"", attempt, e, message)
---------------Reference log end----------------
            }
        }
    }",,
activemq,19007,"LOG.debug(""commit: "" + xid + "" syncCount: "" + size())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/transaction/LocalTransaction.java/#L48,"@Override
    public void commit(boolean onePhase) throws XAException, IOException {
        if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""commit: "" + xid + "" syncCount: "" + size())
---------------Reference log end----------------
        }
        
        // Get ready for commit.
        try {
            prePrepare();
        } catch (XAException e) {
            throw e;
        } catch (Throwable e) {
            LOG.warn(""COMMIT FAILED: "", e);
            rollback();
            // Let them know we rolled back.
            XAException xae = new XAException(""COMMIT FAILED: Transaction rolled back"");
            xae.errorCode = XAException.XA_RBOTHER;
            xae.initCause(e);
            throw xae;
        }

        setState(Transaction.FINISHED_STATE);
        context.getTransactions().remove(xid);
        try {
            transactionStore.commit(getTransactionId(), false, preCommitTask, postCommitTask);
            this.waitPostCommitDone(postCommitTask);
        } catch (Throwable t) {
            LOG.warn(""Store COMMIT FAILED: "", t);
            rollback();
            XAException xae = new XAException(""STORE COMMIT FAILED: Transaction rolled back"");
            xae.errorCode = XAException.XA_RBOTHER;
            xae.initCause(t);
            throw xae;
        }
    }",,
activemq,18548,"LOG.warn(""cannot resolve subscription matching name: {}"", consumerToAbort)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/AbortSlowConsumerStrategyView.java/#L97,"public void abortConnection(ObjectName consumerToAbort) {
        Subscription sub = broker.getSubscriber(consumerToAbort);
        if (sub != null) {
            LOG.info(""aborting consumer connection via jmx: {}"", sub.getConsumerInfo().getConsumerId().getConnectionId());
            strategy.abortConsumer(sub, true);
        } else {
            
---------------Reference log start----------------
LOG.warn(""cannot resolve subscription matching name: {}"", consumerToAbort)
---------------Reference log end----------------
        }
    }",,
activemq,18247,"LOG.debug(""Session {} closed"", getSessionId())",debug,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpSession.java/#L116,"@Override
    public void close() {
        
---------------Reference log start----------------
LOG.debug(""Session {} closed"", getSessionId())
---------------Reference log end----------------

        connection.sendToActiveMQ(new RemoveInfo(getSessionId()), new ResponseHandler() {

            @Override
            public void onResponse(AmqpProtocolConverter converter, Response response) throws IOException {
                getEndpoint().setContext(null);
                getEndpoint().close();
                getEndpoint().free();
            }
        });
    }",,
activemq,17853,"LOGGER.debug(""Could not create JCA enabled connection factory: "" + t, t)",debug,https://github.com/apache/activemq/blob/main/activemq-spring/src/main/java/org/apache/activemq/pool/PooledConnectionFactoryBean.java/#L129,"public void afterPropertiesSet() throws Exception {
        if (pooledConnectionFactory == null && transactionManager != null && resourceName != null) {
            try {
                LOGGER.debug(""Trying to build a JcaPooledConnectionFactory"");
                JcaPooledConnectionFactory f = new JcaPooledConnectionFactory();
                f.setName(resourceName);
                f.setTransactionManager((TransactionManager) transactionManager);
                f.setMaxConnections(maxConnections);
                f.setMaximumActiveSessionPerConnection(maximumActive);
                f.setConnectionFactory(connectionFactory);
                this.pooledConnectionFactory = f;
            } catch (Throwable t) {
                
---------------Reference log start----------------
LOGGER.debug(""Could not create JCA enabled connection factory: "" + t, t)
---------------Reference log end----------------
            }
        }
        if (pooledConnectionFactory == null && transactionManager != null) {
            try {
                LOGGER.debug(""Trying to build a XaPooledConnectionFactory"");
                XaPooledConnectionFactory f = new XaPooledConnectionFactory();
                f.setTransactionManager((TransactionManager) transactionManager);
                f.setMaxConnections(maxConnections);
                f.setMaximumActiveSessionPerConnection(maximumActive);
                f.setConnectionFactory(connectionFactory);
                this.pooledConnectionFactory = f;
            } catch (Throwable t) {
                LOGGER.debug(""Could not create XA enabled connection factory: "" + t, t);
            }
        }
        if (pooledConnectionFactory == null) {
            try {
                LOGGER.debug(""Trying to build a PooledConnectionFactory"");
                PooledConnectionFactory f = new PooledConnectionFactory();
                f.setMaxConnections(maxConnections);
                f.setMaximumActiveSessionPerConnection(maximumActive);
                f.setConnectionFactory(connectionFactory);
                this.pooledConnectionFactory = f;
            } catch (Throwable t) {
                LOGGER.debug(""Could not create pooled connection factory: "" + t, t);
            }
        }
        if (pooledConnectionFactory == null) {
            throw new IllegalStateException(""Unable to create pooled connection factory.  Enable DEBUG log level for more informations"");
        }
    }",,
activemq,18993,"LOG.error(""Could not close broken connection: "", eoc)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/proxy/ProxyConnector.java/#L74,"@Override
            public void onAccept(Transport localTransport) {
                ProxyConnection connection = null;
                try {
                    Transport remoteTransport = createRemoteTransport(localTransport);
                    connection = new ProxyConnection(localTransport, remoteTransport);
                    connection.start();
                    connections.add(connection);
                } catch (Exception e) {
                    onAcceptError(e);
                    try {
                        if (connection != null) {
                            connection.stop();
                        }
                    } catch (Exception eoc) {
                        
---------------Reference log start----------------
LOG.error(""Could not close broken connection: "", eoc)
---------------Reference log end----------------
                    }
                }
            }",,
activemq,17803,"LOG.trace(this + "" setBatch: new last recovered: "" + Arrays.toString(perPriorityLastRecovered))",trace,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/JDBCMessageStore.java/#L470,"@Override
    public void setBatch(MessageId messageId) {
        if (LOG.isTraceEnabled()) {
            LOG.trace(this + "" setBatch: last recovered: "" + Arrays.toString(perPriorityLastRecovered));
        }
        try {
            long[] storedValues = persistenceAdapter.getStoreSequenceIdForMessageId(null, messageId, destination);
            setLastRecovered(storedValues[0]);
        } catch (IOException ignoredAsAlreadyLogged) {
            resetBatching();
        }
        if (LOG.isTraceEnabled()) {
            
---------------Reference log start----------------
LOG.trace(this + "" setBatch: new last recovered: "" + Arrays.toString(perPriorityLastRecovered))
---------------Reference log end----------------
        }
    }",,
activemq,19841,"LOG.debug(""Initializing ActiveMQ WebConsole..."")",debug,https://github.com/apache/activemq/blob/main/activemq-web-console/src/main/java/org/apache/activemq/web/WebConsoleStarter.java/#L39,"public void contextInitialized(ServletContextEvent event) {
        
---------------Reference log start----------------
LOG.debug(""Initializing ActiveMQ WebConsole..."")
---------------Reference log end----------------

        String webconsoleType = getWebconsoleType();

        ServletContext servletContext = event.getServletContext();
        WebApplicationContext context = createWebapplicationContext(servletContext, webconsoleType);

        initializeWebClient(servletContext, context);

        // for embedded console log what port it uses
        if (""embedded"".equals(webconsoleType)) {
            // show the url for the web consoles / main page so people can spot it
            String port = System.getProperty(""jetty.port"");
            String host = System.getProperty(""jetty.host"");
            if (host != null && port != null) {
                LOG.info(""ActiveMQ WebConsole available at http://{}:{}/"", host, port);
                LOG.info(""ActiveMQ Jolokia REST API available at http://{}:{}/api/jolokia/"", host, port);
            }
        }

        LOG.debug(""ActiveMQ WebConsole initialized."");
    }",,
activemq,18073,"LOG.debug(""Found some corrupted data blocks in the journal: {}"", corruptedLocations.size())",debug,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/scheduler/JobSchedulerStoreImpl.java/#L945,"private void recoverIndex(Transaction tx) throws IOException {
        long start = System.currentTimeMillis();

        // It is possible index updates got applied before the journal updates..
        // in that case we need to removed references to Jobs that are not in the journal
        final Location lastAppendLocation = journal.getLastAppendLocation();
        long undoCounter = 0;

        // Go through all the jobs in each scheduler and check if any are added after
        // the last appended location and remove those.  For now we ignore the update
        // location since the scheduled job will update itself after the next fire and
        // a new update will replace any existing update.
        for (Iterator<Map.Entry<String, JobSchedulerImpl>> i = metaData.getJobSchedulers().iterator(tx); i.hasNext();) {
            Map.Entry<String, JobSchedulerImpl> entry = i.next();
            JobSchedulerImpl scheduler = entry.getValue();

            for (Iterator<JobLocation> jobLocationIterator = scheduler.getAllScheduledJobs(tx); jobLocationIterator.hasNext();) {
                final JobLocation job = jobLocationIterator.next();
                if (job.getLocation().compareTo(lastAppendLocation) >= 0) {
                    if (scheduler.removeJobAtTime(tx, job.getJobId(), job.getNextTime())) {
                        LOG.trace(""Removed Job past last appened in the journal: {}"", job.getJobId());
                        undoCounter++;
                    }
                }
            }
        }

        if (undoCounter > 0) {
            // The rolled back operations are basically in flight journal writes.  To avoid getting
            // these the end user should do sync writes to the journal.
            long end = System.currentTimeMillis();
            LOG.info(""Rolled back {} messages from the index in {} seconds."", undoCounter, ((end - start) / 1000.0f));
            undoCounter = 0;
        }

        // Now we check for missing and corrupt journal files.

        // 1. Collect the set of all referenced journal files based on the Location of the
        //    the scheduled jobs and the marked last update field.
        HashSet<Integer> missingJournalFiles = new HashSet<Integer>();
        for (Iterator<Map.Entry<String, JobSchedulerImpl>> i = metaData.getJobSchedulers().iterator(tx); i.hasNext();) {
            Map.Entry<String, JobSchedulerImpl> entry = i.next();
            JobSchedulerImpl scheduler = entry.getValue();

            for (Iterator<JobLocation> jobLocationIterator = scheduler.getAllScheduledJobs(tx); jobLocationIterator.hasNext();) {
                final JobLocation job = jobLocationIterator.next();
                missingJournalFiles.add(job.getLocation().getDataFileId());
                if (job.getLastUpdate() != null) {
                    missingJournalFiles.add(job.getLastUpdate().getDataFileId());
                }
            }
        }

        // 2. Remove from that set all known data file Id's in the journal and what's left
        //    is the missing set which will soon also contain the corrupted set.
        missingJournalFiles.removeAll(journal.getFileMap().keySet());
        if (!missingJournalFiles.isEmpty()) {
            LOG.info(""Some journal files are missing: {}"", missingJournalFiles);
        }

        // 3. Now check all references in the journal logs for corruption and add any
        //    corrupt journal files to the missing set.
        HashSet<Location> corruptedLocations = new HashSet<Location>();

        if (isCheckForCorruptJournalFiles()) {
            Collection<DataFile> dataFiles = journal.getFileMap().values();
            for (DataFile dataFile : dataFiles) {
                int id = dataFile.getDataFileId();
                for (long offset : dataFile.getCorruptedBlocks()) {
                    corruptedLocations.add(new Location(id, (int) offset));
                }
            }

            if (!corruptedLocations.isEmpty()) {
                
---------------Reference log start----------------
LOG.debug(""Found some corrupted data blocks in the journal: {}"", corruptedLocations.size())
---------------Reference log end----------------
            }
        }

        // 4. Now we either fail or we remove all references to missing or corrupt journal
        //    files from the various JobSchedulerImpl instances.  We only remove the Job if
        //    the initial Add operation is missing when the ignore option is set, the updates
        //    could be lost but that's price you pay when ignoring the missing logs.
        if (!missingJournalFiles.isEmpty() || !corruptedLocations.isEmpty()) {
            if (!isIgnoreMissingJournalfiles()) {
                throw new IOException(""Detected missing/corrupt journal files."");
            }

            // Remove all Jobs that reference an Location that is either missing or corrupt.
            undoCounter = removeJobsInMissingOrCorruptJounralFiles(tx, missingJournalFiles, corruptedLocations);

            // Clean up the Journal Reference count Map.
            removeJournalRCForMissingFiles(tx, missingJournalFiles);
        }

        if (undoCounter > 0) {
            long end = System.currentTimeMillis();
            LOG.info(""Detected missing/corrupt journal files.  Dropped {} jobs from the "" +
                     ""index in {} seconds."", undoCounter, ((end - start) / 1000.0f));
        }
    }",,
activemq,18434,"LOG.trace(""Error on start: "", e)",trace,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/http/HttpClientTransport.java/#L281,"@Override
    protected void doStart() throws Exception {

        if (LOG.isTraceEnabled()) {
            LOG.trace(""HTTP GET consumer thread starting: "" + this);
        }
        HttpClient httpClient = getReceiveHttpClient();
        URI remoteUrl = getRemoteUrl();

        HttpHead httpMethod = new HttpHead(remoteUrl.toString());
        configureMethod(httpMethod);

        // Request the options from the server so we can find out if the broker we are
        // talking to supports GZip compressed content.  If so and useCompression is on
        // then we can compress our POST data, otherwise we must send it uncompressed to
        // ensure backwards compatibility.
        HttpOptions optionsMethod = new HttpOptions(remoteUrl.toString());
        ResponseHandler<String> handler = new BasicResponseHandler() {
            @Override
            public String handleResponse(HttpResponse response) throws HttpResponseException, IOException {

                for(Header header : response.getAllHeaders()) {
                    if (header.getName().equals(""Accepts-Encoding"") && header.getValue().contains(""gzip"")) {
                        LOG.info(""Broker Servlet supports GZip compression."");
                        canSendCompressed = true;
                        break;
                    }
                }

                return super.handleResponse(response);
            }
        };

        try {
            httpClient.execute(httpMethod, new BasicResponseHandler());
            httpClient.execute(optionsMethod, handler);
        } catch(Exception e) {
            
---------------Reference log start----------------
LOG.trace(""Error on start: "", e)
---------------Reference log end----------------
            throw new IOException(""Failed to perform GET on: "" + remoteUrl + "" as response was: "" + e.getMessage());
        }

        super.doStart();
    }",,
activemq,18082,"LOG.error(""failed to deliver pending outcome for tid: "" + txid, ex)",error,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MultiKahaDBTransactionStore.java/#L500,"@Override
    public synchronized void recover(final TransactionRecoveryListener listener) throws IOException {

        for (final PersistenceAdapter adapter : multiKahaDBPersistenceAdapter.adapters) {
            adapter.createTransactionStore().recover(new TransactionRecoveryListener() {
                @Override
                public void recover(XATransactionId xid, Message[] addedMessages, MessageAck[] acks) {
                    try {
                        getTx(xid).trackStore(adapter.createTransactionStore(), xid);
                    } catch (IOException e) {
                        LOG.error(""Failed to access transaction store: "" + adapter + "" for prepared xa tid: "" + xid, e);
                    }
                    listener.recover(xid, addedMessages, acks);
                }
            });
        }

        boolean recoveryWorkPending = false;
        try {
            Broker broker = multiKahaDBPersistenceAdapter.getBrokerService().getBroker();
            // force completion of local xa
            for (TransactionId txid : broker.getPreparedTransactions(null)) {
                if (multiKahaDBPersistenceAdapter.isLocalXid(txid)) {
                    recoveryWorkPending = true;
                    if (corruptJournalDetected.get()) {
                        // not having a record is meaningless once our tx store is corrupt; we need a heuristic decision
                        LOG.warn(""Pending multi store local transaction {} requires manual heuristic outcome via JMX"", txid);
                        logSomeContext(txid);
                    } else {
                        try {
                            if (pendingCommit.keySet().contains(txid)) {
                                // we recorded the commit outcome, finish the job
                                LOG.info(""delivering pending commit outcome for tid: "" + txid);
                                broker.commitTransaction(null, txid, false);
                            } else {
                                // we have not record an outcome, and would have reported a commit failure, so we must rollback
                                LOG.info(""delivering rollback outcome to store for tid: "" + txid);
                                broker.forgetTransaction(null, txid);
                            }
                            persistCompletion(txid);
                        } catch (Exception ex) {
                            
---------------Reference log start----------------
LOG.error(""failed to deliver pending outcome for tid: "" + txid, ex)
---------------Reference log end----------------
                        }
                    }
                }
            }
        } catch (Exception e) {
            LOG.error(""failed to resolve pending local transactions"", e);
        }
        // can we ignore corruption and resume
        if (corruptJournalDetected.get() && !recoveryWorkPending) {
            // move to new write file, gc will cleanup
            journal.rotateWriteFile();
            loaded();
            corruptJournalDetected.set(false);
            LOG.info(""No heuristics outcome pending after corrupt tx store detection, auto resolving"");
        }
    }",,
activemq,17888,"LOG.info(""Recovery replayed "" + redoCounter + "" operations from the journal in "" + ((end - start) / 1000.0f) + "" seconds."")",info,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L737,"private void recover() throws IllegalStateException, IOException {
        this.indexLock.writeLock().lock();
        try {

            long start = System.currentTimeMillis();
            boolean requiresJournalReplay = recoverProducerAudit();
            requiresJournalReplay |= recoverAckMessageFileMap();
            Location lastIndoubtPosition = getRecoveryPosition();
            Location recoveryPosition = requiresJournalReplay ? journal.getNextLocation(null) : lastIndoubtPosition;
            if (recoveryPosition != null) {
                int redoCounter = 0;
                int dataFileRotationTracker = recoveryPosition.getDataFileId();
                LOG.info(""Recovering from the journal @"" + recoveryPosition);
                while (recoveryPosition != null) {
                    try {
                        JournalCommand<?> message = load(recoveryPosition);
                        metadata.lastUpdate = recoveryPosition;
                        process(message, recoveryPosition, lastIndoubtPosition);
                        redoCounter++;
                    } catch (IOException failedRecovery) {
                        if (isIgnoreMissingJournalfiles()) {
                            LOG.debug(""Failed to recover data at position:"" + recoveryPosition, failedRecovery);
                            // track this dud location
                            journal.corruptRecoveryLocation(recoveryPosition);
                        } else {
                            throw new IOException(""Failed to recover data at position:"" + recoveryPosition, failedRecovery);
                        }
                    }
                    recoveryPosition = journal.getNextLocation(recoveryPosition);
                    // hold on to the minimum number of open files during recovery
                    if (recoveryPosition != null && dataFileRotationTracker != recoveryPosition.getDataFileId()) {
                        dataFileRotationTracker = recoveryPosition.getDataFileId();
                        journal.cleanup();
                    }
                    if (LOG.isInfoEnabled() && redoCounter % 100000 == 0) {
                        LOG.info(""@"" + recoveryPosition + "", "" + redoCounter + "" entries recovered .."");
                    }
                }
                if (LOG.isInfoEnabled()) {
                    long end = System.currentTimeMillis();
                    
---------------Reference log start----------------
LOG.info(""Recovery replayed "" + redoCounter + "" operations from the journal in "" + ((end - start) / 1000.0f) + "" seconds."")
---------------Reference log end----------------
                }
            }

            // We may have to undo some index updates.
            pageFile.tx().execute(new Transaction.Closure<IOException>() {
                @Override
                public void execute(Transaction tx) throws IOException {
                    recoverIndex(tx);
                }
            });

            // rollback any recovered inflight local transactions, and discard any inflight XA transactions.
            Set<TransactionId> toRollback = new HashSet<>();
            Set<TransactionId> toDiscard = new HashSet<>();
            synchronized (inflightTransactions) {
                for (Iterator<TransactionId> it = inflightTransactions.keySet().iterator(); it.hasNext(); ) {
                    TransactionId id = it.next();
                    if (id.isLocalTransaction()) {
                        toRollback.add(id);
                    } else {
                        toDiscard.add(id);
                    }
                }
                for (TransactionId tx: toRollback) {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""rolling back recovered indoubt local transaction "" + tx);
                    }
                    store(new KahaRollbackCommand().setTransactionInfo(TransactionIdConversion.convertToLocal(tx)), false, null, null);
                }
                for (TransactionId tx: toDiscard) {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""discarding recovered in-flight XA transaction "" + tx);
                    }
                    inflightTransactions.remove(tx);
                }
            }

            synchronized (preparedTransactions) {
                Set<TransactionId> txIds = new LinkedHashSet<TransactionId>(preparedTransactions.keySet());
                for (TransactionId txId : txIds) {
                    switch (purgeRecoveredXATransactionStrategy){
                        case NEVER:
                            LOG.warn(""Recovered prepared XA TX: [{}]"", txId);
                            break;
                        case COMMIT:
                            store(new KahaCommitCommand().setTransactionInfo(TransactionIdConversion.convert(txId)), false, null, null);
                            LOG.warn(""Recovered and Committing prepared XA TX: [{}]"", txId);
                            break;
                        case ROLLBACK:
                            store(new KahaRollbackCommand().setTransactionInfo(TransactionIdConversion.convert(txId)), false, null, null);
                            LOG.warn(""Recovered and Rolling Back prepared XA TX: [{}]"", txId);
                            break;
                    }
                }
            }

        } finally {
            this.indexLock.writeLock().unlock();
        }
    }",,
activemq,19540,"LOG.debug(""on close, rollback duplicate: {}"", old.getMessage().getMessageId())",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQMessageConsumer.java/#L878,"public void dispose() throws JMSException {
        if (!unconsumedMessages.isClosed()) {

            // Do we have any acks we need to send out before closing?
            // Ack any delivered messages now.
            if (!session.getTransacted()) {
                deliverAcks();
                if (isAutoAcknowledgeBatch()) {
                    acknowledge();
                }
            }
            if (executorService != null) {
                ThreadPoolUtils.shutdownGraceful(executorService, 60000L);
                executorService = null;
            }
            if (optimizedAckTask != null) {
                this.session.connection.getScheduler().cancel(optimizedAckTask);
                optimizedAckTask = null;
            }

            if (session.isClientAcknowledge() || session.isIndividualAcknowledge()) {
                if (!this.info.isBrowser()) {
                    // rollback duplicates that aren't acknowledged
                    List<MessageDispatch> tmp = null;
                    synchronized (this.deliveredMessages) {
                        tmp = new ArrayList<MessageDispatch>(this.deliveredMessages);
                    }
                    for (MessageDispatch old : tmp) {
                        this.session.connection.rollbackDuplicate(this, old.getMessage());
                    }
                    tmp.clear();
                }
            }
            if (!session.isTransacted()) {
                synchronized(deliveredMessages) {
                    deliveredMessages.clear();
                }
            }
            unconsumedMessages.close();
            this.session.removeConsumer(this);
            List<MessageDispatch> list = unconsumedMessages.removeAll();
            if (!this.info.isBrowser()) {
                for (MessageDispatch old : list) {
                    // ensure we don't filter this as a duplicate
                    if (old.getMessage() != null) {
                        
---------------Reference log start----------------
LOG.debug(""on close, rollback duplicate: {}"", old.getMessage().getMessageId())
---------------Reference log end----------------
                    }
                    session.connection.rollbackDuplicate(this, old.getMessage());
                }
            }
        }
        if (previouslyDeliveredMessages != null) {
            for (PreviouslyDelivered previouslyDelivered : previouslyDeliveredMessages.values()) {
                session.connection.rollbackDuplicate(this, previouslyDelivered.message);
            }
        }
        clearPreviouslyDelivered();
    }",,
activemq,19324,"LOG.error(""Error redispatching unconsumed messages from stale server session {}"", ss, t)",error,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ServerSessionPoolImpl.java/#L246,"public void removeFromPool(ServerSessionImpl ss) {
        sessionLock.lock();
        try {
            activeSessions.remove(ss);
        } finally {
            sessionLock.unlock();
        }
        try {
            ActiveMQSession session = (ActiveMQSession)ss.getSession();
            List<MessageDispatch> l = session.getUnconsumedMessages();
            if (!isClosing() && !l.isEmpty()) {
                ActiveMQConnection connection = activeMQAsfEndpointWorker.getConnection();
                if (connection != null) {
                    for (Iterator<MessageDispatch> i = l.iterator(); i.hasNext();) {
                        MessageDispatch md = i.next();
                        if (connection.hasDispatcher(md.getConsumerId())) {
                            dispatchToSession(md);
                            LOG.trace(""on remove of {} redispatch of {}"", session, md);
                        } else {
                            LOG.trace(""on remove not redispatching {}, dispatcher no longer present on {}"", md, session.getConnection());
                        }
                    }
                } else {
                    LOG.trace(""on remove of {} not redispatching while disconnected"", session);
                }
            }
        } catch (Throwable t) {
            
---------------Reference log start----------------
LOG.error(""Error redispatching unconsumed messages from stale server session {}"", ss, t)
---------------Reference log end----------------
        }
        ss.close();
        synchronized (closing) {
            closing.notify();
        }
    }",,
activemq,18716,"perDestinationsLogger.info(""Sending message: {}"", copy)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/LoggingBrokerPlugin.java/#L287,"private void logSend(Message copy) {
        copy.getSize();
        Logger perDestinationsLogger = LOG;
        if (isPerDestinationLogger()) {
            ActiveMQDestination destination = copy.getDestination();
            perDestinationsLogger = LoggerFactory.getLogger(LOG.getName() +
                    ""."" + destination.getDestinationTypeAsString() + ""."" + destination.getPhysicalName());
        }
        
---------------Reference log start----------------
perDestinationsLogger.info(""Sending message: {}"", copy)
---------------Reference log end----------------
    }
    }",,
activemq,17895,"LOG.warn(""Cannot recover ackMessageFileMap"", e)",warn,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L852,"@SuppressWarnings(""unchecked"")
    private boolean recoverAckMessageFileMap() throws IOException {
        boolean requiresReplay = true;
        if (metadata.ackMessageFileMapLocation != null) {
            try {
                KahaAckMessageFileMapCommand audit = (KahaAckMessageFileMapCommand) load(metadata.ackMessageFileMapLocation);
                ObjectInputStream objectIn = new MessageDatabaseObjectInputStream(audit.getAckMessageFileMap().newInput());
                metadata.ackMessageFileMap = (Map<Integer, Set<Integer>>) objectIn.readObject();
                metadata.ackMessageFileMapDirtyFlag.lazySet(true);
                requiresReplay = false;
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.warn(""Cannot recover ackMessageFileMap"", e)
---------------Reference log end----------------
            }
        }
        // got no ackMessageFileMap stored so got to recreate via replay from start of the journal
        return requiresReplay;
    }",,
activemq,18877,"LOG.debug(""Deactivating keepActive={}, {}"", keepDurableSubsActive, this)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/region/DurableTopicSubscription.java/#L196,"public void deactivate(boolean keepDurableSubsActive, long lastDeliveredSequenceId) throws Exception {
        
---------------Reference log start----------------
LOG.debug(""Deactivating keepActive={}, {}"", keepDurableSubsActive, this)
---------------Reference log end----------------
        active.set(false);
        this.keepDurableSubsActive = keepDurableSubsActive;
        offlineTimestamp.set(System.currentTimeMillis());
        usageManager.getMemoryUsage().removeUsageListener(this);

        ArrayList<Topic> topicsToDeactivate = new ArrayList<Topic>();
        List<MessageReference> savedDispateched = null;

        synchronized (pendingLock) {
            if (!keepDurableSubsActive) {
                pending.stop();
            }

            synchronized (dispatchLock) {
                for (Destination destination : durableDestinations.values()) {
                    Topic topic = (Topic) destination;
                    if (!keepDurableSubsActive) {
                        topicsToDeactivate.add(topic);
                    } else {
                        topic.getDestinationStatistics().getInflight().subtract(dispatched.size());
                    }
                }

                // Before we add these back to pending they need to be in producer order not
                // dispatch order so we can add them to the front of the pending list.
                Collections.reverse(dispatched);

                for (final MessageReference node : dispatched) {
                    // Mark the dispatched messages as redelivered for next time.
                    if (lastDeliveredSequenceId == RemoveInfo.LAST_DELIVERED_UNKNOWN || lastDeliveredSequenceId == 0 ||
                            (lastDeliveredSequenceId > 0 && node.getMessageId().getBrokerSequenceId() <= lastDeliveredSequenceId)) {
                        Integer count = redeliveredMessages.get(node.getMessageId());
                        if (count != null) {
                            redeliveredMessages.put(node.getMessageId(), Integer.valueOf(count.intValue() + 1));
                        } else {
                            redeliveredMessages.put(node.getMessageId(), Integer.valueOf(1));
                        }
                    }
                    if (keepDurableSubsActive && pending.isTransient()) {
                        pending.addMessageFirst(node);
                        pending.rollback(node.getMessageId());
                    }
                    // createMessageDispatch increments on remove from pending for dispatch
                    node.decrementReferenceCount();
                }

                if (!topicsToDeactivate.isEmpty()) {
                    savedDispateched = new ArrayList<MessageReference>(dispatched);
                }
                dispatched.clear();
                getSubscriptionStatistics().getInflightMessageSize().reset();
            }
            if (!keepDurableSubsActive && pending.isTransient()) {
                try {
                    pending.reset();
                    while (pending.hasNext()) {
                        MessageReference node = pending.next();
                        node.decrementReferenceCount();
                        pending.remove();
                    }
                } finally {
                    pending.release();
                }
            }
        }
        for(Topic topic: topicsToDeactivate) {
            topic.deactivate(context, this, savedDispateched);
        }
        prefetchExtension.set(0);
    }",,
activemq,18633,"LOG.error(exception.getLocalizedMessage(), e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L695,"private void doStartPersistenceAdapter() throws Exception {
        PersistenceAdapter persistenceAdapterToStart = getPersistenceAdapter();
        if (persistenceAdapterToStart == null) {
            checkStartException();
            throw new ConfigurationException(""Cannot start null persistence adapter"");
        }
        persistenceAdapterToStart.setUsageManager(getProducerSystemUsage());
        persistenceAdapterToStart.setBrokerName(getBrokerName());
        LOG.info(""Using Persistence Adapter: {}"", persistenceAdapterToStart);
        if (deleteAllMessagesOnStartup) {
            deleteAllMessages();
        }
        persistenceAdapterToStart.start();

        getTempDataStore();
        if (tempDataStore != null) {
            try {
                // start after we have the store lock
                tempDataStore.start();
            } catch (Exception e) {
                RuntimeException exception = new RuntimeException(
                        ""Failed to start temp data store: "" + tempDataStore, e);
                LOG.error(exception.getLocalizedMessage(), e);
                throw exception;
            }
        }

        getJobSchedulerStore();
        if (jobSchedulerStore != null) {
            try {
                jobSchedulerStore.start();
            } catch (Exception e) {
                RuntimeException exception = new RuntimeException(
                        ""Failed to start job scheduler store: "" + jobSchedulerStore, e);
                
---------------Reference log start----------------
LOG.error(exception.getLocalizedMessage(), e)
---------------Reference log end----------------
                throw exception;
            }
        }
    }",,
activemq,18100,"LOG.error(""Failed to load message at: {}"", location, ioe)",error,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/KahaDBStore.java/#L1431,"Message loadMessage(Location location) throws IOException {
        try {
            JournalCommand<?> command = load(location);
            KahaAddMessageCommand addMessage = null;
            switch (command.type()) {
                case KAHA_UPDATE_MESSAGE_COMMAND:
                    addMessage = ((KahaUpdateMessageCommand) command).getMessage();
                    break;
                case KAHA_ADD_MESSAGE_COMMAND:
                    addMessage = (KahaAddMessageCommand) command;
                    break;
                default:
                    throw new IOException(""Could not load journal record, unexpected command type: "" + command.type() + "" at location: "" + location);
            }
            if (!addMessage.hasMessage()) {
                throw new IOException(""Could not load journal record, null message content at location: "" + location);
            }
            Message msg = (Message) wireFormat.unmarshal(new DataInputStream(addMessage.getMessage().newInput()));
            return msg;
        } catch (Throwable t) {
            IOException ioe = IOExceptionSupport.create(""Unexpected error on journal read at: "" + location , t);
            
---------------Reference log start----------------
LOG.error(""Failed to load message at: {}"", location, ioe)
---------------Reference log end----------------
            brokerService.handleIOException(ioe);
            throw ioe;
        }
    }",,
activemq,19384,"log.debug(this + "", setting [keyStoreKeyPassword] to: "" + keyStoreKeyPassword)",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ActiveMQConnectionSupport.java/#L246,"public void setKeyStoreKeyPassword(String keyStoreKeyPassword) {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(this + "", setting [keyStoreKeyPassword] to: "" + keyStoreKeyPassword)
---------------Reference log end----------------
        }
        info.setKeyStoreKeyPassword(keyStoreKeyPassword);
    }",,
activemq,19844,"LOG.debug(""ActiveMQ WebConsole initialized."")",debug,https://github.com/apache/activemq/blob/main/activemq-web-console/src/main/java/org/apache/activemq/web/WebConsoleStarter.java/#L59,"public void contextInitialized(ServletContextEvent event) {
        LOG.debug(""Initializing ActiveMQ WebConsole..."");

        String webconsoleType = getWebconsoleType();

        ServletContext servletContext = event.getServletContext();
        WebApplicationContext context = createWebapplicationContext(servletContext, webconsoleType);

        initializeWebClient(servletContext, context);

        // for embedded console log what port it uses
        if (""embedded"".equals(webconsoleType)) {
            // show the url for the web consoles / main page so people can spot it
            String port = System.getProperty(""jetty.port"");
            String host = System.getProperty(""jetty.host"");
            if (host != null && port != null) {
                LOG.info(""ActiveMQ WebConsole available at http://{}:{}/"", host, port);
                LOG.info(""ActiveMQ Jolokia REST API available at http://{}:{}/api/jolokia/"", host, port);
            }
        }

        
---------------Reference log start----------------
LOG.debug(""ActiveMQ WebConsole initialized."")
---------------Reference log end----------------
    }
    }",,
activemq,19509,"LOG.debug(""Failed to submit control for consumer: "" + control.getConsumerId() + "" with: "" + control.getPrefetch(), ex)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/state/ConnectionStateTracker.java/#L755,"public void connectionInterruptProcessingComplete(Transport transport, ConnectionId connectionId) {
        ConnectionState connectionState = connectionStates.get(connectionId);
        if (connectionState != null) {
            connectionState.setConnectionInterruptProcessingComplete(true);
            Map<ConsumerId, ConsumerInfo> stalledConsumers = connectionState.getRecoveringPullConsumers();
            for (Entry<ConsumerId, ConsumerInfo> entry: stalledConsumers.entrySet()) {
                ConsumerControl control = new ConsumerControl();
                control.setConsumerId(entry.getKey());
                control.setPrefetch(entry.getValue().getPrefetchSize());
                control.setDestination(entry.getValue().getDestination());
                try {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""restored recovering consumer: "" + control.getConsumerId() + "" with: "" + control.getPrefetch());
                    }
                    transport.oneway(control);
                } catch (Exception ex) {
                    if (LOG.isDebugEnabled()) {
                        
---------------Reference log start----------------
LOG.debug(""Failed to submit control for consumer: "" + control.getConsumerId() + "" with: "" + control.getPrefetch(), ex)
---------------Reference log end----------------
                    }
                }
            }
            stalledConsumers.clear();
        }
    }",,
activemq,18690,"LOG.trace(""JobScheduler adding job[{}] to fire at: {}"", jobId, JobSupport.getDateTime(executionTime))",trace,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/scheduler/memory/InMemoryJobScheduler.java/#L256,"private void doSchedule(final String jobId, final ByteSequence payload, final String cronEntry, long delay, long period, int repeat) throws IOException {
        long startTime = System.currentTimeMillis();
        long executionTime = 0;
        // round startTime - so we can schedule more jobs at the same time
        startTime = ((startTime + 500) / 500) * 500;

        if (cronEntry != null && cronEntry.length() > 0) {
            try {
                executionTime = CronParser.getNextScheduledTime(cronEntry, startTime);
            } catch (MessageFormatException e) {
                throw new IOException(e.getMessage());
            }
        }

        if (executionTime == 0) {
            // start time not set by CRON - so it it to the current time
            executionTime = startTime;
        }

        if (delay > 0) {
            executionTime += delay;
        } else {
            executionTime += period;
        }

        InMemoryJob newJob = new InMemoryJob(jobId);
        newJob.setStart(startTime);
        newJob.setCronEntry(cronEntry);
        newJob.setDelay(delay);
        newJob.setPeriod(period);
        newJob.setRepeat(repeat);
        newJob.setNextTime(executionTime);
        newJob.setPayload(payload.getData());

        
---------------Reference log start----------------
LOG.trace(""JobScheduler adding job[{}] to fire at: {}"", jobId, JobSupport.getDateTime(executionTime))
---------------Reference log end----------------

        lock.writeLock().lock();
        try {
            ScheduledTask task = jobs.get(executionTime);
            if (task == null) {
                task = new ScheduledTask(executionTime);
                task.add(newJob);
                jobs.put(task.getExecutionTime(), task);
                timer.schedule(task, new Date(newJob.getNextTime()));
            } else {
                task.add(newJob);
            }
        } finally {
            lock.writeLock().unlock();
        }
    }",,
activemq,18443,"LOG.info(""Configuring Jetty server using {}"", jettyOptions.getConfig())",info,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/WebTransportServerSupport.java/#L60,"protected void createServer() {
        LOG.info(""Starting Jetty server"");
        if (jettyOptions.getConfig() != null) {
            try {
                
---------------Reference log start----------------
LOG.info(""Configuring Jetty server using {}"", jettyOptions.getConfig())
---------------Reference log end----------------
                File file = new File(jettyOptions.getConfig());
                if (!file.exists()) {
                    throw new IllegalArgumentException(""Jetty XML not found: "" + file.getAbsolutePath());
                }
                XmlConfiguration xmlConfiguration = new XmlConfiguration(Resource.newResource(file));
                server = (Server) xmlConfiguration.configure();
            } catch (Throwable t) {
                throw new IllegalStateException(""Jetty configuration can't be loaded"", t);
            }
        } else {
            server = new Server();
        }
        try {
            server.getClass().getMethod(""setStopTimeout"", Long.TYPE).invoke(server, 500l);
        } catch (Throwable t) {
            //ignore, jetty 8.
        }
    }",,
activemq,17925,"LOG.trace(""Journal activity detected, no Ack compaction scheduled."")",trace,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L2043,"Set<Integer> checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
        MDC.put(""activemq.persistenceDir"", getDirectory().getName());
        LOG.debug(""Checkpoint started."");

        // reflect last update exclusive of current checkpoint
        Location lastUpdate = metadata.lastUpdate;

        metadata.state = OPEN_STATE;
        metadata.producerSequenceIdTrackerLocation = checkpointProducerAudit();
        if (metadata.ackMessageFileMapDirtyFlag.get() || (metadata.ackMessageFileMapLocation == null)) {
            metadata.ackMessageFileMapLocation = checkpointAckMessageFileMap();
        }
        metadata.ackMessageFileMapDirtyFlag.lazySet(false);
        Location[] inProgressTxRange = getInProgressTxLocationRange();
        metadata.firstInProgressTransactionLocation = inProgressTxRange[0];
        tx.store(metadata.page, metadataMarshaller, true);

        final TreeSet<Integer> gcCandidateSet = new TreeSet<>();
        if (cleanup) {

            final TreeSet<Integer> completeFileSet = new TreeSet<>(journal.getFileMap().keySet());
            gcCandidateSet.addAll(completeFileSet);

            if (LOG.isTraceEnabled()) {
                LOG.trace(""Last update: "" + lastUpdate + "", full gc candidates set: "" + gcCandidateSet);
            }

            if (lastUpdate != null) {
                // we won't delete past the last update, ackCompaction journal can be a candidate in error
                gcCandidateSet.removeAll(new TreeSet<Integer>(gcCandidateSet.tailSet(lastUpdate.getDataFileId())));
            }

            // Don't GC files under replication
            if( journalFilesBeingReplicated!=null ) {
                gcCandidateSet.removeAll(journalFilesBeingReplicated);
            }

            if (metadata.producerSequenceIdTrackerLocation != null) {
                int dataFileId = metadata.producerSequenceIdTrackerLocation.getDataFileId();
                if (gcCandidateSet.contains(dataFileId) && gcCandidateSet.first() == dataFileId) {
                    // rewrite so we don't prevent gc
                    metadata.producerSequenceIdTracker.setModified(true);
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(""rewriting producerSequenceIdTracker:"" + metadata.producerSequenceIdTrackerLocation);
                    }
                }
                gcCandidateSet.remove(dataFileId);
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after producerSequenceIdTrackerLocation:"" + metadata.producerSequenceIdTrackerLocation + "", "" + gcCandidateSet);
                }
            }

            if (metadata.ackMessageFileMapLocation != null) {
                int dataFileId = metadata.ackMessageFileMapLocation.getDataFileId();
                gcCandidateSet.remove(dataFileId);
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after ackMessageFileMapLocation:"" + metadata.ackMessageFileMapLocation + "", "" + gcCandidateSet);
                }
            }

            // Don't GC files referenced by in-progress tx
            if (inProgressTxRange[0] != null) {
                for (int pendingTx=inProgressTxRange[0].getDataFileId(); pendingTx <= inProgressTxRange[1].getDataFileId(); pendingTx++) {
                    gcCandidateSet.remove(pendingTx);
                }
            }
            if (LOG.isTraceEnabled()) {
                LOG.trace(""gc candidates after in progress tx range:"" + Arrays.asList(inProgressTxRange) + "", "" + gcCandidateSet);
            }

            // Go through all the destinations to see if any of them can remove GC candidates.
            for (Entry<String, StoredDestination> entry : storedDestinations.entrySet()) {
                if( gcCandidateSet.isEmpty() ) {
                    break;
                }

                // Use a visitor to cut down the number of pages that we load
                entry.getValue().locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
                    int last=-1;
                    @Override
                    public boolean isInterestedInKeysBetween(Location first, Location second) {
                        if( first==null ) {
                            SortedSet<Integer> subset = gcCandidateSet.headSet(second.getDataFileId()+1);
                            if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
                                subset.remove(second.getDataFileId());
                            }
                            return !subset.isEmpty();
                        } else if( second==null ) {
                            SortedSet<Integer> subset = gcCandidateSet.tailSet(first.getDataFileId());
                            if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
                                subset.remove(first.getDataFileId());
                            }
                            return !subset.isEmpty();
                        } else {
                            SortedSet<Integer> subset = gcCandidateSet.subSet(first.getDataFileId(), second.getDataFileId()+1);
                            if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
                                subset.remove(first.getDataFileId());
                            }
                            if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
                                subset.remove(second.getDataFileId());
                            }
                            return !subset.isEmpty();
                        }
                    }

                    @Override
                    public void visit(List<Location> keys, List<Long> values) {
                        for (Location l : keys) {
                            int fileId = l.getDataFileId();
                            if( last != fileId ) {
                                gcCandidateSet.remove(fileId);
                                last = fileId;
                            }
                        }
                    }
                });

                // Durable Subscription
                if (entry.getValue().subLocations != null) {
                    Iterator<Entry<String, Location>> iter = entry.getValue().subLocations.iterator(tx);
                    while (iter.hasNext()) {
                        Entry<String, Location> subscription = iter.next();
                        int dataFileId = subscription.getValue().getDataFileId();

                        // Move subscription along if it has no outstanding messages that need ack'd
                        // and its in the last log file in the journal.
                        if (!gcCandidateSet.isEmpty() && gcCandidateSet.first() == dataFileId) {
                            final StoredDestination destination = entry.getValue();
                            final String subscriptionKey = subscription.getKey();
                            SequenceSet pendingAcks = destination.ackPositions.get(tx, subscriptionKey);

                            // When pending is size one that is the next message Id meaning there
                            // are no pending messages currently.
                            if (pendingAcks == null || pendingAcks.isEmpty() ||
                                (pendingAcks.size() == 1 && pendingAcks.getTail().range() == 1)) {

                                if (LOG.isTraceEnabled()) {
                                    LOG.trace(""Found candidate for rewrite: sub {} on {} from file {}"", subscriptionKey, entry.getKey(), dataFileId);
                                }

                                final KahaSubscriptionCommand kahaSub =
                                    destination.subscriptions.get(tx, subscriptionKey);
                                destination.subLocations.put(
                                    tx, subscriptionKey, checkpointSubscriptionCommand(kahaSub));

                                // Skips the remove from candidates if we rewrote the subscription
                                // in order to prevent duplicate subscription commands on recover.
                                // If another subscription is on the same file and isn't rewritten
                                // than it will remove the file from the set.
                                continue;
                            }
                        }

                        if (LOG.isTraceEnabled()) {
                            final StoredDestination destination = entry.getValue();
                            final String subscriptionKey = subscription.getKey();
                            final SequenceSet pendingAcks = destination.ackPositions.get(tx, subscriptionKey);
                            LOG.trace(""sub {} on {} in dataFile {} has pendingCount {}"", subscriptionKey, entry.getKey(), dataFileId, pendingAcks.rangeSize()-1);
                        }
                        gcCandidateSet.remove(dataFileId);
                    }
                }

                if (LOG.isTraceEnabled()) {
                    LOG.trace(""gc candidates after dest:"" + entry.getKey() + "", "" + gcCandidateSet);
                }
            }

            // check we are not deleting file with ack for in-use journal files
            if (LOG.isTraceEnabled()) {
                LOG.trace(""gc candidates: "" + gcCandidateSet);
                LOG.trace(""ackMessageFileMap: "" +  metadata.ackMessageFileMap);
            }

            boolean ackMessageFileMapMod = false;
            Iterator<Integer> candidates = gcCandidateSet.iterator();
            while (candidates.hasNext()) {
                Integer candidate = candidates.next();
                Set<Integer> referencedFileIds = metadata.ackMessageFileMap.get(candidate);
                if (referencedFileIds != null) {
                    for (Integer referencedFileId : referencedFileIds) {
                        if (completeFileSet.contains(referencedFileId) && !gcCandidateSet.contains(referencedFileId)) {
                            // active file that is not targeted for deletion is referenced so don't delete
                            candidates.remove();
                            break;
                        }
                    }
                    if (gcCandidateSet.contains(candidate)) {
                        ackMessageFileMapMod |= (metadata.ackMessageFileMap.remove(candidate) != null);
                        metadata.ackMessageFileMapDirtyFlag.lazySet(true);
                    } else {
                        if (LOG.isTraceEnabled()) {
                            LOG.trace(""not removing data file: "" + candidate
                                    + "" as contained ack(s) refer to referenced file: "" + referencedFileIds);
                        }
                    }
                }
            }

            if (!gcCandidateSet.isEmpty()) {
                LOG.debug(""Cleanup removing the data files: {}"", gcCandidateSet);
                for (Integer candidate : gcCandidateSet) {
                    for (Set<Integer> ackFiles : metadata.ackMessageFileMap.values()) {
                        ackMessageFileMapMod |= ackFiles.remove(candidate);
                        metadata.ackMessageFileMapDirtyFlag.lazySet(true);
                    }
                }
                if (ackMessageFileMapMod) {
                    checkpointUpdate(tx, false);
                }
            } else if (isEnableAckCompaction()) {
                if (++checkPointCyclesWithNoGC >= getCompactAcksAfterNoGC()) {
                    // First check length of journal to make sure it makes sense to even try.
                    //
                    // If there is only one journal file with Acks in it we don't need to move
                    // it since it won't be chained to any later logs.
                    //
                    // If the logs haven't grown since the last time then we need to compact
                    // otherwise there seems to still be room for growth and we don't need to incur
                    // the overhead.  Depending on configuration this check can be avoided and
                    // Ack compaction will run any time the store has not GC'd a journal file in
                    // the configured amount of cycles.
                    if (metadata.ackMessageFileMap.size() > 1 &&
                        (journalLogOnLastCompactionCheck == journal.getCurrentDataFileId() || isCompactAcksIgnoresStoreGrowth())) {

                        LOG.trace(""No files GC'd checking if threshold to ACK compaction has been met."");
                        try {
                            scheduler.execute(new AckCompactionRunner());
                        } catch (Exception ex) {
                            LOG.warn(""Error on queueing the Ack Compactor"", ex);
                        }
                    } else {
                        
---------------Reference log start----------------
LOG.trace(""Journal activity detected, no Ack compaction scheduled."")
---------------Reference log end----------------
                    }

                    checkPointCyclesWithNoGC = 0;
                } else {
                    LOG.trace(""Not yet time to check for compaction: {} of {} cycles"",
                              checkPointCyclesWithNoGC, getCompactAcksAfterNoGC());
                }

                journalLogOnLastCompactionCheck = journal.getCurrentDataFileId();
            }
        }
        MDC.remove(""activemq.persistenceDir"");

        LOG.debug(""Checkpoint done."");
        return gcCandidateSet;
    }",,
activemq,19761,"log.error(""Could not create TransportLogger, reason: "" + e, e)",error,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/udp/UdpTransportFactory.java/#L95,"@Override
    public Transport compositeConfigure(Transport transport, WireFormat format, Map options) {
        IntrospectionSupport.setProperties(transport, options);
        final UdpTransport udpTransport = (UdpTransport)transport;

        // deal with fragmentation
        transport = new CommandJoiner(transport, asOpenWireFormat(format));

        if (udpTransport.isTrace()) {
            try {
                transport = TransportLoggerSupport.createTransportLogger(transport);
            } catch (Throwable e) {
                
---------------Reference log start----------------
log.error(""Could not create TransportLogger, reason: "" + e, e)
---------------Reference log end----------------
            }
        }

        transport = new InactivityMonitor(transport, format);

        if (format instanceof OpenWireFormat) {
            transport = configureClientSideNegotiator(transport, format, udpTransport);
        }

        return transport;
    }",,
activemq,19020,"LOG.info(""Installing StaticsBroker"")",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/plugin/StatisticsBrokerPlugin.java/#L47,"public Broker installPlugin(Broker broker) throws Exception {
        StatisticsBroker answer = new StatisticsBroker(broker);
        
---------------Reference log start----------------
LOG.info(""Installing StaticsBroker"")
---------------Reference log end----------------
        return answer;
    }",,
activemq,19041,"LOG.info(""Ignoring no space left exception, "" + exception, exception)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/util/DefaultIOExceptionHandler.java/#L65,"@Override
    public void handle(IOException exception) {
        if (!broker.isStarted() || ignoreAllErrors) {
            allowIOResumption();
            LOG.info(""Ignoring IO exception, "" + exception, exception);
            return;
        }

        if (ignoreNoSpaceErrors) {
            Throwable cause = exception;
            while (cause != null && cause instanceof IOException) {
                String message = cause.getMessage();
                if (message != null && message.contains(noSpaceMessage)) {
                    
---------------Reference log start----------------
LOG.info(""Ignoring no space left exception, "" + exception, exception)
---------------Reference log end----------------
                    allowIOResumption();
                    return;
                }
                cause = cause.getCause();
            }
        }

        if (ignoreSQLExceptions) {
            Throwable cause = exception;
            while (cause != null) {
                if (cause instanceof SQLException) {
                    String message = cause.getMessage();

                    if (message == null) {
                        message = """";
                    }

                    if (message.contains(sqlExceptionMessage)) {
                        LOG.info(""Ignoring SQLException, "" + exception, cause);
                        return;
                    }
                }
                cause = cause.getCause();
            }
        }

        if (stopStartConnectors) {
            if (handlingException.compareAndSet(false, true)) {
                LOG.info(""Initiating stop/restart of transports on "" + broker + "" due to IO exception, "" + exception, exception);

                new Thread(""IOExceptionHandler: stop transports"") {
                    @Override
                    public void run() {
                        try {
                            ServiceStopper stopper = new ServiceStopper();
                            broker.stopAllConnectors(stopper);
                            LOG.info(""Successfully stopped transports on "" + broker);
                        } catch (Exception e) {
                            LOG.warn(""Failure occurred while stopping broker connectors"", e);
                        } finally {
                            // resume again
                            new Thread(""IOExceptionHandler: restart transports"") {
                                @Override
                                public void run() {
                                    try {
                                        allowIOResumption();
                                        while (hasLockOwnership() && isPersistenceAdapterDown()) {
                                            LOG.info(""waiting for broker persistence adapter checkpoint to succeed before restarting transports"");
                                            TimeUnit.MILLISECONDS.sleep(resumeCheckSleepPeriod);
                                        }
                                        if (hasLockOwnership()) {
                                            Map<ActiveMQDestination, Destination> destinations = ((RegionBroker)broker.getRegionBroker()).getDestinationMap();
                                            for (Destination destination : destinations.values()) {

                                                if (destination instanceof Queue) {
                                                    Queue queue = (Queue)destination;
                                                    if (queue.isResetNeeded()) {
                                                        queue.clearPendingMessages(0);
                                                    }
                                                }
                                            }
                                            broker.startAllConnectors();
                                            LOG.info(""Successfully restarted transports on "" + broker);
                                        }
                                    } catch (Exception e) {
                                        LOG.warn(""Stopping "" + broker + "" due to failure restarting transports"", e);
                                        stopBroker(e);
                                    } finally {
                                        handlingException.compareAndSet(true, false);
                                    }
                                }

                                private boolean isPersistenceAdapterDown() {
                                    boolean checkpointSuccess = false;
                                    try {
                                        broker.getPersistenceAdapter().checkpoint(true);
                                        checkpointSuccess = true;
                                    } catch (Throwable ignored) {
                                    }
                                    return !checkpointSuccess;
                                }
                            }.start();


                        }
                    }
                }.start();
            }

            throw new SuppressReplyException(""Stop/RestartTransportsInitiated"", exception);
        }

        if (handlingException.compareAndSet(false, true)) {
            stopBroker(exception);
        }

        // we don't want to propagate the exception back to the client
        // They will see a delay till they see a disconnect via socket.close
        // at which point failover: can kick in.
        throw new SuppressReplyException(""ShutdownBrokerInitiated"", exception);
    }",,
activemq,18334,"LOG.debug(""msg:"" + msg + "", id:"" + id + "", destinationName:"" + destinationName)",debug,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/MessageListenerServlet.java/#L392,"protected void doMessages(AjaxWebClient client, HttpServletRequest request, HttpServletResponse response) throws JMSException, IOException {

        int messages = 0;
        // This is a poll for any messages

        long timeout = getReadTimeout(request);
        if (LOG.isDebugEnabled()) {
            LOG.debug(""doMessage timeout="" + timeout);
        }

        // this is non-null if we're resuming the continuation.
        // attributes set in AjaxListener
        UndeliveredAjaxMessage undelivered_message = null;
        Message message = null;
        undelivered_message = (UndeliveredAjaxMessage)request.getAttribute(""undelivered_message"");
        if( undelivered_message != null ) {
            message = undelivered_message.getMessage();
        }

        synchronized (client) {

            List<MessageConsumer> consumers = client.getConsumers();
            MessageAvailableConsumer consumer = null;
            if( undelivered_message != null ) {
                consumer = (MessageAvailableConsumer)undelivered_message.getConsumer();
            }

            if (message == null) {
                // Look for a message that is ready to go
                for (int i = 0; message == null && i < consumers.size(); i++) {
                    consumer = (MessageAvailableConsumer)consumers.get(i);
                    if (consumer.getAvailableListener() == null) {
                        continue;
                    }

                    // Look for any available messages
                    message = consumer.receive(10);
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""received "" + message + "" from "" + consumer);
                    }
                }
            }

            // prepare the response
            response.setContentType(""text/xml"");
            response.setHeader(""Cache-Control"", ""no-cache"");

            if (message == null && client.getListener().getUndeliveredMessages().size() == 0) {
                Continuation continuation = ContinuationSupport.getContinuation(request);

                // Add a listener to the continuation to make sure it actually
                // will expire (seems like a bug in Jetty Servlet 3 continuations,
                // see https://issues.apache.org/jira/browse/AMQ-3447
                continuation.addContinuationListener(new ContinuationListener() {
                    @Override
                    public void onTimeout(Continuation cont) {
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Continuation "" + cont.toString() + "" expired."");
                        }
                    }

                    @Override
                    public void onComplete(Continuation cont) {
                        if (LOG.isDebugEnabled()) {
                           LOG.debug(""Continuation "" + cont.toString() + "" completed."");
                        }
                    }
                });

                if (continuation.isExpired()) {
                    response.setStatus(HttpServletResponse.SC_OK);
                    StringWriter swriter = new StringWriter();
                    PrintWriter writer = new PrintWriter(swriter);
                    writer.println(""<ajax-response>"");
                    writer.print(""</ajax-response>"");

                    writer.flush();
                    String m = swriter.toString();
                    response.getWriter().println(m);

                    return;
                }

                continuation.setTimeout(timeout);
                continuation.suspend();
                LOG.debug( ""Suspending continuation "" + continuation );

                // Fetch the listeners
                AjaxListener listener = client.getListener();
                listener.access();

                // register this continuation with our listener.
                listener.setContinuation(continuation);

                return;
            }

            StringWriter swriter = new StringWriter();
            PrintWriter writer = new PrintWriter(swriter);

            Map<MessageAvailableConsumer, String> consumerIdMap = client.getIdMap();
            Map<MessageAvailableConsumer, String> consumerDestinationNameMap = client.getDestinationNameMap();
            response.setStatus(HttpServletResponse.SC_OK);
            writer.println(""<ajax-response>"");

            // Send any message we already have
            if (message != null) {
                String id = consumerIdMap.get(consumer);
                String destinationName = consumerDestinationNameMap.get(consumer);
                LOG.debug( ""sending pre-existing message"" );
                writeMessageResponse(writer, message, id, destinationName);

                messages++;
            }

            // send messages buffered while continuation was unavailable.
            LinkedList<UndeliveredAjaxMessage> undeliveredMessages = ((AjaxListener)consumer.getAvailableListener()).getUndeliveredMessages();
            LOG.debug(""Send "" + undeliveredMessages.size() + "" unconsumed messages"");
            synchronized( undeliveredMessages ) {
                for (Iterator<UndeliveredAjaxMessage> it = undeliveredMessages.iterator(); it.hasNext();) {
                    messages++;
                    UndeliveredAjaxMessage undelivered = it.next();
                    Message msg = undelivered.getMessage();
                    consumer = (MessageAvailableConsumer)undelivered.getConsumer();
                    String id = consumerIdMap.get(consumer);
                    String destinationName = consumerDestinationNameMap.get(consumer);
                    LOG.debug( ""sending undelivered/buffered messages"" );
                    
---------------Reference log start----------------
LOG.debug(""msg:"" + msg + "", id:"" + id + "", destinationName:"" + destinationName)
---------------Reference log end----------------
                    writeMessageResponse(writer, msg, id, destinationName);
                    it.remove();
                    if (messages >= maximumMessages) {
                        break;
                    }
                }
            }

            // Send the rest of the messages
            for (int i = 0; i < consumers.size() && messages < maximumMessages; i++) {
                consumer = (MessageAvailableConsumer)consumers.get(i);
                if (consumer.getAvailableListener() == null) {
                    continue;
                }

                // Look for any available messages
                while (messages < maximumMessages) {
                    message = consumer.receiveNoWait();
                    if (message == null) {
                        break;
                    }
                    messages++;
                    String id = consumerIdMap.get(consumer);
                    String destinationName = consumerDestinationNameMap.get(consumer);
                    LOG.debug( ""sending final available messages"" );
                    writeMessageResponse(writer, message, id, destinationName);
                }
            }

            writer.print(""</ajax-response>"");

            writer.flush();
            String m = swriter.toString();
            response.getWriter().println(m);
        }
    }",,
activemq,19395,"log.debug(""setting [topicPrefetch] to: "" + topicPrefetch)",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ActiveMQConnectionSupport.java/#L441,"public void setTopicPrefetch(Integer topicPrefetch) {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""setting [topicPrefetch] to: "" + topicPrefetch)
---------------Reference log end----------------
        }
        info.setTopicPrefetch(topicPrefetch);
    }",,
activemq,19326,"LOG.trace(""on remove not redispatching {}, dispatcher no longer present on {}"", md, session.getConnection())",trace,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ServerSessionPoolImpl.java/#L238,"public void removeFromPool(ServerSessionImpl ss) {
        sessionLock.lock();
        try {
            activeSessions.remove(ss);
        } finally {
            sessionLock.unlock();
        }
        try {
            ActiveMQSession session = (ActiveMQSession)ss.getSession();
            List<MessageDispatch> l = session.getUnconsumedMessages();
            if (!isClosing() && !l.isEmpty()) {
                ActiveMQConnection connection = activeMQAsfEndpointWorker.getConnection();
                if (connection != null) {
                    for (Iterator<MessageDispatch> i = l.iterator(); i.hasNext();) {
                        MessageDispatch md = i.next();
                        if (connection.hasDispatcher(md.getConsumerId())) {
                            dispatchToSession(md);
                            LOG.trace(""on remove of {} redispatch of {}"", session, md);
                        } else {
                            
---------------Reference log start----------------
LOG.trace(""on remove not redispatching {}, dispatcher no longer present on {}"", md, session.getConnection())
---------------Reference log end----------------
                        }
                    }
                } else {
                    LOG.trace(""on remove of {} not redispatching while disconnected"", session);
                }
            }
        } catch (Throwable t) {
            LOG.error(""Error redispatching unconsumed messages from stale server session {}"", ss, t);
        }
        ss.close();
        synchronized (closing) {
            closing.notify();
        }
    }",,
activemq,18127,"LOG.info(""Creating durable subscriber ("" + clientName + "") to: "" + dest.toString())",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/JmsConsumerClient.java/#L236,"public MessageConsumer createJmsConsumer(Destination dest) throws JMSException {
        if (client.isDurable()) {
            String clientName = getClientName();
            if (clientName == null) {
                clientName = ""JmsConsumer"";
                setClientName(clientName);
            }
            
---------------Reference log start----------------
LOG.info(""Creating durable subscriber ("" + clientName + "") to: "" + dest.toString())
---------------Reference log end----------------
            jmsConsumer = getSession().createDurableSubscriber((Topic) dest, clientName);
        } else {
            LOG.info(""Creating non-durable consumer to: "" + dest.toString());
            jmsConsumer = getSession().createConsumer(dest);
        }
        return jmsConsumer;
    }",,
activemq,18631,"LOG.info(""Using Persistence Adapter: {}"", persistenceAdapterToStart)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L669,"private void doStartPersistenceAdapter() throws Exception {
        PersistenceAdapter persistenceAdapterToStart = getPersistenceAdapter();
        if (persistenceAdapterToStart == null) {
            checkStartException();
            throw new ConfigurationException(""Cannot start null persistence adapter"");
        }
        persistenceAdapterToStart.setUsageManager(getProducerSystemUsage());
        persistenceAdapterToStart.setBrokerName(getBrokerName());
        
---------------Reference log start----------------
LOG.info(""Using Persistence Adapter: {}"", persistenceAdapterToStart)
---------------Reference log end----------------
        if (deleteAllMessagesOnStartup) {
            deleteAllMessages();
        }
        persistenceAdapterToStart.start();

        getTempDataStore();
        if (tempDataStore != null) {
            try {
                // start after we have the store lock
                tempDataStore.start();
            } catch (Exception e) {
                RuntimeException exception = new RuntimeException(
                        ""Failed to start temp data store: "" + tempDataStore, e);
                LOG.error(exception.getLocalizedMessage(), e);
                throw exception;
            }
        }

        getJobSchedulerStore();
        if (jobSchedulerStore != null) {
            try {
                jobSchedulerStore.start();
            } catch (Exception e) {
                RuntimeException exception = new RuntimeException(
                        ""Failed to start job scheduler store: "" + jobSchedulerStore, e);
                LOG.error(exception.getLocalizedMessage(), e);
                throw exception;
            }
        }
    }",,
activemq,18764,"LOG.warn(""ERROR Rolling back disconnected client's xa transactions: "", e)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransactionBroker.java/#L327,"public void removeConnection(ConnectionContext context, ConnectionInfo info, Throwable error) throws Exception {
        for (Iterator<Transaction> iter = context.getTransactions().values().iterator(); iter.hasNext();) {
            try {
                Transaction transaction = iter.next();
                transaction.rollback();
            } catch (Exception e) {
                LOG.warn(""ERROR Rolling back disconnected client's transactions: "", e);
            }
            iter.remove();
        }

        synchronized (xaTransactions) {
            // first find all txs that belongs to the connection
            ArrayList<XATransaction> txs = new ArrayList<XATransaction>();
            for (XATransaction tx : xaTransactions.values()) {
                if (tx.getConnectionId() != null && tx.getConnectionId().equals(info.getConnectionId()) && !tx.isPrepared()) {
                    txs.add(tx);
                }
            }

            // then remove them
            // two steps needed to avoid ConcurrentModificationException, from removeTransaction()
            for (XATransaction tx : txs) {
                try {
                    tx.rollback();
                } catch (Exception e) {
                    
---------------Reference log start----------------
LOG.warn(""ERROR Rolling back disconnected client's xa transactions: "", e)
---------------Reference log end----------------
                }
            }

        }
        next.removeConnection(context, info, error);
    }",,
activemq,17904,"LOG.error(""KahaDB failed to store to Journal, command of type: "" + data.type(), ioe)",error,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/MessageDatabase.java/#L1181,"public Location store(JournalCommand<?> data, boolean sync, IndexAware before, Runnable after, Runnable onJournalStoreComplete) throws IOException {
        try {
            ByteSequence sequence = toByteSequence(data);
            Location location;

            checkpointLock.readLock().lock();
            try {

                long start = System.currentTimeMillis();
                location = onJournalStoreComplete == null ? journal.write(sequence, sync) : journal.write(sequence, onJournalStoreComplete) ;
                long start2 = System.currentTimeMillis();
                //Track the last async update so we know if we need to sync at the next checkpoint
                if (!sync && journal.isJournalDiskSyncPeriodic()) {
                    lastAsyncJournalUpdate.set(location);
                }
                process(data, location, before);

                long end = System.currentTimeMillis();
                long totalTimeMillis = end - start;
                if (LOG_SLOW_ACCESS_TIME > 0 && totalTimeMillis > LOG_SLOW_ACCESS_TIME) {
                    if (LOG.isInfoEnabled()) {
                        LOG.info(""Slow KahaDB access: Journal append took: ""+(start2-start)+"" ms, Index update took ""+(end-start2)+"" ms"");
                    }
                    persistenceAdapterStatistics.addSlowWriteTime(totalTimeMillis);
                }

                persistenceAdapterStatistics.addWriteTime(totalTimeMillis);

            } finally {
                checkpointLock.readLock().unlock();
            }

            if (after != null) {
                after.run();
            }

            return location;
        } catch (IOException ioe) {
            
---------------Reference log start----------------
LOG.error(""KahaDB failed to store to Journal, command of type: "" + data.type(), ioe)
---------------Reference log end----------------
            brokerService.handleIOException(ioe);
            throw ioe;
        }
    }",,
activemq,19164,"LOG.debug(""{} message not forwarded to {} because message came from there or fails TTL, brokerPath: {}, message: {}"", configuration.getBrokerName(), remoteBrokerName, Arrays.toString(md.getMessage().getBrokerPath()), md.getMessage())",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L1200,"protected void serviceLocalCommand(Command command) {
        if (!disposed.get()) {
            try {
                if (command.isMessageDispatch()) {
                    safeWaitUntilStarted();
                    networkBridgeStatistics.getEnqueues().increment();
                    final MessageDispatch md = (MessageDispatch) command;
                    final DemandSubscription sub = subscriptionMapByLocalId.get(md.getConsumerId());
                    if (sub != null && md.getMessage() != null && sub.incrementOutstandingResponses()) {

                        if (suppressMessageDispatch(md, sub)) {
                            
---------------Reference log start----------------
LOG.debug(""{} message not forwarded to {} because message came from there or fails TTL, brokerPath: {}, message: {}"", configuration.getBrokerName(), remoteBrokerName, Arrays.toString(md.getMessage().getBrokerPath()), md.getMessage())
---------------Reference log end----------------
                            // still ack as it may be durable
                            try {
                                localBroker.oneway(new MessageAck(md, MessageAck.INDIVIDUAL_ACK_TYPE, 1));
                            } finally {
                                sub.decrementOutstandingResponses();
                            }
                            return;
                        }

                        Message message = configureMessage(md);
                        LOG.debug(""bridging ({} -> {}), consumer: {}, destination: {}, brokerPath: {}, message: {}"",
                                configuration.getBrokerName(), remoteBrokerName, md.getConsumerId(), message.getDestination(), Arrays.toString(message.getBrokerPath()), (LOG.isTraceEnabled() ? message : message.getMessageId()));
                        if (isDuplex() && NetworkBridgeFilter.isAdvisoryInterpretedByNetworkBridge(message)) {
                            try {
                                // never request b/c they are eventually                     acked async
                                remoteBroker.oneway(message);
                            } finally {
                                sub.decrementOutstandingResponses();
                            }
                            return;
                        }
                        if (isPermissableDestination(md.getDestination())) {
                           if (message.isPersistent() || configuration.isAlwaysSyncSend()) {

                              // The message was not sent using async send, so we should only
                              // ack the local broker when we get confirmation that the remote
                              // broker has received the message.
                              remoteBroker.asyncRequest(message, new ResponseCallback() {
                                 @Override
                                 public void onCompletion(FutureResponse future) {
                                    try {
                                       Response response = future.getResult();
                                       if (response.isException()) {
                                          ExceptionResponse er = (ExceptionResponse) response;
                                          serviceLocalException(md, er.getException());
                                       } else {
                                          localBroker.oneway(new MessageAck(md, MessageAck.INDIVIDUAL_ACK_TYPE, 1));
                                          networkBridgeStatistics.getDequeues().increment();
                                       }
                                    } catch (IOException e) {
                                       serviceLocalException(md, e);
                                    } finally {
                                       sub.decrementOutstandingResponses();
                                    }
                                 }
                              });

                           } else {
                              // If the message was originally sent using async send, we will
                              // preserve that QOS by bridging it using an async send (small chance
                              // of message loss).
                              try {
                                 remoteBroker.oneway(message);
                                 localBroker.oneway(new MessageAck(md, MessageAck.INDIVIDUAL_ACK_TYPE, 1));
                                 networkBridgeStatistics.getDequeues().increment();
                              } finally {
                                 sub.decrementOutstandingResponses();
                              }
                           }
                           serviceOutbound(message);
                        }
                    } else {
                        LOG.debug(""No subscription registered with this network bridge for consumerId: {} for message: {}"", md.getConsumerId(), md.getMessage());
                    }
                } else if (command.isBrokerInfo()) {
                    futureLocalBrokerInfo.set((BrokerInfo) command);
                } else if (command.isShutdownInfo()) {
                    LOG.info(""{} Shutting down {}"", configuration.getBrokerName(), configuration.getName());
                    stop();
                } else if (command.getClass() == ConnectionError.class) {
                    ConnectionError ce = (ConnectionError) command;
                    serviceLocalException(ce.getException());
                } else {
                    switch (command.getDataStructureType()) {
                        case WireFormatInfo.DATA_STRUCTURE_TYPE:
                            break;
                        case BrokerSubscriptionInfo.DATA_STRUCTURE_TYPE:
                            break;
                        default:
                            LOG.warn(""Unexpected local command: {}"", command);
                    }
                }
            } catch (Throwable e) {
                LOG.warn(""Caught an exception processing local command"", e);
                serviceLocalException(e);
            }
        }
    }",,
activemq,18000,"LOG.warn(""Failed to close file"", e)",warn,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/disk/journal/DataFileAccessor.java/#L63,"public void dispose() {
        if (disposed) {
            return;
        }
        disposed = true;
        try {
            dataFile.closeRandomAccessFile(file);
        } catch (IOException e) {
            
---------------Reference log start----------------
LOG.warn(""Failed to close file"", e)
---------------Reference log end----------------
        }
    }",,
activemq,18514,"LOG.info(""The connection to '{}' is taking a long time to shutdown."", transport.getRemoteAddress())",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransportConnection.java/#L1108,"@Override
    public void stop() throws Exception {
        // do not stop task the task runner factories (taskRunnerFactory, stopTaskRunnerFactory)
        // as their lifecycle is handled elsewhere

        stopAsync();
        while (!stopped.await(5, TimeUnit.SECONDS)) {
            
---------------Reference log start----------------
LOG.info(""The connection to '{}' is taking a long time to shutdown."", transport.getRemoteAddress())
---------------Reference log end----------------
        }
    }",,
activemq,18136,"LOG.info(""Finished sending"")",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/JmsProducerClient.java/#L159,"public void sendCountBasedMessages(long messageCount) throws JMSException {
        // Parse through different ways to send messages
        // Avoided putting the condition inside the loop to prevent effect on performance
        Destination[] dest = createDestinations(destCount);

        // Create a producer, if none is created.
        if (getJmsProducer() == null) {
            if (dest.length == 1) {
                createJmsProducer(dest[0]);
            } else {
                createJmsProducer();
            }
        }
        try {
            getConnection().start();
            if (client.getMsgFileName() != null) {
                LOG.info(""Starting to publish "" +
                    messageCount +
                    "" messages from file "" +
                    client.getMsgFileName()
                );
            } else {
                LOG.info(""Starting to publish "" +
                    messageCount +
                    "" messages of size "" +
                    client.getMessageSize() +
                    "" byte(s).""
                );
            }

            // Send one type of message only, avoiding the creation of different messages on sending
            if (!client.isCreateNewMsg()) {
                // Create only a single message
                createJmsTextMessage();

                // Send to more than one actual destination
                if (dest.length > 1) {
                    for (int i = 0; i < messageCount; i++) {
                        for (int j = 0; j < dest.length; j++) {
                            getJmsProducer().send(dest[j], getJmsTextMessage());
                            incThroughput();
                            sleep();
                            commitTxIfNecessary();
                        }
                    }
                    // Send to only one actual destination
                } else {
                    for (int i = 0; i < messageCount; i++) {
                        getJmsProducer().send(getJmsTextMessage());
                        incThroughput();
                        sleep();
                        commitTxIfNecessary();
                    }
                }

                // Send different type of messages using indexing to identify each one.
                // Message size will vary. Definitely slower, since messages properties
                // will be set individually each send.
            } else {
                // Send to more than one actual destination
                if (dest.length > 1) {
                    for (int i = 0; i < messageCount; i++) {
                        for (int j = 0; j < dest.length; j++) {
                            getJmsProducer().send(dest[j], createJmsTextMessage(""Text Message ["" + i + ""]""));
                            incThroughput();
                            sleep();
                            commitTxIfNecessary();
                        }
                    }

                    // Send to only one actual destination
                } else {
                    for (int i = 0; i < messageCount; i++) {
                        getJmsProducer().send(createJmsTextMessage(""Text Message ["" + i + ""]""));
                        incThroughput();
                        sleep();
                        commitTxIfNecessary();
                    }
                }
            }
        } finally {
            
---------------Reference log start----------------
LOG.info(""Finished sending"")
---------------Reference log end----------------
            getConnection().close();
        }
    }",,
activemq,18130,LOG.warn(ex.getMessage()),warn,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/JmsConsumerClient.java/#L285,"protected void sleep() {
        if (client.getRecvDelay() > 0) {
            try {
                LOG.trace(""Sleeping for "" + client.getRecvDelay() + "" milliseconds"");
                Thread.sleep(client.getRecvDelay());
            } catch (java.lang.InterruptedException ex) {
                
---------------Reference log start----------------
LOG.warn(ex.getMessage())
---------------Reference log end----------------
            }
        }
    }",,
activemq,18957,"LOG.error(""Policy not applied!  Error parsing DN for addition of {}"", result.getName(), e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/security/SimpleCachedLDAPAuthorizationMap.java/#L809,"public void objectAdded(NamingEvent namingEvent, DestinationType destinationType, PermissionType permissionType) {
        LOG.debug(""Adding object: {}"", namingEvent.getNewBinding());
        SearchResult result = (SearchResult) namingEvent.getNewBinding();

        try {
            DefaultAuthorizationMap map = this.map.get();
            LdapName name = new LdapName(result.getName());
            AuthorizationEntry entry = getEntry(map, name, destinationType);

            applyACL(entry, result, permissionType);
            if (!(entry instanceof TempDestinationAuthorizationEntry)) {
                map.put(entry.getDestination(), entry);
            }
        } catch (InvalidNameException e) {
            
---------------Reference log start----------------
LOG.error(""Policy not applied!  Error parsing DN for addition of {}"", result.getName(), e)
---------------Reference log end----------------
        } catch (Exception e) {
            LOG.error(""Policy not applied!  Error processing object addition for addition of {}"", result.getName(), e);
        }
    }",,
activemq,19727,"LOG.trace(""restore requestMap, replay: {}"", command)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/failover/FailoverTransport.java/#L860,"protected void restoreTransport(Transport t) throws Exception, IOException {
        t.start();
        // send information to the broker - informing it we are an ft client
        ConnectionControl cc = new ConnectionControl();
        cc.setFaultTolerant(true);
        t.oneway(cc);
        stateTracker.restore(t);
        Map<Integer, Command> tmpMap = null;
        synchronized (requestMap) {
            tmpMap = new LinkedHashMap<Integer, Command>(requestMap);
        }
        for (Command command : tmpMap.values()) {
            
---------------Reference log start----------------
LOG.trace(""restore requestMap, replay: {}"", command)
---------------Reference log end----------------
            t.oneway(command);
        }
    }",,
activemq,18163,"log.debug(""Sampler start"")",debug,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-perf-maven-plugin/src/main/java/org/apache/activemq/tool/sampler/AbstractPerformanceSampler.java/#L185,"@Override
    public void run() {
        try {
            log.debug(""Ramp up start"");
            onRampUpStart();
            if (perfEventListener != null) {
                perfEventListener.onRampUpStart(this);
            }

            if (rampUpTime > 0) {
                try {
                    Thread.sleep(rampUpTime);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }

            
---------------Reference log start----------------
log.debug(""Sampler start"")
---------------Reference log end----------------
            onSamplerStart();
            if (perfEventListener != null) {
                perfEventListener.onSamplerStart(this);
            }

            sample();

            log.debug(""Sampler end"");
            onSamplerEnd();
            if (perfEventListener != null) {
                perfEventListener.onSamplerEnd(this);
            }

            if (rampDownTime > 0) {
                try {
                    Thread.sleep(rampDownTime);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }

            log.debug(""Ramp down end"");
            onRampDownEnd();
            if (perfEventListener != null) {
                perfEventListener.onRampDownEnd(this);
            }
        } finally {
            completionLatch.countDown();
        }
    }",,
activemq,19774,"LOG.warn(""Failed to unmarshal partial command: "" + command)",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/CommandJoiner.java/#L71,"public void onCommand(Object o) {
        Command command = (Command)o;
        byte type = command.getDataStructureType();
        if (type == PartialCommand.DATA_STRUCTURE_TYPE || type == LastPartialCommand.DATA_STRUCTURE_TYPE) {
            PartialCommand header = (PartialCommand)command;
            byte[] partialData = header.getData();
            try {
                out.write(partialData);
            } catch (IOException e) {
                getTransportListener().onException(e);
            }
            if (type == LastPartialCommand.DATA_STRUCTURE_TYPE) {
                try {
                    byte[] fullData = out.toByteArray();
                    out.reset();
                    DataInputStream dataIn = new DataInputStream(new ByteArrayInputStream(fullData));
                    Command completeCommand = (Command)wireFormat.unmarshal(dataIn);

                    LastPartialCommand lastCommand = (LastPartialCommand)command;
                    lastCommand.configure(completeCommand);

                    getTransportListener().onCommand(completeCommand);
                } catch (IOException e) {
                    
---------------Reference log start----------------
LOG.warn(""Failed to unmarshal partial command: "" + command)
---------------Reference log end----------------
                    getTransportListener().onException(e);
                }
            }
        } else {
            getTransportListener().onCommand(command);
        }
    }",,
activemq,19184,"LOG.error(""Failed to add static destination {}"", dest, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DurableConduitBridge.java/#L91,"@Override
    protected void setupStaticDestinations() {
        super.setupStaticDestinations();
        ActiveMQDestination[] dests = configuration.isDynamicOnly() ? null : durableDestinations;
        if (dests != null) {
            for (ActiveMQDestination dest : dests) {
                if (isPermissableDestination(dest) && !doesConsumerExist(dest)) {
                    try {
                        //Filtering by non-empty subscriptions, see AMQ-5875
                        if (dest.isTopic()) {
                            RegionBroker regionBroker = (RegionBroker) brokerService.getRegionBroker();
                            TopicRegion topicRegion = (TopicRegion) regionBroker.getTopicRegion();

                            String candidateSubName = getSubscriberName(dest);
                            for (Subscription subscription : topicRegion.getDurableSubscriptions().values()) {
                                String subName = subscription.getConsumerInfo().getSubscriptionName();
                                String clientId = subscription.getContext().getClientId();
                                if (subName != null && subName.equals(candidateSubName) && clientId.startsWith(configuration.getName())) {
                                    DemandSubscription sub = createDemandSubscription(dest, subName);
                                    if (sub != null) {
                                        sub.getLocalInfo().setSubscriptionName(getSubscriberName(dest));
                                        sub.setStaticallyIncluded(true);
                                        addSubscription(sub);
                                        break;
                                    }
                                }
                            }
                        }
                    } catch (IOException e) {
                        
---------------Reference log start----------------
LOG.error(""Failed to add static destination {}"", dest, e)
---------------Reference log end----------------
                    }
                    LOG.trace(""Forwarding messages for durable destination: {}"", dest);
                } else if (configuration.isSyncDurableSubs() && !isPermissableDestination(dest)) {
                    if (dest.isTopic()) {
                        RegionBroker regionBroker = (RegionBroker) brokerService.getRegionBroker();
                        TopicRegion topicRegion = (TopicRegion) regionBroker.getTopicRegion();

                        String candidateSubName = getSubscriberName(dest);
                        for (Subscription subscription : topicRegion.getDurableSubscriptions().values()) {
                            String subName = subscription.getConsumerInfo().getSubscriptionName();
                            if (subName != null && subName.equals(candidateSubName) &&
                                    subscription instanceof DurableTopicSubscription) {
                               try {
                                    DurableTopicSubscription durableSub = (DurableTopicSubscription) subscription;
                                    //check the clientId so we only remove subs for the matching bridge
                                    if (durableSub.getSubscriptionKey().getClientId().equals(localClientId)) {
                                        // remove the NC subscription as it is no longer for a permissible dest
                                        RemoveSubscriptionInfo sending = new RemoveSubscriptionInfo();
                                        sending.setClientId(localClientId);
                                        sending.setSubscriptionName(subName);
                                        sending.setConnectionId(this.localConnectionInfo.getConnectionId());
                                        localBroker.oneway(sending);
                                    }
                                } catch (IOException e) {
                                    LOG.debug(""Exception removing NC durable subscription: {}"", subName, e);
                                    serviceRemoteException(e);
                                }
                                break;
                            }
                        }
                    }
                }
            }
        }
    }",,
activemq,17806,"LOG.debug(""Executing SQL: "" + createStatement)",debug,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/adapter/DefaultJDBCAdapter.java/#L112,"private void executeStatement(TransactionContext transactionContext, String createStatement, boolean ignoreStatementExecutionFailure) throws IOException {
        Statement statement = null;
        try {
            
---------------Reference log start----------------
LOG.debug(""Executing SQL: "" + createStatement)
---------------Reference log end----------------
            statement = transactionContext.getConnection().createStatement();
            statement.execute(createStatement);

            commitIfAutoCommitIsDisabled(transactionContext);
        } catch (SQLException e) {
            if (ignoreStatementExecutionFailure) {
                LOG.debug(""Could not create JDBC tables; The message table already existed. "" + String.format(FAILURE_MESSAGE, createStatement, e.getMessage(), e.getSQLState(), e.getErrorCode()));
            } else {
                LOG.warn(""Could not create JDBC tables; they could already exist. "" + String.format(FAILURE_MESSAGE, createStatement, e.getMessage(), e.getSQLState(), e.getErrorCode()));
                JDBCPersistenceAdapter.log(""Failure details: "", e);
            }
        } finally {
            closeStatement(statement);
        }
    }",,
activemq,18718,"LOG.info(""Forgetting transaction: {}"", transactionId.getTransactionKey())",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/LoggingBrokerPlugin.java/#L301,"@Override
    public void forgetTransaction(ConnectionContext context, TransactionId transactionId) throws Exception {
        if (isLogAll() || isLogTransactionEvents()) {
            
---------------Reference log start----------------
LOG.info(""Forgetting transaction: {}"", transactionId.getTransactionKey())
---------------Reference log end----------------
        }
        super.forgetTransaction(context, transactionId);
    }",,
activemq,18189,"LOG.info("" TEST REPORT OUTPUT : "" + reportFile.getAbsolutePath())",info,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-memtest-maven-plugin/src/main/java/org/apache/activemq/tool/ReportGenerator.java/#L72,"public void stopGenerateReport() {
        writeWithIndent(0, ""</test-report>"");
        this.getWriter().flush();
        this.getWriter().close();
        
---------------Reference log start----------------
LOG.info("" TEST REPORT OUTPUT : "" + reportFile.getAbsolutePath())
---------------Reference log end----------------

    }",,
activemq,17966,"logger.warn(""Journal failed while writing at: "" + wb.dataFile.getDataFileId() + "":"" + wb.offset, error)",warn,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/disk/journal/DataFileAppender.java/#L352,"protected void processQueue() {
        DataFile dataFile = null;
        RecoverableRandomAccessFile file = null;
        WriteBatch wb = null;
        try (DataByteArrayOutputStream buff = new DataByteArrayOutputStream(maxWriteBatchSize);) {

            while (true) {

                // Block till we get a command.
                synchronized (enqueueMutex) {
                    while (true) {
                        if (nextWriteBatch != null) {
                            wb = nextWriteBatch;
                            nextWriteBatch = null;
                            break;
                        }
                        if (shutdown) {
                            return;
                        }
                        enqueueMutex.wait();
                    }
                    enqueueMutex.notifyAll();
                }

                if (dataFile != wb.dataFile) {
                    if (file != null) {
                        if (periodicSync) {
                            if (logger.isTraceEnabled()) {
                                logger.trace(""Syncing file {} on rotate"", dataFile.getFile().getName());
                            }
                            file.sync();
                        }
                        dataFile.closeRandomAccessFile(file);
                    }
                    dataFile = wb.dataFile;
                    file = dataFile.appendRandomAccessFile();
                }

                Journal.WriteCommand write = wb.writes.getHead();

                // Write an empty batch control record.
                buff.reset();
                buff.write(EMPTY_BATCH_CONTROL_RECORD);

                boolean forceToDisk = false;
                while (write != null) {
                    forceToDisk |= write.sync | (syncOnComplete && write.onComplete != null);
                    buff.writeInt(write.location.getSize());
                    buff.writeByte(write.location.getType());
                    buff.write(write.data.getData(), write.data.getOffset(), write.data.getLength());
                    write = write.getNext();
                }

                // append 'unset', zero length next batch so read can always find eof
                buff.write(Journal.EOF_RECORD);

                ByteSequence sequence = buff.toByteSequence();

                // Now we can fill in the batch control record properly.
                buff.reset();
                buff.skip(RECORD_HEAD_SPACE + Journal.BATCH_CONTROL_RECORD_MAGIC.length);
                buff.writeInt(sequence.getLength() - Journal.BATCH_CONTROL_RECORD_SIZE - Journal.EOF_RECORD.length);
                if( journal.isChecksum() ) {
                    Checksum checksum = new Adler32();
                    checksum.update(sequence.getData(), sequence.getOffset()+Journal.BATCH_CONTROL_RECORD_SIZE, sequence.getLength()-Journal.BATCH_CONTROL_RECORD_SIZE-Journal.EOF_RECORD.length);
                    buff.writeLong(checksum.getValue());
                }

                // Now do the 1 big write.
                file.seek(wb.offset);
                if (maxStat > 0) {
                    if (statIdx < maxStat) {
                        stats[statIdx++] = sequence.getLength();
                    } else {
                        long all = 0;
                        for (;statIdx > 0;) {
                            all+= stats[--statIdx];
                        }
                        logger.info(""Ave writeSize: "" + all/maxStat);
                    }
                }
                file.write(sequence.getData(), sequence.getOffset(), sequence.getLength());

                ReplicationTarget replicationTarget = journal.getReplicationTarget();
                if( replicationTarget!=null ) {
                    replicationTarget.replicate(wb.writes.getHead().location, sequence, forceToDisk);
                }

                if (forceToDisk) {
                    file.sync();
                }

                Journal.WriteCommand lastWrite = wb.writes.getTail();
                journal.setLastAppendLocation(lastWrite.location);

                signalDone(wb);
            }
        } catch (Throwable error) {
            
---------------Reference log start----------------
logger.warn(""Journal failed while writing at: "" + wb.dataFile.getDataFileId() + "":"" + wb.offset, error)
---------------Reference log end----------------
            synchronized (enqueueMutex) {
                shutdown = true;
                running = false;
                signalError(wb, error);
                if (nextWriteBatch != null) {
                    signalError(nextWriteBatch, error);
                    nextWriteBatch = null;
                    enqueueMutex.notifyAll();
                }
            }
        } finally {
            try {
                if (file != null) {
                    if (periodicSync) {
                        if (logger.isTraceEnabled()) {
                            logger.trace(""Syning file {} on close"", dataFile.getFile().getName());
                        }
                        file.sync();
                    }
                    dataFile.closeRandomAccessFile(file);
                }
            } catch (Throwable ignore) {
            }
            shutdownDone.countDown();
            running = false;
        }
    }",,
activemq,19171,"LOG.error(""Failed to remove duplicated sub as a result of sub with higher priority, sub: {}"", existingSub, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/DemandForwardingBridgeSupport.java/#L1501,"private boolean hasLowerPriority(Subscription existingSub, ConsumerInfo candidateInfo) {
        boolean suppress = false;

        if (existingSub.getConsumerInfo().getPriority() >= candidateInfo.getPriority()) {
            LOG.debug(""{} Ignoring duplicate subscription from {}, sub: {} is duplicate by network subscription with equal or higher network priority: {}, networkConsumerIds: {}"",
                    configuration.getBrokerName(), remoteBrokerName, candidateInfo, existingSub, existingSub.getConsumerInfo().getNetworkConsumerIds());
            suppress = true;
        } else {
            // remove the existing lower priority duplicate and allow this candidate
            try {
                removeDuplicateSubscription(existingSub);

                LOG.debug(""{} Replacing duplicate subscription {} with sub from {}, which has a higher priority, new sub: {}, networkConsumerIds: {}"",
                        configuration.getBrokerName(), existingSub.getConsumerInfo(), remoteBrokerName, candidateInfo, candidateInfo.getNetworkConsumerIds());
            } catch (IOException e) {
                
---------------Reference log start----------------
LOG.error(""Failed to remove duplicated sub as a result of sub with higher priority, sub: {}"", existingSub, e)
---------------Reference log end----------------
            }
        }
        return suppress;
    }",,
activemq,19289,"LOG.warn(""No topics defined for Subscription "" + command)",warn,https://github.com/apache/activemq/blob/main/activemq-mqtt/src/main/java/org/apache/activemq/transport/mqtt/MQTTProtocolConverter.java/#L424,"public void onUnSubscribe(UNSUBSCRIBE command) throws MQTTProtocolException {
        checkConnected();
        if (command.qos() != QoS.AT_LEAST_ONCE && (version != V3_1 || publishDollarTopics != true)) {
            throw new MQTTProtocolException(""Failed to process unsubscribe request"", true, new Exception(""UNSUBSCRIBE frame not properly formatted, QoS""));
        }
        UTF8Buffer[] topics = command.topics();
        if (topics != null) {
            for (UTF8Buffer topic : topics) {
                MQTTProtocolSupport.validate(topic.toString());
                try {
                    findSubscriptionStrategy().onUnSubscribe(topic.toString());
                } catch (IOException e) {
                    throw new MQTTProtocolException(""Failed to process unsubscribe request"", true, e);
                }
            }
            UNSUBACK ack = new UNSUBACK();
            ack.messageId(command.messageId());
            sendToMQTT(ack.encode());
        } else {
            
---------------Reference log start----------------
LOG.warn(""No topics defined for Subscription "" + command)
---------------Reference log end----------------
            throw new MQTTProtocolException(""UNSUBSCRIBE command received with no topic filter"");
        }
    }",,
activemq,18092,"LOG.info(""Stopped KahaDB"")",info,https://github.com/apache/activemq/blob/main/activemq-kahadb-store/src/main/java/org/apache/activemq/store/kahadb/KahaDBStore.java/#L310,"@Override
    public void doStop(ServiceStopper stopper) throws Exception {
        // drain down async jobs
        LOG.info(""Stopping async queue tasks"");
        if (this.globalQueueSemaphore != null) {
            this.globalQueueSemaphore.tryAcquire(this.maxAsyncJobs, 60, TimeUnit.SECONDS);
        }
        synchronized (this.asyncQueueMaps) {
            for (Map<AsyncJobKey, StoreTask> m : asyncQueueMaps) {
                synchronized (m) {
                    for (StoreTask task : m.values()) {
                        task.cancel();
                    }
                }
            }
            this.asyncQueueMaps.clear();
        }
        LOG.info(""Stopping async topic tasks"");
        if (this.globalTopicSemaphore != null) {
            this.globalTopicSemaphore.tryAcquire(this.maxAsyncJobs, 60, TimeUnit.SECONDS);
        }
        synchronized (this.asyncTopicMaps) {
            for (Map<AsyncJobKey, StoreTask> m : asyncTopicMaps) {
                synchronized (m) {
                    for (StoreTask task : m.values()) {
                        task.cancel();
                    }
                }
            }
            this.asyncTopicMaps.clear();
        }
        if (this.globalQueueSemaphore != null) {
            this.globalQueueSemaphore.drainPermits();
        }
        if (this.globalTopicSemaphore != null) {
            this.globalTopicSemaphore.drainPermits();
        }
        if (this.queueExecutor != null) {
            ThreadPoolUtils.shutdownNow(queueExecutor);
            queueExecutor = null;
        }
        if (this.topicExecutor != null) {
            ThreadPoolUtils.shutdownNow(topicExecutor);
            topicExecutor = null;
        }
        
---------------Reference log start----------------
LOG.info(""Stopped KahaDB"")
---------------Reference log end----------------
        super.doStop(stopper);
    }",,
activemq,18597,"LOG.warn(""Failed to register MBean {}"", key)",warn,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/jmx/ManagedRegionBroker.java/#L388,"protected void registerProducer(ObjectName key, ActiveMQDestination dest, ProducerView view) throws Exception {

        if (dest != null) {
            if (dest.isQueue()) {
                if (dest.isTemporary()) {
                    temporaryQueueProducers.put(key, view);
                } else {
                    queueProducers.put(key, view);
                }
            } else {
                if (dest.isTemporary()) {
                    temporaryTopicProducers.put(key, view);
                } else {
                    topicProducers.put(key, view);
                }
            }
        } else {
            dynamicDestinationProducers.put(key, view);
        }

        try {
            if (AsyncAnnotatedMBean.registerMBean(asyncInvokeService, mbeanTimeout, managementContext, view, key) != null) {
                registeredMBeans.add(key);
            }
        } catch (Throwable e) {
            
---------------Reference log start----------------
LOG.warn(""Failed to register MBean {}"", key)
---------------Reference log end----------------
            LOG.debug(""Failure reason: "", e);
        }
    }",,
activemq,19756,"LOG.debug(""Received command on: "" + this + "" from address: "" + endpoint + "" command: "" + command)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/udp/UdpTransportServer.java/#L115,"protected void processInboundConnection(Command command) {
        DatagramEndpoint endpoint = (DatagramEndpoint)command.getFrom();
        if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""Received command on: "" + this + "" from address: "" + endpoint + "" command: "" + command)
---------------Reference log end----------------
        }
        Transport transport = null;
        synchronized (transports) {
            transport = transports.get(endpoint);
            if (transport == null) {
                if (usingWireFormatNegotiation && !command.isWireFormatInfo()) {
                    LOG.error(""Received inbound server communication from: "" + command.getFrom() + "" expecting WireFormatInfo but was command: "" + command);
                } else {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Creating a new UDP server connection"");
                    }
                    try {
                        transport = createTransport(command, endpoint);
                        transport = configureTransport(transport);
                        transports.put(endpoint, transport);
                    } catch (IOException e) {
                        LOG.error(""Caught: "" + e, e);
                        getAcceptListener().onAcceptError(e);
                    }
                }
            } else {
                LOG.warn(""Discarding duplicate command to server from: "" + endpoint + "" command: "" + command);
            }
        }
    }",,
activemq,18242,"LOG.trace(""Sender:[{}] msgId={} draining={}, drain={}, credit={}, remoteCredit={}, queued={}"", getEndpoint().getName(), jms.getJMSMessageID(), draining, getEndpoint().getDrain(), getEndpoint().getCredit(), getEndpoint().getRemoteCredit(), getEndpoint().getQueued())",trace,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpSender.java/#L464,"public void pumpOutbound() throws Exception {
        while (!isClosed()) {
            while (currentBuffer != null) {
                int sent = getEndpoint().send(currentBuffer.data, currentBuffer.offset, currentBuffer.length);
                if (sent > 0) {
                    currentBuffer.moveHead(sent);
                    if (currentBuffer.length == 0) {
                        if (presettle) {
                            settle(currentDelivery, MessageAck.INDIVIDUAL_ACK_TYPE);
                        } else {
                            getEndpoint().advance();
                        }
                        currentBuffer = null;
                        currentDelivery = null;
                        logicalDeliveryCount++;
                    }
                } else {
                    return;
                }
            }

            if (outbound.isEmpty()) {
                return;
            }

            final MessageDispatch md = outbound.removeFirst();
            try {

                ActiveMQMessage temp = null;
                if (md.getMessage() != null) {
                    temp = (ActiveMQMessage) md.getMessage().copy();
                }

                final ActiveMQMessage jms = temp;
                if (jms == null) {
                    LOG.trace(""Sender:[{}] browse done."", getEndpoint().getName());
                    // It's the end of browse signal in response to a MessagePull
                    getEndpoint().drained();
                    draining = false;
                    currentCreditRequest = 0;
                    logicalDeliveryCount = 0;
                } else {
                    if (LOG.isTraceEnabled()) {
                        
---------------Reference log start----------------
LOG.trace(""Sender:[{}] msgId={} draining={}, drain={}, credit={}, remoteCredit={}, queued={}"", getEndpoint().getName(), jms.getJMSMessageID(), draining, getEndpoint().getDrain(), getEndpoint().getCredit(), getEndpoint().getRemoteCredit(), getEndpoint().getQueued())
---------------Reference log end----------------
                    }

                    if (draining && getEndpoint().getCredit() == 0) {
                        LOG.trace(""Sender:[{}] browse complete."", getEndpoint().getName());
                        getEndpoint().drained();
                        draining = false;
                        currentCreditRequest = 0;
                        logicalDeliveryCount = 0;
                    }

                    jms.setRedeliveryCounter(md.getRedeliveryCounter());
                    jms.setReadOnlyBody(true);
                    final EncodedMessage amqp = outboundTransformer.transform(jms);
                    if (amqp != null && amqp.getLength() > 0) {
                        currentBuffer = new Buffer(amqp.getArray(), amqp.getArrayOffset(), amqp.getLength());
                        if (presettle) {
                            currentDelivery = getEndpoint().delivery(EMPTY_BYTE_ARRAY, 0, 0);
                        } else {
                            final byte[] tag = tagCache.getNextTag();
                            currentDelivery = getEndpoint().delivery(tag, 0, tag.length);
                        }
                        currentDelivery.setContext(md);
                        currentDelivery.setMessageFormat((int) amqp.getMessageFormat());
                    } else {
                        // TODO: message could not be generated what now?
                    }
                }
            } catch (Exception e) {
                LOG.warn(""Error detected while flushing outbound messages: {}"", e.getMessage());
            }
        }
    }",,
activemq,19542,"LOG.debug(""Sending old pending ack {}, new pending: {}"", oldPendingAck, pendingAck)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQMessageConsumer.java/#L1067,"private void ackLater(MessageDispatch md, byte ackType) throws JMSException {

        // Don't acknowledge now, but we may need to let the broker know the
        // consumer got the message to expand the pre-fetch window
        if (session.getTransacted()) {
            registerSync();
        }

        deliveredCounter++;

        synchronized(deliveredMessages) {
            MessageAck oldPendingAck = pendingAck;
            pendingAck = new MessageAck(md, ackType, deliveredCounter);
            pendingAck.setTransactionId(session.getTransactionContext().getTransactionId());
            if( oldPendingAck==null ) {
                pendingAck.setFirstMessageId(pendingAck.getLastMessageId());
            } else if ( oldPendingAck.getAckType() == pendingAck.getAckType() ) {
                pendingAck.setFirstMessageId(oldPendingAck.getFirstMessageId());
            } else {
                // old pending ack being superseded by ack of another type, if is is not a delivered
                // ack and hence important, send it now so it is not lost.
                if (!oldPendingAck.isDeliveredAck()) {
                    
---------------Reference log start----------------
LOG.debug(""Sending old pending ack {}, new pending: {}"", oldPendingAck, pendingAck)
---------------Reference log end----------------
                    session.sendAck(oldPendingAck);
                } else {
                    LOG.debug(""dropping old pending ack {}, new pending: {}"", oldPendingAck, pendingAck);
                }
            }
            // AMQ-3956 evaluate both expired and normal msgs as
            // otherwise consumer may get stalled
            if ((0.5 * info.getPrefetchSize()) <= (deliveredCounter + ackCounter - additionalWindowSize)) {
                LOG.debug(""ackLater: sending: {}"", pendingAck);
                session.sendAck(pendingAck);
                pendingAck=null;
                deliveredCounter = 0;
                additionalWindowSize = 0;
            }
        }
    }",,
activemq,19195,"LOG.error(""Failed to create replyTo bridge for topic: {}"", replyToProducerTopic, e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/jms/SimpleJmsTopicConnector.java/#L403,"@Override
    protected Destination createReplyToBridge(Destination destination, Connection replyToProducerConnection,
                                              Connection replyToConsumerConnection) {
        Topic replyToProducerTopic = (Topic)destination;
        boolean isInbound = replyToProducerConnection.equals(localConnection.get());

        if (isInbound) {
            InboundTopicBridge bridge = (InboundTopicBridge)replyToBridges.get(replyToProducerTopic);
            if (bridge == null) {
                bridge = new InboundTopicBridge() {
                    @Override
                    protected Destination processReplyToDestination(Destination destination) {
                        return null;
                    }
                };
                try {
                    TopicSession replyToConsumerSession = ((TopicConnection)replyToConsumerConnection)
                        .createTopicSession(false, Session.AUTO_ACKNOWLEDGE);
                    Topic replyToConsumerTopic = replyToConsumerSession.createTemporaryTopic();
                    replyToConsumerSession.close();
                    bridge.setConsumerTopic(replyToConsumerTopic);
                    bridge.setProducerTopic(replyToProducerTopic);
                    bridge.setProducerConnection((TopicConnection)replyToProducerConnection);
                    bridge.setConsumerConnection((TopicConnection)replyToConsumerConnection);
                    bridge.setDoHandleReplyTo(false);
                    if (bridge.getJmsMessageConvertor() == null) {
                        bridge.setJmsMessageConvertor(getInboundMessageConvertor());
                    }
                    bridge.setJmsConnector(this);
                    bridge.start();
                    LOG.info(""Created replyTo bridge for {}"", replyToProducerTopic);
                } catch (Exception e) {
                    
---------------Reference log start----------------
LOG.error(""Failed to create replyTo bridge for topic: {}"", replyToProducerTopic, e)
---------------Reference log end----------------
                    return null;
                }
                replyToBridges.put(replyToProducerTopic, bridge);
            }
            return bridge.getConsumerTopic();
        } else {
            OutboundTopicBridge bridge = (OutboundTopicBridge)replyToBridges.get(replyToProducerTopic);
            if (bridge == null) {
                bridge = new OutboundTopicBridge() {
                    @Override
                    protected Destination processReplyToDestination(Destination destination) {
                        return null;
                    }
                };
                try {
                    TopicSession replyToConsumerSession = ((TopicConnection)replyToConsumerConnection)
                        .createTopicSession(false, Session.AUTO_ACKNOWLEDGE);
                    Topic replyToConsumerTopic = replyToConsumerSession.createTemporaryTopic();
                    replyToConsumerSession.close();
                    bridge.setConsumerTopic(replyToConsumerTopic);
                    bridge.setProducerTopic(replyToProducerTopic);
                    bridge.setProducerConnection((TopicConnection)replyToProducerConnection);
                    bridge.setConsumerConnection((TopicConnection)replyToConsumerConnection);
                    bridge.setDoHandleReplyTo(false);
                    if (bridge.getJmsMessageConvertor() == null) {
                        bridge.setJmsMessageConvertor(getOutboundMessageConvertor());
                    }
                    bridge.setJmsConnector(this);
                    bridge.start();
                    LOG.info(""Created replyTo bridge for {}"", replyToProducerTopic);
                } catch (Exception e) {
                    LOG.error(""Failed to create replyTo bridge for topic: {}"", replyToProducerTopic, e);
                    return null;
                }
                replyToBridges.put(replyToProducerTopic, bridge);
            }
            return bridge.getConsumerTopic();
        }
    }",,
activemq,18991,"LOG.debug(""{} detail: {}"", message, cause, cause)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/advisory/AdvisoryBroker.java/#L830,"private void handleFireFailure(String message, Throwable cause) {
        LOG.warn(""Failed to fire {} advisory, reason: {}"", message, cause);
        
---------------Reference log start----------------
LOG.debug(""{} detail: {}"", message, cause, cause)
---------------Reference log end----------------
    }
    }",,
activemq,19603,"log.error(""Object "" + object + "" is not a reference - cannot load"")",error,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/jndi/JNDIReferenceFactory.java/#L77,"public Object getObjectInstance(Object object, Name name, Context nameCtx, Hashtable environment) throws Exception {
        Object result = null;
        if (object instanceof Reference) {
            Reference reference = (Reference)object;

            if (log.isTraceEnabled()) {
                log.trace(""Getting instance of "" + reference.getClassName());
            }

            Class theClass = loadClass(this, reference.getClassName());
            if (JNDIStorableInterface.class.isAssignableFrom(theClass)) {

                JNDIStorableInterface store = JNDIStorableInterface.class.cast(theClass.getConstructor().newInstance());
                Properties properties = new Properties();
                for (Enumeration iter = reference.getAll(); iter.hasMoreElements();) {

                    StringRefAddr addr = (StringRefAddr)iter.nextElement();
                    properties.put(addr.getType(), (addr.getContent() == null) ? """" : addr.getContent());

                }
                store.setProperties(properties);
                result = store;
            }
        } else {
            
---------------Reference log start----------------
log.error(""Object "" + object + "" is not a reference - cannot load"")
---------------Reference log end----------------
            throw new RuntimeException(""Object "" + object + "" is not a reference"");
        }
        return result;
    }",,
activemq,18444,"LOG.info(""Using Jetty configured connector"")",info,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/WebTransportServerSupport.java/#L92,"public URI bind() throws Exception {
        URI bind = getBindLocation();
        String bindHost = bind.getHost();
        bindHost = (bindHost == null || bindHost.length() == 0) ? ""localhost"" : bindHost;
        InetAddress addr = InetAddress.getByName(bindHost);
        host = addr.getCanonicalHostName();
        if (server.getConnectors().length == 0) {
            LOG.info(""Creating Jetty connector"");
            setConnectorProperty(""Host"", String.class, host);
            setConnectorProperty(""Port"", Integer.TYPE, bindAddress.getPort());
            server.addConnector(connector);
        } else {
            
---------------Reference log start----------------
LOG.info(""Using Jetty configured connector"")
---------------Reference log end----------------
            connector = server.getConnectors()[0];
            for (Connector c : server.getConnectors()) {
                if (c.getName() != null && c.getName().equalsIgnoreCase(""activemq"")) {
                    connector = c;
                }
            }
            setConnectorProperty(""Host"", String.class, host);
            setConnectorProperty(""Port"", Integer.TYPE, bindAddress.getPort());
            server.addConnector(connector);
        }
        if (addr.isAnyLocalAddress()) {
            host = InetAddressUtil.getLocalHostName();
        }
        URI boundUri = new URI(bind.getScheme(), bind.getUserInfo(), host, bindAddress.getPort(), bind.getPath(), bind.getQuery(), bind.getFragment());
        setConnectURI(boundUri);
        return boundUri;
    }",,
activemq,18733,"LOG.info(""preProcessDispatch: {}"", messageDispatch)",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/LoggingBrokerPlugin.java/#L430,"@Override
    public void preProcessDispatch(MessageDispatch messageDispatch) {
        if (isLogAll() || isLogInternalEvents() || isLogConsumerEvents()) {
            
---------------Reference log start----------------
LOG.info(""preProcessDispatch: {}"", messageDispatch)
---------------Reference log end----------------
        }
        super.preProcessDispatch(messageDispatch);
    }",,
activemq,18668,"LOG.debug(""Caught exception, must be shutting down. This exception is ignored."", e)",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L2531,"protected void removeShutdownHook() {
        if (shutdownHook != null) {
            try {
                Runtime.getRuntime().removeShutdownHook(shutdownHook);
            } catch (Exception e) {
                
---------------Reference log start----------------
LOG.debug(""Caught exception, must be shutting down. This exception is ignored."", e)
---------------Reference log end----------------
            }
        }
    }",,
activemq,19525,"LOG.debug(""transport interrupted - processing required, dispatchers: "" + transportInterruptionProcessingComplete.get())",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/ActiveMQConnection.java/#L2016,"@Override
    public void transportInterupted() {
        transportInterruptionProcessingComplete.set(1);
        for (Iterator<ActiveMQSession> i = this.sessions.iterator(); i.hasNext();) {
            ActiveMQSession s = i.next();
            s.clearMessagesInProgress(transportInterruptionProcessingComplete);
        }

        for (ActiveMQConnectionConsumer connectionConsumer : this.connectionConsumers) {
            connectionConsumer.clearMessagesInProgress(transportInterruptionProcessingComplete);
        }

        if (transportInterruptionProcessingComplete.decrementAndGet() > 0) {
            if (LOG.isDebugEnabled()) {
                
---------------Reference log start----------------
LOG.debug(""transport interrupted - processing required, dispatchers: "" + transportInterruptionProcessingComplete.get())
---------------Reference log end----------------
            }
            signalInterruptionProcessingNeeded();
        }

        for (Iterator<TransportListener> iter = transportListeners.iterator(); iter.hasNext();) {
            TransportListener listener = iter.next();
            listener.transportInterupted();
        }
    }",,
activemq,18225,"LOG.debug(""Sending more credit ({}) to transaction coordinator on session {}"", getConfiguredReceiverCredit() - getEndpoint().getCredit(), session.getSessionId())",debug,https://github.com/apache/activemq/blob/main/activemq-amqp/src/main/java/org/apache/activemq/transport/amqp/protocol/AmqpTransactionCoordinator.java/#L163,"private void replenishCredit() {
        if (getEndpoint().getCredit() <= (getConfiguredReceiverCredit() * .2)) {
            
---------------Reference log start----------------
LOG.debug(""Sending more credit ({}) to transaction coordinator on session {}"", getConfiguredReceiverCredit() - getEndpoint().getCredit(), session.getSessionId())
---------------Reference log end----------------
            getEndpoint().flow(getConfiguredReceiverCredit() - getEndpoint().getCredit());
            session.pumpProtonToSocket();
        }
    }",,
activemq,18329,"LOG.debug(""Continuation "" + cont.toString() + "" completed."")",debug,https://github.com/apache/activemq/blob/main/activemq-web/src/main/java/org/apache/activemq/web/MessageListenerServlet.java/#L329,"@Override
                    public void onComplete(Continuation cont) {
                        if (LOG.isDebugEnabled()) {
                           
---------------Reference log start----------------
LOG.debug(""Continuation "" + cont.toString() + "" completed."")
---------------Reference log end----------------
                        }
                    }",,
activemq,18383,"LOG.debug(""abort"")",debug,https://github.com/apache/activemq/blob/main/activemq-jaas/src/main/java/org/apache/activemq/jaas/GuestLoginModule.java/#L126,"@Override
    public boolean abort() throws LoginException {

        if (debug) {
            
---------------Reference log start----------------
LOG.debug(""abort"")
---------------Reference log end----------------
        }
        if (!succeeded) {
            return false;
        } else if (succeeded && commitSucceeded) {
            // we succeeded, but another required module failed
            logout();
        } else {
            // our commit failed
            succeeded = false;
        }
        return true;
    }",,
activemq,18521,"LOG.trace(""Exception caught stopping. This exception is ignored."", ignore)",trace,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/TransportConnection.java/#L1192,"protected void doStop() throws Exception {
        LOG.debug(""Stopping connection: {}"", transport.getRemoteAddress());
        connector.onStopped(this);
        try {
            synchronized (this) {
                if (duplexBridge != null) {
                    duplexBridge.stop();
                }
            }
        } catch (Exception ignore) {
            
---------------Reference log start----------------
LOG.trace(""Exception caught stopping. This exception is ignored."", ignore)
---------------Reference log end----------------
        }
        try {
            transport.stop();
            LOG.debug(""Stopped transport: {}"", transport.getRemoteAddress());
        } catch (Exception e) {
            LOG.debug(""Could not stop transport to {}. This exception is ignored."", transport.getRemoteAddress(), e);
        }
        if (taskRunner != null) {
            taskRunner.shutdown(1);
            taskRunner = null;
        }
        active = false;
        // Run the MessageDispatch callbacks so that message references get
        // cleaned up.
        synchronized (dispatchQueue) {
            for (Iterator<Command> iter = dispatchQueue.iterator(); iter.hasNext(); ) {
                Command command = iter.next();
                if (command.isMessageDispatch()) {
                    MessageDispatch md = (MessageDispatch) command;
                    TransmitCallback sub = md.getTransmitCallback();
                    broker.postProcessDispatch(md);
                    if (sub != null) {
                        sub.onFailure();
                    }
                }
            }
            dispatchQueue.clear();
        }
        //
        // Remove all logical connection associated with this connection
        // from the broker.
        if (!broker.isStopped()) {
            List<TransportConnectionState> connectionStates = listConnectionStates();
            connectionStates = listConnectionStates();
            for (TransportConnectionState cs : connectionStates) {
                cs.getContext().getStopping().set(true);
                try {
                    LOG.debug(""Cleaning up connection resources: {}"", getRemoteAddress());
                    processRemoveConnection(cs.getInfo().getConnectionId(), RemoveInfo.LAST_DELIVERED_UNKNOWN);
                } catch (Throwable ignore) {
                    LOG.debug(""Exception caught removing connection {}. This exception is ignored."", cs.getInfo().getConnectionId(), ignore);
                }
            }
        }
        LOG.debug(""Connection Stopped: {}"", getRemoteAddress());
    }",,
activemq,19093,"LOG.info(""Unexpected local exception: {}"", error.getMessage())",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/network/ForwardingBridge.java/#L214,"public void serviceLocalException(Throwable error) {
        
---------------Reference log start----------------
LOG.info(""Unexpected local exception: {}"", error.getMessage())
---------------Reference log end----------------
        LOG.debug(""Exception trace: "", error);
        fireBridgeFailed();
    }",,
activemq,18661,"LOG.error(""Failed to check temporary store usage limits"", e)",error,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/BrokerService.java/#L2141,"protected void scheduleDiskUsageLimitsCheck() throws IOException {
        if (schedulePeriodForDiskUsageCheck > 0 &&
                (getPersistenceAdapter() != null || getTmpDataDirectory() != null)) {
            Runnable diskLimitCheckTask = () -> {
                try {
                    checkStoreUsageLimits();
                } catch (Throwable e) {
                    LOG.error(""Failed to check persistent disk usage limits"", e);
                }

                try {
                    checkTmpStoreUsageLimits();
                } catch (Throwable e) {
                    
---------------Reference log start----------------
LOG.error(""Failed to check temporary store usage limits"", e)
---------------Reference log end----------------
                }
            };
            scheduler.executePeriodically(diskLimitCheckTask, schedulePeriodForDiskUsageCheck);
        }
    }",,
activemq,19795,"LOG.warn(""Attempted to set the Traffic Class to "" + this.trafficClass + "" but the result Traffic Class was "" + resultTrafficClass + "". Please check that your system "" + ""allows you to set the ECN bits (the first two bits)."")",warn,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/tcp/TcpTransport.java/#L734,"private boolean setTrafficClass(Socket sock) throws SocketException,
            IllegalArgumentException {
        if (sock == null
            || (!this.diffServChosen && !this.typeOfServiceChosen)) {
            return false;
        }
        if (this.diffServChosen && this.typeOfServiceChosen) {
            throw new IllegalArgumentException(""Cannot set both the ""
                + "" Differentiated Services and Type of Services transport ""
                + "" options on the same connection."");
        }

        sock.setTrafficClass(this.trafficClass);

        int resultTrafficClass = sock.getTrafficClass();
        if (this.trafficClass != resultTrafficClass) {
            // In the case where the user has specified the ECN bits (e.g. in
            // Type of Service) but the system won't allow the ECN bits to be
            // set or in the case where setting the traffic class failed for
            // other reasons, emit a warning.
            if ((this.trafficClass >> 2) == (resultTrafficClass >> 2)
                    && (this.trafficClass & 3) != (resultTrafficClass & 3)) {
                
---------------Reference log start----------------
LOG.warn(""Attempted to set the Traffic Class to "" + this.trafficClass + "" but the result Traffic Class was "" + resultTrafficClass + "". Please check that your system "" + ""allows you to set the ECN bits (the first two bits)."")
---------------Reference log end----------------
            } else {
                LOG.warn(""Attempted to set the Traffic Class to ""
                    + this.trafficClass + "" but the result Traffic Class was ""
                    + resultTrafficClass + "". Please check that your system ""
                         + ""supports java.net.setTrafficClass."");
            }
            return false;
        }
        // Reset the guards that prevent both the Differentiated Services
        // option and the Type of Service option from being set on the same
        // connection.
        this.diffServChosen = false;
        this.typeOfServiceChosen = false;
        return true;
    }",,
activemq,18420,"LOG.debug(""Failed to close STOMP WebSocket cleanly"", e)",debug,https://github.com/apache/activemq/blob/main/activemq-http/src/main/java/org/apache/activemq/transport/ws/jetty9/StompSocket.java/#L77,"@Override
    public void onWebSocketClose(int arg0, String arg1) {
        try {
            if (protocolLock.tryLock() || protocolLock.tryLock(ORDERLY_CLOSE_TIMEOUT, TimeUnit.SECONDS)) {
                LOG.debug(""Stomp WebSocket closed: code[{}] message[{}]"", arg0, arg1);
                protocolConverter.onStompCommand(new StompFrame(Stomp.Commands.DISCONNECT));
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
LOG.debug(""Failed to close STOMP WebSocket cleanly"", e)
---------------Reference log end----------------
        } finally {
            if (protocolLock.isHeldByCurrentThread()) {
                protocolLock.unlock();
            }
        }
    }",,
activemq,18721,"LOG.info(""Adding destination: {}:{}"", destination.getDestinationTypeAsString(), destination.getPhysicalName())",info,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/broker/util/LoggingBrokerPlugin.java/#L329,"@Override
    public org.apache.activemq.broker.region.Destination addDestination(ConnectionContext context,
            ActiveMQDestination destination, boolean create) throws Exception {
        if (isLogAll() || isLogInternalEvents()) {
            
---------------Reference log start----------------
LOG.info(""Adding destination: {}:{}"", destination.getDestinationTypeAsString(), destination.getPhysicalName())
---------------Reference log end----------------
        }
        return super.addDestination(context, destination, create);
    }",,
activemq,19378,"log.debug(this + "", setting [password] property"")",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ActiveMQConnectionSupport.java/#L174,"public void setPassword(String password) {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(this + "", setting [password] property"")
---------------Reference log end----------------
        }
        info.setPassword(password);
    }",,
activemq,19375,"LOG.debug(""reconnect XAResource with: "" + this.getInfo(), existingConnection == null ? """" : existingConnection.getFirstFailureError())",debug,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/ActiveMQResourceAdapter.java/#L289,"private void ensureConnection(TransactionContext xaRecoveryTransactionContext) throws XAException {
        final ActiveMQConnection existingConnection  = xaRecoveryTransactionContext.getConnection();
        if (existingConnection == null || existingConnection.isTransportFailed()) {
            try {
                
---------------Reference log start----------------
LOG.debug(""reconnect XAResource with: "" + this.getInfo(), existingConnection == null ? """" : existingConnection.getFirstFailureError())
---------------Reference log end----------------
                xaRecoveryTransactionContext.setConnection(makeConnection());
            } catch (JMSException e) {
                throw toXAException(e);
            } finally {
                if (existingConnection != null) {
                    try {
                        existingConnection.close();
                    } catch (Exception ignored) {
                    }
                }
            }
        }
    }",,
activemq,19586,"LOG.trace(""Attempting to load class: {} using classloader: {}"", className, cl)",trace,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/util/ClassLoadingAwareObjectInputStream.java/#L130,"private Class<?> load(String className, ClassLoader... cl) throws ClassNotFoundException {
        // check for simple types first
        final Class<?> clazz = loadSimpleType(className);
        if (clazz != null) {
            LOG.trace(""Loaded class: {} as simple type -> {}"", className, clazz);
            return clazz;
        }

        // try the different class loaders
        for (ClassLoader loader : cl) {
            
---------------Reference log start----------------
LOG.trace(""Attempting to load class: {} using classloader: {}"", className, cl)
---------------Reference log end----------------
            try {
                Class<?> answer = Class.forName(className, false, loader);
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""Loaded class: {} using classloader: {} -> {}"", className, cl, answer);
                }
                return answer;
            } catch (ClassNotFoundException e) {
                LOG.trace(""Class not found: {} using classloader: {}"", className, cl);
                // ignore
            }
        }

        // and then the fallback class loader
        return Class.forName(className, false, FALLBACK_CLASS_LOADER);
    }",,
activemq,18186,"log.warn(""JMSException encounter closing InternalClient connection - ignoring"", jmsEx)",warn,https://github.com/apache/activemq/blob/main/activemq-tooling/activemq-junit/src/main/java/org/apache/activemq/junit/EmbeddedActiveMQBroker.java/#L724,"void stop() {
            if (null != connection) {
                try {
                    connection.close();
                } catch (JMSException jmsEx) {
                    
---------------Reference log start----------------
log.warn(""JMSException encounter closing InternalClient connection - ignoring"", jmsEx)
---------------Reference log end----------------
                }
            }
        }",,
activemq,17767,"LOG.trace(this + "", completion for: "" + getSubscriptionKey(clientId, subscriptionName))",trace,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/JDBCTopicMessageStore.java/#L332,"public void complete(String clientId, String subscriptionName) {
        pendingCompletion.remove(getSubscriptionKey(clientId, subscriptionName));
        
---------------Reference log start----------------
LOG.trace(this + "", completion for: "" + getSubscriptionKey(clientId, subscriptionName))
---------------Reference log end----------------
    }
    }",,
activemq,19641,"LOG.debug(""Waiting "" + reconnectDelay + "" ms before attempting connection. "")",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/fanout/FanoutTransport.java/#L271,"private boolean doConnect() {
        long closestReconnectDate = 0;
        synchronized (reconnectMutex) {

            if (disposed || connectionFailure != null) {
                reconnectMutex.notifyAll();
            }

            if (transports.size() == connectedCount || disposed || connectionFailure != null) {
                return false;
            } else {

                if (transports.isEmpty()) {
                    // connectionFailure = new IOException(""No uris available to
                    // connect to."");
                } else {

                    // Try to connect them up.
                    Iterator<FanoutTransportHandler> iter = transports.iterator();
                    while (iter.hasNext() && !disposed) {

                        long now = System.currentTimeMillis();

                        FanoutTransportHandler fanoutHandler = iter.next();
                        if (fanoutHandler.transport != null) {
                            continue;
                        }

                        // Are we waiting a little to try to reconnect this one?
                        if (fanoutHandler.reconnectDate != 0 && fanoutHandler.reconnectDate > now) {
                            if (closestReconnectDate == 0 || fanoutHandler.reconnectDate < closestReconnectDate) {
                                closestReconnectDate = fanoutHandler.reconnectDate;
                            }
                            continue;
                        }

                        URI uri = fanoutHandler.uri;
                        try {
                            LOG.debug(""Stopped: "" + this);
                            LOG.debug(""Attempting connect to: "" + uri);
                            Transport t = TransportFactory.compositeConnect(uri);
                            fanoutHandler.transport = t;
                            t.setTransportListener(fanoutHandler);
                            if (started) {
                                restoreTransport(fanoutHandler);
                            }
                            LOG.debug(""Connection established"");
                            fanoutHandler.reconnectDelay = initialReconnectDelay;
                            fanoutHandler.connectFailures = 0;
                            if (primary == null) {
                                primary = fanoutHandler;
                            }
                            connectedCount++;
                        } catch (Exception e) {
                            LOG.debug(""Connect fail to: "" + uri + "", reason: "" + e);

                            if (fanoutHandler.transport != null) {
                                ServiceSupport.dispose(fanoutHandler.transport);
                                fanoutHandler.transport = null;
                            }

                            if (maxReconnectAttempts > 0 && ++fanoutHandler.connectFailures >= maxReconnectAttempts) {
                                LOG.error(""Failed to connect to transport after: "" + fanoutHandler.connectFailures + "" attempt(s)"");
                                connectionFailure = e;
                                reconnectMutex.notifyAll();
                                return false;
                            } else {

                                if (useExponentialBackOff) {
                                    // Exponential increment of reconnect delay.
                                    fanoutHandler.reconnectDelay *= backOffMultiplier;
                                    if (fanoutHandler.reconnectDelay > maxReconnectDelay) {
                                        fanoutHandler.reconnectDelay = maxReconnectDelay;
                                    }
                                }

                                fanoutHandler.reconnectDate = now + fanoutHandler.reconnectDelay;

                                if (closestReconnectDate == 0 || fanoutHandler.reconnectDate < closestReconnectDate) {
                                    closestReconnectDate = fanoutHandler.reconnectDate;
                                }
                            }
                        }
                    }

                    if (transports.size() == connectedCount || disposed) {
                        reconnectMutex.notifyAll();
                        return false;
                    }
                }
            }
        }

        try {
            long reconnectDelay = closestReconnectDate - System.currentTimeMillis();
            if (reconnectDelay > 0) {
                
---------------Reference log start----------------
LOG.debug(""Waiting "" + reconnectDelay + "" ms before attempting connection. "")
---------------Reference log end----------------
                Thread.sleep(reconnectDelay);
            }
        } catch (InterruptedException e1) {
            Thread.currentThread().interrupt();
        }
        return true;
    }",,
activemq,17848,"LOG.trace(""Setting auto commit to {} on connection {}"", autoCommit, connection)",trace,https://github.com/apache/activemq/blob/main/activemq-jdbc-store/src/main/java/org/apache/activemq/store/jdbc/TransactionContext.java/#L82,"private Connection lockAndWrapped(Lock toLock) throws IOException {
        if (connection == null) {
            toLock.lock();
            try {
                connection = dataSource.getConnection();
                if (networkTimeout > 0) {
                    connection.setNetworkTimeout(Executors.newSingleThreadExecutor(), networkTimeout);
                }
                if (persistenceAdapter.isChangeAutoCommitAllowed()) {
                    boolean autoCommit = !inTx;
                    if (connection.getAutoCommit() != autoCommit) {
                        
---------------Reference log start----------------
LOG.trace(""Setting auto commit to {} on connection {}"", autoCommit, connection)
---------------Reference log end----------------
                        connection.setAutoCommit(autoCommit);
                    }
                }
                connection = new UnlockOnCloseConnection(connection, toLock);
            } catch (SQLException e) {
                JDBCPersistenceAdapter.log(""Could not get JDBC connection: "", e);
                inTx = false;
                try {
                    toLock.unlock();
                } catch (IllegalMonitorStateException oops) {
                    LOG.error(""Thread does not hold the context lock on close of:""  + connection, oops);
                }
                silentClose();
                IOException ioe = IOExceptionSupport.create(e);
                if (persistenceAdapter.getBrokerService() != null) {
                    persistenceAdapter.getBrokerService().handleIOException(ioe);
                }
                throw ioe;
            }

            try {
                connection.setTransactionIsolation(transactionIsolation);
            } catch (Throwable e) {
                // ignore
                LOG.trace(""Cannot set transaction isolation to "" + transactionIsolation + "" due "" + e.getMessage()
                        + "". This exception is ignored."", e);
            }
        }
        return connection;
    }",,
activemq,19080,"log.debug(""$$ SENDING: "" + CustomLogWriter.commandToString(command))",debug,https://github.com/apache/activemq/blob/main/activemq-broker/src/main/java/org/apache/activemq/transport/logwriters/CustomLogWriter.java/#L67,"public void logOneWay (Logger log, Object command) {
        
---------------Reference log start----------------
log.debug(""$$ SENDING: "" + CustomLogWriter.commandToString(command))
---------------Reference log end----------------
    }
    }",,
activemq,19696,"LOG.debug(""Running {}"", this)",debug,https://github.com/apache/activemq/blob/main/activemq-client/src/main/java/org/apache/activemq/transport/AbstractInactivityMonitor.java/#L195,"@Override
                    public void run() {
                        
---------------Reference log start----------------
LOG.debug(""Running {}"", this)
---------------Reference log end----------------
                        if (monitorStarted.get()) {
                            try {
                                // If we can't get the lock it means another
                                // write beat us into the
                                // send and we don't need to heart beat now.
                                if (sendLock.writeLock().tryLock()) {
                                    KeepAliveInfo info = new KeepAliveInfo();
                                    info.setResponseRequired(keepAliveResponseRequired);
                                    doOnewaySend(info);
                                }
                            } catch (IOException e) {
                                onException(e);
                            } finally {
                                if (sendLock.writeLock().isHeldByCurrentThread()) {
                                    sendLock.writeLock().unlock();
                                }
                            }
                        }
                    }",,
activemq,19427,"LOG.trace(""Invoking MessageEndpoint.release()"")",trace,https://github.com/apache/activemq/blob/main/activemq-ra/src/main/java/org/apache/activemq/ra/MessageEndpointProxy.java/#L73,"public void release() {
        
---------------Reference log start----------------
LOG.trace(""Invoking MessageEndpoint.release()"")
---------------Reference log end----------------
        state.release(this);
    }",,
tomcat,15706,"log.warn(sm.getString(""staticMembershipProvider.pingThread.failed""), x)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/membership/StaticMembershipProvider.java/#L409,"@Override
        public void run() {
            while (running) {
                try {
                    sleep(pingInterval);
                    ping();
                }catch (InterruptedException ix) {
                }catch (Exception x) {
                    
---------------Reference log start----------------
log.warn(sm.getString(""staticMembershipProvider.pingThread.failed""), x)
---------------Reference log end----------------
                }
            }
        }",,
tomcat,15385,"log.warn(sm.getString(""webappClassLoader.addPermissionNoProtocol"", protocol, url.toExternalForm()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/loader/WebappClassLoaderBase.java/#L525,"void addPermission(URL url) {
        if (url == null) {
            return;
        }
        if (securityManager != null) {
            String protocol = url.getProtocol();
            if (""file"".equalsIgnoreCase(protocol)) {
                URI uri;
                File f;
                String path;
                try {
                    uri = url.toURI();
                    f = new File(uri);
                    path = f.getCanonicalPath();
                } catch (IOException | URISyntaxException e) {
                    log.warn(sm.getString(
                            ""webappClassLoader.addPermissionNoCanonicalFile"",
                            url.toExternalForm()));
                    return;
                }
                if (f.isFile()) {
                    // Allow the file to be read
                    addPermission(new FilePermission(path, ""read""));
                } else if (f.isDirectory()) {
                    addPermission(new FilePermission(path, ""read""));
                    addPermission(new FilePermission(
                            path + File.separator + ""-"", ""read""));
                } else {
                    // File does not exist - ignore (shouldn't happen)
                }
            } else {
                // Unsupported URL protocol
                
---------------Reference log start----------------
log.warn(sm.getString(""webappClassLoader.addPermissionNoProtocol"", protocol, url.toExternalForm()))
---------------Reference log end----------------
            }
        }
    }",,
tomcat,15552,"containerLog.error(sm.getString(""jndiRealm.exception""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JNDIRealm.java/#L1274,"@Override
    public Principal authenticate(String username, String credentials) {

        JNDIConnection connection = null;
        Principal principal = null;

        try {

            // Ensure that we have a directory context available
            connection = get();

            try {

                // Occasionally the directory context will timeout.  Try one more
                // time before giving up.

                // Authenticate the specified username if possible
                principal = authenticate(connection, username, credentials);

            } catch (NullPointerException | NamingException e) {
                /*
                 * BZ 61313
                 * NamingException may or may not indicate an error that is
                 * recoverable via fail over. Therefore a decision needs to be
                 * made whether to fail over or not. Generally, attempting to
                 * fail over when it is not appropriate is better than not
                 * failing over when it is appropriate so the code always
                 * attempts to fail over for NamingExceptions.
                 */

                /*
                 * BZ 42449
                 * Catch NPE - Kludge Sun's LDAP provider with broken SSL.
                 */

                // log the exception so we know it's there.
                containerLog.info(sm.getString(""jndiRealm.exception.retry""), e);

                // close the connection so we know it will be reopened.
                close(connection);
                closePooledConnections();

                // open a new directory context.
                connection = get();

                // Try the authentication again.
                principal = authenticate(connection, username, credentials);
            }


            // Release this context
            release(connection);

            // Return the authenticated Principal (if any)
            return principal;

        } catch (NamingException e) {

            // Log the problem for posterity
            
---------------Reference log start----------------
containerLog.error(sm.getString(""jndiRealm.exception""), e)
---------------Reference log end----------------

            // close the connection so we know it will be reopened.
            close(connection);
            closePooledConnections();

            // Return ""not authenticated"" for this request
            if (containerLog.isDebugEnabled()) {
                containerLog.debug(""Returning null principal."");
            }
            return null;
        }
    }",,
tomcat,17629,"log.error(""Jmx registration failed."", e)",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/jmx/JmxUtil.java/#L39,"public static ObjectName registerJmx(ObjectName base, String keyprop, Object obj) {
        ObjectName oname = null;
        try {
            oname = getObjectName(base, keyprop);
            if (oname != null) {
              ManagementFactory.getPlatformMBeanServer().registerMBean(obj, oname);
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(""Jmx registration failed."", e)
---------------Reference log end----------------
        }
        return oname;
    }",,
tomcat,16982,"log.debug(""Before fill(): parsingHeader: ["" + parsingHeader + ""], parsingRequestLine: ["" + parsingRequestLine + ""], parsingRequestLinePhase: ["" + parsingRequestLinePhase + ""], parsingRequestLineStart: ["" + parsingRequestLineStart + ""], byteBuffer.position(): ["" + byteBuffer.position() + ""], byteBuffer.limit(): ["" + byteBuffer.limit() + ""], end: ["" + end + ""]"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http11/Http11InputBuffer.java/#L775,"private boolean fill(boolean block) throws IOException {

        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Before fill(): parsingHeader: ["" + parsingHeader + ""], parsingRequestLine: ["" + parsingRequestLine + ""], parsingRequestLinePhase: ["" + parsingRequestLinePhase + ""], parsingRequestLineStart: ["" + parsingRequestLineStart + ""], byteBuffer.position(): ["" + byteBuffer.position() + ""], byteBuffer.limit(): ["" + byteBuffer.limit() + ""], end: ["" + end + ""]"")
---------------Reference log end----------------
        }

        if (parsingHeader) {
            if (byteBuffer.limit() >= headerBufferSize) {
                if (parsingRequestLine) {
                    // Avoid unknown protocol triggering an additional error
                    request.protocol().setString(Constants.HTTP_11);
                }
                throw new IllegalArgumentException(sm.getString(""iib.requestheadertoolarge.error""));
            }
        } else {
            byteBuffer.limit(end).position(end);
        }

        int nRead = -1;
        byteBuffer.mark();
        try {
            if (byteBuffer.position() < byteBuffer.limit()) {
                byteBuffer.position(byteBuffer.limit());
            }
            byteBuffer.limit(byteBuffer.capacity());
            SocketWrapperBase<?> socketWrapper = this.wrapper;
            if (socketWrapper != null) {
                nRead = socketWrapper.read(block, byteBuffer);
            } else {
                throw new CloseNowException(sm.getString(""iib.eof.error""));
            }
        } finally {
            // Ensure that the buffer limit and position are returned to a
            // consistent ""ready for read"" state if an error occurs during in
            // the above code block.
            byteBuffer.limit(byteBuffer.position()).reset();
        }

        if (log.isDebugEnabled()) {
            log.debug(""Received [""
                    + new String(byteBuffer.array(), byteBuffer.position(), byteBuffer.remaining(), StandardCharsets.ISO_8859_1) + ""]"");
        }

        if (nRead > 0) {
            return true;
        } else if (nRead == -1) {
            throw new EOFException(sm.getString(""iib.eof.error""));
        } else {
            return false;
        }

    }",,
tomcat,15712,"log.info(sm.getString(""mcastServiceImpl.setTTL"", Integer.toString(mcastTTL)))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/membership/McastServiceImpl.java/#L239,"protected void setupSocket() throws IOException {
        if (mcastBindAddress != null) {
            try {
                log.info(sm.getString(""mcastServiceImpl.bind"", address, Integer.toString(port)));
                socket = new MulticastSocket(new InetSocketAddress(address,port));
            } catch (BindException e) {
                /*
                 * On some platforms (e.g. Linux) it is not possible to bind
                 * to the multicast address. In this case only bind to the
                 * port.
                 */
                log.info(sm.getString(""mcastServiceImpl.bind.failed""));
                socket = new MulticastSocket(port);
            }
        } else {
            socket = new MulticastSocket(port);
        }
        socket.setLoopbackMode(localLoopbackDisabled); //hint if we want disable loop back(local machine) messages
        if (mcastBindAddress != null) {
            if(log.isInfoEnabled()) {
                log.info(sm.getString(""mcastServiceImpl.setInterface"", mcastBindAddress));
            }
            socket.setInterface(mcastBindAddress);
        } //end if
        //force a so timeout so that we don't block forever
        if (mcastSoTimeout <= 0) {
            mcastSoTimeout = (int)sendFrequency;
        }
        if (log.isInfoEnabled()) {
            log.info(sm.getString(""mcastServiceImpl.setSoTimeout"",
                    Integer.toString(mcastSoTimeout)));
        }
        socket.setSoTimeout(mcastSoTimeout);

        if ( mcastTTL >= 0 ) {
            if(log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""mcastServiceImpl.setTTL"", Integer.toString(mcastTTL)))
---------------Reference log end----------------
            }
            socket.setTimeToLive(mcastTTL);
        }
    }",,
tomcat,15709,"log.info(sm.getString(""mcastServiceImpl.bind"", address, Integer.toString(port)))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/membership/McastServiceImpl.java/#L206,"protected void setupSocket() throws IOException {
        if (mcastBindAddress != null) {
            try {
                
---------------Reference log start----------------
log.info(sm.getString(""mcastServiceImpl.bind"", address, Integer.toString(port)))
---------------Reference log end----------------
                socket = new MulticastSocket(new InetSocketAddress(address,port));
            } catch (BindException e) {
                /*
                 * On some platforms (e.g. Linux) it is not possible to bind
                 * to the multicast address. In this case only bind to the
                 * port.
                 */
                log.info(sm.getString(""mcastServiceImpl.bind.failed""));
                socket = new MulticastSocket(port);
            }
        } else {
            socket = new MulticastSocket(port);
        }
        socket.setLoopbackMode(localLoopbackDisabled); //hint if we want disable loop back(local machine) messages
        if (mcastBindAddress != null) {
            if(log.isInfoEnabled()) {
                log.info(sm.getString(""mcastServiceImpl.setInterface"", mcastBindAddress));
            }
            socket.setInterface(mcastBindAddress);
        } //end if
        //force a so timeout so that we don't block forever
        if (mcastSoTimeout <= 0) {
            mcastSoTimeout = (int)sendFrequency;
        }
        if (log.isInfoEnabled()) {
            log.info(sm.getString(""mcastServiceImpl.setSoTimeout"",
                    Integer.toString(mcastSoTimeout)));
        }
        socket.setSoTimeout(mcastSoTimeout);

        if ( mcastTTL >= 0 ) {
            if(log.isInfoEnabled()) {
                log.info(sm.getString(""mcastServiceImpl.setTTL"", Integer.toString(mcastTTL)));
            }
            socket.setTimeToLive(mcastTTL);
        }
    }",,
tomcat,15355,"log.error(sm.getString(""remoteCidrValve.noPort""))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/valves/RemoteCIDRValve.java/#L153,"@Override
    public boolean isAllowed(final String property) {

        final int portIdx = property.indexOf(';');
        final int port;
        final String nonPortPart;

        if (portIdx == -1) {
            if (getAddConnectorPort()) {
                
---------------Reference log start----------------
log.error(sm.getString(""remoteCidrValve.noPort""))
---------------Reference log end----------------
                return false;
            }
            port = -1;
            nonPortPart = property;
        } else {
            if (!getAddConnectorPort()) {
                log.error(sm.getString(""remoteCidrValve.unexpectedPort""));
                return false;
            }
            nonPortPart = property.substring(0, portIdx);
            try {
                port = Integer.parseInt(property.substring(portIdx + 1));
            } catch (NumberFormatException e) {
                // This should be in the 'could never happen' category but handle it
                // to be safe.
                log.error(sm.getString(""remoteCidrValve.noPort""), e);
                return false;
            }
        }

        final InetAddress addr;
        try {
            addr = InetAddress.getByName(nonPortPart);
        } catch (UnknownHostException e) {
            // This should be in the 'could never happen' category but handle it
            // to be safe.
            log.error(sm.getString(""remoteCidrValve.noRemoteIp""), e);
            return false;
        }

        for (final NetMask nm : deny) {
            if (getAddConnectorPort()) {
                if (nm.matches(addr, port)) {
                    return false;
                }
            } else {
                if (nm.matches(addr)) {
                    return false;
                }
            }
        }

        for (final NetMask nm : allow) {
            if (getAddConnectorPort()) {
                if (nm.matches(addr, port)) {
                    return true;
                }
            } else {
                if (nm.matches(addr)) {
                    return true;
                }
            }
        }

        // Allow if deny is specified but allow isn't
        if (!deny.isEmpty() && allow.isEmpty()) {
            return true;
        }

        // Deny this request
        return false;
    }",,
tomcat,16580,"log.error(sm.getString(""naming.bindFailed"", e))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/NamingContextListener.java/#L601,"private void createNamingContext()
        throws NamingException {

        // Creating the comp subcontext
        if (container instanceof Server) {
            compCtx = namingContext;
            envCtx = namingContext;
        } else {
            compCtx = namingContext.createSubcontext(""comp"");
            envCtx = compCtx.createSubcontext(""env"");
        }

        int i;

        if (log.isDebugEnabled()) {
            log.debug(""Creating JNDI naming context"");
        }

        if (namingResources == null) {
            namingResources = new NamingResourcesImpl();
            namingResources.setContainer(container);
        }

        // Resource links
        ContextResourceLink[] resourceLinks =
            namingResources.findResourceLinks();
        for (i = 0; i < resourceLinks.length; i++) {
            addResourceLink(resourceLinks[i]);
        }

        // Resources
        ContextResource[] resources = namingResources.findResources();
        for (i = 0; i < resources.length; i++) {
            addResource(resources[i]);
        }

        // Resources Env
        ContextResourceEnvRef[] resourceEnvRefs = namingResources.findResourceEnvRefs();
        for (i = 0; i < resourceEnvRefs.length; i++) {
            addResourceEnvRef(resourceEnvRefs[i]);
        }

        // Environment entries
        ContextEnvironment[] contextEnvironments =
            namingResources.findEnvironments();
        for (i = 0; i < contextEnvironments.length; i++) {
            addEnvironment(contextEnvironments[i]);
        }

        // EJB references
        ContextEjb[] ejbs = namingResources.findEjbs();
        for (i = 0; i < ejbs.length; i++) {
            addEjb(ejbs[i]);
        }

        // Message Destination References
        MessageDestinationRef[] mdrs = namingResources.findMessageDestinationRefs();
        for (i = 0; i < mdrs.length; i++) {
            addMessageDestinationRef(mdrs[i]);
        }

        // WebServices references
        ContextService[] services = namingResources.findServices();
        for (i = 0; i < services.length; i++) {
            addService(services[i]);
        }

        // Binding a User Transaction reference
        if (container instanceof Context) {
            try {
                Reference ref = new TransactionRef();
                compCtx.bind(""UserTransaction"", ref);
                ContextTransaction transaction = namingResources.getTransaction();
                if (transaction != null) {
                    Iterator<String> params = transaction.listProperties();
                    while (params.hasNext()) {
                        String paramName = params.next();
                        String paramValue = (String) transaction.getProperty(paramName);
                        StringRefAddr refAddr = new StringRefAddr(paramName, paramValue);
                        ref.add(refAddr);
                    }
                }
            } catch (NameAlreadyBoundException e) {
                // Ignore because UserTransaction was obviously
                // added via ResourceLink
            } catch (NamingException e) {
                log.error(sm.getString(""naming.bindFailed"", e));
            }
        }

        // Binding the resources directory context
        if (container instanceof Context) {
            try {
                compCtx.bind(""Resources"",
                             ((Context) container).getResources());
            } catch (NamingException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""naming.bindFailed"", e))
---------------Reference log end----------------
            }
        }

    }",,
tomcat,15283,"log.warn(sm.getString(""coyoteRequest.uploadCreate"", location.getAbsolutePath(), getMappingData().wrapper.getName()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/connector/Request.java/#L2854,"private void parseParts(boolean explicit) {

        // Return immediately if the parts have already been parsed
        if (parts != null || partsParseException != null) {
            return;
        }

        Context context = getContext();
        MultipartConfigElement mce = getWrapper().getMultipartConfigElement();

        if (mce == null) {
            if(context.getAllowCasualMultipartParsing()) {
                mce = new MultipartConfigElement(null, connector.getMaxPostSize(),
                        connector.getMaxPostSize(), connector.getMaxPostSize());
            } else {
                if (explicit) {
                    partsParseException = new IllegalStateException(
                            sm.getString(""coyoteRequest.noMultipartConfig""));
                    return;
                } else {
                    parts = Collections.emptyList();
                    return;
                }
            }
        }

        Parameters parameters = coyoteRequest.getParameters();
        parameters.setLimit(getConnector().getMaxParameterCount());

        boolean success = false;
        try {
            File location;
            String locationStr = mce.getLocation();
            if (locationStr == null || locationStr.length() == 0) {
                location = ((File) context.getServletContext().getAttribute(
                        ServletContext.TEMPDIR));
            } else {
                // If relative, it is relative to TEMPDIR
                location = new File(locationStr);
                if (!location.isAbsolute()) {
                    location = new File(
                            (File) context.getServletContext().getAttribute(ServletContext.TEMPDIR),
                            locationStr).getAbsoluteFile();
                }
            }

            if (!location.exists() && context.getCreateUploadTargets()) {
                
---------------Reference log start----------------
log.warn(sm.getString(""coyoteRequest.uploadCreate"", location.getAbsolutePath(), getMappingData().wrapper.getName()))
---------------Reference log end----------------
                if (!location.mkdirs()) {
                    log.warn(sm.getString(""coyoteRequest.uploadCreateFail"",
                            location.getAbsolutePath()));
                }
            }

            if (!location.isDirectory()) {
                parameters.setParseFailedReason(FailReason.MULTIPART_CONFIG_INVALID);
                partsParseException = new IOException(
                        sm.getString(""coyoteRequest.uploadLocationInvalid"",
                                location));
                return;
            }


            // Create a new file upload handler
            DiskFileItemFactory factory = new DiskFileItemFactory();
            try {
                factory.setRepository(location.getCanonicalFile());
            } catch (IOException ioe) {
                parameters.setParseFailedReason(FailReason.IO_ERROR);
                partsParseException = ioe;
                return;
            }
            factory.setSizeThreshold(mce.getFileSizeThreshold());

            ServletFileUpload upload = new ServletFileUpload();
            upload.setFileItemFactory(factory);
            upload.setFileSizeMax(mce.getMaxFileSize());
            upload.setSizeMax(mce.getMaxRequestSize());

            parts = new ArrayList<>();
            try {
                List<FileItem> items =
                        upload.parseRequest(new ServletRequestContext(this));
                int maxPostSize = getConnector().getMaxPostSize();
                int postSize = 0;
                Charset charset = getCharset();
                for (FileItem item : items) {
                    ApplicationPart part = new ApplicationPart(item, location);
                    parts.add(part);
                    if (part.getSubmittedFileName() == null) {
                        String name = part.getName();
                        if (maxPostSize >= 0) {
                            // Have to calculate equivalent size. Not completely
                            // accurate but close enough.
                            postSize += name.getBytes(charset).length;
                            // Equals sign
                            postSize++;
                            // Value length
                            postSize += part.getSize();
                            // Value separator
                            postSize++;
                            if (postSize > maxPostSize) {
                                parameters.setParseFailedReason(FailReason.POST_TOO_LARGE);
                                throw new IllegalStateException(sm.getString(
                                        ""coyoteRequest.maxPostSizeExceeded""));
                            }
                        }
                        String value = null;
                        try {
                            value = part.getString(charset.name());
                        } catch (UnsupportedEncodingException uee) {
                            // Not possible
                        }
                        parameters.addParameter(name, value);
                    }
                }

                success = true;
            } catch (InvalidContentTypeException e) {
                parameters.setParseFailedReason(FailReason.INVALID_CONTENT_TYPE);
                partsParseException = new ServletException(e);
            } catch (SizeException e) {
                parameters.setParseFailedReason(FailReason.POST_TOO_LARGE);
                checkSwallowInput();
                partsParseException = new IllegalStateException(e);
            } catch (FileUploadException e) {
                parameters.setParseFailedReason(FailReason.IO_ERROR);
                partsParseException = new IOException(e);
            } catch (IllegalStateException e) {
                // addParameters() will set parseFailedReason
                checkSwallowInput();
                partsParseException = e;
            }
        } finally {
            // This might look odd but is correct. setParseFailedReason() only
            // sets the failure reason if none is currently set. This code could
            // be more efficient but it is written this way to be robust with
            // respect to changes in the remainder of the method.
            if (partsParseException != null || !success) {
                parameters.setParseFailedReason(FailReason.UNKNOWN);
            }
        }
    }",,
tomcat,16469,"log.debug(sm.getString(""fileResource.getUrlFail"", resource.getPath()), e)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/webresources/FileResource.java/#L264,"@Override
    public URL getURL() {
        if (resource.exists()) {
            try {
                return resource.toURI().toURL();
            } catch (MalformedURLException e) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""fileResource.getUrlFail"", resource.getPath()), e)
---------------Reference log end----------------
                }
                return null;
            }
        } else {
            return null;
        }
    }",,
tomcat,17468,"log.debug(""IntrospectionUtils:"" + sb.toString())",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/IntrospectionUtils.java/#L507,"public static Object callMethodN(Object target, String methodN,
            Object params[], Class<?> typeParams[]) throws Exception {
        Method m = null;
        m = findMethod(target.getClass(), methodN, typeParams);
        if (m == null) {
            if (log.isDebugEnabled()) {
                log.debug(""IntrospectionUtils: Can't find method "" + methodN +
                        "" in "" + target + "" CLASS "" + target.getClass());
            }
            return null;
        }
        try {
            Object o = m.invoke(target, params);

            if (log.isDebugEnabled()) {
                // debug
                StringBuilder sb = new StringBuilder();
                sb.append(target.getClass().getName()).append('.')
                        .append(methodN).append(""( "");
                for (int i = 0; i < params.length; i++) {
                    if (i > 0) {
                        sb.append("", "");
                    }
                    sb.append(params[i]);
                }
                sb.append("")"");
                
---------------Reference log start----------------
log.debug(""IntrospectionUtils:"" + sb.toString())
---------------Reference log end----------------
            }
            return o;
        } catch (InvocationTargetException ie) {
            ExceptionUtils.handleThrowable(ie.getCause());
            throw ie;
        }
    }",,
tomcat,16561,"log.info(sm.getString(""aprListener.skipFIPSInitialization""))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/AprLifecycleListener.java/#L294,"private static void initializeSSL() throws Exception {

        if (""off"".equalsIgnoreCase(SSLEngine)) {
            return;
        }
        if (sslInitialized) {
             //only once per VM
            return;
        }

        sslInitialized = true;

        String methodName = ""randSet"";
        Class<?> paramTypes[] = new Class[1];
        paramTypes[0] = String.class;
        Object paramValues[] = new Object[1];
        paramValues[0] = SSLRandomSeed;
        Class<?> clazz = Class.forName(""org.apache.tomcat.jni.SSL"");
        Method method = clazz.getMethod(methodName, paramTypes);
        method.invoke(null, paramValues);


        methodName = ""initialize"";
        paramValues[0] = ""on"".equalsIgnoreCase(SSLEngine)?null:SSLEngine;
        method = clazz.getMethod(methodName, paramTypes);
        method.invoke(null, paramValues);

        if (!(null == FIPSMode || ""off"".equalsIgnoreCase(FIPSMode))) {

            fipsModeActive = false;

            final boolean enterFipsMode;
            int fipsModeState = SSL.fipsModeGet();

            if(log.isDebugEnabled()) {
                log.debug(sm.getString(""aprListener.currentFIPSMode"",
                                       Integer.valueOf(fipsModeState)));
            }

            if (""on"".equalsIgnoreCase(FIPSMode)) {
                if (fipsModeState == FIPS_ON) {
                    
---------------Reference log start----------------
log.info(sm.getString(""aprListener.skipFIPSInitialization""))
---------------Reference log end----------------
                    fipsModeActive = true;
                    enterFipsMode = false;
                } else {
                    enterFipsMode = true;
                }
            } else if (""require"".equalsIgnoreCase(FIPSMode)) {
                if (fipsModeState == FIPS_ON) {
                    fipsModeActive = true;
                    enterFipsMode = false;
                } else {
                    throw new IllegalStateException(
                            sm.getString(""aprListener.requireNotInFIPSMode""));
                }
            } else if (""enter"".equalsIgnoreCase(FIPSMode)) {
                if (fipsModeState == FIPS_OFF) {
                    enterFipsMode = true;
                } else {
                    throw new IllegalStateException(sm.getString(
                            ""aprListener.enterAlreadyInFIPSMode"",
                            Integer.valueOf(fipsModeState)));
                }
            } else {
                throw new IllegalArgumentException(sm.getString(
                        ""aprListener.wrongFIPSMode"", FIPSMode));
            }

            if (enterFipsMode) {
                log.info(sm.getString(""aprListener.initializingFIPS""));

                fipsModeState = SSL.fipsModeSet(FIPS_ON);
                if (fipsModeState != FIPS_ON) {
                    // This case should be handled by the native method,
                    // but we'll make absolutely sure, here.
                    String message = sm.getString(""aprListener.initializeFIPSFailed"");
                    log.error(message);
                    throw new IllegalStateException(message);
                }

                fipsModeActive = true;
                log.info(sm.getString(""aprListener.initializeFIPSSuccess""));
            }
        }

        log.info(sm.getString(""aprListener.initializedOpenSSL"", SSL.versionString()));
    }",,
tomcat,16763,"log.error(sm.getString(""standardService.engine.startFailed""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardService.java/#L150,"@Override
    public void setContainer(Engine engine) {
        Engine oldEngine = this.engine;
        if (oldEngine != null) {
            oldEngine.setService(null);
        }
        this.engine = engine;
        if (this.engine != null) {
            this.engine.setService(this);
        }
        if (getState().isAvailable()) {
            if (this.engine != null) {
                try {
                    this.engine.start();
                } catch (LifecycleException e) {
                    
---------------Reference log start----------------
log.error(sm.getString(""standardService.engine.startFailed""), e)
---------------Reference log end----------------
                }
            }
            // Restart MapperListener to pick up new engine.
            try {
                mapperListener.stop();
            } catch (LifecycleException e) {
                log.error(sm.getString(""standardService.mapperListener.stopFailed""), e);
            }
            try {
                mapperListener.start();
            } catch (LifecycleException e) {
                log.error(sm.getString(""standardService.mapperListener.startFailed""), e);
            }
            if (oldEngine != null) {
                try {
                    oldEngine.stop();
                } catch (LifecycleException e) {
                    log.error(sm.getString(""standardService.engine.stopFailed""), e);
                }
            }
        }

        // Report this property change to interested listeners
        support.firePropertyChange(""container"", oldEngine, this.engine);
    }",,
tomcat,15773,"log.error(sm.getString(""abstractReplicatedMap.unable.transferState""), x)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/tipis/AbstractReplicatedMap.java/#L570,"public void transferState() {
        try {
            Member[] members = getMapMembers();
            Member backup = members.length > 0 ? members[0] : null;
            if (backup != null) {
                MapMessage msg = new MapMessage(mapContextName, getStateMessageType(), false,
                                                null, null, null, null, null);
                Response[] resp = rpcChannel.send(new Member[] {backup}, msg, RpcChannel.FIRST_REPLY, channelSendOptions, rpcTimeout);
                if (resp.length > 0) {
                    synchronized (stateMutex) {
                        msg = (MapMessage) resp[0].getMessage();
                        msg.deserialize(getExternalLoaders());
                        ArrayList<?> list = (ArrayList<?>) msg.getValue();
                        for (Object o : list) {
                            messageReceived((Serializable) o, resp[0].getSource());
                        } //for
                    }
                    stateTransferred = true;
                } else {
                    log.warn(sm.getString(""abstractReplicatedMap.transferState.noReplies""));
                }
            }
        } catch (ChannelException | ClassNotFoundException | IOException x) {
            
---------------Reference log start----------------
log.error(sm.getString(""abstractReplicatedMap.unable.transferState""), x)
---------------Reference log end----------------
        }
        this.state = State.STATETRANSFERRED;
    }",,
tomcat,16404,"log.info(sm.getString(""farmWarDeployer.alreadyDeployed"", cn.getName()))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/deploy/FarmWarDeployer.java/#L469,"@Override
    public void fileModified(File newWar) {
        try {
            File deployWar = new File(getDeployDirFile(), newWar.getName());
            ContextName cn = new ContextName(deployWar.getName(), true);
            if (deployWar.exists() && deployWar.lastModified() > newWar.lastModified()) {
                if (log.isInfoEnabled()) {
                    
---------------Reference log start----------------
log.info(sm.getString(""farmWarDeployer.alreadyDeployed"", cn.getName()))
---------------Reference log end----------------
                }
                return;
            }
            if (log.isInfoEnabled()) {
                log.info(sm.getString(""farmWarDeployer.modInstall"",
                        cn.getName(), deployWar.getAbsolutePath()));
            }
            // install local
            if (tryAddServiced(cn.getName())) {
                try {
                    copy(newWar, deployWar);
                } finally {
                    removeServiced(cn.getName());
                }
                check(cn.getName());
            } else {
                log.error(sm.getString(""farmWarDeployer.servicingDeploy"",
                        cn.getName(), deployWar.getName()));
            }
            install(cn.getName(), deployWar);
        } catch (Exception x) {
            log.error(sm.getString(""farmWarDeployer.modInstallFail""), x);
        }
    }",,
tomcat,15952,"log.debug(""Checking for reauthenticate in session "" + session)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/FormAuthenticator.java/#L144,"@Override
    protected boolean doAuthenticate(Request request, HttpServletResponse response)
            throws IOException {

        // References to objects we will need later
        Session session = null;
        Principal principal = null;

        // Have we authenticated this user before but have caching disabled?
        if (!cache) {
            session = request.getSessionInternal(true);
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Checking for reauthenticate in session "" + session)
---------------Reference log end----------------
            }
            String username = (String) session.getNote(Constants.SESS_USERNAME_NOTE);
            String password = (String) session.getNote(Constants.SESS_PASSWORD_NOTE);
            if (username != null && password != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""Reauthenticating username '"" + username + ""'"");
                }
                principal = context.getRealm().authenticate(username, password);
                if (principal != null) {
                    register(request, response, principal, HttpServletRequest.FORM_AUTH, username, password);
                    if (!matchRequest(request)) {
                        return true;
                    }
                }
                if (log.isDebugEnabled()) {
                    log.debug(""Reauthentication failed, proceed normally"");
                }
            }
        }

        // Is this the re-submit of the original request URI after successful
        // authentication?  If so, forward the *original* request instead.
        if (matchRequest(request)) {
            session = request.getSessionInternal(true);
            if (log.isDebugEnabled()) {
                log.debug(""Restore request from session '"" + session.getIdInternal() + ""'"");
            }
            if (restoreRequest(request, session)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Proceed to restored request"");
                }
                return true;
            } else {
                if (log.isDebugEnabled()) {
                    log.debug(""Restore of original request failed"");
                }
                response.sendError(HttpServletResponse.SC_BAD_REQUEST);
                return false;
            }
        }

        // This check has to be after the previous check for a matching request
        // because that matching request may also include a cached Principal.
        if (checkForCachedAuthentication(request, response, true)) {
            return true;
        }

        // Acquire references to objects we will need to evaluate
        String contextPath = request.getContextPath();
        String requestURI = request.getDecodedRequestURI();

        // Is this the action request from the login page?
        boolean loginAction = requestURI.startsWith(contextPath) && requestURI.endsWith(Constants.FORM_ACTION);

        LoginConfig config = context.getLoginConfig();

        // No -- Save this request and redirect to the form login page
        if (!loginAction) {
            // If this request was to the root of the context without a trailing
            // '/', need to redirect to add it else the submit of the login form
            // may not go to the correct web application
            if (request.getServletPath().length() == 0 && request.getPathInfo() == null) {
                StringBuilder location = new StringBuilder(requestURI);
                location.append('/');
                if (request.getQueryString() != null) {
                    location.append('?');
                    location.append(request.getQueryString());
                }
                response.sendRedirect(response.encodeRedirectURL(location.toString()));
                return false;
            }

            session = request.getSessionInternal(true);
            if (log.isDebugEnabled()) {
                log.debug(""Save request in session '"" + session.getIdInternal() + ""'"");
            }
            try {
                saveRequest(request, session);
            } catch (IOException ioe) {
                log.debug(""Request body too big to save during authentication"");
                response.sendError(HttpServletResponse.SC_FORBIDDEN, sm.getString(""authenticator.requestBodyTooBig""));
                return false;
            }
            forwardToLoginPage(request, response, config);
            return false;
        }

        // Yes -- Acknowledge the request, validate the specified credentials
        // and redirect to the error page if they are not correct
        request.getResponse().sendAcknowledgement(ContinueResponseTiming.ALWAYS);
        Realm realm = context.getRealm();
        if (characterEncoding != null) {
            request.setCharacterEncoding(characterEncoding);
        }
        String username = request.getParameter(Constants.FORM_USERNAME);
        String password = request.getParameter(Constants.FORM_PASSWORD);
        if (log.isDebugEnabled()) {
            log.debug(""Authenticating username '"" + username + ""'"");
        }
        principal = realm.authenticate(username, password);
        if (principal == null) {
            forwardToErrorPage(request, response, config);
            return false;
        }

        if (log.isDebugEnabled()) {
            log.debug(""Authentication of '"" + username + ""' was successful"");
        }

        if (session == null) {
            session = request.getSessionInternal(false);
        }
        if (session != null && getChangeSessionIdOnAuthentication()) {
            // Does session id match?
            String expectedSessionId = (String) session.getNote(Constants.SESSION_ID_NOTE);
            if (expectedSessionId == null || !expectedSessionId.equals(request.getRequestedSessionId())) {
                session.expire();
                session = null;
            }
        }
        if (session == null) {
            if (containerLog.isDebugEnabled()) {
                containerLog.debug(""User took so long to log on the session expired"");
            }
            if (landingPage == null) {
                response.sendError(
                        HttpServletResponse.SC_REQUEST_TIMEOUT, sm.getString(""authenticator.sessionExpired""));
            } else {
                // Make the authenticator think the user originally requested
                // the landing page
                String uri = request.getContextPath() + landingPage;
                SavedRequest saved = new SavedRequest();
                saved.setMethod(""GET"");
                saved.setRequestURI(uri);
                saved.setDecodedRequestURI(uri);
                request.getSessionInternal(true).setNote(Constants.FORM_REQUEST_NOTE, saved);
                response.sendRedirect(response.encodeRedirectURL(uri));
            }
            return false;
        }

        register(request, response, principal, HttpServletRequest.FORM_AUTH, username, password);

        // Redirect the user to the original request URI (which will cause
        // the original request to be restored)
        requestURI = savedRequestURL(session);
        if (log.isDebugEnabled()) {
            log.debug(""Redirecting to original '"" + requestURI + ""'"");
        }
        if (requestURI == null) {
            if (landingPage == null) {
                response.sendError(HttpServletResponse.SC_BAD_REQUEST, sm.getString(""authenticator.formlogin""));
            } else {
                // Make the authenticator think the user originally requested
                // the landing page
                String uri = request.getContextPath() + landingPage;
                SavedRequest saved = new SavedRequest();
                saved.setMethod(""GET"");
                saved.setRequestURI(uri);
                saved.setDecodedRequestURI(uri);
                session.setNote(Constants.FORM_REQUEST_NOTE, saved);
                response.sendRedirect(response.encodeRedirectURL(uri));
            }
        } else {
            // Until the Servlet API allows specifying the type of redirect to
            // use.
            Response internalResponse = request.getResponse();
            String location = response.encodeRedirectURL(requestURI);
            if (""HTTP/1.1"".equals(request.getProtocol())) {
                internalResponse.sendRedirect(location, HttpServletResponse.SC_SEE_OTHER);
            } else {
                internalResponse.sendRedirect(location, HttpServletResponse.SC_FOUND);
            }
        }
        return false;
    }",,
tomcat,16061,"log.info(sm.getString(""memoryUserDatabase.reload"", id, uri))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/users/MemoryUserDatabase.java/#L673,"@Override
    public void backgroundProcess() {
        if (!watchSource) {
            return;
        }

        URI uri = ConfigFileLoader.getSource().getURI(getPathname());
        URLConnection uConn = null;
        try {
            URL url = uri.toURL();
            uConn = url.openConnection();

            if (this.lastModified != uConn.getLastModified()) {
                writeLock.lock();
                try {
                    long detectedLastModified = uConn.getLastModified();
                    // Last modified as a resolution of 1s. Ensure that a write
                    // to the file is not in progress by ensuring that the last
                    // modified time is at least 2 seconds ago.
                    if (this.lastModified != detectedLastModified &&
                            detectedLastModified + 2000 < System.currentTimeMillis()) {
                        
---------------Reference log start----------------
log.info(sm.getString(""memoryUserDatabase.reload"", id, uri))
---------------Reference log end----------------
                        open();
                    }
                } finally {
                    writeLock.unlock();
                }
            }
        } catch (Exception ioe) {
            log.error(sm.getString(""memoryUserDatabase.reloadError"", id, uri), ioe);
        } finally {
            if (uConn != null) {
                try {
                    // Can't close a uConn directly. Have to do it like this.
                    uConn.getInputStream().close();
                } catch (FileNotFoundException fnfe) {
                    // The file doesn't exist.
                    // This has been logged above. No need to log again.
                    // Set the last modified time to avoid repeated log messages
                    this.lastModified = 0;
                } catch (IOException ioe) {
                    log.warn(sm.getString(""memoryUserDatabase.fileClose"", pathname), ioe);
                }
            }
        }
    }",,
tomcat,15235,"log.info(sm.getString(""managerBase.sessionNotFound"", sessionId))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/ManagerBase.java/#L1238,"public void expireSession( String sessionId ) {
        Session s = sessions.get(sessionId);
        if (s == null) {
            if (log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""managerBase.sessionNotFound"", sessionId))
---------------Reference log end----------------
            }
            return;
        }
        s.expire();
    }",,
tomcat,15566,"containerLog.trace(""  validating credentials by binding as the user"")",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JNDIRealm.java/#L1767,"protected boolean bindAsUser(DirContext context, User user, String credentials) throws NamingException {

        if (credentials == null || user == null) {
            return false;
        }

        // This is returned from the directory so will be attribute value
        // escaped if required
        String dn = user.getDN();
        if (dn == null) {
            return false;
        }

        // Validate the credentials specified by the user
        if (containerLog.isTraceEnabled()) {
            
---------------Reference log start----------------
containerLog.trace(""  validating credentials by binding as the user"")
---------------Reference log end----------------
        }

        userCredentialsAdd(context, dn, credentials);

        // Elicit an LDAP bind operation
        boolean validated = false;
        try {
            if (containerLog.isTraceEnabled()) {
                containerLog.trace(""  binding as ""  + dn);
            }
            context.getAttributes("""", null);
            validated = true;
        }
        catch (AuthenticationException e) {
            if (containerLog.isTraceEnabled()) {
                containerLog.trace(""  bind attempt failed"");
            }
        }

        userCredentialsRemove(context);

        return validated;
    }",,
tomcat,17408,"log.debug(sm.getString(""digester.noRulesFound"", match))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/Digester.java/#L1275,"@Override
    public void startElement(String namespaceURI, String localName, String qName, Attributes list)
            throws SAXException {
        boolean debug = log.isDebugEnabled();

        if (saxLog.isDebugEnabled()) {
            saxLog.debug(""startElement("" + namespaceURI + "","" + localName + "","" + qName + "")"");
        }

        // Parse system properties
        list = updateAttributes(list);

        // Save the body text accumulated for our surrounding element
        bodyTexts.push(bodyText);
        bodyText = new StringBuilder();

        // the actual element name is either in localName or qName, depending
        // on whether the parser is namespace aware
        String name = localName;
        if ((name == null) || (name.length() < 1)) {
            name = qName;
        }

        // Compute the current matching rule
        StringBuilder sb = new StringBuilder(match);
        if (match.length() > 0) {
            sb.append('/');
        }
        sb.append(name);
        match = sb.toString();
        if (debug) {
            log.debug(""  New match='"" + match + ""'"");
        }

        // Fire ""begin"" events for all relevant rules
        List<Rule> rules = getRules().match(namespaceURI, match);
        matches.push(rules);
        if ((rules != null) && (rules.size() > 0)) {
            for (Rule value : rules) {
                try {
                    Rule rule = value;
                    if (debug) {
                        log.debug(""  Fire begin() for "" + rule);
                    }
                    rule.begin(namespaceURI, name, list);
                } catch (Exception e) {
                    log.error(sm.getString(""digester.error.begin""), e);
                    throw createSAXException(e);
                } catch (Error e) {
                    log.error(sm.getString(""digester.error.begin""), e);
                    throw e;
                }
            }
        } else {
            if (debug) {
                
---------------Reference log start----------------
log.debug(sm.getString(""digester.noRulesFound"", match))
---------------Reference log end----------------
            }
        }

    }",,
tomcat,17350,"log.error(sm.getString(""webXml.mergeConflictString"", mapName, key, fragment.getName(), fragment.getURL()))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/descriptor/web/WebXml.java/#L2198,"private boolean mergeLifecycleCallback(
            Map<String, String> fragmentMap, Map<String, String> tempMap,
            WebXml fragment, String mapName) {
        for (Entry<String, String> entry : fragmentMap.entrySet()) {
            final String key = entry.getKey();
            final String value = entry.getValue();
            if (tempMap.containsKey(key)) {
                if (value != null && !value.equals(tempMap.get(key))) {
                    
---------------Reference log start----------------
log.error(sm.getString(""webXml.mergeConflictString"", mapName, key, fragment.getName(), fragment.getURL()))
---------------Reference log end----------------
                    return false;
                }
            } else {
                tempMap.put(key, value);
            }
        }
        return true;
    }",,
tomcat,16068,"log.warn(sm.getString(""namingResources.mbeanCreateFail"", cr.getName()), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/deploy/NamingResourcesImpl.java/#L969,"@Override
    protected void initInternal() throws LifecycleException {
        super.initInternal();

        // Set this before we register currently known naming resources to avoid
        // timing issues. Duplication registration is not an issue.
        resourceRequireExplicitRegistration = true;

        for (ContextResource cr : resources.values()) {
            try {
                MBeanUtils.createMBean(cr);
            } catch (Exception e) {
                
---------------Reference log start----------------
log.warn(sm.getString(""namingResources.mbeanCreateFail"", cr.getName()), e)
---------------Reference log end----------------
            }
        }

        for (ContextEnvironment ce : envs.values()) {
            try {
                MBeanUtils.createMBean(ce);
            } catch (Exception e) {
                log.warn(sm.getString(
                        ""namingResources.mbeanCreateFail"", ce.getName()), e);
            }
        }

        for (ContextResourceLink crl : resourceLinks.values()) {
            try {
                MBeanUtils.createMBean(crl);
            } catch (Exception e) {
                log.warn(sm.getString(
                        ""namingResources.mbeanCreateFail"", crl.getName()), e);
            }
        }
    }",,
tomcat,16867,"log.warn(sm.getString(""compressionConfig.ContentEncodingParseFail""), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/CompressionConfig.java/#L214,"public boolean useCompression(Request request, Response response) {
        // Check if compression is enabled
        if (compressionLevel == 0) {
            return false;
        }

        MimeHeaders responseHeaders = response.getMimeHeaders();

        // Check if content is not already compressed
        MessageBytes contentEncodingMB = responseHeaders.getValue(""Content-Encoding"");
        if (contentEncodingMB != null) {
            // Content-Encoding values are ordered but order is not important
            // for this check so use a Set rather than a List
            Set<String> tokens = new HashSet<>();
            try {
                TokenList.parseTokenList(responseHeaders.values(""Content-Encoding""), tokens);
            } catch (IOException e) {
                // Because we are using StringReader, any exception here is a
                // Tomcat bug.
                
---------------Reference log start----------------
log.warn(sm.getString(""compressionConfig.ContentEncodingParseFail""), e)
---------------Reference log end----------------
                return false;
            }
            if (tokens.contains(""gzip"") || tokens.contains(""br"")) {
                return false;
            }
        }

        // If force mode, the length and MIME type checks are skipped
        if (compressionLevel != 2) {
            // Check if the response is of sufficient length to trigger the compression
            long contentLength = response.getContentLengthLong();
            if (contentLength != -1 && contentLength < compressionMinSize) {
                return false;
            }

            // Check for compatible MIME-TYPE
            String[] compressibleMimeTypes = getCompressibleMimeTypes();
            if (compressibleMimeTypes != null &&
                    !startsWithStringArray(compressibleMimeTypes, response.getContentType())) {
                return false;
            }
        }

        // Check if the resource has a strong ETag
        String eTag = responseHeaders.getHeader(""ETag"");
        if (eTag != null && !eTag.trim().startsWith(""W/"")) {
            // Has an ETag that doesn't start with ""W/..."" so it must be a
            // strong ETag
            return false;
        }

        // If processing reaches this far, the response might be compressed.
        // Therefore, set the Vary header to keep proxies happy
        ResponseUtil.addVaryFieldName(responseHeaders, ""accept-encoding"");

        // Check if user-agent supports gzip encoding
        // Only interested in whether gzip encoding is supported. Other
        // encodings and weights can be ignored.
        Enumeration<String> headerValues = request.getMimeHeaders().values(""accept-encoding"");
        boolean foundGzip = false;
        while (!foundGzip && headerValues.hasMoreElements()) {
            List<AcceptEncoding> acceptEncodings = null;
            try {
                acceptEncodings = AcceptEncoding.parse(new StringReader(headerValues.nextElement()));
            } catch (IOException ioe) {
                // If there is a problem reading the header, disable compression
                return false;
            }

            for (AcceptEncoding acceptEncoding : acceptEncodings) {
                if (""gzip"".equalsIgnoreCase(acceptEncoding.getEncoding())) {
                    foundGzip = true;
                    break;
                }
            }
        }

        if (!foundGzip) {
            return false;
        }

        // If force mode, the browser checks are skipped
        if (compressionLevel != 2) {
            // Check for incompatible Browser
            Pattern noCompressionUserAgents = this.noCompressionUserAgents;
            if (noCompressionUserAgents != null) {
                MessageBytes userAgentValueMB = request.getMimeHeaders().getValue(""user-agent"");
                if(userAgentValueMB != null) {
                    String userAgentValue = userAgentValueMB.toString();
                    if (noCompressionUserAgents.matcher(userAgentValue).matches()) {
                        return false;
                    }
                }
            }
        }

        // All checks have passed. Compression is enabled.

        // Compressed content length is unknown so mark it as such.
        response.setContentLength(-1);
        // Configure the content encoding for compressed content
        responseHeaders.setValue(""Content-Encoding"").setString(""gzip"");

        return true;
    }",,
tomcat,17020,"log.debug(sm.getString(""wsWebSocketContainer.sessionCloseFail"", session.getId()), ioe)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/websocket/WsWebSocketContainer.java/#L1046,"public void destroy() {
        CloseReason cr = new CloseReason(
                CloseCodes.GOING_AWAY, sm.getString(""wsWebSocketContainer.shutdown""));

        for (WsSession session : sessions.keySet()) {
            try {
                session.close(cr);
            } catch (IOException ioe) {
                
---------------Reference log start----------------
log.debug(sm.getString(""wsWebSocketContainer.sessionCloseFail"", session.getId()), ioe)
---------------Reference log end----------------
            }
        }

        // Only unregister with AsyncChannelGroupUtil if this instance
        // registered with it
        if (asynchronousChannelGroup != null) {
            synchronized (asynchronousChannelGroupLock) {
                if (asynchronousChannelGroup != null) {
                    AsyncChannelGroupUtil.unregister();
                    asynchronousChannelGroup = null;
                }
            }
        }
    }",,
tomcat,17470,"log.debug(""IntrospectionUtils: Unable to resolve host name:"" + object)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/IntrospectionUtils.java/#L538,"public static Object convert(String object, Class<?> paramType) {
        Object result = null;
        if (""java.lang.String"".equals(paramType.getName())) {
            result = object;
        } else if (""java.lang.Integer"".equals(paramType.getName())
                || ""int"".equals(paramType.getName())) {
            try {
                result = Integer.valueOf(object);
            } catch (NumberFormatException ex) {
            }
            // Try a setFoo ( boolean )
        } else if (""java.lang.Boolean"".equals(paramType.getName())
                || ""boolean"".equals(paramType.getName())) {
            result = Boolean.valueOf(object);

            // Try a setFoo ( InetAddress )
        } else if (""java.net.InetAddress"".equals(paramType
                .getName())) {
            try {
                result = InetAddress.getByName(object);
            } catch (UnknownHostException exc) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""IntrospectionUtils: Unable to resolve host name:"" + object)
---------------Reference log end----------------
                }
            }

            // Unknown type
        } else {
            if (log.isDebugEnabled()) {
                log.debug(""IntrospectionUtils: Unknown type "" +
                        paramType.getName());
            }
        }
        if (result == null) {
            throw new IllegalArgumentException(sm.getString(""introspectionUtils.conversionError"", object, paramType.getName()));
        }
        return result;
    }",,
tomcat,15315,"log.debug(""finished decoding with element size of: "" + list.size())",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/valves/ExtendedAccessLogValve.java/#L561,"@Override
    protected AccessLogElement[] createLogElements() {
        if (log.isDebugEnabled()) {
            log.debug(""decodePattern, pattern ="" + pattern);
        }
        List<AccessLogElement> list = new ArrayList<>();

        PatternTokenizer tokenizer = new PatternTokenizer(pattern);
        try {

            // Ignore leading whitespace.
            tokenizer.getWhiteSpaces();

            if (tokenizer.isEnded()) {
                log.info(sm.getString(""extendedAccessLogValve.emptyPattern""));
                return null;
            }

            String token = tokenizer.getToken();
            while (token != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""token = "" + token);
                }
                AccessLogElement element = getLogElement(token, tokenizer);
                if (element == null) {
                    break;
                }
                list.add(element);
                String whiteSpaces = tokenizer.getWhiteSpaces();
                if (whiteSpaces.length() > 0) {
                    list.add(new StringElement(whiteSpaces));
                }
                if (tokenizer.isEnded()) {
                    break;
                }
                token = tokenizer.getToken();
            }
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""finished decoding with element size of: "" + list.size())
---------------Reference log end----------------
            }
            return list.toArray(new AccessLogElement[0]);
        } catch (IOException e) {
            log.error(sm.getString(""extendedAccessLogValve.patternParseError"", pattern), e);
            return null;
        }
    }",,
tomcat,17535,"log.debug(""Compiled "" + ctxt.getServletJavaFileName() + "" "" + (t2 - t1) + ""ms"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/JDTCompiler.java/#L492,"@Override
    protected void generateClass(Map<String,SmapStratum> smaps)
        throws FileNotFoundException, JasperException, Exception {

        long t1 = 0;
        if (log.isDebugEnabled()) {
            t1 = System.currentTimeMillis();
        }

        final String sourceFile = ctxt.getServletJavaFileName();
        final String outputDir = ctxt.getOptions().getScratchDir().getAbsolutePath();
        String packageName = ctxt.getServletPackageName();
        final String targetClassName =
                ((packageName.length() != 0) ? (packageName + ""."") : """") + ctxt.getServletClassName();
        final ClassLoader classLoader = ctxt.getJspLoader();
        String[] fileNames = new String[] {sourceFile};
        String[] classNames = new String[] {targetClassName};
        final List<JavacErrorDetail> problemList = new ArrayList<>();

        class CompilationUnit implements ICompilationUnit {

            private final String className;
            private final String sourceFile;

            CompilationUnit(String sourceFile, String className) {
                this.className = className;
                this.sourceFile = sourceFile;
            }

            @Override
            public char[] getFileName() {
                return sourceFile.toCharArray();
            }

            @Override
            public char[] getContents() {
                char[] result = null;
                try (FileInputStream is = new FileInputStream(sourceFile);
                        InputStreamReader isr = new InputStreamReader(is, ctxt.getOptions().getJavaEncoding());
                        Reader reader = new BufferedReader(isr)) {
                    char[] chars = new char[8192];
                    StringBuilder buf = new StringBuilder();
                    int count;
                    while ((count = reader.read(chars, 0, chars.length)) > 0) {
                        buf.append(chars, 0, count);
                    }
                    result = new char[buf.length()];
                    buf.getChars(0, result.length, result, 0);
                } catch (IOException e) {
                    log.error(Localizer.getMessage(""jsp.error.compilation.source"", sourceFile), e);
                }
                return result;
            }

            @Override
            public char[] getMainTypeName() {
                int dot = className.lastIndexOf('.');
                if (dot > 0) {
                    return className.substring(dot + 1).toCharArray();
                }
                return className.toCharArray();
            }

            @Override
            public char[][] getPackageName() {
                StringTokenizer izer = new StringTokenizer(className, ""."");
                char[][] result = new char[izer.countTokens()-1][];
                for (int i = 0; i < result.length; i++) {
                    String tok = izer.nextToken();
                    result[i] = tok.toCharArray();
                }
                return result;
            }

            @Override
            public boolean ignoreOptionalProblems() {
                return false;
            }
        }

        final INameEnvironment env = new INameEnvironment() {

                @Override
                public NameEnvironmentAnswer findType(char[][] compoundTypeName) {
                    StringBuilder result = new StringBuilder();
                    for (int i = 0; i < compoundTypeName.length; i++) {
                        if (i > 0) {
                            result.append('.');
                        }
                        result.append(compoundTypeName[i]);
                    }
                    return findType(result.toString());
                }

                @Override
                public NameEnvironmentAnswer findType(char[] typeName, char[][] packageName) {
                    StringBuilder result = new StringBuilder();
                    int i=0;
                    for (; i < packageName.length; i++) {
                        if (i > 0) {
                            result.append('.');
                        }
                        result.append(packageName[i]);
                    }
                    if (i > 0) {
                        result.append('.');
                    }
                    result.append(typeName);
                    return findType(result.toString());
                }

                private NameEnvironmentAnswer findType(String className) {

                    if (className.equals(targetClassName)) {
                        ICompilationUnit compilationUnit = new CompilationUnit(sourceFile, className);
                        return new NameEnvironmentAnswer(compilationUnit, null);
                    }

                    String resourceName = className.replace('.', '/') + "".class"";

                    try (InputStream is = classLoader.getResourceAsStream(resourceName)) {
                        if (is != null) {
                            byte[] classBytes;
                            byte[] buf = new byte[8192];
                            ByteArrayOutputStream baos = new ByteArrayOutputStream(buf.length);
                            int count;
                            while ((count = is.read(buf, 0, buf.length)) > 0) {
                                baos.write(buf, 0, count);
                            }
                            baos.flush();
                            classBytes = baos.toByteArray();
                            char[] fileName = className.toCharArray();
                            ClassFileReader classFileReader = new ClassFileReader(classBytes, fileName, true);
                            return new NameEnvironmentAnswer(classFileReader, null);
                        }
                    } catch (IOException | ClassFormatException exc) {
                        log.error(Localizer.getMessage(""jsp.error.compilation.dependent"", className), exc);
                    }
                    return null;
                }

                private boolean isPackage(String result) {
                    if (result.equals(targetClassName) || result.startsWith(targetClassName + '$')) {
                        return false;
                    }
                    String resourceName = result.replace('.', '/') + "".class"";
                    try (InputStream is =
                        classLoader.getResourceAsStream(resourceName)) {
                        return is == null;
                    } catch (IOException e) {
                        // we are here, since close on is failed. That means it was not null
                        return false;
                    }
                }

                @Override
                public boolean isPackage(char[][] parentPackageName, char[] packageName) {
                    StringBuilder result = new StringBuilder();
                    int i = 0;
                    if (parentPackageName != null) {
                        for (; i < parentPackageName.length; i++) {
                            if (i > 0) {
                                result.append('.');
                            }
                            result.append(parentPackageName[i]);
                        }
                    }

                    if (Character.isUpperCase(packageName[0])) {
                        if (!isPackage(result.toString())) {
                            return false;
                        }
                    }
                    if (i > 0) {
                        result.append('.');
                    }
                    result.append(packageName);

                    return isPackage(result.toString());
                }

                @Override
                public void cleanup() {
                }

            };

        final IErrorHandlingPolicy policy = DefaultErrorHandlingPolicies.proceedWithAllProblems();

        final Map<String,String> settings = new HashMap<>();
        settings.put(CompilerOptions.OPTION_LineNumberAttribute,
                     CompilerOptions.GENERATE);
        settings.put(CompilerOptions.OPTION_SourceFileAttribute,
                     CompilerOptions.GENERATE);
        settings.put(CompilerOptions.OPTION_ReportDeprecation,
                     CompilerOptions.IGNORE);
        if (ctxt.getOptions().getJavaEncoding() != null) {
            settings.put(CompilerOptions.OPTION_Encoding,
                    ctxt.getOptions().getJavaEncoding());
        }
        if (ctxt.getOptions().getClassDebugInfo()) {
            settings.put(CompilerOptions.OPTION_LocalVariableAttribute,
                         CompilerOptions.GENERATE);
        }

        // Source JVM
        if(ctxt.getOptions().getCompilerSourceVM() != null) {
            String opt = ctxt.getOptions().getCompilerSourceVM();
            if(opt.equals(""1.1"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_1);
            } else if(opt.equals(""1.2"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_2);
            } else if(opt.equals(""1.3"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_3);
            } else if(opt.equals(""1.4"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_4);
            } else if(opt.equals(""1.5"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_5);
            } else if(opt.equals(""1.6"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_6);
            } else if(opt.equals(""1.7"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_7);
            } else if(opt.equals(""1.8"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
            // Version format changed from Java 9 onwards.
            // Support old format that was used in EA implementation as well
            } else if(opt.equals(""9"") || opt.equals(""1.9"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_9);
            } else if(opt.equals(""10"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_10);
            } else if(opt.equals(""11"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_11);
            } else if(opt.equals(""12"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_12);
            } else if(opt.equals(""13"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_13);
            } else if(opt.equals(""14"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_14);
            } else if(opt.equals(""15"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_15);
            } else if(opt.equals(""16"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_16);
            } else if(opt.equals(""17"")) {
                // Constant not available in latest ECJ version shipped with
                // Tomcat. May be supported in a snapshot build.
                // This is checked against the actual version below.
                settings.put(CompilerOptions.OPTION_Source, ""17"");
            } else {
                log.warn(Localizer.getMessage(""jsp.warning.unknown.sourceVM"", opt));
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
            }
        } else {
            // Default to 1.8
            settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
        }

        // Target JVM
        if(ctxt.getOptions().getCompilerTargetVM() != null) {
            String opt = ctxt.getOptions().getCompilerTargetVM();
            if(opt.equals(""1.1"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_1);
            } else if(opt.equals(""1.2"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_2);
            } else if(opt.equals(""1.3"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_3);
            } else if(opt.equals(""1.4"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_4);
            } else if(opt.equals(""1.5"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_5);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_5);
            } else if(opt.equals(""1.6"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_6);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_6);
            } else if(opt.equals(""1.7"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_7);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_7);
            } else if(opt.equals(""1.8"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_8);
            // Version format changed from Java 9 onwards.
            // Support old format that was used in EA implementation as well
            } else if(opt.equals(""9"") || opt.equals(""1.9"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_9);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_9);
            } else if(opt.equals(""10"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_10);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_10);
            } else if(opt.equals(""11"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_11);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_11);
            } else if(opt.equals(""12"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_12);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_12);
            } else if(opt.equals(""13"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_13);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_13);
            } else if(opt.equals(""14"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_14);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_14);
            } else if(opt.equals(""15"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_15);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_15);
            } else if(opt.equals(""16"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_16);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_16);
            } else if(opt.equals(""17"")) {
                // Constant not available in latest ECJ version shipped with
                // Tomcat. May be supported in a snapshot build.
                // This is checked against the actual version below.
                settings.put(CompilerOptions.OPTION_TargetPlatform, ""17"");
                settings.put(CompilerOptions.OPTION_Compliance, ""17"");
            } else {
                log.warn(Localizer.getMessage(""jsp.warning.unknown.targetVM"", opt));
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
            }
        } else {
            // Default to 1.8
            settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
            settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_8);
        }

        final IProblemFactory problemFactory = new DefaultProblemFactory(Locale.getDefault());

        final ICompilerRequestor requestor = new ICompilerRequestor() {
                @Override
                public void acceptResult(CompilationResult result) {
                    try {
                        if (result.hasProblems()) {
                            IProblem[] problems = result.getProblems();
                            for (IProblem problem : problems) {
                                if (problem.isError()) {
                                    String name =
                                            new String(problem.getOriginatingFileName());
                                    try {
                                        problemList.add(ErrorDispatcher.createJavacError
                                                (name, pageNodes, new StringBuilder(problem.getMessage()),
                                                        problem.getSourceLineNumber(), ctxt));
                                    } catch (JasperException e) {
                                        log.error(Localizer.getMessage(""jsp.error.compilation.jdtProblemError""), e);
                                    }
                                }
                            }
                        }
                        if (problemList.isEmpty()) {
                            ClassFile[] classFiles = result.getClassFiles();
                            for (ClassFile classFile : classFiles) {
                                char[][] compoundName =
                                        classFile.getCompoundName();
                                StringBuilder classFileName = new StringBuilder(outputDir).append('/');
                                for (int j = 0;
                                     j < compoundName.length; j++) {
                                    if (j > 0) {
                                        classFileName.append('/');
                                    }
                                    classFileName.append(compoundName[j]);
                                }
                                byte[] bytes = classFile.getBytes();
                                classFileName.append("".class"");
                                try (FileOutputStream fout = new FileOutputStream(classFileName.toString());
                                        BufferedOutputStream bos = new BufferedOutputStream(fout)) {
                                    bos.write(bytes);
                                }
                            }
                        }
                    } catch (IOException exc) {
                        log.error(Localizer.getMessage(""jsp.error.compilation.jdt""), exc);
                    }
                }
            };

        ICompilationUnit[] compilationUnits =
            new ICompilationUnit[classNames.length];
        for (int i = 0; i < compilationUnits.length; i++) {
            String className = classNames[i];
            compilationUnits[i] = new CompilationUnit(fileNames[i], className);
        }
        CompilerOptions cOptions = new CompilerOptions(settings);

        // Check source/target JDK versions as the newest versions are allowed
        // in Tomcat configuration but may not be supported by the ECJ version
        // being used.
        String requestedSource = ctxt.getOptions().getCompilerSourceVM();
        if (requestedSource != null) {
            String actualSource = CompilerOptions.versionFromJdkLevel(cOptions.sourceLevel);
            if (!requestedSource.equals(actualSource)) {
                log.warn(Localizer.getMessage(""jsp.warning.unsupported.sourceVM"", requestedSource, actualSource));
            }
        }
        String requestedTarget = ctxt.getOptions().getCompilerTargetVM();
        if (requestedTarget != null) {
            String actualTarget = CompilerOptions.versionFromJdkLevel(cOptions.targetJDK);
            if (!requestedTarget.equals(actualTarget)) {
                log.warn(Localizer.getMessage(""jsp.warning.unsupported.targetVM"", requestedTarget, actualTarget));
            }
        }

        cOptions.parseLiteralExpressionsAsConstants = true;
        Compiler compiler = new Compiler(env,
                                         policy,
                                         cOptions,
                                         requestor,
                                         problemFactory);
        compiler.compile(compilationUnits);

        if (!ctxt.keepGenerated()) {
            File javaFile = new File(ctxt.getServletJavaFileName());
            if (!javaFile.delete()) {
                throw new JasperException(Localizer.getMessage(
                        ""jsp.warning.compiler.javafile.delete.fail"", javaFile));
            }
        }

        if (!problemList.isEmpty()) {
            JavacErrorDetail[] jeds =
                problemList.toArray(new JavacErrorDetail[0]);
            errDispatcher.javacError(jeds);
        }

        if( log.isDebugEnabled() ) {
            long t2=System.currentTimeMillis();
            
---------------Reference log start----------------
log.debug(""Compiled "" + ctxt.getServletJavaFileName() + "" "" + (t2 - t1) + ""ms"")
---------------Reference log end----------------
        }

        if (ctxt.isPrototypeMode()) {
            return;
        }

        // JSR45 Support
        if (! options.isSmapSuppressed()) {
            SmapUtil.installSmap(smaps);
        }
    }",,
tomcat,16139,"log.debug(""Calling main() method"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/Tool.java/#L227,"@SuppressWarnings(""null"")
    public static void main(String args[]) {

        // Verify that ""catalina.home"" was passed.
        if (catalinaHome == null) {
            log.error(""Must set '"" + Constants.CATALINA_HOME_PROP + ""' system property"");
            System.exit(1);
        }

        // Process command line options
        int index = 0;
        while (true) {
            if (index == args.length) {
                usage();
                System.exit(1);
            }
            if (""-ant"".equals(args[index])) {
                ant = true;
            } else if (""-common"".equals(args[index])) {
                common = true;
            } else if (""-server"".equals(args[index])) {
                server = true;
            } else if (""-shared"".equals(args[index])) {
                shared = true;
            } else {
                break;
            }
            index++;
        }
        if (index > args.length) {
            usage();
            System.exit(1);
        }

        // Set ""ant.home"" if requested
        if (ant) {
            System.setProperty(""ant.home"", catalinaHome);
        }

        // Construct the class loader we will be using
        ClassLoader classLoader = null;
        try {
            List<File> packed = new ArrayList<>();
            List<File> unpacked = new ArrayList<>();
            unpacked.add(new File(catalinaHome, ""classes""));
            packed.add(new File(catalinaHome, ""lib""));
            if (common) {
                unpacked.add(new File(catalinaHome,
                                      ""common"" + File.separator + ""classes""));
                packed.add(new File(catalinaHome,
                                    ""common"" + File.separator + ""lib""));
            }
            if (server) {
                unpacked.add(new File(catalinaHome,
                                      ""server"" + File.separator + ""classes""));
                packed.add(new File(catalinaHome,
                                    ""server"" + File.separator + ""lib""));
            }
            if (shared) {
                unpacked.add(new File(catalinaHome,
                                      ""shared"" + File.separator + ""classes""));
                packed.add(new File(catalinaHome,
                                    ""shared"" + File.separator + ""lib""));
            }
            classLoader =
                ClassLoaderFactory.createClassLoader
                (unpacked.toArray(new File[0]),
                 packed.toArray(new File[0]),
                 null);
        } catch (Throwable t) {
            Bootstrap.handleThrowable(t);
            log.error(""Class loader creation threw exception"", t);
            System.exit(1);
        }
        Thread.currentThread().setContextClassLoader(classLoader);

        // Load our application class
        Class<?> clazz = null;
        String className = args[index++];
        try {
            if (log.isDebugEnabled()) {
                log.debug(""Loading application class "" + className);
            }
            clazz = classLoader.loadClass(className);
        } catch (Throwable t) {
            Bootstrap.handleThrowable(t);
            log.error(""Exception creating instance of "" + className, t);
            System.exit(1);
        }

        Method method = null;
        String params[] = new String[args.length - index];
        System.arraycopy(args, index, params, 0, params.length);
        try {
            if (log.isDebugEnabled()) {
                log.debug(""Identifying main() method"");
            }
            String methodName = ""main"";
            Class<?> paramTypes[] = new Class[1];
            paramTypes[0] = params.getClass();
            method = clazz.getMethod(methodName, paramTypes);
        } catch (Throwable t) {
            Bootstrap.handleThrowable(t);
            log.error(""Exception locating main() method"", t);
            System.exit(1);
        }

        // Invoke the main method of the application class
        try {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Calling main() method"")
---------------Reference log end----------------
            }
            Object paramValues[] = new Object[1];
            paramValues[0] = params;
            method.invoke(null, paramValues);
        } catch (Throwable t) {
            t = Bootstrap.unwrapInvocationTargetException(t);
            Bootstrap.handleThrowable(t);
            log.error(""Exception calling main() method"", t);
            System.exit(1);
        }

    }",,
tomcat,16348,"log.debug(sm.getString(""deltaManager.receiveMessage.delta"", getName(), msg.getSessionID()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/session/DeltaManager.java/#L1193,"protected void handleSESSION_DELTA(SessionMessage msg, Member sender)
            throws IOException, ClassNotFoundException {
        counterReceive_EVT_SESSION_DELTA++;
        byte[] delta = msg.getSession();
        DeltaSession session = (DeltaSession) findSession(msg.getSessionID());
        if (session == null) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""deltaManager.receiveMessage.delta.unknown"",
                        getName(), msg.getSessionID()));
            }
        } else {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""deltaManager.receiveMessage.delta"", getName(), msg.getSessionID()))
---------------Reference log end----------------
            }

            session.deserializeAndExecuteDeltaRequest(delta);
        }
    }",,
tomcat,17226,"log.debug(sm.getString(""endpoint.err.handshake""), x)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/Nio2Endpoint.java/#L1626,"@Override
        protected void doRun() {
            boolean launch = false;
            try {
                int handshake = -1;

                try {
                    if (socketWrapper.getSocket().isHandshakeComplete()) {
                        // No TLS handshaking required. Let the handler
                        // process this socket / event combination.
                        handshake = 0;
                    } else if (event == SocketEvent.STOP || event == SocketEvent.DISCONNECT ||
                            event == SocketEvent.ERROR) {
                        // Unable to complete the TLS handshake. Treat it as
                        // if the handshake failed.
                        handshake = -1;
                    } else {
                        handshake = socketWrapper.getSocket().handshake();
                        // The handshake process reads/writes from/to the
                        // socket. status may therefore be OPEN_WRITE once
                        // the handshake completes. However, the handshake
                        // happens when the socket is opened so the status
                        // must always be OPEN_READ after it completes. It
                        // is OK to always set this as it is only used if
                        // the handshake completes.
                        event = SocketEvent.OPEN_READ;
                    }
                } catch (IOException x) {
                    handshake = -1;
                    if (log.isDebugEnabled()) {
                        
---------------Reference log start----------------
log.debug(sm.getString(""endpoint.err.handshake""), x)
---------------Reference log end----------------
                    }
                }
                if (handshake == 0) {
                    SocketState state = SocketState.OPEN;
                    // Process the request from this socket
                    if (event == null) {
                        state = getHandler().process(socketWrapper, SocketEvent.OPEN_READ);
                    } else {
                        state = getHandler().process(socketWrapper, event);
                    }
                    if (state == SocketState.CLOSED) {
                        // Close socket and pool
                        socketWrapper.close();
                    } else if (state == SocketState.UPGRADING) {
                        launch = true;
                    }
                } else if (handshake == -1 ) {
                    getHandler().process(socketWrapper, SocketEvent.CONNECT_FAIL);
                    socketWrapper.close();
                }
            } catch (VirtualMachineError vme) {
                ExceptionUtils.handleThrowable(vme);
            } catch (Throwable t) {
                log.error(sm.getString(""endpoint.processing.fail""), t);
                if (socketWrapper != null) {
                    ((Nio2SocketWrapper) socketWrapper).close();
                }
            } finally {
                if (launch) {
                    try {
                        getExecutor().execute(new SocketProcessor(socketWrapper, SocketEvent.OPEN_READ));
                    } catch (NullPointerException npe) {
                        if (running) {
                            log.error(sm.getString(""endpoint.launch.fail""),
                                    npe);
                        }
                    }
                }
                socketWrapper = null;
                event = null;
                //return to cache
                if (running && !paused && processorCache != null) {
                    processorCache.push(this);
                }
            }
        }",,
tomcat,16295,"log.debug(sm.getString(""jvmRoute.foundManager"", manager, request.getContext().getName()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/session/JvmRouteBinderValve.java/#L235,"protected Manager getManager(Request request) {
        Manager manager = request.getContext().getManager();
        if (log.isDebugEnabled()) {
            if(manager != null) {
                
---------------Reference log start----------------
log.debug(sm.getString(""jvmRoute.foundManager"", manager, request.getContext().getName()))
---------------Reference log end----------------
            } else {
                log.debug(sm.getString(""jvmRoute.notFoundManager"", request.getContext().getName()));
            }
        }
        return manager;
    }",,
tomcat,15711,"log.info(sm.getString(""mcastServiceImpl.setSoTimeout"", Integer.toString(mcastSoTimeout)))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/membership/McastServiceImpl.java/#L232,"protected void setupSocket() throws IOException {
        if (mcastBindAddress != null) {
            try {
                log.info(sm.getString(""mcastServiceImpl.bind"", address, Integer.toString(port)));
                socket = new MulticastSocket(new InetSocketAddress(address,port));
            } catch (BindException e) {
                /*
                 * On some platforms (e.g. Linux) it is not possible to bind
                 * to the multicast address. In this case only bind to the
                 * port.
                 */
                log.info(sm.getString(""mcastServiceImpl.bind.failed""));
                socket = new MulticastSocket(port);
            }
        } else {
            socket = new MulticastSocket(port);
        }
        socket.setLoopbackMode(localLoopbackDisabled); //hint if we want disable loop back(local machine) messages
        if (mcastBindAddress != null) {
            if(log.isInfoEnabled()) {
                log.info(sm.getString(""mcastServiceImpl.setInterface"", mcastBindAddress));
            }
            socket.setInterface(mcastBindAddress);
        } //end if
        //force a so timeout so that we don't block forever
        if (mcastSoTimeout <= 0) {
            mcastSoTimeout = (int)sendFrequency;
        }
        if (log.isInfoEnabled()) {
            
---------------Reference log start----------------
log.info(sm.getString(""mcastServiceImpl.setSoTimeout"", Integer.toString(mcastSoTimeout)))
---------------Reference log end----------------
        }
        socket.setSoTimeout(mcastSoTimeout);

        if ( mcastTTL >= 0 ) {
            if(log.isInfoEnabled()) {
                log.info(sm.getString(""mcastServiceImpl.setTTL"", Integer.toString(mcastTTL)));
            }
            socket.setTimeToLive(mcastTTL);
        }
    }",,
tomcat,15764,"log.error(sm.getString(""abstractReplicatedMap.unable.deserialize.MapMessage""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/tipis/AbstractReplicatedMap.java/#L311,"protected void ping(long timeout) throws ChannelException {
        MapMessage msg = new MapMessage(this.mapContextName,
                                        MapMessage.MSG_PING,
                                        false,
                                        null,
                                        null,
                                        null,
                                        channel.getLocalMember(false),
                                        null);
        if ( channel.getMembers().length > 0 ) {
            try {
                //send a ping, wait for all nodes to reply
                Response[] resp = rpcChannel.send(channel.getMembers(),
                                                  msg, RpcChannel.ALL_REPLY,
                                                  (channelSendOptions),
                                                  (int) accessTimeout);
                for (Response response : resp) {
                    MapMessage mapMsg = (MapMessage) response.getMessage();
                    try {
                        mapMsg.deserialize(getExternalLoaders());
                        Member member = response.getSource();
                        State state = (State) mapMsg.getValue();
                        if (state.isAvailable()) {
                            memberAlive(member);
                        } else if (state == State.STATETRANSFERRED) {
                            synchronized (mapMembers) {
                                if (log.isInfoEnabled()) {
                                    log.info(sm.getString(""abstractReplicatedMap.ping.stateTransferredMember"",
                                            member));
                                }
                                if (mapMembers.containsKey(member)) {
                                    mapMembers.put(member, Long.valueOf(System.currentTimeMillis()));
                                }
                            }
                        } else {
                            if (log.isInfoEnabled()) {
                                log.info(sm.getString(""abstractReplicatedMap.mapMember.unavailable"",
                                        member));
                            }
                        }
                    } catch (ClassNotFoundException | IOException e) {
                        
---------------Reference log start----------------
log.error(sm.getString(""abstractReplicatedMap.unable.deserialize.MapMessage""), e)
---------------Reference log end----------------
                    }
                }
            } catch (ChannelException ce) {
                // Handle known failed members
                FaultyMember[] faultyMembers = ce.getFaultyMembers();
                for (FaultyMember faultyMember : faultyMembers) {
                    memberDisappeared(faultyMember.getMember());
                }
                throw ce;
            }
        }
        //update our map of members, expire some if we didn't receive a ping back
        synchronized (mapMembers) {
            Member[] members = mapMembers.keySet().toArray(new Member[0]);
            long now = System.currentTimeMillis();
            for (Member member : members) {
                long access = mapMembers.get(member).longValue();
                if ( (now - access) > timeout ) {
                    log.warn(sm.getString(""abstractReplicatedMap.ping.timeout"", member, mapname));
                    memberDisappeared(member);
                }
            }
        }//synch
    }",,
tomcat,15889,"log.error(sm.getString(""nioReceiver.eventsError""), x)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/NioReceiver.java/#L179,"public void events() {
        if (events.isEmpty()) {
            return;
        }
        Runnable r = null;
        while ((r = events.pollFirst()) != null ) {
            try {
                if (log.isTraceEnabled()) {
                    log.trace(""Processing event in selector:"" + r);
                }
                r.run();
            } catch (Exception x) {
                
---------------Reference log start----------------
log.error(sm.getString(""nioReceiver.eventsError""), x)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,16614,"log.error(sm.getString(""standardContext.setManager.stop""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardContext.java/#L1993,"@Override
    public void setManager(Manager manager) {

        Lock writeLock = managerLock.writeLock();
        writeLock.lock();
        Manager oldManager = null;
        try {
            // Change components if necessary
            oldManager = this.manager;
            if (oldManager == manager) {
                return;
            }
            this.manager = manager;

            // Stop the old component if necessary
            if (oldManager instanceof Lifecycle) {
                try {
                    ((Lifecycle) oldManager).stop();
                    ((Lifecycle) oldManager).destroy();
                } catch (LifecycleException e) {
                    
---------------Reference log start----------------
log.error(sm.getString(""standardContext.setManager.stop""), e)
---------------Reference log end----------------
                }
            }

            // Start the new component if necessary
            if (manager != null) {
                manager.setContext(this);
            }
            if (getState().isAvailable() && manager instanceof Lifecycle) {
                try {
                    ((Lifecycle) manager).start();
                } catch (LifecycleException e) {
                    log.error(sm.getString(""standardContext.setManager.start""), e);
                }
            }
        } finally {
            writeLock.unlock();
        }

        // Report this property change to interested listeners
        support.firePropertyChange(""manager"", oldManager, manager);
    }",,
tomcat,17506,"log.debug(Localizer.getMessage(""jsp.tldCache.noTldInJar"", jarFileUrl.toString()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/servlet/TldScanner.java/#L327,"@Override
        public void scan(Jar jar, String webappPath, boolean isWebapp) throws IOException {
            boolean found = false;
            URL jarFileUrl = jar.getJarFileURL();
            jar.nextEntry();
            for (String entryName = jar.getEntryName();
                entryName != null;
                jar.nextEntry(), entryName = jar.getEntryName()) {
                if (!(entryName.startsWith(""META-INF/"") &&
                        entryName.endsWith(TLD_EXT))) {
                    continue;
                }
                found = true;
                TldResourcePath tldResourcePath =
                        new TldResourcePath(jarFileUrl, webappPath, entryName);
                try {
                    parseTld(tldResourcePath);
                } catch (SAXException e) {
                    throw new IOException(e);
                }
            }
            if (found) {
                if (log.isDebugEnabled()) {
                    log.debug(Localizer.getMessage(""jsp.tldCache.tldInJar"", jarFileUrl.toString()));
                }
            } else {
                foundJarWithoutTld = true;
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(Localizer.getMessage(""jsp.tldCache.noTldInJar"", jarFileUrl.toString()))
---------------Reference log end----------------
                }
            }
        }",,
tomcat,15492,"log.debug(sm.getString(""remoteIpFilter.invalidHostWithPort"", hostHeaderValue, hostHeader))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/filters/RemoteIpFilter.java/#L892,"public void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException {

        boolean isInternal = internalProxies != null &&
                internalProxies.matcher(request.getRemoteAddr()).matches();

        if (isInternal || (trustedProxies != null &&
                trustedProxies.matcher(request.getRemoteAddr()).matches())) {
            String remoteIp = null;
            // In java 6, proxiesHeaderValue should be declared as a java.util.Deque
            LinkedList<String> proxiesHeaderValue = new LinkedList<>();
            StringBuilder concatRemoteIpHeaderValue = new StringBuilder();

            for (Enumeration<String> e = request.getHeaders(remoteIpHeader); e.hasMoreElements();) {
                if (concatRemoteIpHeaderValue.length() > 0) {
                    concatRemoteIpHeaderValue.append("", "");
                }

                concatRemoteIpHeaderValue.append(e.nextElement());
            }

            String[] remoteIpHeaderValue = commaDelimitedListToStringArray(concatRemoteIpHeaderValue.toString());
            int idx;
            if (!isInternal) {
                proxiesHeaderValue.addFirst(request.getRemoteAddr());
            }
            // loop on remoteIpHeaderValue to find the first trusted remote ip and to build the proxies chain
            for (idx = remoteIpHeaderValue.length - 1; idx >= 0; idx--) {
                String currentRemoteIp = remoteIpHeaderValue[idx];
                remoteIp = currentRemoteIp;
                if (internalProxies !=null && internalProxies.matcher(currentRemoteIp).matches()) {
                    // do nothing, internalProxies IPs are not appended to the
                } else if (trustedProxies != null &&
                        trustedProxies.matcher(currentRemoteIp).matches()) {
                    proxiesHeaderValue.addFirst(currentRemoteIp);
                } else {
                    idx--; // decrement idx because break statement doesn't do it
                    break;
                }
            }
            // continue to loop on remoteIpHeaderValue to build the new value of the remoteIpHeader
            LinkedList<String> newRemoteIpHeaderValue = new LinkedList<>();
            for (; idx >= 0; idx--) {
                String currentRemoteIp = remoteIpHeaderValue[idx];
                newRemoteIpHeaderValue.addFirst(currentRemoteIp);
            }

            XForwardedRequest xRequest = new XForwardedRequest(request);
            if (remoteIp != null) {

                xRequest.setRemoteAddr(remoteIp);
                if (getEnableLookups()) {
                    // This isn't a lazy lookup but that would be a little more
                    // invasive - mainly in XForwardedRequest - and if
                    // enableLookups is true is seems reasonable that the
                    // hostname will be required so look it up here.
                    try {
                        InetAddress inetAddress = InetAddress.getByName(remoteIp);
                        // We know we need a DNS look up so use getCanonicalHostName()
                        xRequest.setRemoteHost(inetAddress.getCanonicalHostName());
                    } catch (UnknownHostException e) {
                        log.debug(sm.getString(""remoteIpFilter.invalidRemoteAddress"", remoteIp), e);
                        xRequest.setRemoteHost(remoteIp);
                    }
                } else {
                    xRequest.setRemoteHost(remoteIp);
                }

                if (proxiesHeaderValue.size() == 0) {
                    xRequest.removeHeader(proxiesHeader);
                } else {
                    String commaDelimitedListOfProxies = listToCommaDelimitedString(proxiesHeaderValue);
                    xRequest.setHeader(proxiesHeader, commaDelimitedListOfProxies);
                }
                if (newRemoteIpHeaderValue.size() == 0) {
                    xRequest.removeHeader(remoteIpHeader);
                } else {
                    String commaDelimitedRemoteIpHeaderValue = listToCommaDelimitedString(newRemoteIpHeaderValue);
                    xRequest.setHeader(remoteIpHeader, commaDelimitedRemoteIpHeaderValue);
                }
            }

            if (protocolHeader != null) {
                String protocolHeaderValue = request.getHeader(protocolHeader);
                if (protocolHeaderValue == null) {
                    // Don't modify the secure, scheme and serverPort attributes
                    // of the request
                } else if (isForwardedProtoHeaderValueSecure(protocolHeaderValue)) {
                    xRequest.setSecure(true);
                    xRequest.setScheme(""https"");
                    setPorts(xRequest, httpsServerPort);
                } else {
                    xRequest.setSecure(false);
                    xRequest.setScheme(""http"");
                    setPorts(xRequest, httpServerPort);
                }
            }

            if (hostHeader != null) {
                String hostHeaderValue = request.getHeader(hostHeader);
                if (hostHeaderValue != null) {
                    try {
                        int portIndex = Host.parse(hostHeaderValue);
                        if (portIndex > -1) {
                            
---------------Reference log start----------------
log.debug(sm.getString(""remoteIpFilter.invalidHostWithPort"", hostHeaderValue, hostHeader))
---------------Reference log end----------------
                            hostHeaderValue = hostHeaderValue.substring(0, portIndex);
                        }

                        xRequest.setServerName(hostHeaderValue);
                        if (isChangeLocalName()) {
                            xRequest.setLocalName(hostHeaderValue);
                        }

                    } catch (IllegalArgumentException iae) {
                        log.debug(sm.getString(""remoteIpFilter.invalidHostHeader"", hostHeaderValue, hostHeader));
                    }
                }
            }
            request.setAttribute(Globals.REQUEST_FORWARDED_ATTRIBUTE, Boolean.TRUE);

            if (log.isDebugEnabled()) {
                log.debug(""Incoming request "" + request.getRequestURI() + "" with originalRemoteAddr ["" + request.getRemoteAddr() +
                        ""], originalRemoteHost=["" + request.getRemoteHost() + ""], originalSecure=["" + request.isSecure() +
                        ""], originalScheme=["" + request.getScheme() + ""], originalServerName=["" + request.getServerName() +
                        ""], originalServerPort=["" + request.getServerPort() +
                        ""] will be seen as newRemoteAddr=["" + xRequest.getRemoteAddr() +
                        ""], newRemoteHost=["" + xRequest.getRemoteHost() + ""], newSecure=["" + xRequest.isSecure() +
                        ""], newScheme=["" + xRequest.getScheme() + ""], newServerName=["" + xRequest.getServerName() +
                        ""], newServerPort=["" + xRequest.getServerPort() + ""]"");
            }
            if (requestAttributesEnabled) {
                request.setAttribute(AccessLog.REMOTE_ADDR_ATTRIBUTE,
                        xRequest.getRemoteAddr());
                request.setAttribute(Globals.REMOTE_ADDR_ATTRIBUTE,
                        xRequest.getRemoteAddr());
                request.setAttribute(AccessLog.REMOTE_HOST_ATTRIBUTE,
                        xRequest.getRemoteHost());
                request.setAttribute(AccessLog.PROTOCOL_ATTRIBUTE,
                        xRequest.getProtocol());
                request.setAttribute(AccessLog.SERVER_NAME_ATTRIBUTE,
                        xRequest.getServerName());
                request.setAttribute(AccessLog.SERVER_PORT_ATTRIBUTE,
                        Integer.valueOf(xRequest.getServerPort()));
            }
            chain.doFilter(xRequest, response);
        } else {
            if (log.isDebugEnabled()) {
                log.debug(""Skip RemoteIpFilter for request "" + request.getRequestURI() + "" with originalRemoteAddr '""
                        + request.getRemoteAddr() + ""'"");
            }
            chain.doFilter(request, response);
        }

    }",,
tomcat,16346,"log.debug(sm.getString(""deltaManager.receiveMessage.eventType"", getName(), msg.getEventTypeString(), sender))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/session/DeltaManager.java/#L1113,"protected void messageReceived(SessionMessage msg, Member sender) {
        ClassLoader contextLoader = Thread.currentThread().getContextClassLoader();
        try {

            ClassLoader[] loaders = getClassLoaders();
            Thread.currentThread().setContextClassLoader(loaders[0]);
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""deltaManager.receiveMessage.eventType"", getName(), msg.getEventTypeString(), sender))
---------------Reference log end----------------
            }

            switch (msg.getEventType()) {
                case SessionMessage.EVT_GET_ALL_SESSIONS:
                    handleGET_ALL_SESSIONS(msg,sender);
                    break;
                case SessionMessage.EVT_ALL_SESSION_DATA:
                    handleALL_SESSION_DATA(msg,sender);
                    break;
                case SessionMessage.EVT_ALL_SESSION_TRANSFERCOMPLETE:
                    handleALL_SESSION_TRANSFERCOMPLETE(msg,sender);
                    break;
                case SessionMessage.EVT_SESSION_CREATED:
                    handleSESSION_CREATED(msg,sender);
                    break;
                case SessionMessage.EVT_SESSION_EXPIRED:
                    handleSESSION_EXPIRED(msg,sender);
                    break;
                case SessionMessage.EVT_SESSION_ACCESSED:
                    handleSESSION_ACCESSED(msg,sender);
                    break;
                case SessionMessage.EVT_SESSION_DELTA:
                   handleSESSION_DELTA(msg,sender);
                   break;
                case SessionMessage.EVT_CHANGE_SESSION_ID:
                    handleCHANGE_SESSION_ID(msg,sender);
                    break;
                case SessionMessage.EVT_ALL_SESSION_NOCONTEXTMANAGER:
                    handleALL_SESSION_NOCONTEXTMANAGER(msg,sender);
                    break;
                default:
                    //we didn't recognize the message type, do nothing
                    break;
            } //switch
        } catch (Exception x) {
            log.error(sm.getString(""deltaManager.receiveMessage.error"",getName()), x);
        } finally {
            Thread.currentThread().setContextClassLoader(contextLoader);
        }
    }",,
tomcat,16126,"log.info(sm.getString(""listener.createFailed"", className), e)",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/ListenerCreateRule.java/#L53,"@Override
    public void begin(String namespace, String name, Attributes attributes)
            throws Exception {
        if (""true"".equals(attributes.getValue(""optional""))) {
            try {
                super.begin(namespace, name, attributes);
            } catch (Exception e) {
                String className = getRealClassName(attributes);
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.info(sm.getString(""listener.createFailed"", className), e)
---------------Reference log end----------------
                } else {
                    log.info(sm.getString(""listener.createFailed"", className));
                }
                Object instance = new OptionalListener(className);
                digester.push(instance);
                StringBuilder code = digester.getGeneratedCode();
                if (code != null) {
                    code.append(OptionalListener.class.getName().replace('$', '.')).append(' ');
                    code.append(digester.toVariableName(instance)).append("" = new "");
                    code.append(OptionalListener.class.getName().replace('$', '.')).append(""(\"""").append(className).append(""\"");"");
                    code.append(System.lineSeparator());
                }
            }
        } else {
            super.begin(namespace, name, attributes);
        }
    }",,
tomcat,16910,"log.debug(sm.getString(""upgradeHandler.writeBody"", connectionId, stream.getIdAsString(), Integer.toString(len), Boolean.valueOf(finished)))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/Http2UpgradeHandler.java/#L757,"void writeBody(Stream stream, ByteBuffer data, int len, boolean finished) throws IOException {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(sm.getString(""upgradeHandler.writeBody"", connectionId, stream.getIdAsString(), Integer.toString(len), Boolean.valueOf(finished)))
---------------Reference log end----------------
        }

        reduceOverheadCount(FrameType.DATA);

        // Need to check this now since sending end of stream will change this.
        boolean writeable = stream.canWrite();
        byte[] header = new byte[9];
        ByteUtil.setThreeBytes(header, 0, len);
        header[3] = FrameType.DATA.getIdByte();
        if (finished) {
            header[4] = FLAG_END_OF_STREAM;
            stream.sentEndOfStream();
            if (!stream.isActive()) {
                setConnectionTimeoutForStreamCount(activeRemoteStreamCount.decrementAndGet());
            }
        }
        if (writeable) {
            ByteUtil.set31Bits(header, 5, stream.getIdAsInt());
            synchronized (socketWrapper) {
                try {
                    socketWrapper.write(true, header, 0, header.length);
                    int orgLimit = data.limit();
                    data.limit(data.position() + len);
                    socketWrapper.write(true, data);
                    data.limit(orgLimit);
                    socketWrapper.flush(true);
                } catch (IOException ioe) {
                    handleAppInitiatedIOException(ioe);
                }
            }
        }
    }",,
tomcat,17652,"log.debug(""Connection doesn't fit into busy array, connection will not be traceable."")",debug,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L777,"protected PooledConnection createConnection(long now, PooledConnection notUsed, String username, String password) throws SQLException {
        //no connections where available we'll create one
        PooledConnection con = create(false);
        if (username!=null) {
          con.getAttributes().put(PooledConnection.PROP_USER, username);
        }
        if (password!=null) {
          con.getAttributes().put(PooledConnection.PROP_PASSWORD, password);
        }
        boolean error = false;
        try {
            //connect and validate the connection
            con.lock();
            con.connect();
            if (con.validate(PooledConnection.VALIDATE_INIT)) {
                //no need to lock a new one, its not contented
                con.setTimestamp(now);
                if (getPoolProperties().isLogAbandoned()) {
                    con.setStackTrace(getThreadDump());
                }
                if (!busy.offer(con)) {
                    
---------------Reference log start----------------
log.debug(""Connection doesn't fit into busy array, connection will not be traceable."")
---------------Reference log end----------------
                }
                createdCount.incrementAndGet();
                return con;
            } else {
                //validation failed, make sure we disconnect
                //and clean up
                throw new SQLException(""Validation Query Failed, enable logValidationErrors for more details."");
            } //end if
        } catch (Exception e) {
            error = true;
            if (log.isDebugEnabled()) {
              log.debug(""Unable to create a new JDBC connection."", e);
            }
            if (e instanceof SQLException) {
                throw (SQLException)e;
            } else {
                SQLException ex = new SQLException(e.getMessage());
                ex.initCause(e);
                throw ex;
            }
        } finally {
            // con can never be null here
            if (error ) {
                release(con);
            }
            con.unlock();
        }//catch
    }",,
tomcat,15574,"containerLog.trace(""Perform a nested group search with base "" + roleBase + "" and filter "" + filter)",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JNDIRealm.java/#L1975,"protected List<String> getRoles(JNDIConnection connection, User user) throws NamingException {

        if (user == null) {
            return null;
        }

        // This is returned from the directory so will be attribute value
        // escaped if required
        String dn = user.getDN();
        // This is the name the user provided to the authentication process so
        // it will not be escaped
        String username = user.getUserName();
        String userRoleId = user.getUserRoleId();

        if (dn == null || username == null) {
            return null;
        }

        if (containerLog.isTraceEnabled()) {
            containerLog.trace(""  getRoles("" + dn + "")"");
        }

        // Start with roles retrieved from the user entry
        List<String> list = new ArrayList<>();
        List<String> userRoles = user.getRoles();
        if (userRoles != null) {
            list.addAll(userRoles);
        }
        if (commonRole != null) {
            list.add(commonRole);
        }

        if (containerLog.isTraceEnabled()) {
            containerLog.trace(""  Found "" + list.size() + "" user internal roles"");
            containerLog.trace(""  Found user internal roles "" + list.toString());
        }

        // Are we configured to do role searches?
        if ((connection.roleFormat == null) || (roleName == null)) {
            return list;
        }

        // Set up parameters for an appropriate search filter
        // The dn is already attribute value escaped but the others are not
        // This is a filter so all input will require filter escaping
        String filter = connection.roleFormat.format(new String[] {
                doFilterEscaping(dn),
                doFilterEscaping(doAttributeValueEscaping(username)),
                doFilterEscaping(doAttributeValueEscaping(userRoleId)) });
        SearchControls controls = new SearchControls();
        if (roleSubtree) {
            controls.setSearchScope(SearchControls.SUBTREE_SCOPE);
        } else {
            controls.setSearchScope(SearchControls.ONELEVEL_SCOPE);
        }
        controls.setReturningAttributes(new String[] {roleName});

        String base = null;
        if (connection.roleBaseFormat != null) {
            NameParser np = connection.context.getNameParser("""");
            Name name = np.parse(dn);
            String nameParts[] = new String[name.size()];
            for (int i = 0; i < name.size(); i++) {
                // May have been returned with \<char> escaping rather than
                // \<hex><hex>. Make sure it is \<hex><hex>.
                nameParts[i] =  convertToHexEscape(name.get(i));
            }
            base = connection.roleBaseFormat.format(nameParts);
        } else {
            base = """";
        }

        // Perform the configured search and process the results
        NamingEnumeration<SearchResult> results = searchAsUser(connection.context, user, base, filter, controls,
                isRoleSearchAsUser());

        if (results == null) {
            return list;  // Should never happen, but just in case ...
        }

        Map<String, String> groupMap = new HashMap<>();
        try {
            while (results.hasMore()) {
                SearchResult result = results.next();
                Attributes attrs = result.getAttributes();
                if (attrs == null) {
                    continue;
                }
                String dname = getDistinguishedName(connection.context, base, result);
                String name = getAttributeValue(roleName, attrs);
                if (name != null && dname != null) {
                    groupMap.put(dname, name);
                }
            }
        } catch (PartialResultException ex) {
            if (!adCompat) {
                throw ex;
            }
        } finally {
            results.close();
        }

        if (containerLog.isTraceEnabled()) {
            Set<Entry<String, String>> entries = groupMap.entrySet();
            containerLog.trace(""  Found "" + entries.size() + "" direct roles"");
            for (Entry<String, String> entry : entries) {
                containerLog.trace(  ""  Found direct role "" + entry.getKey() + "" -> "" + entry.getValue());
            }
        }

        // if nested group search is enabled, perform searches for nested groups until no new group is found
        if (getRoleNested()) {

            // The following efficient algorithm is known as memberOf Algorithm, as described in ""Practices in
            // Directory Groups"". It avoids group slurping and handles cyclic group memberships as well.
            // See http://middleware.internet2.edu/dir/ for details

            Map<String, String> newGroups = new HashMap<>(groupMap);
            while (!newGroups.isEmpty()) {
                Map<String, String> newThisRound = new HashMap<>(); // Stores the groups we find in this iteration

                for (Entry<String, String> group : newGroups.entrySet()) {
                    // Group key is already value escaped if required
                    // Group value is not value escaped
                    // Everything needs to be filter escaped
                    filter = connection.roleFormat.format(new String[] {
                            doFilterEscaping(group.getKey()),
                            doFilterEscaping(doAttributeValueEscaping(group.getValue())),
                            doFilterEscaping(doAttributeValueEscaping(group.getValue())) });

                    if (containerLog.isTraceEnabled()) {
                        
---------------Reference log start----------------
containerLog.trace(""Perform a nested group search with base "" + roleBase + "" and filter "" + filter)
---------------Reference log end----------------
                    }

                    results = searchAsUser(connection.context, user, base, filter, controls, isRoleSearchAsUser());

                    try {
                        while (results.hasMore()) {
                            SearchResult result = results.next();
                            Attributes attrs = result.getAttributes();
                            if (attrs == null) {
                                continue;
                            }
                            String dname = getDistinguishedName(connection.context, roleBase, result);
                            String name = getAttributeValue(roleName, attrs);
                            if (name != null && dname != null && !groupMap.keySet().contains(dname)) {
                                groupMap.put(dname, name);
                                newThisRound.put(dname, name);

                                if (containerLog.isTraceEnabled()) {
                                    containerLog.trace(""  Found nested role "" + dname + "" -> "" + name);
                                }
                            }
                        }
                    } catch (PartialResultException ex) {
                        if (!adCompat) {
                            throw ex;
                        }
                    } finally {
                        results.close();
                    }
                }

                newGroups = newThisRound;
            }
        }

        list.addAll(groupMap.values());
        return list;
    }",,
tomcat,15855,"log.warn(sm.getString(""nonBlockingCoordinator.electionMessage.sendfailed"", msg.getMembers()[current]))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/group/interceptors/NonBlockingCoordinator.java/#L277,"protected void sendElectionMsgToNextInline(Member local, CoordinationMessage msg) throws ChannelException {
        int next = Arrays.nextIndex(local,msg.getMembers());
        int current = next;
        msg.leader = msg.getMembers()[0];
        boolean sent =  false;
        while ( !sent && current >= 0 ) {
            try {
                sendElectionMsg(local, msg.getMembers()[current], msg);
                sent = true;
            }catch ( ChannelException x  ) {
                
---------------Reference log start----------------
log.warn(sm.getString(""nonBlockingCoordinator.electionMessage.sendfailed"", msg.getMembers()[current]))
---------------Reference log end----------------
                current = Arrays.nextIndex(msg.getMembers()[current],msg.getMembers());
                if ( current == next ) {
                    throw x;
                }
            }
        }
    }",,
tomcat,16738,"log.warn(sm.getString(""standardHost.problematicAppBase"", getName()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardHost.java/#L255,"@Override
    public void setAppBase(String appBase) {
        if (appBase.trim().equals("""")) {
            
---------------Reference log start----------------
log.warn(sm.getString(""standardHost.problematicAppBase"", getName()))
---------------Reference log end----------------
        }
        String oldAppBase = this.appBase;
        this.appBase = appBase;
        support.firePropertyChange(""appBase"", oldAppBase, this.appBase);
        this.appBaseFile = null;
    }",,
tomcat,16930,"log.debug(sm.getString(""upgradeHandler.goaway.debug"", connectionId, Integer.toString(lastStreamId), Long.toHexString(errorCode), debugData))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/Http2UpgradeHandler.java/#L1794,"@Override
    public void goaway(int lastStreamId, long errorCode, String debugData) {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(sm.getString(""upgradeHandler.goaway.debug"", connectionId, Integer.toString(lastStreamId), Long.toHexString(errorCode), debugData))
---------------Reference log end----------------
        }
        close();
    }",,
tomcat,16605,"log.error(sm.getString(""naming.unbindFailed"", name), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/NamingContextListener.java/#L1212,"public void removeResourceEnvRef(String name) {

        try {
            envCtx.unbind(name);
        } catch (NamingException e) {
            
---------------Reference log start----------------
log.error(sm.getString(""naming.unbindFailed"", name), e)
---------------Reference log end----------------
        }

    }",,
tomcat,16219,"log.info(sm.getString(""hostConfig.deployWar"", war.getAbsolutePath()))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/HostConfig.java/#L952,"protected void deployWAR(ContextName cn, File war) {

        File xml = new File(host.getAppBaseFile(), cn.getBaseName() + ""/"" + Constants.ApplicationContextXml);

        File warTracker = new File(host.getAppBaseFile(), cn.getBaseName() + Constants.WarTracker);

        boolean xmlInWar = false;
        try (JarFile jar = new JarFile(war)) {
            JarEntry entry = jar.getJarEntry(Constants.ApplicationContextXml);
            if (entry != null) {
                xmlInWar = true;
            }
        } catch (IOException e) {
            /* Ignore */
        }

        // If there is an expanded directory then any xml in that directory
        // should only be used if the directory is not out of date and
        // unpackWARs is true. Note the code below may apply further limits
        boolean useXml = false;
        // If the xml file exists then expandedDir must exists so no need to
        // test that here
        if (xml.exists() && unpackWARs && (!warTracker.exists() || warTracker.lastModified() == war.lastModified())) {
            useXml = true;
        }

        Context context = null;
        boolean deployThisXML = isDeployThisXML(war, cn);

        try {
            if (deployThisXML && useXml && !copyXML) {
                synchronized (digesterLock) {
                    try {
                        context = (Context) digester.parse(xml);
                    } catch (Exception e) {
                        log.error(sm.getString(""hostConfig.deployDescriptor.error"", war.getAbsolutePath()), e);
                    } finally {
                        digester.reset();
                        if (context == null) {
                            context = new FailedContext();
                        }
                    }
                }
                context.setConfigFile(xml.toURI().toURL());
            } else if (deployThisXML && xmlInWar) {
                synchronized (digesterLock) {
                    try (JarFile jar = new JarFile(war)) {
                        JarEntry entry = jar.getJarEntry(Constants.ApplicationContextXml);
                        try (InputStream istream = jar.getInputStream(entry)) {
                            context = (Context) digester.parse(istream);
                        }
                    } catch (Exception e) {
                        log.error(sm.getString(""hostConfig.deployDescriptor.error"", war.getAbsolutePath()), e);
                    } finally {
                        digester.reset();
                        if (context == null) {
                            context = new FailedContext();
                        }
                        context.setConfigFile(UriUtil.buildJarUrl(war, Constants.ApplicationContextXml));
                    }
                }
            } else if (!deployThisXML && xmlInWar) {
                // Block deployment as META-INF/context.xml may contain security
                // configuration necessary for a secure deployment.
                log.error(sm.getString(""hostConfig.deployDescriptor.blocked"",
                        cn.getPath(), Constants.ApplicationContextXml,
                        new File(host.getConfigBaseFile(), cn.getBaseName() + "".xml"")));
            } else {
                context = (Context) Class.forName(contextClass).getConstructor().newInstance();
            }
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            log.error(sm.getString(""hostConfig.deployWar.error"", war.getAbsolutePath()), t);
        } finally {
            if (context == null) {
                context = new FailedContext();
            }
        }

        boolean copyThisXml = false;
        if (deployThisXML) {
            if (host instanceof StandardHost) {
                copyThisXml = ((StandardHost) host).isCopyXML();
            }

            // If Host is using default value Context can override it.
            if (!copyThisXml && context instanceof StandardContext) {
                copyThisXml = ((StandardContext) context).getCopyXML();
            }

            if (xmlInWar && copyThisXml) {
                // Change location of XML file to config base
                xml = new File(host.getConfigBaseFile(), cn.getBaseName() + "".xml"");
                try (JarFile jar = new JarFile(war)) {
                    JarEntry entry = jar.getJarEntry(Constants.ApplicationContextXml);
                    try (InputStream istream = jar.getInputStream(entry);
                            OutputStream ostream = new FileOutputStream(xml)) {
                        IOTools.flow(istream, ostream);
                    }
                } catch (IOException e) {
                    /* Ignore */
                }
            }
        }

        DeployedApplication deployedApp = new DeployedApplication(
                cn.getName(), xml.exists() && deployThisXML && copyThisXml);

        long startTime = 0;
        // Deploy the application in this WAR file
        if(log.isInfoEnabled()) {
            startTime = System.currentTimeMillis();
            
---------------Reference log start----------------
log.info(sm.getString(""hostConfig.deployWar"", war.getAbsolutePath()))
---------------Reference log end----------------
        }

        try {
            // Populate redeploy resources with the WAR file
            deployedApp.redeployResources.put(war.getAbsolutePath(), Long.valueOf(war.lastModified()));

            if (deployThisXML && xml.exists() && copyThisXml) {
                deployedApp.redeployResources.put(xml.getAbsolutePath(), Long.valueOf(xml.lastModified()));
            } else {
                // In case an XML file is added to the config base later
                deployedApp.redeployResources.put(
                        (new File(host.getConfigBaseFile(), cn.getBaseName() + "".xml"")).getAbsolutePath(),
                        Long.valueOf(0));
            }

            Class<?> clazz = Class.forName(host.getConfigClass());
            LifecycleListener listener = (LifecycleListener) clazz.getConstructor().newInstance();
            context.addLifecycleListener(listener);

            context.setName(cn.getName());
            context.setPath(cn.getPath());
            context.setWebappVersion(cn.getVersion());
            context.setDocBase(cn.getBaseName() + "".war"");
            host.addChild(context);
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            log.error(sm.getString(""hostConfig.deployWar.error"", war.getAbsolutePath()), t);
        } finally {
            // If we're unpacking WARs, the docBase will be mutated after
            // starting the context
            boolean unpackWAR = unpackWARs;
            if (unpackWAR && context instanceof StandardContext) {
                unpackWAR = ((StandardContext) context).getUnpackWAR();
            }
            if (unpackWAR && context.getDocBase() != null) {
                File docBase = new File(host.getAppBaseFile(), cn.getBaseName());
                deployedApp.redeployResources.put(docBase.getAbsolutePath(), Long.valueOf(docBase.lastModified()));
                addWatchedResources(deployedApp, docBase.getAbsolutePath(), context);
                if (deployThisXML && !copyThisXml && (xmlInWar || xml.exists())) {
                    deployedApp.redeployResources.put(xml.getAbsolutePath(), Long.valueOf(xml.lastModified()));
                }
            } else {
                // Passing null for docBase means that no resources will be
                // watched. This will be logged at debug level.
                addWatchedResources(deployedApp, null, context);
            }
            // Add the global redeploy resources (which are never deleted) at
            // the end so they don't interfere with the deletion process
            addGlobalRedeployResources(deployedApp);
        }

        deployed.put(cn.getName(), deployedApp);

        if (log.isInfoEnabled()) {
            log.info(sm.getString(""hostConfig.deployWar.finished"",
                    war.getAbsolutePath(), Long.valueOf(System.currentTimeMillis() - startTime)));
        }
    }",,
tomcat,16745,"container.getLogger().debug(""Processing "" + errorPage)",getLogger,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardHostValve.java/#L357,"private boolean custom(Request request, Response response,
                             ErrorPage errorPage) {

        if (container.getLogger().isDebugEnabled()) {
            
---------------Reference log start----------------
container.getLogger().debug(""Processing "" + errorPage)
---------------Reference log end----------------
        }

        try {
            // Forward control to the specified location
            ServletContext servletContext =
                request.getContext().getServletContext();
            RequestDispatcher rd =
                servletContext.getRequestDispatcher(errorPage.getLocation());

            if (rd == null) {
                container.getLogger().error(
                    sm.getString(""standardHostValue.customStatusFailed"", errorPage.getLocation()));
                return false;
            }

            if (response.isCommitted()) {
                // Response is committed - including the error page is the
                // best we can do
                rd.include(request.getRequest(), response.getResponse());
            } else {
                // Reset the response (keeping the real error code and message)
                response.resetBuffer(true);
                response.setContentLength(-1);

                rd.forward(request.getRequest(), response.getResponse());

                // If we forward, the response is suspended again
                response.setSuspended(false);
            }

            // Indicate that we have successfully processed this custom page
            return true;

        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            // Report our failure to process this custom page
            container.getLogger().error(""Exception Processing "" + errorPage, t);
            return false;
        }
    }",,
tomcat,15710,"log.info(sm.getString(""mcastServiceImpl.setInterface"", mcastBindAddress))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/membership/McastServiceImpl.java/#L223,"protected void setupSocket() throws IOException {
        if (mcastBindAddress != null) {
            try {
                log.info(sm.getString(""mcastServiceImpl.bind"", address, Integer.toString(port)));
                socket = new MulticastSocket(new InetSocketAddress(address,port));
            } catch (BindException e) {
                /*
                 * On some platforms (e.g. Linux) it is not possible to bind
                 * to the multicast address. In this case only bind to the
                 * port.
                 */
                log.info(sm.getString(""mcastServiceImpl.bind.failed""));
                socket = new MulticastSocket(port);
            }
        } else {
            socket = new MulticastSocket(port);
        }
        socket.setLoopbackMode(localLoopbackDisabled); //hint if we want disable loop back(local machine) messages
        if (mcastBindAddress != null) {
            if(log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""mcastServiceImpl.setInterface"", mcastBindAddress))
---------------Reference log end----------------
            }
            socket.setInterface(mcastBindAddress);
        } //end if
        //force a so timeout so that we don't block forever
        if (mcastSoTimeout <= 0) {
            mcastSoTimeout = (int)sendFrequency;
        }
        if (log.isInfoEnabled()) {
            log.info(sm.getString(""mcastServiceImpl.setSoTimeout"",
                    Integer.toString(mcastSoTimeout)));
        }
        socket.setSoTimeout(mcastSoTimeout);

        if ( mcastTTL >= 0 ) {
            if(log.isInfoEnabled()) {
                log.info(sm.getString(""mcastServiceImpl.setTTL"", Integer.toString(mcastTTL)));
            }
            socket.setTimeToLive(mcastTTL);
        }
    }",,
tomcat,16241,"log.warn(sm.getString(""hostConfig.canonicalizing"", resource.getParentFile(), app.name), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/HostConfig.java/#L1579,"private boolean isDeletableResource(DeployedApplication app, File resource) {
        // The resource may be a file, a directory or a symlink to a file or
        // directory.

        // Check that the resource is absolute. This should always be the case.
        if (!resource.isAbsolute()) {
            log.warn(sm.getString(""hostConfig.resourceNotAbsolute"", app.name, resource));
            return false;
        }

        // Determine where the resource is located
        String canonicalLocation;
        try {
            canonicalLocation = resource.getParentFile().getCanonicalPath();
        } catch (IOException e) {
            
---------------Reference log start----------------
log.warn(sm.getString(""hostConfig.canonicalizing"", resource.getParentFile(), app.name), e)
---------------Reference log end----------------
            return false;
        }

        String canonicalAppBase;
        try {
            canonicalAppBase = host.getAppBaseFile().getCanonicalPath();
        } catch (IOException e) {
            log.warn(sm.getString(
                    ""hostConfig.canonicalizing"", host.getAppBaseFile(), app.name), e);
            return false;
        }

        if (canonicalLocation.equals(canonicalAppBase)) {
            // Resource is located in the appBase so it may be deleted
            return true;
        }

        String canonicalConfigBase;
        try {
            canonicalConfigBase = host.getConfigBaseFile().getCanonicalPath();
        } catch (IOException e) {
            log.warn(sm.getString(
                    ""hostConfig.canonicalizing"", host.getConfigBaseFile(), app.name), e);
            return false;
        }

        if (canonicalLocation.equals(canonicalConfigBase) &&
                resource.getName().endsWith("".xml"")) {
            // Resource is an xml file in the configBase so it may be deleted
            return true;
        }

        // All other resources should not be deleted
        return false;
    }",,
tomcat,17046,"log.warn(sm.getString(""jarScan.webinfclassesFail""), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/scan/StandardJarScanner.java/#L222,"@Override
    public void scan(JarScanType scanType, ServletContext context,
            JarScannerCallback callback) {

        if (log.isTraceEnabled()) {
            log.trace(sm.getString(""jarScan.webinflibStart""));
        }

        if (jarScanFilter.isSkipAll()) {
            return;
        }

        Set<URL> processedURLs = new HashSet<>();

        // Scan WEB-INF/lib
        Set<String> dirList = context.getResourcePaths(Constants.WEB_INF_LIB);
        if (dirList != null) {
            for (String path : dirList) {
                if (path.endsWith(Constants.JAR_EXT) &&
                        getJarScanFilter().check(scanType,
                                path.substring(path.lastIndexOf('/')+1))) {
                    // Need to scan this JAR
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""jarScan.webinflibJarScan"", path));
                    }
                    URL url = null;
                    try {
                        url = context.getResource(path);
                        processedURLs.add(url);
                        process(scanType, callback, url, path, true, null);
                    } catch (IOException e) {
                        log.warn(sm.getString(""jarScan.webinflibFail"", url), e);
                    }
                } else {
                    if (log.isTraceEnabled()) {
                        log.trace(sm.getString(""jarScan.webinflibJarNoScan"", path));
                    }
                }
            }
        }

        // Scan WEB-INF/classes
        try {
            URL webInfURL = context.getResource(Constants.WEB_INF_CLASSES);
            if (webInfURL != null) {
                // WEB-INF/classes will also be included in the URLs returned
                // by the web application class loader so ensure the class path
                // scanning below does not re-scan this location.
                processedURLs.add(webInfURL);

                if (isScanAllDirectories()) {
                    URL url = context.getResource(Constants.WEB_INF_CLASSES + ""/META-INF"");
                    if (url != null) {
                        try {
                            callback.scanWebInfClasses();
                        } catch (IOException e) {
                            
---------------Reference log start----------------
log.warn(sm.getString(""jarScan.webinfclassesFail""), e)
---------------Reference log end----------------
                        }
                    }
                }
            }
        } catch (MalformedURLException e) {
            // Ignore. Won't happen. URLs are of the correct form.
        }

        // Scan the classpath
        if (isScanClassPath()) {
            doScanClassPath(scanType, context, callback, processedURLs);
        }
    }",,
tomcat,17396,"log.error(sm.getString(""digester.error.end""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/Digester.java/#L1035,"@Override
    public void endElement(String namespaceURI, String localName, String qName)
            throws SAXException {

        boolean debug = log.isDebugEnabled();

        if (debug) {
            if (saxLog.isDebugEnabled()) {
                saxLog.debug(""endElement("" + namespaceURI + "","" + localName + "","" + qName + "")"");
            }
            log.debug(""  match='"" + match + ""'"");
            log.debug(""  bodyText='"" + bodyText + ""'"");
        }

        // Parse system properties
        bodyText = updateBodyText(bodyText);

        // the actual element name is either in localName or qName, depending
        // on whether the parser is namespace aware
        String name = localName;
        if ((name == null) || (name.length() < 1)) {
            name = qName;
        }

        // Fire ""body"" events for all relevant rules
        List<Rule> rules = matches.pop();
        if ((rules != null) && (rules.size() > 0)) {
            String bodyText = this.bodyText.toString().intern();
            for (Rule value : rules) {
                try {
                    Rule rule = value;
                    if (debug) {
                        log.debug(""  Fire body() for "" + rule);
                    }
                    rule.body(namespaceURI, name, bodyText);
                } catch (Exception e) {
                    log.error(sm.getString(""digester.error.body""), e);
                    throw createSAXException(e);
                } catch (Error e) {
                    log.error(sm.getString(""digester.error.body""), e);
                    throw e;
                }
            }
        } else {
            if (debug) {
                log.debug(sm.getString(""digester.noRulesFound"", match));
            }
            if (rulesValidation) {
                log.warn(sm.getString(""digester.noRulesFound"", match));
            }
        }

        // Recover the body text from the surrounding element
        bodyText = bodyTexts.pop();

        // Fire ""end"" events for all relevant rules in reverse order
        if (rules != null) {
            for (int i = 0; i < rules.size(); i++) {
                int j = (rules.size() - i) - 1;
                try {
                    Rule rule = rules.get(j);
                    if (debug) {
                        log.debug(""  Fire end() for "" + rule);
                    }
                    rule.end(namespaceURI, name);
                } catch (Exception e) {
                    
---------------Reference log start----------------
log.error(sm.getString(""digester.error.end""), e)
---------------Reference log end----------------
                    throw createSAXException(e);
                } catch (Error e) {
                    log.error(sm.getString(""digester.error.end""), e);
                    throw e;
                }
            }
        }

        // Recover the previous match expression
        int slash = match.lastIndexOf('/');
        if (slash >= 0) {
            match = match.substring(0, slash);
        } else {
            match = """";
        }

    }",,
tomcat,16543,"log.info(sm.getString(""cgiServlet.runBadHeader"", line))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L1692,"protected void run() throws IOException {

            /*
             * REMIND:  this method feels too big; should it be re-written?
             */

            if (!isReady()) {
                throw new IOException(this.getClass().getName() + "": not ready to run."");
            }

            if (log.isDebugEnabled()) {
                log.debug(""envp: ["" + env + ""], command: ["" + command + ""]"");
            }

            if ((command.contains(File.separator + ""."" + File.separator)) ||
                    (command.contains(File.separator + "".."")) ||
                    (command.contains("".."" + File.separator))) {
                throw new IOException(this.getClass().getName() + ""Illegal Character in CGI command path "" +
                        ""('.' or '..') detected.  Not running CGI ["" + command + ""]."");
            }

            /* original content/structure of this section taken from
             * http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4216884
             * with major modifications by Martin Dengler
             */
            Runtime rt = null;
            BufferedReader cgiHeaderReader = null;
            InputStream cgiOutput = null;
            BufferedReader commandsStdErr = null;
            Thread errReaderThread = null;
            BufferedOutputStream commandsStdIn = null;
            Process proc = null;
            int bufRead = -1;

            List<String> cmdAndArgs = new ArrayList<>();
            if (cgiExecutable.length() != 0) {
                cmdAndArgs.add(cgiExecutable);
            }
            if (cgiExecutableArgs != null) {
                cmdAndArgs.addAll(cgiExecutableArgs);
            }
            cmdAndArgs.add(command);
            cmdAndArgs.addAll(params);

            try {
                rt = Runtime.getRuntime();
                proc = rt.exec(
                        cmdAndArgs.toArray(new String[0]),
                        hashToStringArray(env), wd);

                String sContentLength = env.get(""CONTENT_LENGTH"");

                if(!"""".equals(sContentLength)) {
                    commandsStdIn = new BufferedOutputStream(proc.getOutputStream());
                    IOTools.flow(stdin, commandsStdIn);
                    commandsStdIn.flush();
                    commandsStdIn.close();
                }

                /* we want to wait for the process to exit,  Process.waitFor()
                 * is useless in our situation; see
                 * http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4223650
                 */

                boolean isRunning = true;
                commandsStdErr = new BufferedReader
                    (new InputStreamReader(proc.getErrorStream()));
                final BufferedReader stdErrRdr = commandsStdErr ;

                errReaderThread = new Thread(() -> sendToLog(stdErrRdr));
                errReaderThread.start();

                InputStream cgiHeaderStream =
                    new HTTPHeaderInputStream(proc.getInputStream());
                cgiHeaderReader =
                    new BufferedReader(new InputStreamReader(cgiHeaderStream));

                // Need to be careful here. If sendError() is called the
                // response body should be provided by the standard error page
                // process. But, if the output of the CGI process isn't read
                // then that process can hang.
                boolean skipBody = false;

                while (isRunning) {
                    try {
                        //set headers
                        String line = null;
                        while (((line = cgiHeaderReader.readLine()) != null) && !line.isEmpty()) {
                            if (log.isTraceEnabled()) {
                                log.trace(""addHeader(\"""" + line + ""\"")"");
                            }
                            if (line.startsWith(""HTTP"")) {
                                skipBody = setStatus(response, getSCFromHttpStatusLine(line));
                            } else if (line.indexOf(':') >= 0) {
                                String header =
                                    line.substring(0, line.indexOf(':')).trim();
                                String value =
                                    line.substring(line.indexOf(':') + 1).trim();
                                if (header.equalsIgnoreCase(""status"")) {
                                    skipBody = setStatus(response, getSCFromCGIStatusHeader(value));
                                } else {
                                    response.addHeader(header , value);
                                }
                            } else {
                                
---------------Reference log start----------------
log.info(sm.getString(""cgiServlet.runBadHeader"", line))
---------------Reference log end----------------
                            }
                        }

                        //write output
                        byte[] bBuf = new byte[2048];

                        OutputStream out = response.getOutputStream();
                        cgiOutput = proc.getInputStream();

                        try {
                            while (!skipBody && (bufRead = cgiOutput.read(bBuf)) != -1) {
                                if (log.isTraceEnabled()) {
                                    log.trace(""output "" + bufRead + "" bytes of data"");
                                }
                                out.write(bBuf, 0, bufRead);
                            }
                        } finally {
                            // Attempt to consume any leftover byte if something bad happens,
                            // such as a socket disconnect on the servlet side; otherwise, the
                            // external process could hang
                            if (bufRead != -1) {
                                while ((bufRead = cgiOutput.read(bBuf)) != -1) {
                                    // NOOP - just read the data
                                }
                            }
                        }

                        proc.exitValue(); // Throws exception if alive

                        isRunning = false;

                    } catch (IllegalThreadStateException e) {
                        try {
                            Thread.sleep(500);
                        } catch (InterruptedException ignored) {
                            // Ignore
                        }
                    }
                } //replacement for Process.waitFor()

            } catch (IOException e){
                log.warn(sm.getString(""cgiServlet.runFail""), e);
                throw e;
            } finally {
                // Close the header reader
                if (cgiHeaderReader != null) {
                    try {
                        cgiHeaderReader.close();
                    } catch (IOException ioe) {
                        log.warn(sm.getString(""cgiServlet.runHeaderReaderFail""), ioe);
                    }
                }
                // Close the output stream if used
                if (cgiOutput != null) {
                    try {
                        cgiOutput.close();
                    } catch (IOException ioe) {
                        log.warn(sm.getString(""cgiServlet.runOutputStreamFail""), ioe);
                    }
                }
                // Make sure the error stream reader has finished
                if (errReaderThread != null) {
                    try {
                        errReaderThread.join(stderrTimeout);
                    } catch (InterruptedException e) {
                        log.warn(sm.getString(""cgiServlet.runReaderInterrupt""));                    }
                }
                if (proc != null){
                    proc.destroy();
                    proc = null;
                }
            }
        }",,
tomcat,17154,"log.info(sm.getString(""channel.nio.ssl.expandNetInBuffer"", Integer.toString(newLimit)))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/SecureNio2Channel.java/#L394,"private int processSNI() throws IOException {
        // If there is no data to process, trigger a read immediately. This is
        // an optimisation for the typical case so we don't create an
        // SNIExtractor only to discover there is no data to process
        if (netInBuffer.position() == 0) {
            sc.read(netInBuffer, AbstractEndpoint.toTimeout(endpoint.getConnectionTimeout()),
                    TimeUnit.MILLISECONDS, socketWrapper, handshakeReadCompletionHandler);
            return 1;
        }

        TLSClientHelloExtractor extractor = new TLSClientHelloExtractor(netInBuffer);

        if (extractor.getResult() == ExtractorResult.UNDERFLOW &&
                netInBuffer.capacity() < endpoint.getSniParseLimit()) {
            // extractor needed more data to process but netInBuffer was full so
            // expand the buffer and read some more data.
            int newLimit = Math.min(netInBuffer.capacity() * 2, endpoint.getSniParseLimit());
            
---------------Reference log start----------------
log.info(sm.getString(""channel.nio.ssl.expandNetInBuffer"", Integer.toString(newLimit)))
---------------Reference log end----------------

            netInBuffer = ByteBufferUtils.expand(netInBuffer, newLimit);
            sc.read(netInBuffer, AbstractEndpoint.toTimeout(endpoint.getConnectionTimeout()),
                    TimeUnit.MILLISECONDS, socketWrapper, handshakeReadCompletionHandler);
            return 1;
        }

        String hostName = null;
        List<Cipher> clientRequestedCiphers = null;
        List<String> clientRequestedApplicationProtocols = null;
        switch (extractor.getResult()) {
        case COMPLETE:
            hostName = extractor.getSNIValue();
            clientRequestedApplicationProtocols =
                    extractor.getClientRequestedApplicationProtocols();
            //$FALL-THROUGH$ to set the client requested ciphers
        case NOT_PRESENT:
            clientRequestedCiphers = extractor.getClientRequestedCiphers();
            break;
        case NEED_READ:
            sc.read(netInBuffer, AbstractEndpoint.toTimeout(endpoint.getConnectionTimeout()),
                    TimeUnit.MILLISECONDS, socketWrapper, handshakeReadCompletionHandler);
            return 1;
        case UNDERFLOW:
            // Unable to buffer enough data to read SNI extension data
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""channel.nio.ssl.sniDefault""));
            }
            hostName = endpoint.getDefaultSSLHostConfigName();
            clientRequestedCiphers = Collections.emptyList();
            break;
        case NON_SECURE:
            netOutBuffer.clear();
            netOutBuffer.put(TLSClientHelloExtractor.USE_TLS_RESPONSE);
            netOutBuffer.flip();
            flush();
            throw new IOException(sm.getString(""channel.nio.ssl.foundHttp""));
        }

        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""channel.nio.ssl.sniHostName"", sc, hostName));
        }

        sslEngine = endpoint.createSSLEngine(hostName, clientRequestedCiphers,
                clientRequestedApplicationProtocols);

        // Populate additional TLS attributes obtained from the handshake that
        // aren't available from the session
        additionalTlsAttributes.put(SSLSupport.REQUESTED_PROTOCOL_VERSIONS_KEY,
                extractor.getClientRequestedProtocols());
        additionalTlsAttributes.put(SSLSupport.REQUESTED_CIPHERS_KEY,
                extractor.getClientRequestedCipherNames());

        // Ensure the application buffers (which have to be created earlier) are
        // big enough.
        getBufHandler().expand(sslEngine.getSession().getApplicationBufferSize());
        if (netOutBuffer.capacity() < sslEngine.getSession().getApplicationBufferSize()) {
            // Info for now as we may need to increase DEFAULT_NET_BUFFER_SIZE
            log.info(sm.getString(""channel.nio.ssl.expandNetOutBuffer"",
                    Integer.toString(sslEngine.getSession().getApplicationBufferSize())));
        }
        netInBuffer = ByteBufferUtils.expand(netInBuffer, sslEngine.getSession().getPacketBufferSize());
        netOutBuffer = ByteBufferUtils.expand(netOutBuffer, sslEngine.getSession().getPacketBufferSize());

        // Set limit and position to expected values
        netOutBuffer.position(0);
        netOutBuffer.limit(0);

        // Initiate handshake
        sslEngine.beginHandshake();
        handshakeStatus = sslEngine.getHandshakeStatus();

        return 0;
    }",,
tomcat,17687,"log.debug(""Unable to close SQL connection"", x)",debug,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/PooledConnection.java/#L655,"public boolean release() {
        try {
            disconnect(true);
        } catch (Exception x) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Unable to close SQL connection"", x)
---------------Reference log end----------------
            }
        }
        if (oname != null) {
            JmxUtil.unregisterJmx(oname);
            oname = null;
        }
        return released.compareAndSet(false, true);

    }",,
tomcat,15747,"log.warn(sm.getString(""jmxRegistry.unregisterJmx.notFound"", oname), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/jmx/JmxRegistry.java/#L140,"public void unregisterJmx(ObjectName oname) {
        if (oname ==null) {
            return;
        }
        try {
            mbserver.unregisterMBean(oname);
        } catch (InstanceNotFoundException e) {
            
---------------Reference log start----------------
log.warn(sm.getString(""jmxRegistry.unregisterJmx.notFound"", oname), e)
---------------Reference log end----------------
        } catch (Exception e) {
            log.warn(sm.getString(""jmxRegistry.unregisterJmx.failed"", oname), e);
        }
    }",,
tomcat,15247,"log.error(sm.getString(""persistentManager.storeLoadKeysError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/PersistentManagerBase.java/#L551,"@Override
    public void load() {

        // Initialize our internal data structures
        sessions.clear();

        if (store == null) {
            return;
        }

        String[] ids = null;
        try {
            if (SecurityUtil.isPackageProtectionEnabled()) {
                try {
                    ids = AccessController.doPrivileged(new PrivilegedStoreKeys());
                } catch (PrivilegedActionException e) {
                    log.error(sm.getString(""persistentManager.storeLoadKeysError""),
                            e.getException());
                    return;
                }
            } else {
                ids = store.keys();
            }
        } catch (IOException e) {
            
---------------Reference log start----------------
log.error(sm.getString(""persistentManager.storeLoadKeysError""), e)
---------------Reference log end----------------
            return;
        }

        int n = ids.length;
        if (n == 0) {
            return;
        }

        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""persistentManager.loading"", String.valueOf(n)));
        }

        for (String id : ids) {
            try {
                swapIn(id);
            } catch (IOException e) {
                log.error(sm.getString(""persistentManager.storeLoadError""), e);
            }
        }

    }",,
tomcat,15179,"manager.getContext().getLogger().error(sm.getString(getStoreName() + "".SQLException"", e))",getContext,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/DataSourceStore.java/#L643,"@Override
    public void save(Session session) throws IOException {
        ByteArrayOutputStream bos = null;
        String saveSql = ""INSERT INTO "" + sessionTable + "" (""
                + sessionIdCol + "", "" + sessionAppCol + "", ""
                + sessionDataCol + "", "" + sessionValidCol
                + "", "" + sessionMaxInactiveCol + "", ""
                + sessionLastAccessedCol
                + "") VALUES (?, ?, ?, ?, ?, ?)"";

        synchronized (session) {
            int numberOfTries = 2;
            while (numberOfTries > 0) {
                Connection _conn = getConnection();
                if (_conn == null) {
                    return;
                }

                try {
                    // If sessions already exist in DB, remove and insert again.
                    // TODO:
                    // * Check if ID exists in database and if so use UPDATE.
                    remove(session.getIdInternal(), _conn);

                    bos = new ByteArrayOutputStream();
                    try (ObjectOutputStream oos =
                            new ObjectOutputStream(new BufferedOutputStream(bos))) {
                        ((StandardSession) session).writeObjectData(oos);
                    }
                    byte[] obs = bos.toByteArray();
                    int size = obs.length;
                    try (ByteArrayInputStream bis = new ByteArrayInputStream(obs, 0, size);
                            InputStream in = new BufferedInputStream(bis, size);
                            PreparedStatement preparedSaveSql = _conn.prepareStatement(saveSql)) {
                        preparedSaveSql.setString(1, session.getIdInternal());
                        preparedSaveSql.setString(2, getName());
                        preparedSaveSql.setBinaryStream(3, in, size);
                        preparedSaveSql.setString(4, session.isValid() ? ""1"" : ""0"");
                        preparedSaveSql.setInt(5, session.getMaxInactiveInterval());
                        preparedSaveSql.setLong(6, session.getLastAccessedTime());
                        preparedSaveSql.execute();
                        // Break out after the finally block
                        numberOfTries = 0;
                    }
                } catch (SQLException e) {
                    
---------------Reference log start----------------
manager.getContext().getLogger().error(sm.getString(getStoreName() + "".SQLException"", e))
---------------Reference log end----------------
                } catch (IOException e) {
                    // Ignore
                } finally {
                    release(_conn);
                }
                numberOfTries--;
            }
        }

        if (manager.getContext().getLogger().isDebugEnabled()) {
            manager.getContext().getLogger().debug(sm.getString(getStoreName() + "".saving"",
                    session.getIdInternal(), sessionTable));
        }
    }",,
tomcat,16386,"log.error(sm.getString(""farmWarDeployer.msgIoe""), x)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/deploy/FarmWarDeployer.java/#L292,"@Override
    public void messageReceived(ClusterMessage msg) {
        try {
            if (msg instanceof FileMessage) {
                FileMessage fmsg = (FileMessage) msg;
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""farmWarDeployer.msgRxDeploy"",
                            fmsg.getContextName(), fmsg.getFileName()));
                }
                FileMessageFactory factory = getFactory(fmsg);
                // TODO correct second try after app is in service!
                if (factory.writeMessage(fmsg)) {
                    //last message received war file is completed
                    String name = factory.getFile().getName();
                    if (!name.endsWith("".war"")) {
                        name = name + "".war"";
                    }
                    File deployable = new File(getDeployDirFile(), name);
                    try {
                        String contextName = fmsg.getContextName();
                        if (tryAddServiced(contextName)) {
                            try {
                                remove(contextName);
                                if (!factory.getFile().renameTo(deployable)) {
                                    log.error(sm.getString(
                                            ""farmWarDeployer.renameFail"",
                                            factory.getFile(), deployable));
                                }
                            } finally {
                                removeServiced(contextName);
                            }
                            check(contextName);
                            if (log.isDebugEnabled()) {
                                log.debug(sm.getString(
                                        ""farmWarDeployer.deployEnd"",
                                        contextName));
                            }
                        } else {
                            log.error(sm.getString(
                                    ""farmWarDeployer.servicingDeploy"",
                                    contextName, name));
                        }
                    } catch (Exception ex) {
                        log.error(sm.getString(""farmWarDeployer.fileMessageError""), ex);
                    } finally {
                        removeFactory(fmsg);
                    }
                }
            } else if (msg instanceof UndeployMessage) {
                try {
                    UndeployMessage umsg = (UndeployMessage) msg;
                    String contextName = umsg.getContextName();
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""farmWarDeployer.msgRxUndeploy"",
                                contextName));
                    }
                    if (tryAddServiced(contextName)) {
                        try {
                            remove(contextName);
                        } finally {
                            removeServiced(contextName);
                        }
                        if (log.isDebugEnabled()) {
                            log.debug(sm.getString(
                                    ""farmWarDeployer.undeployEnd"",
                                    contextName));
                        }
                    } else {
                        log.error(sm.getString(
                                ""farmWarDeployer.servicingUndeploy"",
                                contextName));
                    }
                } catch (Exception ex) {
                    log.error(sm.getString(""farmWarDeployer.undeployMessageError""), ex);
                }
            }
        } catch (java.io.IOException x) {
            
---------------Reference log start----------------
log.error(sm.getString(""farmWarDeployer.msgIoe""), x)
---------------Reference log end----------------
        }
    }",,
tomcat,16423,"log.error(sm.getString(""ReplicationValve.filter.failure"", filter), pse)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/tcp/ReplicationValve.java/#L170,"public void setFilter(String filter) {
        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""ReplicationValve.filter.loading"", filter));
        }

        if (filter == null || filter.length() == 0) {
            this.filter = null;
        } else {
            try {
                this.filter = Pattern.compile(filter);
            } catch (PatternSyntaxException pse) {
                
---------------Reference log start----------------
log.error(sm.getString(""ReplicationValve.filter.failure"", filter), pse)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,15370,"containerLog.debug(""Load-balancer is in DISABLED state; draining this node"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/valves/LoadBalancerDrainingValve.java/#L179,"@Override
    public void invoke(Request request, Response response) throws IOException, ServletException {
        if  (""DIS"".equals(request.getAttribute(ATTRIBUTE_KEY_JK_LB_ACTIVATION)) &&
                !request.isRequestedSessionIdValid()) {

            if (containerLog.isDebugEnabled()) {
                
---------------Reference log start----------------
containerLog.debug(""Load-balancer is in DISABLED state; draining this node"")
---------------Reference log end----------------
            }

            boolean ignoreRebalance = false;
            Cookie sessionCookie = null;

            final Cookie[] cookies = request.getCookies();

            final String sessionCookieName = SessionConfig.getSessionCookieName(request.getContext());

            if (null != cookies) {
                for (Cookie cookie : cookies) {
                    final String cookieName = cookie.getName();
                    if (containerLog.isTraceEnabled()) {
                        containerLog.trace(""Checking cookie "" + cookieName + ""="" + cookie.getValue());
                    }

                    if (sessionCookieName.equals(cookieName) &&
                            request.getRequestedSessionId().equals(cookie.getValue())) {
                        sessionCookie = cookie;
                    } else if (null != _ignoreCookieName &&
                            _ignoreCookieName.equals(cookieName) &&
                            null != _ignoreCookieValue &&
                            _ignoreCookieValue.equals(cookie.getValue())) {
                        // The client presenting a valid ignore-cookie value?
                        ignoreRebalance = true;
                    }
                }
            }

            if (ignoreRebalance) {
                if (containerLog.isDebugEnabled()) {
                    containerLog.debug(""Client is presenting a valid "" + _ignoreCookieName +
                            "" cookie, re-balancing is being skipped"");
                }

                getNext().invoke(request, response);

                return;
            }

            // Kill any session cookie that was found
            // TODO: Consider implications of SSO cookies
            if (null != sessionCookie) {
                sessionCookie.setPath(SessionConfig.getSessionCookiePath(request.getContext()));
                sessionCookie.setMaxAge(0); // Delete
                sessionCookie.setValue(""""); // Purge the cookie's value
                // Replicate logic used to set secure attribute for session cookies
                SessionCookieConfig sessionCookieConfig = request.getContext().getServletContext().getSessionCookieConfig();
                sessionCookie.setSecure(request.isSecure() || sessionCookieConfig.isSecure());
                response.addCookie(sessionCookie);
            }

            // Re-write the URI if it contains a ;jsessionid parameter
            String uri = request.getRequestURI();
            String sessionURIParamName = SessionConfig.getSessionUriParamName(request.getContext());
            if (uri.contains("";"" + sessionURIParamName + ""="")) {
                uri = uri.replaceFirst("";"" + sessionURIParamName + ""=[^&?]*"", """");
            }

            String queryString = request.getQueryString();

            if (null != queryString) {
                uri = uri + ""?"" + queryString;
            }

            // NOTE: Do not call response.encodeRedirectURL or the bad
            // sessionid will be restored
            response.setHeader(""Location"", uri);
            response.setStatus(_redirectStatusCode);
        } else {
            getNext().invoke(request, response);
        }
    }",,
tomcat,16568,"log.error(msg, e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/ThreadLocalLeakPreventionListener.java/#L103,"@Override
    public void containerEvent(ContainerEvent event) {
        try {
            super.containerEvent(event);
        } catch (Exception e) {
            String msg =
                sm.getString(
                    ""threadLocalLeakPreventionListener.containerEvent.error"",
                    event);
            
---------------Reference log start----------------
log.error(msg, e)
---------------Reference log end----------------
        }

    }",,
tomcat,16716,"log.debug(sm.getString(""applicationFilterConfig.jmxUnregister"", getFilterClass(), getFilterName()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/ApplicationFilterConfig.java/#L376,"private void unregisterJMX() {
        // unregister this component
        if (oname != null) {
            try {
                Registry.getRegistry(null, null).unregisterComponent(oname);
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""applicationFilterConfig.jmxUnregister"", getFilterClass(), getFilterName()))
---------------Reference log end----------------
                }
            } catch(Exception ex) {
                log.warn(sm.getString(""applicationFilterConfig.jmxUnregisterFail"",
                        getFilterClass(), getFilterName()), ex);
            }
        }
    }",,
tomcat,17633,"log.error(""Error during connection pool creation."", x)",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/DataSourceProxy.java/#L221,"public ConnectionPool getPool() {
        try {
            return createPool();
        }catch (SQLException x) {
            
---------------Reference log start----------------
log.error(""Error during connection pool creation."", x)
---------------Reference log end----------------
            return null;
        }
    }",,
tomcat,16211,"log.info(sm.getString(""hostConfig.deployDescriptor.finished"", contextXml.getAbsolutePath(), Long.valueOf(System.currentTimeMillis() - startTime)))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/HostConfig.java/#L711,"@SuppressWarnings(""null"") // context is not null
    protected void deployDescriptor(ContextName cn, File contextXml) {

        DeployedApplication deployedApp = new DeployedApplication(cn.getName(), true);

        long startTime = 0;
        // Assume this is a configuration descriptor and deploy it
        if (log.isInfoEnabled()) {
           startTime = System.currentTimeMillis();
           log.info(sm.getString(""hostConfig.deployDescriptor"", contextXml.getAbsolutePath()));
        }

        Context context = null;
        boolean isExternalWar = false;
        boolean isExternal = false;
        File expandedDocBase = null;

        try (FileInputStream fis = new FileInputStream(contextXml)) {
            synchronized (digesterLock) {
                try {
                    context = (Context) digester.parse(fis);
                } catch (Exception e) {
                    log.error(sm.getString(""hostConfig.deployDescriptor.error"", contextXml.getAbsolutePath()), e);
                } finally {
                    digester.reset();
                    if (context == null) {
                        context = new FailedContext();
                    }
                }
            }

            if (context.getPath() != null) {
                log.warn(sm.getString(""hostConfig.deployDescriptor.path"", context.getPath(),
                        contextXml.getAbsolutePath()));
            }

            Class<?> clazz = Class.forName(host.getConfigClass());
            LifecycleListener listener = (LifecycleListener) clazz.getConstructor().newInstance();
            context.addLifecycleListener(listener);

            context.setConfigFile(contextXml.toURI().toURL());
            context.setName(cn.getName());
            context.setPath(cn.getPath());
            context.setWebappVersion(cn.getVersion());
            // Add the associated docBase to the redeployed list if it's a WAR
            if (context.getDocBase() != null) {
                File docBase = new File(context.getDocBase());
                if (!docBase.isAbsolute()) {
                    docBase = new File(host.getAppBaseFile(), context.getDocBase());
                }
                // If external docBase, register .xml as redeploy first
                if (!docBase.getCanonicalFile().toPath().startsWith(host.getAppBaseFile().toPath())) {
                    isExternal = true;
                    deployedApp.redeployResources.put(
                            contextXml.getAbsolutePath(), Long.valueOf(contextXml.lastModified()));
                    deployedApp.redeployResources.put(
                            docBase.getAbsolutePath(), Long.valueOf(docBase.lastModified()));
                    if (docBase.getAbsolutePath().toLowerCase(Locale.ENGLISH).endsWith("".war"")) {
                        isExternalWar = true;
                    }
                    // Check that a WAR or DIR in the appBase is not 'hidden'
                    File war = new File(host.getAppBaseFile(), cn.getBaseName() + "".war"");
                    if (war.exists()) {
                        log.warn(sm.getString(""hostConfig.deployDescriptor.hiddenWar"",
                                contextXml.getAbsolutePath(), war.getAbsolutePath()));
                    }
                    File dir = new File(host.getAppBaseFile(), cn.getBaseName());
                    if (dir.exists()) {
                        log.warn(sm.getString(""hostConfig.deployDescriptor.hiddenDir"",
                                contextXml.getAbsolutePath(), dir.getAbsolutePath()));
                    }
                } else {
                    log.warn(sm.getString(""hostConfig.deployDescriptor.localDocBaseSpecified"", docBase));
                    // Ignore specified docBase
                    context.setDocBase(null);
                }
            }

            host.addChild(context);
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            log.error(sm.getString(""hostConfig.deployDescriptor.error"", contextXml.getAbsolutePath()), t);
        } finally {
            // Get paths for WAR and expanded WAR in appBase

            // default to appBase dir + name
            expandedDocBase = new File(host.getAppBaseFile(), cn.getBaseName());
            if (context.getDocBase() != null && !context.getDocBase().toLowerCase(Locale.ENGLISH).endsWith("".war"")) {
                // first assume docBase is absolute
                expandedDocBase = new File(context.getDocBase());
                if (!expandedDocBase.isAbsolute()) {
                    // if docBase specified and relative, it must be relative to appBase
                    expandedDocBase = new File(host.getAppBaseFile(), context.getDocBase());
                }
            }

            boolean unpackWAR = unpackWARs;
            if (unpackWAR && context instanceof StandardContext) {
                unpackWAR = ((StandardContext) context).getUnpackWAR();
            }

            // Add the eventual unpacked WAR and all the resources which will be
            // watched inside it
            if (isExternalWar) {
                if (unpackWAR) {
                    deployedApp.redeployResources.put(
                            expandedDocBase.getAbsolutePath(), Long.valueOf(expandedDocBase.lastModified()));
                    addWatchedResources(deployedApp, expandedDocBase.getAbsolutePath(), context);
                } else {
                    addWatchedResources(deployedApp, null, context);
                }
            } else {
                // Find an existing matching war and expanded folder
                if (!isExternal) {
                    File warDocBase = new File(expandedDocBase.getAbsolutePath() + "".war"");
                    if (warDocBase.exists()) {
                        deployedApp.redeployResources.put(
                                warDocBase.getAbsolutePath(), Long.valueOf(warDocBase.lastModified()));
                    } else {
                        // Trigger a redeploy if a WAR is added
                        deployedApp.redeployResources.put(warDocBase.getAbsolutePath(), Long.valueOf(0));
                    }
                }
                if (unpackWAR) {
                    deployedApp.redeployResources.put(
                            expandedDocBase.getAbsolutePath(), Long.valueOf(expandedDocBase.lastModified()));
                    addWatchedResources(deployedApp, expandedDocBase.getAbsolutePath(), context);
                } else {
                    addWatchedResources(deployedApp, null, context);
                }
                if (!isExternal) {
                    // For external docBases, the context.xml will have been
                    // added above.
                    deployedApp.redeployResources.put(
                            contextXml.getAbsolutePath(), Long.valueOf(contextXml.lastModified()));
                }
            }
            // Add the global redeploy resources (which are never deleted) at
            // the end so they don't interfere with the deletion process
            addGlobalRedeployResources(deployedApp);
        }

        if (host.findChild(context.getName()) != null) {
            deployed.put(context.getName(), deployedApp);
        }

        if (log.isInfoEnabled()) {
            
---------------Reference log start----------------
log.info(sm.getString(""hostConfig.deployDescriptor.finished"", contextXml.getAbsolutePath(), Long.valueOf(System.currentTimeMillis() - startTime)))
---------------Reference log end----------------
        }
    }",,
tomcat,17133,"log.warn(sm.getString(""acceptor.stop.interrupted"", getThreadName()), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/Acceptor.java/#L175,"public void stop(int waitSeconds) {
        stopCalled = true;
        if (waitSeconds > 0) {
            try {
                if (!stopLatch.await(waitSeconds, TimeUnit.SECONDS)) {
                   log.warn(sm.getString(""acceptor.stop.fail"", getThreadName()));
                }
            } catch (InterruptedException e) {
                
---------------Reference log start----------------
log.warn(sm.getString(""acceptor.stop.interrupted"", getThreadName()), e)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,15838,"log.error(sm.getString(""encryptInterceptor.decrypt.failed""), gse)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/group/interceptors/EncryptInterceptor.java/#L150,"@Override
    public void messageReceived(ChannelMessage msg) {
        try {
            byte[] data = msg.getMessage().getBytes();

            data = encryptionManager.decrypt(data);

            XByteBuffer xbb = msg.getMessage();

            // Completely replace the message with the decrypted one
            xbb.clear();
            xbb.append(data, 0, data.length);

            super.messageReceived(msg);
        } catch (GeneralSecurityException gse) {
            
---------------Reference log start----------------
log.error(sm.getString(""encryptInterceptor.decrypt.failed""), gse)
---------------Reference log end----------------
        }
    }",,
tomcat,16454,"log.debug(sm.getString(""jarResource.getInputStreamFail"", getResource().getName(), getBaseUrl()), e)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/webresources/JarWarResource.java/#L72,"@Override
    protected JarInputStreamWrapper getJarInputStreamWrapper() {
        JarFile warFile = null;
        JarInputStream jarIs = null;
        JarEntry entry = null;
        try {
            warFile = getArchiveResourceSet().openJarFile();
            JarEntry jarFileInWar = warFile.getJarEntry(archivePath);
            InputStream isInWar = warFile.getInputStream(jarFileInWar);

            jarIs = new JarInputStream(isInWar);
            entry = jarIs.getNextJarEntry();
            while (entry != null &&
                    !entry.getName().equals(getResource().getName())) {
                entry = jarIs.getNextJarEntry();
            }

            if (entry == null) {
                return null;
            }

            return new JarInputStreamWrapper(entry, jarIs);
        } catch (IOException e) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""jarResource.getInputStreamFail"", getResource().getName(), getBaseUrl()), e)
---------------Reference log end----------------
            }
            // Ensure jarIs is closed if there is an exception
            entry = null;
            return null;
        } finally {
            if (entry == null) {
                if (jarIs != null) {
                    try {
                        jarIs.close();
                    } catch (IOException ioe) {
                        // Ignore
                    }
                }
                if (warFile != null) {
                    getArchiveResourceSet().closeJarFile();
                }
            }
        }
    }",,
tomcat,17662,"log.debug(""checkAbandoned failed."", e)",debug,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L1103,"public void checkAbandoned() {
        try {
            if (busy.isEmpty()) {
              return;
            }
            Iterator<PooledConnection> locked = busy.iterator();
            int sto = getPoolProperties().getSuspectTimeout();
            while (locked.hasNext()) {
                PooledConnection con = locked.next();
                boolean setToNull = false;
                try {
                    con.lock();
                    //the con has been returned to the pool or released
                    //ignore it
                    if (idle.contains(con) || con.isReleased()) {
                      continue;
                    }
                    long time = con.getTimestamp();
                    long now = System.currentTimeMillis();
                    if (shouldAbandon() && (now - time) > con.getAbandonTimeout()) {
                        busy.remove(con);
                        abandon(con);
                        setToNull = true;
                    } else if (sto > 0 && (now - time) > (sto * 1000L)) {
                        suspect(con);
                    } else {
                        //do nothing
                    } //end if
                } finally {
                    con.unlock();
                    if (setToNull) {
                      con = null;
                    }
                }
            } //while
        } catch (ConcurrentModificationException e) {
            
---------------Reference log start----------------
log.debug(""checkAbandoned failed."", e)
---------------Reference log end----------------
        } catch (Exception e) {
            log.warn(""checkAbandoned failed, it will be retried."",e);
        }
    }",,
tomcat,16246,"log.warn(sm.getString(""hostConfig.jmx.register"", oname), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/HostConfig.java/#L1646,"public void start() {

        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""hostConfig.start""));
        }

        try {
            ObjectName hostON = host.getObjectName();
            oname = new ObjectName
                (hostON.getDomain() + "":type=Deployer,host="" + host.getName());
            Registry.getRegistry(null, null).registerComponent
                (this, oname, this.getClass().getName());
        } catch (Exception e) {
            
---------------Reference log start----------------
log.warn(sm.getString(""hostConfig.jmx.register"", oname), e)
---------------Reference log end----------------
        }

        if (!host.getAppBaseFile().isDirectory()) {
            log.error(sm.getString(""hostConfig.appBase"", host.getName(),
                    host.getAppBaseFile().getPath()));
            host.setDeployOnStartup(false);
            host.setAutoDeploy(false);
        }

        if (host.getDeployOnStartup()) {
            deployApps();
        }
    }",,
tomcat,17656,"log.error(""Failed to re-connect connection ["" + this + ""] that expired because of maxAge"", e)",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L980,"protected boolean reconnectIfExpired(PooledConnection con) {
        if (con.isMaxAgeExpired()) {
            try {
                if (log.isDebugEnabled()) {
                  log.debug( ""Connection [""+this+""] expired because of maxAge, trying to reconnect"" );
                }
                con.reconnect();
                reconnectedCount.incrementAndGet();
                if ( isInitNewConnections() && !con.validate( PooledConnection.VALIDATE_INIT)) {
                    return false;
                }
            } catch(Exception e) {
                
---------------Reference log start----------------
log.error(""Failed to re-connect connection ["" + this + ""] that expired because of maxAge"", e)
---------------Reference log end----------------
                return false;
            }
        }
        return true;
    }",,
tomcat,17155,"log.debug(sm.getString(""channel.nio.ssl.sniDefault""))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/SecureNio2Channel.java/#L422,"private int processSNI() throws IOException {
        // If there is no data to process, trigger a read immediately. This is
        // an optimisation for the typical case so we don't create an
        // SNIExtractor only to discover there is no data to process
        if (netInBuffer.position() == 0) {
            sc.read(netInBuffer, AbstractEndpoint.toTimeout(endpoint.getConnectionTimeout()),
                    TimeUnit.MILLISECONDS, socketWrapper, handshakeReadCompletionHandler);
            return 1;
        }

        TLSClientHelloExtractor extractor = new TLSClientHelloExtractor(netInBuffer);

        if (extractor.getResult() == ExtractorResult.UNDERFLOW &&
                netInBuffer.capacity() < endpoint.getSniParseLimit()) {
            // extractor needed more data to process but netInBuffer was full so
            // expand the buffer and read some more data.
            int newLimit = Math.min(netInBuffer.capacity() * 2, endpoint.getSniParseLimit());
            log.info(sm.getString(""channel.nio.ssl.expandNetInBuffer"",
                    Integer.toString(newLimit)));

            netInBuffer = ByteBufferUtils.expand(netInBuffer, newLimit);
            sc.read(netInBuffer, AbstractEndpoint.toTimeout(endpoint.getConnectionTimeout()),
                    TimeUnit.MILLISECONDS, socketWrapper, handshakeReadCompletionHandler);
            return 1;
        }

        String hostName = null;
        List<Cipher> clientRequestedCiphers = null;
        List<String> clientRequestedApplicationProtocols = null;
        switch (extractor.getResult()) {
        case COMPLETE:
            hostName = extractor.getSNIValue();
            clientRequestedApplicationProtocols =
                    extractor.getClientRequestedApplicationProtocols();
            //$FALL-THROUGH$ to set the client requested ciphers
        case NOT_PRESENT:
            clientRequestedCiphers = extractor.getClientRequestedCiphers();
            break;
        case NEED_READ:
            sc.read(netInBuffer, AbstractEndpoint.toTimeout(endpoint.getConnectionTimeout()),
                    TimeUnit.MILLISECONDS, socketWrapper, handshakeReadCompletionHandler);
            return 1;
        case UNDERFLOW:
            // Unable to buffer enough data to read SNI extension data
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""channel.nio.ssl.sniDefault""))
---------------Reference log end----------------
            }
            hostName = endpoint.getDefaultSSLHostConfigName();
            clientRequestedCiphers = Collections.emptyList();
            break;
        case NON_SECURE:
            netOutBuffer.clear();
            netOutBuffer.put(TLSClientHelloExtractor.USE_TLS_RESPONSE);
            netOutBuffer.flip();
            flush();
            throw new IOException(sm.getString(""channel.nio.ssl.foundHttp""));
        }

        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""channel.nio.ssl.sniHostName"", sc, hostName));
        }

        sslEngine = endpoint.createSSLEngine(hostName, clientRequestedCiphers,
                clientRequestedApplicationProtocols);

        // Populate additional TLS attributes obtained from the handshake that
        // aren't available from the session
        additionalTlsAttributes.put(SSLSupport.REQUESTED_PROTOCOL_VERSIONS_KEY,
                extractor.getClientRequestedProtocols());
        additionalTlsAttributes.put(SSLSupport.REQUESTED_CIPHERS_KEY,
                extractor.getClientRequestedCipherNames());

        // Ensure the application buffers (which have to be created earlier) are
        // big enough.
        getBufHandler().expand(sslEngine.getSession().getApplicationBufferSize());
        if (netOutBuffer.capacity() < sslEngine.getSession().getApplicationBufferSize()) {
            // Info for now as we may need to increase DEFAULT_NET_BUFFER_SIZE
            log.info(sm.getString(""channel.nio.ssl.expandNetOutBuffer"",
                    Integer.toString(sslEngine.getSession().getApplicationBufferSize())));
        }
        netInBuffer = ByteBufferUtils.expand(netInBuffer, sslEngine.getSession().getPacketBufferSize());
        netOutBuffer = ByteBufferUtils.expand(netOutBuffer, sslEngine.getSession().getPacketBufferSize());

        // Set limit and position to expected values
        netOutBuffer.position(0);
        netOutBuffer.limit(0);

        // Initiate handshake
        sslEngine.beginHandshake();
        handshakeStatus = sslEngine.getHandshakeStatus();

        return 0;
    }",,
tomcat,15901,"log.warn(sm.getString(""nioReceiver.cleanup.fail""), ignore)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/NioReceiver.java/#L403,"private void closeSelector() throws IOException {
        Selector selector = this.selector.getAndSet(null);
        if (selector == null) {
            return;
        }
        try {
            // look at each key in the selected set
            for (SelectionKey key : selector.keys()) {
                key.channel().close();
                key.attach(null);
                key.cancel();
            }
        } catch (IOException ignore){
            if (log.isWarnEnabled()) {
                
---------------Reference log start----------------
log.warn(sm.getString(""nioReceiver.cleanup.fail""), ignore)
---------------Reference log end----------------
            }
        } catch (ClosedSelectorException ignore){
            // Ignore
        }
        try {
            selector.selectNow();
        } catch (Throwable t){
            ExceptionUtils.handleThrowable(t);
            // Ignore everything else
        }
        selector.close();
    }",,
tomcat,15323,"log.error(sm.getString(""extendedAccessLogValve.badXParam""))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/valves/ExtendedAccessLogValve.java/#L729,"protected AccessLogElement getXParameterElement(PatternTokenizer tokenizer)
            throws IOException {
        if (!tokenizer.hasSubToken()) {
            log.error(sm.getString(""extendedAccessLogValve.badXParam""));
            return null;
        }
        String token = tokenizer.getToken();
        if (""threadname"".equals(token)) {
            return new ThreadNameElement();
        }

        if (!tokenizer.hasParameter()) {
            
---------------Reference log start----------------
log.error(sm.getString(""extendedAccessLogValve.badXParam""))
---------------Reference log end----------------
            return null;
        }
        String parameter = tokenizer.getParameter();
        if (parameter == null) {
            log.error(sm.getString(""extendedAccessLogValve.noClosing""));
            return null;
        }
        if (""A"".equals(token)) {
            return new ServletContextElement(parameter);
        } else if (""C"".equals(token)) {
            return new CookieElement(parameter);
        } else if (""R"".equals(token)) {
            return new RequestAttributeElement(parameter);
        } else if (""S"".equals(token)) {
            return new SessionAttributeElement(parameter);
        } else if (""H"".equals(token)) {
            return getServletRequestElement(parameter);
        } else if (""P"".equals(token)) {
            return new RequestParameterElement(parameter);
        } else if (""O"".equals(token)) {
            return new ResponseAllHeaderElement(parameter);
        }
        log.error(sm.getString(""extendedAccessLogValve.badXParamValue"", token));
        return null;
    }",,
tomcat,16954,"log.debug(sm.getString(""asyncStateMachine.stateChange"", state, newState))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/AsyncStateMachine.java/#L518,"private synchronized void updateState(AsyncState newState) {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(sm.getString(""asyncStateMachine.stateChange"", state, newState))
---------------Reference log end----------------
        }
        state = newState;
    }",,
tomcat,15388,"log.info(sm.getString(""webappClassLoader.addTransformer"", transformer, getContextName()))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/loader/WebappClassLoaderBase.java/#L691,"@Override
    public void addTransformer(ClassFileTransformer transformer) {

        if (transformer == null) {
            throw new IllegalArgumentException(sm.getString(
                    ""webappClassLoader.addTransformer.illegalArgument"", getContextName()));
        }

        if (this.transformers.contains(transformer)) {
            // if the same instance of this transformer was already added, bail out
            log.warn(sm.getString(""webappClassLoader.addTransformer.duplicate"",
                    transformer, getContextName()));
            return;
        }
        this.transformers.add(transformer);

        
---------------Reference log start----------------
log.info(sm.getString(""webappClassLoader.addTransformer"", transformer, getContextName()))
---------------Reference log end----------------
    }
    }",,
tomcat,16283,log.debug(msg),debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/util/CustomObjectInputStream.java/#L152,"@Override
    public Class<?> resolveClass(ObjectStreamClass classDesc)
        throws ClassNotFoundException, IOException {

        String name = classDesc.getName();
        if (allowedClassNamePattern != null) {
            boolean allowed = allowedClassNamePattern.matcher(name).matches();
            if (!allowed) {
                boolean doLog = warnOnFailure && reportedClasses.add(name);
                String msg = sm.getString(""customObjectInputStream.nomatch"", name, allowedClassNameFilter);
                if (doLog) {
                    log.warn(msg);
                } else if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(msg)
---------------Reference log end----------------
                }
                throw new InvalidClassException(msg);
            }
        }

        try {
            return Class.forName(name, false, classLoader);
        } catch (ClassNotFoundException e) {
            try {
                // Try also the superclass because of primitive types
                return super.resolveClass(classDesc);
            } catch (ClassNotFoundException e2) {
                // Rethrow original exception, as it can have more information
                // about why the class was not found. BZ 48007
                throw e;
            }
        }
    }",,
tomcat,15935,"containerLog.debug(sm.getString(""singleSignOn.debug.principalFound"", entry.getPrincipal() != null ? entry.getPrincipal().getName() : """", entry.getAuthType()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/SingleSignOn.java/#L273,"@Override
    public void invoke(Request request, Response response)
        throws IOException, ServletException {

        request.removeNote(Constants.REQ_SSOID_NOTE);

        // Has a valid user already been authenticated?
        if (containerLog.isDebugEnabled()) {
            containerLog.debug(sm.getString(""singleSignOn.debug.invoke"", request.getRequestURI()));
        }
        if (request.getUserPrincipal() != null) {
            if (containerLog.isDebugEnabled()) {
                containerLog.debug(sm.getString(""singleSignOn.debug.hasPrincipal"",
                        request.getUserPrincipal().getName()));
            }
            getNext().invoke(request, response);
            return;
        }

        // Check for the single sign on cookie
        if (containerLog.isDebugEnabled()) {
            containerLog.debug(sm.getString(""singleSignOn.debug.cookieCheck""));
        }
        Cookie cookie = null;
        Cookie cookies[] = request.getCookies();
        if (cookies != null) {
            for (Cookie value : cookies) {
                if (cookieName.equals(value.getName())) {
                    cookie = value;
                    break;
                }
            }
        }
        if (cookie == null) {
            if (containerLog.isDebugEnabled()) {
                containerLog.debug(sm.getString(""singleSignOn.debug.cookieNotFound""));
            }
            getNext().invoke(request, response);
            return;
        }

        // Look up the cached Principal associated with this cookie value
        if (containerLog.isDebugEnabled()) {
            containerLog.debug(sm.getString(""singleSignOn.debug.principalCheck"",
                    cookie.getValue()));
        }
        SingleSignOnEntry entry = cache.get(cookie.getValue());
        if (entry != null) {
            if (containerLog.isDebugEnabled()) {
                
---------------Reference log start----------------
containerLog.debug(sm.getString(""singleSignOn.debug.principalFound"", entry.getPrincipal() != null ? entry.getPrincipal().getName() : """", entry.getAuthType()))
---------------Reference log end----------------
            }
            request.setNote(Constants.REQ_SSOID_NOTE, cookie.getValue());
            // Only set security elements if reauthentication is not required
            if (!getRequireReauthentication()) {
                request.setAuthType(entry.getAuthType());
                request.setUserPrincipal(entry.getPrincipal());
            }
        } else {
            if (containerLog.isDebugEnabled()) {
                containerLog.debug(sm.getString(""singleSignOn.debug.principalNotFound"",
                        cookie.getValue()));
            }
            // No need to return a valid SSO session ID
            cookie.setValue(""REMOVE"");
            // Age of zero will trigger removal
            cookie.setMaxAge(0);
            // Domain and path have to match the original cookie to 'replace'
            // the original cookie
            cookie.setPath(""/"");
            String domain = getCookieDomain();
            if (domain != null) {
                cookie.setDomain(domain);
            }
            // This is going to trigger a Set-Cookie header. While the value is
            // not security sensitive, ensure that expectations for secure and
            // httpOnly are met
            cookie.setSecure(request.isSecure());
            if (request.getServletContext().getSessionCookieConfig().isHttpOnly() ||
                    request.getContext().getUseHttpOnly()) {
                cookie.setHttpOnly(true);
            }

            response.addCookie(cookie);
        }

        // Invoke the next Valve in our pipeline
        getNext().invoke(request, response);
    }",,
tomcat,17669,"ConnectionPool.log.error(""Unable to cancel ConnectionFuture."", x)",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L1502,"@Override
        public void run() {
            try {
                Connection con = get(); //complete this future
                con.close(); //return to the pool
            }catch (ExecutionException ex) {
                //we can ignore this
            }catch (Exception x) {
                
---------------Reference log start----------------
ConnectionPool.log.error(""Unable to cancel ConnectionFuture."", x)
---------------Reference log end----------------
            }
        }",,
tomcat,15966,"log.warn(msg, t)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/FormAuthenticator.java/#L440,"protected void forwardToLoginPage(Request request,
            HttpServletResponse response, LoginConfig config)
            throws IOException {

        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""formAuthenticator.forwardLogin"",
                    request.getRequestURI(), request.getMethod(),
                    config.getLoginPage(), context.getName()));
        }

        String loginPage = config.getLoginPage();
        if (loginPage == null || loginPage.length() == 0) {
            String msg = sm.getString(""formAuthenticator.noLoginPage"",
                    context.getName());
            log.warn(msg);
            response.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR,
                    msg);
            return;
        }

        if (getChangeSessionIdOnAuthentication()) {
            Session session = request.getSessionInternal(false);
            if (session != null) {
                String newSessionId = changeSessionID(request, session);
                session.setNote(Constants.SESSION_ID_NOTE, newSessionId);
            }
        }

        // Always use GET for the login page, regardless of the method used
        String oldMethod = request.getMethod();
        request.getCoyoteRequest().method().setString(""GET"");

        RequestDispatcher disp =
            context.getServletContext().getRequestDispatcher(loginPage);
        try {
            if (context.fireRequestInitEvent(request.getRequest())) {
                disp.forward(request.getRequest(), response);
                context.fireRequestDestroyEvent(request.getRequest());
            }
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            String msg = sm.getString(""formAuthenticator.forwardLoginFail"");
            
---------------Reference log start----------------
log.warn(msg, t)
---------------Reference log end----------------
            request.setAttribute(RequestDispatcher.ERROR_EXCEPTION, t);
            response.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR,
                    msg);
        } finally {
            // Restore original method so that it is written into access log
            request.getCoyoteRequest().method().setString(oldMethod);
        }
    }",,
tomcat,16089,"log.error(sm.getString(""catalina.stopError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/Catalina.java/#L684,"public void stopServer(String[] arguments) {

        if (arguments != null) {
            arguments(arguments);
        }

        Server s = getServer();
        if (s == null) {
            parseServerXml(false);
            if (getServer() == null) {
                log.error(sm.getString(""catalina.stopError""));
                System.exit(1);
            }
        } else {
            // Server object already present. Must be running as a service
            try {
                s.stop();
                s.destroy();
            } catch (LifecycleException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""catalina.stopError""), e)
---------------Reference log end----------------
            }
            return;
        }

        // Stop the existing server
        s = getServer();
        if (s.getPortWithOffset() > 0) {
            try (Socket socket = new Socket(s.getAddress(), s.getPortWithOffset());
                    OutputStream stream = socket.getOutputStream()) {
                String shutdown = s.getShutdown();
                for (int i = 0; i < shutdown.length(); i++) {
                    stream.write(shutdown.charAt(i));
                }
                stream.flush();
            } catch (ConnectException ce) {
                log.error(sm.getString(""catalina.stopServer.connectException"", s.getAddress(),
                        String.valueOf(s.getPortWithOffset()), String.valueOf(s.getPort()),
                        String.valueOf(s.getPortOffset())));
                log.error(sm.getString(""catalina.stopError""), ce);
                System.exit(1);
            } catch (IOException e) {
                log.error(sm.getString(""catalina.stopError""), e);
                System.exit(1);
            }
        } else {
            log.error(sm.getString(""catalina.stopServer""));
            System.exit(1);
        }
    }",,
tomcat,15463,"log.error(sm.getString(""webappClassLoader.transformError"", name), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/loader/WebappClassLoaderBase.java/#L2465,"protected Class<?> findClassInternal(String name) {

        checkStateForResourceLoading(name);

        if (name == null) {
            return null;
        }
        String path = binaryNameToPath(name, true);

        ResourceEntry entry = resourceEntries.get(path);
        WebResource resource = null;

        if (entry == null) {
            resource = resources.getClassLoaderResource(path);

            if (!resource.exists()) {
                return null;
            }

            entry = new ResourceEntry();
            entry.lastModified = resource.getLastModified();

            // Add the entry in the local resource repository
            synchronized (resourceEntries) {
                // Ensures that all the threads which may be in a race to load
                // a particular class all end up with the same ResourceEntry
                // instance
                ResourceEntry entry2 = resourceEntries.get(path);
                if (entry2 == null) {
                    resourceEntries.put(path, entry);
                } else {
                    entry = entry2;
                }
            }
        }

        Class<?> clazz = entry.loadedClass;
        if (clazz != null) {
            return clazz;
        }

        synchronized (JreCompat.isGraalAvailable() ? this : getClassLoadingLock(name)) {
            clazz = entry.loadedClass;
            if (clazz != null) {
                return clazz;
            }

            if (resource == null) {
                resource = resources.getClassLoaderResource(path);
            }

            if (!resource.exists()) {
                return null;
            }

            byte[] binaryContent = resource.getContent();
            if (binaryContent == null) {
                // Something went wrong reading the class bytes (and will have
                // been logged at debug level).
                return null;
            }
            Manifest manifest = resource.getManifest();
            URL codeBase = resource.getCodeBase();
            Certificate[] certificates = resource.getCertificates();

            if (transformers.size() > 0) {
                // If the resource is a class just being loaded, decorate it
                // with any attached transformers

                // Ignore leading '/' and trailing CLASS_FILE_SUFFIX
                // Should be cheaper than replacing '.' by '/' in class name.
                String internalName = path.substring(1, path.length() - CLASS_FILE_SUFFIX.length());

                for (ClassFileTransformer transformer : this.transformers) {
                    try {
                        byte[] transformed = transformer.transform(
                                this, internalName, null, null, binaryContent);
                        if (transformed != null) {
                            binaryContent = transformed;
                        }
                    } catch (IllegalClassFormatException e) {
                        
---------------Reference log start----------------
log.error(sm.getString(""webappClassLoader.transformError"", name), e)
---------------Reference log end----------------
                        return null;
                    }
                }
            }

            // Looking up the package
            String packageName = null;
            int pos = name.lastIndexOf('.');
            if (pos != -1) {
                packageName = name.substring(0, pos);
            }

            Package pkg = null;

            if (packageName != null) {
                pkg = getPackage(packageName);
                // Define the package (if null)
                if (pkg == null) {
                    try {
                        if (manifest == null) {
                            definePackage(packageName, null, null, null, null, null, null, null);
                        } else {
                            definePackage(packageName, manifest, codeBase);
                        }
                    } catch (IllegalArgumentException e) {
                        // Ignore: normal error due to dual definition of package
                    }
                    pkg = getPackage(packageName);
                }
            }

            if (securityManager != null) {

                // Checking sealing
                if (pkg != null) {
                    boolean sealCheck = true;
                    if (pkg.isSealed()) {
                        sealCheck = pkg.isSealed(codeBase);
                    } else {
                        sealCheck = (manifest == null) || !isPackageSealed(packageName, manifest);
                    }
                    if (!sealCheck) {
                        throw new SecurityException
                            (""Sealing violation loading "" + name + "" : Package ""
                             + packageName + "" is sealed."");
                    }
                }

            }

            try {
                clazz = defineClass(name, binaryContent, 0,
                        binaryContent.length, new CodeSource(codeBase, certificates));
            } catch (UnsupportedClassVersionError ucve) {
                throw new UnsupportedClassVersionError(
                        ucve.getLocalizedMessage() + "" "" +
                        sm.getString(""webappClassLoader.wrongVersion"",
                                name));
            }
            entry.loadedClass = clazz;
        }

        return clazz;
    }",,
tomcat,17051,"log.warn(sm.getString(""jarScan.classPath.badEntry"", classPathEntry), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/scan/StandardJarScanner.java/#L345,"protected void addClassPath(Deque<URL> classPathUrlsToProcess) {
        String classPath = System.getProperty(""java.class.path"");

        if (classPath == null || classPath.length() == 0) {
            return;
        }

        String[] classPathEntries = classPath.split(File.pathSeparator);
        for (String classPathEntry : classPathEntries) {
            File f = new File(classPathEntry);
            try {
                classPathUrlsToProcess.add(f.toURI().toURL());
            } catch (MalformedURLException e) {
                
---------------Reference log start----------------
log.warn(sm.getString(""jarScan.classPath.badEntry"", classPathEntry), e)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,15477,"log.warn(sm.getString(""expiresFilter.unknownParameterIgnored"", name, value))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/filters/ExpiresFilter.java/#L1423,"@Override
    public void init(FilterConfig filterConfig) throws ServletException {
        for (Enumeration<String> names = filterConfig.getInitParameterNames(); names.hasMoreElements();) {
            String name = names.nextElement();
            String value = filterConfig.getInitParameter(name);

            try {
                if (name.startsWith(PARAMETER_EXPIRES_BY_TYPE)) {
                    String contentType = name.substring(
                            PARAMETER_EXPIRES_BY_TYPE.length()).trim().toLowerCase(Locale.ENGLISH);
                    ExpiresConfiguration expiresConfiguration = parseExpiresConfiguration(value);
                    this.expiresConfigurationByContentType.put(contentType,
                            expiresConfiguration);
                } else if (name.equalsIgnoreCase(PARAMETER_EXPIRES_DEFAULT)) {
                    ExpiresConfiguration expiresConfiguration = parseExpiresConfiguration(value);
                    this.defaultExpiresConfiguration = expiresConfiguration;
                } else if (name.equalsIgnoreCase(PARAMETER_EXPIRES_EXCLUDED_RESPONSE_STATUS_CODES)) {
                    this.excludedResponseStatusCodes = commaDelimitedListToIntArray(value);
                } else {
                    
---------------Reference log start----------------
log.warn(sm.getString(""expiresFilter.unknownParameterIgnored"", name, value))
---------------Reference log end----------------
                }
            } catch (RuntimeException e) {
                throw new ServletException(sm.getString(
                        ""expiresFilter.exceptionProcessingParameter"", name,
                        value), e);
            }
        }

        log.debug(sm.getString(""expiresFilter.filterInitialized"",
                this.toString()));
    }",,
tomcat,16704,"log.error(sm.getString(""containerBase.threadedStartFailed""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/ContainerBase.java/#L930,"@Override
    protected synchronized void startInternal() throws LifecycleException {

        // Start our subordinate components, if any
        logger = null;
        getLogger();
        Cluster cluster = getClusterInternal();
        if (cluster instanceof Lifecycle) {
            ((Lifecycle) cluster).start();
        }
        Realm realm = getRealmInternal();
        if (realm instanceof Lifecycle) {
            ((Lifecycle) realm).start();
        }

        // Start our child containers, if any
        Container children[] = findChildren();
        List<Future<Void>> results = new ArrayList<>();
        for (Container child : children) {
            results.add(startStopExecutor.submit(new StartChild(child)));
        }

        MultiThrowable multiThrowable = null;

        for (Future<Void> result : results) {
            try {
                result.get();
            } catch (Throwable e) {
                
---------------Reference log start----------------
log.error(sm.getString(""containerBase.threadedStartFailed""), e)
---------------Reference log end----------------
                if (multiThrowable == null) {
                    multiThrowable = new MultiThrowable();
                }
                multiThrowable.add(e);
            }

        }
        if (multiThrowable != null) {
            throw new LifecycleException(sm.getString(""containerBase.threadedStartFailed""),
                    multiThrowable.getThrowable());
        }

        // Start the Valves in our pipeline (including the basic), if any
        if (pipeline instanceof Lifecycle) {
            ((Lifecycle) pipeline).start();
        }

        setState(LifecycleState.STARTING);

        // Start our thread
        if (backgroundProcessorDelay > 0) {
            monitorFuture = Container.getService(ContainerBase.this).getServer()
                    .getUtilityExecutor().scheduleWithFixedDelay(
                            new ContainerBackgroundProcessorMonitor(), 0, 60, TimeUnit.SECONDS);
        }
    }",,
tomcat,16901,"log.debug(sm.getString(""upgradeHandler.ioerror"", connectionId), ioe)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/Http2UpgradeHandler.java/#L410,"@Override
    public SocketState upgradeDispatch(SocketEvent status) {
        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""upgradeHandler.upgradeDispatch.entry"", connectionId, status));
        }

        // WebConnection is not used so passing null here is fine
        // Might not be necessary. init() will handle that.
        init(null);


        SocketState result = SocketState.CLOSED;

        try {
            switch(status) {
            case OPEN_READ:
                synchronized (socketWrapper) {
                    if (!socketWrapper.canWrite()) {
                        // Only send a ping if there is no other data waiting to be sent.
                        // Ping manager will ensure they aren't sent too frequently.
                        pingManager.sendPing(false);
                    }
                }
                try {
                    // There is data to read so use the read timeout while
                    // reading frames ...
                    socketWrapper.setReadTimeout(protocol.getReadTimeout());
                    // ... and disable the connection timeout
                    setConnectionTimeout(-1);
                    while (true) {
                        try {
                            if (!parser.readFrame(false)) {
                                break;
                            }
                        } catch (StreamException se) {
                            // Stream errors are not fatal to the connection so
                            // continue reading frames
                            Stream stream = getStream(se.getStreamId(), false);
                            if (stream == null) {
                                sendStreamReset(se);
                            } else {
                                stream.close(se);
                            }
                        } finally {
                            if (overheadCount.get() > 0) {
                                throw new ConnectionException(
                                        sm.getString(""upgradeHandler.tooMuchOverhead"", connectionId),
                                        Http2Error.ENHANCE_YOUR_CALM);
                            }
                        }
                    }

                    // Need to know the correct timeout before starting the read
                    // but that may not be known at this time if one or more
                    // requests are currently being processed so don't set a
                    // timeout for the socket...
                    socketWrapper.setReadTimeout(-1);

                    // ...set a timeout on the connection
                    setConnectionTimeoutForStreamCount(activeRemoteStreamCount.get());

                } catch (Http2Exception ce) {
                    // Really ConnectionException
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""upgradeHandler.connectionError""), ce);
                    }
                    closeConnection(ce);
                    break;
                }

                if (connectionState.get() != ConnectionState.CLOSED) {
                    result = SocketState.UPGRADED;
                }
                break;

            case OPEN_WRITE:
                processWrites();

                result = SocketState.UPGRADED;
                break;

            case TIMEOUT:
                closeConnection(null);
                break;

            case DISCONNECT:
            case ERROR:
            case STOP:
            case CONNECT_FAIL:
                close();
                break;
            }
        } catch (IOException ioe) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""upgradeHandler.ioerror"", connectionId), ioe)
---------------Reference log end----------------
            }
            close();
        }

        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""upgradeHandler.upgradeDispatch.exit"", connectionId, result));
        }
        return result;
    }",,
tomcat,17118,"log.error(sm.getString(""endpoint.sendfile.closeError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/NioEndpoint.java/#L1238,"@Override
        protected void doClose() {
            if (log.isDebugEnabled()) {
                log.debug(""Calling ["" + getEndpoint() + ""].closeSocket(["" + this + ""])"");
            }
            try {
                getEndpoint().connections.remove(getSocket().getIOChannel());
                if (getSocket().isOpen()) {
                    getSocket().close(true);
                }
                if (getEndpoint().running && !getEndpoint().paused) {
                    if (nioChannels == null || !nioChannels.push(getSocket())) {
                        getSocket().free();
                    }
                }
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                if (log.isDebugEnabled()) {
                    log.error(sm.getString(""endpoint.debug.channelCloseFail""), e);
                }
            } finally {
                socketBufferHandler = SocketBufferHandler.EMPTY;
                nonBlockingWriteBuffer.clear();
                reset(NioChannel.CLOSED_NIO_CHANNEL);
            }
            try {
                SendfileData data = getSendfileData();
                if (data != null && data.fchannel != null && data.fchannel.isOpen()) {
                    data.fchannel.close();
                }
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.error(sm.getString(""endpoint.sendfile.closeError""), e)
---------------Reference log end----------------
                }
            }
        }",,
tomcat,17678,"log.debug(""Unable to close underlying SQL connection"", ignore)",debug,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/PooledConnection.java/#L422,"private void disconnect(boolean finalize) {
        if (isDiscarded() && connection == null) {
            return;
        }
        setDiscarded(true);
        if (connection != null) {
            try {
                parent.disconnectEvent(this, finalize);
                if (xaConnection == null) {
                    connection.close();
                } else {
                    xaConnection.close();
                }
            }catch (Exception ignore) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""Unable to close underlying SQL connection"", ignore)
---------------Reference log end----------------
                }
            }
        }
        connection = null;
        xaConnection = null;
        lastConnected = -1;
        if (finalize) {
          parent.finalize(this);
        }
    }",,
tomcat,16016,"log.debug(""store "" + elementDesc.getTag() + ""( "" + aElement + "" )"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/storeconfig/LoaderSF.java/#L47,"@Override
    public void store(PrintWriter aWriter, int indent, Object aElement)
            throws Exception {
        StoreDescription elementDesc = getRegistry().findDescription(
                aElement.getClass());
        if (elementDesc != null) {
            Loader loader = (Loader) aElement;
            if (!isDefaultLoader(loader)) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""store "" + elementDesc.getTag() + ""( "" + aElement + "" )"")
---------------Reference log end----------------
                }
                getStoreAppender().printIndent(aWriter, indent + 2);
                getStoreAppender().printTag(aWriter, indent + 2, loader,
                        elementDesc);
            }
        } else {
            if (log.isWarnEnabled()) {
                log
                        .warn(""Descriptor for element""
                                + aElement.getClass()
                                + "" not configured or element class not StandardManager!"");
            }
        }
    }",,
tomcat,15422,"log.error(sm.getString(""webappClassLoader.transformError"", name), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/loader/WebappClassLoaderBase.java/#L1194,"@Override
    public InputStream getResourceAsStream(String name) {

        if (log.isDebugEnabled()) {
            log.debug(""getResourceAsStream("" + name + "")"");
        }

        checkStateForResourceLoading(name);

        InputStream stream = null;

        boolean delegateFirst = delegate || filter(name, false);

        // (1) Delegate to parent if requested
        if (delegateFirst) {
            if (log.isDebugEnabled()) {
                log.debug(""  Delegating to parent classloader "" + parent);
            }
            stream = parent.getResourceAsStream(name);
            if (stream != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""  --> Returning stream from parent"");
                }
                return stream;
            }
        }

        // (2) Search local repositories
        if (log.isDebugEnabled()) {
            log.debug(""  Searching local repositories"");
        }
        String path = nameToPath(name);
        WebResource resource = resources.getClassLoaderResource(path);
        if (resource.exists()) {
            stream = resource.getInputStream();
            // Filter out .class resources through the ClassFileTranformer
            if (name.endsWith(CLASS_FILE_SUFFIX) && transformers.size() > 0) {
                // If the resource is a class, decorate it with any attached transformers
                ByteArrayOutputStream baos = new ByteArrayOutputStream();
                byte[] buf = new byte[8192];
                int numRead;
                try {
                    while ((numRead = stream.read(buf)) >= 0) {
                        baos.write(buf, 0, numRead);
                    }
                } catch (IOException e) {
                    log.error(sm.getString(""webappClassLoader.transformError"", name), e);
                    return null;
                } finally {
                    try {
                        stream.close();
                    } catch (IOException e) {
                    }
                }
                byte[] binaryContent = baos.toByteArray();
                String internalName = path.substring(1, path.length() - CLASS_FILE_SUFFIX.length());
                for (ClassFileTransformer transformer : this.transformers) {
                    try {
                        byte[] transformed = transformer.transform(
                                this, internalName, null, null, binaryContent);
                        if (transformed != null) {
                            binaryContent = transformed;
                        }
                    } catch (IllegalClassFormatException e) {
                        
---------------Reference log start----------------
log.error(sm.getString(""webappClassLoader.transformError"", name), e)
---------------Reference log end----------------
                        return null;
                    }
                }
                stream = new ByteArrayInputStream(binaryContent);
            }
            trackLastModified(path, resource);
        }
        try {
            if (hasExternalRepositories && stream == null) {
                URL url = super.findResource(name);
                if (url != null) {
                    stream = url.openStream();
                }
            }
        } catch (IOException e) {
            // Ignore
        }
        if (stream != null) {
            if (log.isDebugEnabled()) {
                log.debug(""  --> Returning stream from local"");
            }
            return stream;
        }

        // (3) Delegate to parent unconditionally
        if (!delegateFirst) {
            if (log.isDebugEnabled()) {
                log.debug(""  Delegating to parent classloader unconditionally "" + parent);
            }
            stream = parent.getResourceAsStream(name);
            if (stream != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""  --> Returning stream from parent"");
                }
                return stream;
            }
        }

        // (4) Resource was not found
        if (log.isDebugEnabled()) {
            log.debug(""  --> Resource not found, returning null"");
        }
        return null;
    }",,
tomcat,16729,"log.debug(sm.getString(""jreLeakListener.gcDaemonFail""), e)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/JreMemoryLeakPreventionListener.java/#L291,"@Override
    public void lifecycleEvent(LifecycleEvent event) {
        // Initialise these classes when Tomcat starts
        if (Lifecycle.BEFORE_INIT_EVENT.equals(event.getType())) {

            /*
             * First call to this loads all drivers visible to the current class
             * loader and its parents.
             *
             * Note: This is called before the context class loader is changed
             *       because we want any drivers located in CATALINA_HOME/lib
             *       and/or CATALINA_HOME/lib to be visible to DriverManager.
             *       Users wishing to avoid having JDBC drivers loaded by this
             *       class loader should add the JDBC driver(s) to the class
             *       path so they are loaded by the system class loader.
             */
            if (driverManagerProtection) {
                DriverManager.getDrivers();
            }

            ClassLoader loader = Thread.currentThread().getContextClassLoader();

            try
            {
                // Use the system classloader as the victim for all this
                // ClassLoader pinning we're about to do.
                Thread.currentThread().setContextClassLoader(
                        ClassLoader.getSystemClassLoader());

                /*
                 * Several components end up calling:
                 * sun.awt.AppContext.getAppContext()
                 *
                 * Those libraries / components known to trigger memory leaks
                 * due to eventual calls to getAppContext() are:
                 * - Google Web Toolkit via its use of javax.imageio
                 * - Batik
                 * - others TBD
                 *
                 * Note tha a call to sun.awt.AppContext.getAppContext() results
                 * in a thread being started named AWT-AppKit that requires a
                 * graphical environment to be available.
                 */

                // Trigger a call to sun.awt.AppContext.getAppContext(). This
                // will pin the system class loader in memory but that shouldn't
                // be an issue.
                if (appContextProtection) {
                    ImageIO.getCacheDirectory();
                }

                // Trigger the creation of the AWT (AWT-Windows, AWT-XAWT,
                // etc.) thread.
                // Note this issue is fixed in Java 8 update 05 onwards.
                if (awtThreadProtection && !JreCompat.isJre9Available()) {
                    java.awt.Toolkit.getDefaultToolkit();
                }

                /*
                 * Several components end up calling
                 * sun.misc.GC.requestLatency(long) which creates a daemon
                 * thread without setting the TCCL.
                 *
                 * Those libraries / components known to trigger memory leaks
                 * due to eventual calls to requestLatency(long) are:
                 * - javax.management.remote.rmi.RMIConnectorServer.start()
                 *
                 * Note: Long.MAX_VALUE is a special case that causes the thread
                 *       to terminate
                 *
                 * Fixed in Java 9 onwards (from early access build 130)
                 */
                if (gcDaemonProtection && !JreCompat.isJre9Available()) {
                    try {
                        Class<?> clazz = Class.forName(""sun.misc.GC"");
                        Method method = clazz.getDeclaredMethod(
                                ""requestLatency"",
                                new Class[] {long.class});
                        method.invoke(null, Long.valueOf(Long.MAX_VALUE - 1));
                    } catch (ClassNotFoundException e) {
                        if (JreVendor.IS_ORACLE_JVM) {
                            log.error(sm.getString(
                                    ""jreLeakListener.gcDaemonFail""), e);
                        } else {
                            
---------------Reference log start----------------
log.debug(sm.getString(""jreLeakListener.gcDaemonFail""), e)
---------------Reference log end----------------
                        }
                    } catch (SecurityException | NoSuchMethodException | IllegalArgumentException |
                            IllegalAccessException e) {
                        log.error(sm.getString(""jreLeakListener.gcDaemonFail""),
                                e);
                    } catch (InvocationTargetException e) {
                        ExceptionUtils.handleThrowable(e.getCause());
                        log.error(sm.getString(""jreLeakListener.gcDaemonFail""),
                                e);
                    }
                }

                /*
                 * Creating a MessageDigest during web application startup
                 * initializes the Java Cryptography Architecture. Under certain
                 * conditions this starts a Token poller thread with TCCL equal
                 * to the web application class loader.
                 *
                 * Instead we initialize JCA right now.
                 *
                 * Fixed in Java 9 onwards (from early access build 133)
                 */
                if (tokenPollerProtection && !JreCompat.isJre9Available()) {
                    java.security.Security.getProviders();
                }

                /*
                 * Several components end up opening JarURLConnections without
                 * first disabling caching. This effectively locks the file.
                 * Whilst more noticeable and harder to ignore on Windows, it
                 * affects all operating systems.
                 *
                 * Those libraries/components known to trigger this issue
                 * include:
                 * - log4j versions 1.2.15 and earlier
                 * - javax.xml.bind.JAXBContext.newInstance()
                 *
                 * https://bugs.openjdk.java.net/browse/JDK-8163449
                 *
                 * Java 9 onwards disables caching for JAR URLConnections
                 * Java 8 and earlier disables caching for all URLConnections
                 */

                // Set the default URL caching policy to not to cache
                if (urlCacheProtection) {
                    try {
                        JreCompat.getInstance().disableCachingForJarUrlConnections();
                    } catch (IOException e) {
                        log.error(sm.getString(""jreLeakListener.jarUrlConnCacheFail""), e);
                    }
                }

                /*
                 * Fixed in Java 9 onwards (from early access build 133)
                 */
                if (xmlParsingProtection && !JreCompat.isJre9Available()) {
                    // There are two known issues with XML parsing that affect
                    // Java 8+. The issues both relate to cached Exception
                    // instances that retain a link to the TCCL via the
                    // backtrace field. Note that YourKit only shows this field
                    // when using the HPROF format memory snapshots.
                    // https://bz.apache.org/bugzilla/show_bug.cgi?id=58486
                    // https://bugs.openjdk.java.net/browse/JDK-8146961
                    DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();
                    try {
                        DocumentBuilder documentBuilder = factory.newDocumentBuilder();
                        // Issue 1
                        // com.sun.org.apache.xml.internal.serialize.DOMSerializerImpl
                        Document document = documentBuilder.newDocument();
                        document.createElement(""dummy"");
                        DOMImplementationLS implementation =
                                (DOMImplementationLS)document.getImplementation();
                        implementation.createLSSerializer().writeToString(document);
                        // Issue 1
                        // com.sun.org.apache.xerces.internal.dom.DOMNormalizer
                        document.normalize();
                    } catch (ParserConfigurationException e) {
                        log.error(sm.getString(""jreLeakListener.xmlParseFail""),
                                e);
                    }
                }

                /*
                 * Fixed in Java 9 onwards (from early access build 130)
                 */
                if (ldapPoolProtection && !JreCompat.isJre9Available()) {
                    try {
                        Class.forName(""com.sun.jndi.ldap.LdapPoolManager"");
                    } catch (ClassNotFoundException e) {
                        if (JreVendor.IS_ORACLE_JVM) {
                            log.error(sm.getString(
                                    ""jreLeakListener.ldapPoolManagerFail""), e);
                        } else {
                            log.debug(sm.getString(
                                    ""jreLeakListener.ldapPoolManagerFail""), e);
                        }
                    }
                }

                /*
                 * Present in Java 7 onwards
                 * Fixed in Java 9 (from early access build 156)
                 */
                if (forkJoinCommonPoolProtection && !JreCompat.isJre9Available()) {
                    // Don't override any explicitly set property
                    if (System.getProperty(FORK_JOIN_POOL_THREAD_FACTORY_PROPERTY) == null) {
                        System.setProperty(FORK_JOIN_POOL_THREAD_FACTORY_PROPERTY,
                                SafeForkJoinWorkerThreadFactory.class.getName());
                    }
                }

                if (classesToInitialize != null) {
                    StringTokenizer strTok =
                        new StringTokenizer(classesToInitialize, "", \r\n\t"");
                    while (strTok.hasMoreTokens()) {
                        String classNameToLoad = strTok.nextToken();
                        try {
                            Class.forName(classNameToLoad);
                        } catch (ClassNotFoundException e) {
                            log.error(
                                sm.getString(""jreLeakListener.classToInitializeFail"",
                                    classNameToLoad), e);
                            // continue with next class to load
                        }
                    }
                }

            } finally {
                Thread.currentThread().setContextClassLoader(loader);
            }
        }
    }",,
tomcat,16929,"log.warn(sm.getString(""upgradeHandler.unexpectedAck"", connectionId, getIdAsString()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/Http2UpgradeHandler.java/#L1770,"@Override
    public void settingsEnd(boolean ack) throws IOException {
        if (ack) {
            if (!localSettings.ack()) {
                // Ack was unexpected
                
---------------Reference log start----------------
log.warn(sm.getString(""upgradeHandler.unexpectedAck"", connectionId, getIdAsString()))
---------------Reference log end----------------
            }
        } else {
            synchronized (socketWrapper) {
                socketWrapper.write(true, SETTINGS_ACK, 0, SETTINGS_ACK.length);
                socketWrapper.flush(true);
            }
        }
    }",,
tomcat,16906,log.debug(msg),debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/Http2UpgradeHandler.java/#L603,"protected void writeSettings() {
        // Send the initial settings frame
        try {
            byte[] settings = localSettings.getSettingsFrameForPending();
            socketWrapper.write(true, settings, 0, settings.length);
            byte[] windowUpdateFrame = createWindowUpdateForSettings();
            if (windowUpdateFrame.length > 0) {
                socketWrapper.write(true,  windowUpdateFrame, 0 , windowUpdateFrame.length);
            }
            socketWrapper.flush(true);
        } catch (IOException ioe) {
            String msg = sm.getString(""upgradeHandler.sendPrefaceFail"", connectionId);
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(msg)
---------------Reference log end----------------
            }
            throw new ProtocolException(msg, ioe);
        }
    }",,
tomcat,16932,"log.debug(sm.getString(""streamStateMachine.debug.change"", connectionId, streamId, oldState, newState))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/StreamStateMachine.java/#L115,"private void stateChange(State oldState, State newState) {
        if (state == oldState) {
            state = newState;
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""streamStateMachine.debug.change"", connectionId, streamId, oldState, newState))
---------------Reference log end----------------
            }
        }
    }",,
tomcat,16764,"log.error(sm.getString(""standardService.mapperListener.stopFailed""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardService.java/#L157,"@Override
    public void setContainer(Engine engine) {
        Engine oldEngine = this.engine;
        if (oldEngine != null) {
            oldEngine.setService(null);
        }
        this.engine = engine;
        if (this.engine != null) {
            this.engine.setService(this);
        }
        if (getState().isAvailable()) {
            if (this.engine != null) {
                try {
                    this.engine.start();
                } catch (LifecycleException e) {
                    log.error(sm.getString(""standardService.engine.startFailed""), e);
                }
            }
            // Restart MapperListener to pick up new engine.
            try {
                mapperListener.stop();
            } catch (LifecycleException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""standardService.mapperListener.stopFailed""), e)
---------------Reference log end----------------
            }
            try {
                mapperListener.start();
            } catch (LifecycleException e) {
                log.error(sm.getString(""standardService.mapperListener.startFailed""), e);
            }
            if (oldEngine != null) {
                try {
                    oldEngine.stop();
                } catch (LifecycleException e) {
                    log.error(sm.getString(""standardService.engine.stopFailed""), e);
                }
            }
        }

        // Report this property change to interested listeners
        support.firePropertyChange(""container"", oldEngine, this.engine);
    }",,
tomcat,17091,"log.warn(sm.getString(""endpoint.nio.stopLatchAwaitFail""))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/NioEndpoint.java/#L310,"@Override
    public void stopInternal() {
        if (!paused) {
            pause();
        }
        if (running) {
            running = false;
            acceptor.stop(10);
            if (poller != null) {
                poller.destroy();
                poller = null;
            }
            try {
                if (!getStopLatch().await(selectorTimeout + 100, TimeUnit.MILLISECONDS)) {
                    
---------------Reference log start----------------
log.warn(sm.getString(""endpoint.nio.stopLatchAwaitFail""))
---------------Reference log end----------------
                }
            } catch (InterruptedException e) {
                log.warn(sm.getString(""endpoint.nio.stopLatchAwaitInterrupted""), e);
            }
            shutdownExecutor();
            if (eventCache != null) {
                eventCache.clear();
                eventCache = null;
            }
            if (nioChannels != null) {
                nioChannels.clear();
                nioChannels = null;
            }
            if (processorCache != null) {
                processorCache.clear();
                processorCache = null;
            }
        }
    }",,
tomcat,16056,"log.warn(sm.getString(""memoryUserDatabase.notPersistable""))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/users/MemoryUserDatabase.java/#L557,"@Override
    public void save() throws Exception {

        if (getReadonly()) {
            log.error(sm.getString(""memoryUserDatabase.readOnly""));
            return;
        }

        if (!isWriteable()) {
            
---------------Reference log start----------------
log.warn(sm.getString(""memoryUserDatabase.notPersistable""))
---------------Reference log end----------------
            return;
        }

        // Write out contents to a temporary file
        File fileNew = new File(pathnameNew);
        if (!fileNew.isAbsolute()) {
            fileNew = new File(System.getProperty(Globals.CATALINA_BASE_PROP), pathnameNew);
        }

        writeLock.lock();
        try {
            try (FileOutputStream fos = new FileOutputStream(fileNew);
                    OutputStreamWriter osw = new OutputStreamWriter(fos, StandardCharsets.UTF_8);
                    PrintWriter writer = new PrintWriter(osw)) {

                // Print the file prolog
                writer.println(""<?xml version='1.0' encoding='utf-8'?>"");
                writer.println(""<tomcat-users xmlns=\""http://tomcat.apache.org/xml\"""");
                writer.print(""              "");
                writer.println(""xmlns:xsi=\""http://www.w3.org/2001/XMLSchema-instance\"""");
                writer.print(""              "");
                writer.println(""xsi:schemaLocation=\""http://tomcat.apache.org/xml tomcat-users.xsd\"""");
                writer.println(""              version=\""1.0\"">"");

                // Print entries for each defined role, group, and user
                Iterator<?> values = null;
                values = getRoles();
                while (values.hasNext()) {
                    writer.print(""  "");
                    writer.println(values.next());
                }
                values = getGroups();
                while (values.hasNext()) {
                    writer.print(""  "");
                    writer.println(values.next());
                }
                values = getUsers();
                while (values.hasNext()) {
                    writer.print(""  "");
                    writer.println(((MemoryUser) values.next()).toXml());
                }

                // Print the file epilog
                writer.println(""</tomcat-users>"");

                // Check for errors that occurred while printing
                if (writer.checkError()) {
                    throw new IOException(sm.getString(""memoryUserDatabase.writeException"",
                            fileNew.getAbsolutePath()));
                }
            } catch (IOException e) {
                if (fileNew.exists() && !fileNew.delete()) {
                    log.warn(sm.getString(""memoryUserDatabase.fileDelete"", fileNew));
                }
                throw e;
            }
            this.lastModified = fileNew.lastModified();
        } finally {
            writeLock.unlock();
        }

        // Perform the required renames to permanently save this file
        File fileOld = new File(pathnameOld);
        if (!fileOld.isAbsolute()) {
            fileOld = new File(System.getProperty(Globals.CATALINA_BASE_PROP), pathnameOld);
        }
        if (fileOld.exists() && !fileOld.delete()) {
            throw new IOException(sm.getString(""memoryUserDatabase.fileDelete"", fileOld));
        }
        File fileOrig = new File(pathname);
        if (!fileOrig.isAbsolute()) {
            fileOrig = new File(System.getProperty(Globals.CATALINA_BASE_PROP), pathname);
        }
        if (fileOrig.exists()) {
            if (!fileOrig.renameTo(fileOld)) {
                throw new IOException(sm.getString(""memoryUserDatabase.renameOld"",
                        fileOld.getAbsolutePath()));
            }
        }
        if (!fileNew.renameTo(fileOrig)) {
            if (fileOld.exists()) {
                if (!fileOld.renameTo(fileOrig)) {
                    log.warn(sm.getString(""memoryUserDatabase.restoreOrig"", fileOld));
                }
            }
            throw new IOException(sm.getString(""memoryUserDatabase.renameNew"",
                    fileOrig.getAbsolutePath()));
        }
        if (fileOld.exists() && !fileOld.delete()) {
            throw new IOException(sm.getString(""memoryUserDatabase.fileDelete"", fileOld));
        }
    }",,
tomcat,16569,"log.debug(""Not renewing threads when the context is stopping. "" + ""It is not configured to do it."")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/ThreadLocalLeakPreventionListener.java/#L123,"private void stopIdleThreads(Context context) {
        if (serverStopping) {
            return;
        }

        if (!(context instanceof StandardContext) ||
            !((StandardContext) context).getRenewThreadsWhenStoppingContext()) {
            
---------------Reference log start----------------
log.debug(""Not renewing threads when the context is stopping. "" + ""It is not configured to do it."")
---------------Reference log end----------------
            return;
        }

        Engine engine = (Engine) context.getParent().getParent();
        Service service = engine.getService();
        Connector[] connectors = service.findConnectors();
        if (connectors != null) {
            for (Connector connector : connectors) {
                ProtocolHandler handler = connector.getProtocolHandler();
                Executor executor = null;
                if (handler != null) {
                    executor = handler.getExecutor();
                }

                if (executor instanceof ThreadPoolExecutor) {
                    ThreadPoolExecutor threadPoolExecutor =
                        (ThreadPoolExecutor) executor;
                    threadPoolExecutor.contextStopping();
                } else if (executor instanceof StandardThreadExecutor) {
                    StandardThreadExecutor stdThreadExecutor =
                        (StandardThreadExecutor) executor;
                    stdThreadExecutor.contextStopping();
                }

            }
        }
    }",,
tomcat,16022,"log.warn(sm.getString(""factory.storeNoDescriptor"", aElement.getClass()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/storeconfig/StoreFactoryBase.java/#L134,"@Override
    public void store(PrintWriter aWriter, int indent, Object aElement)
            throws Exception {

        StoreDescription elementDesc = getRegistry().findDescription(
                aElement.getClass());

        if (elementDesc != null) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""factory.storeTag"",
                        elementDesc.getTag(), aElement));
            }
            getStoreAppender().printIndent(aWriter, indent + 2);
            if (!elementDesc.isChildren()) {
                getStoreAppender().printTag(aWriter, indent, aElement,
                        elementDesc);
            } else {
                getStoreAppender().printOpenTag(aWriter, indent + 2, aElement,
                        elementDesc);
                storeChildren(aWriter, indent + 2, aElement, elementDesc);
                getStoreAppender().printIndent(aWriter, indent + 2);
                getStoreAppender().printCloseTag(aWriter, elementDesc);
            }
        } else {
            
---------------Reference log start----------------
log.warn(sm.getString(""factory.storeNoDescriptor"", aElement.getClass()))
---------------Reference log end----------------
        }
    }",,
tomcat,15581,"containerLog.error(sm.getString(""jndiRealm.exception""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JNDIRealm.java/#L2240,"@Override
    protected String getPassword(String username) {
        String userPassword = getUserPassword();
        if (userPassword == null || userPassword.isEmpty()) {
            return null;
        }

        JNDIConnection connection = null;
        User user = null;
        try {
            // Ensure that we have a directory context available
            connection = get();

            // Occasionally the directory context will timeout.  Try one more
            // time before giving up.
            try {
                user = getUser(connection, username, null);
            } catch (NullPointerException | NamingException e) {
                // log the exception so we know it's there.
                containerLog.info(sm.getString(""jndiRealm.exception.retry""), e);

                // close the connection so we know it will be reopened.
                close(connection);
                closePooledConnections();

                // open a new directory context.
                connection = get();

                // Try the authentication again.
                user = getUser(connection, username, null);
            }

            // Release this context
            release(connection);

            if (user == null) {
                // User should be found...
                return null;
            } else {
                // ... and have a password
                return user.getPassword();
            }
        } catch (NamingException e) {
            // Log the problem for posterity
            
---------------Reference log start----------------
containerLog.error(sm.getString(""jndiRealm.exception""), e)
---------------Reference log end----------------
            return null;
        }
    }",,
tomcat,16265,"log.info(sm.getString(""lifecycleBase.alreadyStarted"", toString()))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/util/LifecycleBase.java/#L166,"@Override
    public final synchronized void start() throws LifecycleException {

        if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) ||
                LifecycleState.STARTED.equals(state)) {

            if (log.isDebugEnabled()) {
                Exception e = new LifecycleException();
                log.debug(sm.getString(""lifecycleBase.alreadyStarted"", toString()), e);
            } else if (log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""lifecycleBase.alreadyStarted"", toString()))
---------------Reference log end----------------
            }

            return;
        }

        if (state.equals(LifecycleState.NEW)) {
            init();
        } else if (state.equals(LifecycleState.FAILED)) {
            stop();
        } else if (!state.equals(LifecycleState.INITIALIZED) &&
                !state.equals(LifecycleState.STOPPED)) {
            invalidTransition(Lifecycle.BEFORE_START_EVENT);
        }

        try {
            setStateInternal(LifecycleState.STARTING_PREP, null, false);
            startInternal();
            if (state.equals(LifecycleState.FAILED)) {
                // This is a 'controlled' failure. The component put itself into the
                // FAILED state so call stop() to complete the clean-up.
                stop();
            } else if (!state.equals(LifecycleState.STARTING)) {
                // Shouldn't be necessary but acts as a check that sub-classes are
                // doing what they are supposed to.
                invalidTransition(Lifecycle.AFTER_START_EVENT);
            } else {
                setStateInternal(LifecycleState.STARTED, null, false);
            }
        } catch (Throwable t) {
            // This is an 'uncontrolled' failure so put the component into the
            // FAILED state and throw an exception.
            handleSubClassException(t, ""lifecycleBase.startFail"", toString());
        }
    }",,
tomcat,17175,"log.debug(sm.getString(""openssl.checkConf""))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/openssl/OpenSSLContext.java/#L317,"@Override
    public synchronized void init(KeyManager[] kms, TrustManager[] tms, SecureRandom sr) {
        if (initialized) {
            log.warn(sm.getString(""openssl.doubleInit""));
            return;
        }
        try {
            if (sslHostConfig.getInsecureRenegotiation()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION);
            }

            // Use server's preference order for ciphers (rather than
            // client's)
            if (sslHostConfig.getHonorCipherOrder()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_CIPHER_SERVER_PREFERENCE);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_CIPHER_SERVER_PREFERENCE);
            }

            // Disable compression if requested
            if (sslHostConfig.getDisableCompression()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_NO_COMPRESSION);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_NO_COMPRESSION);
            }

            // Disable TLS Session Tickets (RFC4507) to protect perfect forward secrecy
            if (sslHostConfig.getDisableSessionTickets()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_NO_TICKET);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_NO_TICKET);
            }

            // List the ciphers that the client is permitted to negotiate
            SSLContext.setCipherSuite(ctx, sslHostConfig.getCiphers());

            if (certificate.getCertificateFile() == null) {
                certificate.setCertificateKeyManager(OpenSSLUtil.chooseKeyManager(kms));
            }

            addCertificate(certificate);

            // Client certificate verification
            int value = 0;
            switch (sslHostConfig.getCertificateVerification()) {
            case NONE:
                value = SSL.SSL_CVERIFY_NONE;
                break;
            case OPTIONAL:
                value = SSL.SSL_CVERIFY_OPTIONAL;
                break;
            case OPTIONAL_NO_CA:
                value = SSL.SSL_CVERIFY_OPTIONAL_NO_CA;
                break;
            case REQUIRED:
                value = SSL.SSL_CVERIFY_REQUIRE;
                break;
            }
            SSLContext.setVerify(ctx, value, sslHostConfig.getCertificateVerificationDepth());

            if (tms != null) {
                // Client certificate verification based on custom trust managers
                x509TrustManager = chooseTrustManager(tms);
                SSLContext.setCertVerifyCallback(ctx, new CertificateVerifier() {
                    @Override
                    public boolean verify(long ssl, byte[][] chain, String auth) {
                        X509Certificate[] peerCerts = certificates(chain);
                        try {
                            x509TrustManager.checkClientTrusted(peerCerts, auth);
                            return true;
                        } catch (Exception e) {
                            log.debug(sm.getString(""openssl.certificateVerificationFailed""), e);
                        }
                        return false;
                    }
                });
                // Pass along the DER encoded certificates of the accepted client
                // certificate issuers, so that their subjects can be presented
                // by the server during the handshake to allow the client choosing
                // an acceptable certificate
                for (X509Certificate caCert : x509TrustManager.getAcceptedIssuers()) {
                    SSLContext.addClientCACertificateRaw(ctx, caCert.getEncoded());
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""openssl.addedClientCaCert"", caCert.toString()));
                    }
                }
            } else {
                // Client certificate verification based on trusted CA files and dirs
                SSLContext.setCACertificate(ctx,
                        SSLHostConfig.adjustRelativePath(sslHostConfig.getCaCertificateFile()),
                        SSLHostConfig.adjustRelativePath(sslHostConfig.getCaCertificatePath()));
            }

            if (negotiableProtocols != null && negotiableProtocols.size() > 0) {
                List<String> protocols = new ArrayList<>(negotiableProtocols);
                protocols.add(""http/1.1"");
                String[] protocolsArray = protocols.toArray(new String[0]);
                SSLContext.setAlpnProtos(ctx, protocolsArray, SSL.SSL_SELECTOR_FAILURE_NO_ADVERTISE);
                SSLContext.setNpnProtos(ctx, protocolsArray, SSL.SSL_SELECTOR_FAILURE_NO_ADVERTISE);
            }

            // Apply OpenSSLConfCmd if used
            OpenSSLConf openSslConf = sslHostConfig.getOpenSslConf();
            if (openSslConf != null && cctx != 0) {
                // Check OpenSSLConfCmd if used
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""openssl.checkConf""))
---------------Reference log end----------------
                }
                try {
                    if (!openSslConf.check(cctx)) {
                        log.error(sm.getString(""openssl.errCheckConf""));
                        throw new Exception(sm.getString(""openssl.errCheckConf""));
                    }
                } catch (Exception e) {
                    throw new Exception(sm.getString(""openssl.errCheckConf""), e);
                }
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""openssl.applyConf""));
                }
                try {
                    if (!openSslConf.apply(cctx, ctx)) {
                        log.error(sm.getString(""openssl.errApplyConf""));
                        throw new SSLException(sm.getString(""openssl.errApplyConf""));
                    }
                } catch (Exception e) {
                    throw new SSLException(sm.getString(""openssl.errApplyConf""), e);
                }
                // Reconfigure the enabled protocols
                int opts = SSLContext.getOptions(ctx);
                List<String> enabled = new ArrayList<>();
                // Seems like there is no way to explicitly disable SSLv2Hello
                // in OpenSSL so it is always enabled
                enabled.add(Constants.SSL_PROTO_SSLv2Hello);
                if ((opts & SSL.SSL_OP_NO_TLSv1) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1);
                }
                if ((opts & SSL.SSL_OP_NO_TLSv1_1) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1_1);
                }
                if ((opts & SSL.SSL_OP_NO_TLSv1_2) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1_2);
                }
                if ((opts & SSL.SSL_OP_NO_SSLv2) == 0) {
                    enabled.add(Constants.SSL_PROTO_SSLv2);
                }
                if ((opts & SSL.SSL_OP_NO_SSLv3) == 0) {
                    enabled.add(Constants.SSL_PROTO_SSLv3);
                }
                sslHostConfig.setEnabledProtocols(
                        enabled.toArray(new String[0]));
                // Reconfigure the enabled ciphers
                sslHostConfig.setEnabledCiphers(SSLContext.getCiphers(ctx));
            }

            sessionContext = new OpenSSLSessionContext(this);
            // If client authentication is being used, OpenSSL requires that
            // this is set so always set it in case an app is configured to
            // require it
            sessionContext.setSessionIdContext(SSLContext.DEFAULT_SESSION_ID_CONTEXT);
            sslHostConfig.setOpenSslContext(Long.valueOf(ctx));
            initialized = true;
        } catch (Exception e) {
            log.warn(sm.getString(""openssl.errorSSLCtxInit""), e);
            destroy();
        }
    }",,
tomcat,16724,"log.error(sm.getString(""standardServer.storeConfig.error""), t)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardServer.java/#L864,"public synchronized void storeConfig() throws InstanceNotFoundException, MBeanException {
        try {
            // Note: Hard-coded domain used since this object is per Server/JVM
            ObjectName sname = new ObjectName(""Catalina:type=StoreConfig"");
            MBeanServer server = Registry.getRegistry(null, null).getMBeanServer();
            if (server.isRegistered(sname)) {
                server.invoke(sname, ""storeConfig"", null, null);
            } else {
                log.error(sm.getString(""standardServer.storeConfig.notAvailable"", sname));
            }
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            
---------------Reference log start----------------
log.error(sm.getString(""standardServer.storeConfig.error""), t)
---------------Reference log end----------------
        }
    }",,
tomcat,16235,"log.error(sm.getString(""hostConfig.context.restart"", app.name), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/HostConfig.java/#L1493,"private void reload(DeployedApplication app, File fileToRemove, String newDocBase) {
        if(log.isInfoEnabled()) {
            log.info(sm.getString(""hostConfig.reload"", app.name));
        }
        Context context = (Context) host.findChild(app.name);
        if (context.getState().isAvailable()) {
            if (fileToRemove != null && newDocBase != null) {
                context.addLifecycleListener(
                        new ExpandedDirectoryRemovalListener(fileToRemove, newDocBase));
            }
            // Reload catches and logs exceptions
            context.reload();
        } else {
            // If the context was not started (for example an error
            // in web.xml) we'll still get to try to start
            if (fileToRemove != null && newDocBase != null) {
                ExpandWar.delete(fileToRemove);
                context.setDocBase(newDocBase);
            }
            try {
                context.start();
            } catch (Exception e) {
                
---------------Reference log start----------------
log.error(sm.getString(""hostConfig.context.restart"", app.name), e)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,16673,"log.debug(""resetContext "" + getObjectName())",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardContext.java/#L5632,"private void resetContext() throws Exception {
        // Restore the original state ( pre reading web.xml in start )
        // If you extend this - override this method and make sure to clean up

        // Don't reset anything that is read from a <Context.../> element since
        // <Context .../> elements are read at initialisation will not be read
        // again for this object
        for (Container child : findChildren()) {
            removeChild(child);
        }
        startupTime = 0;
        startTime = 0;
        tldScanTime = 0;

        // Bugzilla 32867
        distributable = false;

        applicationListeners = new String[0];
        applicationEventListenersList.clear();
        applicationLifecycleListenersObjects = new Object[0];
        jspConfigDescriptor = null;

        initializers.clear();

        createdServlets.clear();

        postConstructMethods.clear();
        preDestroyMethods.clear();

        if(log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""resetContext "" + getObjectName())
---------------Reference log end----------------
        }
    }",,
tomcat,16115,"host.getLogger().info(sm.getString(""userConfig.deploy"", user))",getLogger,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/UserConfig.java/#L346,"private void deploy(String user, String home) {

        // Does this user have a web application to be deployed?
        String contextPath = ""/~"" + user;
        if (host.findChild(contextPath) != null) {
            return;
        }
        File app = new File(home, directoryName);
        if (!app.exists() || !app.isDirectory()) {
            return;
        }

        
---------------Reference log start----------------
host.getLogger().info(sm.getString(""userConfig.deploy"", user))
---------------Reference log end----------------

        // Deploy the web application for this user
        try {
            Class<?> clazz = Class.forName(contextClass);
            Context context = (Context) clazz.getConstructor().newInstance();
            context.setPath(contextPath);
            context.setDocBase(app.toString());
            clazz = Class.forName(configClass);
            LifecycleListener listener = (LifecycleListener) clazz.getConstructor().newInstance();
            context.addLifecycleListener(listener);
            host.addChild(context);
        } catch (Exception e) {
            host.getLogger().error(sm.getString(""userConfig.error"", user), e);
        }

    }",,
tomcat,16796,"log.error(sm.getString(""globalResources.createError.runtime""), ex)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/mbeans/GlobalResourcesLifecycleListener.java/#L143,"protected void createMBeans(String prefix, Context context) throws NamingException {

        if (log.isDebugEnabled()) {
            log.debug(""Creating MBeans for Global JNDI Resources in Context '"" +
                prefix + ""'"");
        }

        try {
            NamingEnumeration<Binding> bindings = context.listBindings("""");
            while (bindings.hasMore()) {
                Binding binding = bindings.next();
                String name = prefix + binding.getName();
                Object value = context.lookup(binding.getName());
                if (log.isDebugEnabled()) {
                    log.debug(""Checking resource "" + name);
                }
                if (value instanceof Context) {
                    createMBeans(name + ""/"", (Context) value);
                } else if (value instanceof UserDatabase) {
                    try {
                        createMBeans(name, (UserDatabase) value);
                    } catch (Exception e) {
                        log.error(sm.getString(""globalResources.userDatabaseCreateError"", name), e);
                    }
                }
            }
        } catch (RuntimeException ex) {
            
---------------Reference log start----------------
log.error(sm.getString(""globalResources.createError.runtime""), ex)
---------------Reference log end----------------
        } catch (OperationNotSupportedException ex) {
            log.error(sm.getString(""globalResources.createError.operation""), ex);
        }
    }",,
tomcat,16446,"log.debug(""No members in cluster, ignoring message:"" + msg)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/tcp/SimpleTcpCluster.java/#L726,"@Override
    public void send(ClusterMessage msg, Member dest, int sendOptions) {
        try {
            msg.setAddress(getLocalMember());
            if (dest != null) {
                if (!getLocalMember().equals(dest)) {
                    channel.send(new Member[] {dest}, msg, sendOptions);
                } else {
                    log.error(sm.getString(""simpleTcpCluster.unableSend.localMember"", msg));
                }
            } else {
                Member[] destmembers = channel.getMembers();
                if (destmembers.length>0) {
                    channel.send(destmembers,msg, sendOptions);
                } else if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""No members in cluster, ignoring message:"" + msg)
---------------Reference log end----------------
                }
            }
        } catch (Exception x) {
            log.error(sm.getString(""simpleTcpCluster.sendFailed""), x);
        }
    }",,
tomcat,17555,"log.warn(Localizer.getMessage(""jsp.warning.compiler.javafile.delete.fail"", file.getAbsolutePath()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/Compiler.java/#L276,"protected Map<String,SmapStratum> generateJava() throws Exception {

        long t1, t2, t3, t4;

        t1 = t2 = t3 = t4 = 0;

        if (log.isDebugEnabled()) {
            t1 = System.currentTimeMillis();
        }

        // Setup page info area
        pageInfo = new PageInfo(new BeanRepository(ctxt.getClassLoader(),
                errDispatcher), ctxt);

        JspConfig jspConfig = options.getJspConfig();
        JspConfig.JspProperty jspProperty = jspConfig.findJspProperty(ctxt
                .getJspFile());

        /*
         * If the current uri is matched by a pattern specified in a
         * jsp-property-group in web.xml, initialize pageInfo with those
         * properties.
         */
        if (jspProperty.isELIgnored() != null) {
            pageInfo.setELIgnored(JspUtil.booleanValue(jspProperty
                    .isELIgnored()));
        }
        if (jspProperty.isScriptingInvalid() != null) {
            pageInfo.setScriptingInvalid(JspUtil.booleanValue(jspProperty
                    .isScriptingInvalid()));
        }
        if (jspProperty.getIncludePrelude() != null) {
            pageInfo.setIncludePrelude(jspProperty.getIncludePrelude());
        }
        if (jspProperty.getIncludeCoda() != null) {
            pageInfo.setIncludeCoda(jspProperty.getIncludeCoda());
        }
        if (jspProperty.isDeferedSyntaxAllowedAsLiteral() != null) {
            pageInfo.setDeferredSyntaxAllowedAsLiteral(JspUtil.booleanValue(jspProperty
                    .isDeferedSyntaxAllowedAsLiteral()));
        }
        if (jspProperty.isTrimDirectiveWhitespaces() != null) {
            pageInfo.setTrimDirectiveWhitespaces(JspUtil.booleanValue(jspProperty
                    .isTrimDirectiveWhitespaces()));
        }
        // Default ContentType processing is deferred until after the page has
        // been parsed
        if (jspProperty.getBuffer() != null) {
            pageInfo.setBufferValue(jspProperty.getBuffer(), null,
                    errDispatcher);
        }
        if (jspProperty.isErrorOnUndeclaredNamespace() != null) {
            pageInfo.setErrorOnUndeclaredNamespace(
                    JspUtil.booleanValue(
                            jspProperty.isErrorOnUndeclaredNamespace()));
        }
        if (ctxt.isTagFile()) {
            try {
                double libraryVersion = Double.parseDouble(ctxt.getTagInfo()
                        .getTagLibrary().getRequiredVersion());
                if (libraryVersion < 2.0) {
                    pageInfo.setIsELIgnored(""true"", null, errDispatcher, true);
                }
                if (libraryVersion < 2.1) {
                    pageInfo.setDeferredSyntaxAllowedAsLiteral(""true"", null,
                            errDispatcher, true);
                }
            } catch (NumberFormatException ex) {
                errDispatcher.jspError(ex);
            }
        }

        ctxt.checkOutputDir();
        String javaFileName = ctxt.getServletJavaFileName();

        try {
            /*
             * The setting of isELIgnored changes the behaviour of the parser
             * in subtle ways. To add to the 'fun', isELIgnored can be set in
             * any file that forms part of the translation unit so setting it
             * in a file included towards the end of the translation unit can
             * change how the parser should have behaved when parsing content
             * up to the point where isELIgnored was set. Arghh!
             * Previous attempts to hack around this have only provided partial
             * solutions. We now use two passes to parse the translation unit.
             * The first just parses the directives and the second parses the
             * whole translation unit once we know how isELIgnored has been set.
             * TODO There are some possible optimisations of this process.
             */
            // Parse the file
            ParserController parserCtl = new ParserController(ctxt, this);

            // Pass 1 - the directives
            Node.Nodes directives =
                parserCtl.parseDirectives(ctxt.getJspFile());
            Validator.validateDirectives(this, directives);

            // Pass 2 - the whole translation unit
            pageNodes = parserCtl.parse(ctxt.getJspFile());

            // Leave this until now since it can only be set once - bug 49726
            if (pageInfo.getContentType() == null &&
                    jspProperty.getDefaultContentType() != null) {
                pageInfo.setContentType(jspProperty.getDefaultContentType());
            }

            if (ctxt.isPrototypeMode()) {
                // generate prototype .java file for the tag file
                try (ServletWriter writer = setupContextWriter(javaFileName)) {
                    Generator.generate(writer, this, pageNodes);
                    return null;
                }
            }

            // Validate and process attributes - don't re-validate the
            // directives we validated in pass 1
            Validator.validateExDirectives(this, pageNodes);

            if (log.isDebugEnabled()) {
                t2 = System.currentTimeMillis();
            }

            // Collect page info
            Collector.collect(this, pageNodes);

            // Compile (if necessary) and load the tag files referenced in
            // this compilation unit.
            tfp = new TagFileProcessor();
            tfp.loadTagFiles(this, pageNodes);

            if (log.isDebugEnabled()) {
                t3 = System.currentTimeMillis();
            }

            // Determine which custom tag needs to declare which scripting vars
            ScriptingVariabler.set(pageNodes, errDispatcher);

            // Optimizations by Tag Plugins
            TagPluginManager tagPluginManager = options.getTagPluginManager();
            tagPluginManager.apply(pageNodes, errDispatcher, pageInfo);

            // Optimization: concatenate contiguous template texts.
            TextOptimizer.concatenate(this, pageNodes);

            // Generate static function mapper codes.
            ELFunctionMapper.map(pageNodes);

            // generate servlet .java file
            try (ServletWriter writer = setupContextWriter(javaFileName)) {
                Generator.generate(writer, this, pageNodes);
            }

            // The writer is only used during the compile, dereference
            // it in the JspCompilationContext when done to allow it
            // to be GC'd and save memory.
            ctxt.setWriter(null);

            if (log.isDebugEnabled()) {
                t4 = System.currentTimeMillis();
                log.debug(""Generated "" + javaFileName + "" total="" + (t4 - t1)
                        + "" generate="" + (t4 - t3) + "" validate="" + (t2 - t1));
            }

        } catch (RuntimeException e) {
            // Remove the generated .java file
            File file = new File(javaFileName);
            if (file.exists()) {
                if (!file.delete()) {
                    
---------------Reference log start----------------
log.warn(Localizer.getMessage(""jsp.warning.compiler.javafile.delete.fail"", file.getAbsolutePath()))
---------------Reference log end----------------
                }
            }
            throw e;
        }

        Map<String,SmapStratum> smaps = null;

        // JSR45 Support
        if (!options.isSmapSuppressed()) {
            smaps = SmapUtil.generateSmap(ctxt, pageNodes);
            // Add them to the web application wide cache for future lookup in
            // error handling etc.
            ctxt.getRuntimeContext().getSmaps().putAll(smaps);
        }

        // If any proto type .java and .class files was generated,
        // the prototype .java may have been replaced by the current
        // compilation (if the tag file is self referencing), but the
        // .class file need to be removed, to make sure that javac would
        // generate .class again from the new .java file just generated.
        tfp.removeProtoTypeFiles(ctxt.getClassFileName());

        return smaps;
    }",,
tomcat,17134,"log.warn(sm.getString(""acceptor.stop.fail"", getThreadName()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/Acceptor.java/#L172,"public void stop(int waitSeconds) {
        stopCalled = true;
        if (waitSeconds > 0) {
            try {
                if (!stopLatch.await(waitSeconds, TimeUnit.SECONDS)) {
                   
---------------Reference log start----------------
log.warn(sm.getString(""acceptor.stop.fail"", getThreadName()))
---------------Reference log end----------------
                }
            } catch (InterruptedException e) {
                log.warn(sm.getString(""acceptor.stop.interrupted"", getThreadName()), e);
            }
        }
    }",,
tomcat,16059,"log.error(sm.getString(""memoryUserDatabase.reloadError"", id, uri), ioe)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/users/MemoryUserDatabase.java/#L681,"@Override
    public void backgroundProcess() {
        if (!watchSource) {
            return;
        }

        URI uri = ConfigFileLoader.getSource().getURI(getPathname());
        URLConnection uConn = null;
        try {
            URL url = uri.toURL();
            uConn = url.openConnection();

            if (this.lastModified != uConn.getLastModified()) {
                writeLock.lock();
                try {
                    long detectedLastModified = uConn.getLastModified();
                    // Last modified as a resolution of 1s. Ensure that a write
                    // to the file is not in progress by ensuring that the last
                    // modified time is at least 2 seconds ago.
                    if (this.lastModified != detectedLastModified &&
                            detectedLastModified + 2000 < System.currentTimeMillis()) {
                        log.info(sm.getString(""memoryUserDatabase.reload"", id, uri));
                        open();
                    }
                } finally {
                    writeLock.unlock();
                }
            }
        } catch (Exception ioe) {
            
---------------Reference log start----------------
log.error(sm.getString(""memoryUserDatabase.reloadError"", id, uri), ioe)
---------------Reference log end----------------
        } finally {
            if (uConn != null) {
                try {
                    // Can't close a uConn directly. Have to do it like this.
                    uConn.getInputStream().close();
                } catch (FileNotFoundException fnfe) {
                    // The file doesn't exist.
                    // This has been logged above. No need to log again.
                    // Set the last modified time to avoid repeated log messages
                    this.lastModified = 0;
                } catch (IOException ioe) {
                    log.warn(sm.getString(""memoryUserDatabase.fileClose"", pathname), ioe);
                }
            }
        }
    }",,
tomcat,15259,"log.error(sm.getString(""persistentManager.swapInException"", id), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/PersistentManagerBase.java/#L795,"private Session securedStoreLoad(String id) throws IOException, ClassNotFoundException {
        try {
            return AccessController.doPrivileged(
                    new PrivilegedStoreLoad(id));
        } catch (PrivilegedActionException ex) {
            Exception e = ex.getException();
            
---------------Reference log start----------------
log.error(sm.getString(""persistentManager.swapInException"", id), e)
---------------Reference log end----------------
            if (e instanceof IOException){
                throw (IOException)e;
            } else if (e instanceof ClassNotFoundException) {
                throw (ClassNotFoundException)e;
            }
        }
        return null;
    }",,
tomcat,15937,"containerLog.debug(sm.getString(""singleSignOn.debug.sessionTimeout"", ssoId, session))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/SingleSignOn.java/#L341,"public void sessionDestroyed(String ssoId, Session session) {

        if (!getState().isAvailable()) {
            return;
        }

        // Was the session destroyed as the result of a timeout or context stop?
        // If so, we'll just remove the expired session from the SSO. If the
        // session was logged out, we'll log out of all session associated with
        // the SSO.
        if (((session.getMaxInactiveInterval() > 0)
            && (session.getIdleTimeInternal() >= session.getMaxInactiveInterval() * 1000))
            || (!session.getManager().getContext().getState().isAvailable())) {
            if (containerLog.isDebugEnabled()) {
                
---------------Reference log start----------------
containerLog.debug(sm.getString(""singleSignOn.debug.sessionTimeout"", ssoId, session))
---------------Reference log end----------------
            }
            removeSession(ssoId, session);
        } else {
            // The session was logged out.
            // Deregister this single session id, invalidating
            // associated sessions
            if (containerLog.isDebugEnabled()) {
                containerLog.debug(sm.getString(""singleSignOn.debug.sessionLogout"",
                        ssoId, session));
            }
            // First remove the session that we know has expired / been logged
            // out since it has already been removed from its Manager and, if
            // we don't remove it first, deregister() will log a warning that it
            // can't be found
            removeSession(ssoId, session);
            // If the SSO session was only associated with one web app the call
            // above will have removed the SSO session from the cache
            if (cache.containsKey(ssoId)) {
                deregister(ssoId);
            }
        }
    }",,
tomcat,16256,"log.debug(""    Including glob jar file "" + file.getAbsolutePath())",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/ClassLoaderFactory.java/#L219,"public static ClassLoader createClassLoader(List<Repository> repositories,
                                                final ClassLoader parent)
        throws Exception {

        if (log.isDebugEnabled()) {
            log.debug(""Creating new class loader"");
        }

        // Construct the ""class path"" for this class loader
        Set<URL> set = new LinkedHashSet<>();

        if (repositories != null) {
            for (Repository repository : repositories)  {
                if (repository.getType() == RepositoryType.URL) {
                    URL url = buildClassLoaderUrl(repository.getLocation());
                    if (log.isDebugEnabled()) {
                        log.debug(""  Including URL "" + url);
                    }
                    set.add(url);
                } else if (repository.getType() == RepositoryType.DIR) {
                    File directory = new File(repository.getLocation());
                    directory = directory.getCanonicalFile();
                    if (!validateFile(directory, RepositoryType.DIR)) {
                        continue;
                    }
                    URL url = buildClassLoaderUrl(directory);
                    if (log.isDebugEnabled()) {
                        log.debug(""  Including directory "" + url);
                    }
                    set.add(url);
                } else if (repository.getType() == RepositoryType.JAR) {
                    File file=new File(repository.getLocation());
                    file = file.getCanonicalFile();
                    if (!validateFile(file, RepositoryType.JAR)) {
                        continue;
                    }
                    URL url = buildClassLoaderUrl(file);
                    if (log.isDebugEnabled()) {
                        log.debug(""  Including jar file "" + url);
                    }
                    set.add(url);
                } else if (repository.getType() == RepositoryType.GLOB) {
                    File directory=new File(repository.getLocation());
                    directory = directory.getCanonicalFile();
                    if (!validateFile(directory, RepositoryType.GLOB)) {
                        continue;
                    }
                    if (log.isDebugEnabled()) {
                        log.debug(""  Including directory glob ""
                            + directory.getAbsolutePath());
                    }
                    String filenames[] = directory.list();
                    if (filenames == null) {
                        continue;
                    }
                    for (String s : filenames) {
                        String filename = s.toLowerCase(Locale.ENGLISH);
                        if (!filename.endsWith("".jar"")) {
                            continue;
                        }
                        File file = new File(directory, s);
                        file = file.getCanonicalFile();
                        if (!validateFile(file, RepositoryType.JAR)) {
                            continue;
                        }
                        if (log.isDebugEnabled()) {
                            
---------------Reference log start----------------
log.debug(""    Including glob jar file "" + file.getAbsolutePath())
---------------Reference log end----------------
                        }
                        URL url = buildClassLoaderUrl(file);
                        set.add(url);
                    }
                }
            }
        }

        // Construct the class loader itself
        final URL[] array = set.toArray(new URL[0]);
        if (log.isDebugEnabled()) {
            for (int i = 0; i < array.length; i++) {
                log.debug(""  location "" + i + "" is "" + array[i]);
            }
        }

        return AccessController.doPrivileged(
                (PrivilegedAction<URLClassLoader>) () -> {
                    if (parent == null) {
                        return new URLClassLoader(array);
                    } else {
                        return new URLClassLoader(array, parent);
                    }
                });
    }",,
tomcat,17636,"log.error(""Unable to purge pool."", x)",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/DataSourceProxy.java/#L1489,"public void purge()  {
        try {
            createPool().purge();
        }catch (SQLException x) {
            
---------------Reference log start----------------
log.error(""Unable to purge pool."", x)
---------------Reference log end----------------
        }
    }",,
tomcat,16109,"log.warn(""Could not close catalina properties file"", ioe)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/CatalinaProperties.java/#L110,"private static void loadProperties() {

        InputStream is = null;
        String fileName = ""catalina.properties"";

        try {
            String configUrl = System.getProperty(""catalina.config"");
            if (configUrl != null) {
                if (configUrl.indexOf('/') == -1) {
                    // No '/'. Must be a file name rather than a URL
                    fileName = configUrl;
                } else {
                    is = (new URL(configUrl)).openStream();
                }
            }
        } catch (Throwable t) {
            handleThrowable(t);
        }

        if (is == null) {
            try {
                File home = new File(Bootstrap.getCatalinaBase());
                File conf = new File(home, ""conf"");
                File propsFile = new File(conf, fileName);
                is = new FileInputStream(propsFile);
            } catch (Throwable t) {
                handleThrowable(t);
            }
        }

        if (is == null) {
            try {
                is = CatalinaProperties.class.getResourceAsStream
                    (""/org/apache/catalina/startup/catalina.properties"");
            } catch (Throwable t) {
                handleThrowable(t);
            }
        }

        if (is != null) {
            try {
                properties = new Properties();
                properties.load(is);
            } catch (Throwable t) {
                handleThrowable(t);
                log.warn(t);
            } finally {
                try {
                    is.close();
                } catch (IOException ioe) {
                    
---------------Reference log start----------------
log.warn(""Could not close catalina properties file"", ioe)
---------------Reference log end----------------
                }
            }
        }

        if ((is == null)) {
            // Do something
            log.warn(""Failed to load catalina properties file"");
            // That's fine - we have reasonable defaults.
            properties = new Properties();
        }

        // Register the properties as system properties
        Enumeration<?> enumeration = properties.propertyNames();
        while (enumeration.hasMoreElements()) {
            String name = (String) enumeration.nextElement();
            String value = properties.getProperty(name);
            if (value != null) {
                System.setProperty(name, value);
            }
        }
    }",,
tomcat,17477,"log.debug(""Failed to convert ["" + m.group(2) + ""] to Integer"", e)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/optimizations/ELInterpreterTagSetters.java/#L148,"@Override
    public String interpreterCall(JspCompilationContext context,
            boolean isTagFile, String expression,
            Class<?> expectedType, String fnmapvar) {

        String result = null;

        // Boolean
        if (Boolean.TYPE == expectedType) {
            Matcher m = PATTERN_BOOLEAN.matcher(expression);
            if (m.matches()) {
                result = m.group(2);
            }
        } else if (Boolean.class == expectedType) {
            Matcher m = PATTERN_BOOLEAN.matcher(expression);
            if (m.matches()) {
                if (""true"".equals(m.group(2))) {
                    result = ""Boolean.TRUE"";
                } else {
                    result = ""Boolean.FALSE"";
                }
            }
        // Character
        } else if (Character.TYPE == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                return ""\'"" + m.group(2).charAt(0) + ""\'"";
            }
        } else if (Character.class == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                return ""Character.valueOf(\'"" + m.group(2).charAt(0) + ""\')"";
            }
        // Numeric - BigDecimal
        } else if (BigDecimal.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    BigDecimal unused = new BigDecimal(m.group(2));
                    result = ""new java.math.BigDecimal(\"""" + m.group(2) + ""\"")"";
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to BigDecimal"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - long/Long
        } else if (Long.TYPE == expectedType || Long.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Long unused = Long.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // Long requires explicit declaration as a long literal
                        result = m.group(2) + ""L"";
                    } else {
                        result = ""Long.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Long"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - int/Integer
        } else if (Integer.TYPE == expectedType || Integer.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Integer unused = Integer.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        result = m.group(2);
                    } else {
                        result = ""Integer.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    
---------------Reference log start----------------
log.debug(""Failed to convert ["" + m.group(2) + ""] to Integer"", e)
---------------Reference log end----------------
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - short/Short
        } else if (Short.TYPE == expectedType || Short.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Short unused = Short.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // short requires a downcast
                        result = ""(short) "" + m.group(2);
                    } else {
                        result = ""Short.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Short"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - byte/Byte
        } else if (Byte.TYPE == expectedType || Byte.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Byte unused = Byte.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // byte requires a downcast
                        result = ""(byte) "" + m.group(2);
                    } else {
                        result = ""Byte.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Byte"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - double/Double
        } else if (Double.TYPE == expectedType || Double.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Double unused = Double.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        result = m.group(2);
                    } else {
                        result = ""Double.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Double"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - float/Float
        } else if (Float.TYPE == expectedType || Float.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Float unused = Float.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // Float requires explicit declaration as a float literal
                        result = m.group(2) + ""f"";
                    } else {
                        result = ""Float.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Float"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - BigInteger
        } else if (BigInteger.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    BigInteger unused = new BigInteger(m.group(2));
                    result = ""new java.math.BigInteger(\"""" + m.group(2) + ""\"")"";
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to BigInteger"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Enum
        } else if (expectedType.isEnum()){
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings({ ""unchecked"", ""rawtypes"" })
                    Enum<?> enumValue = Enum.valueOf((Class<? extends Enum>) expectedType, m.group(2));
                    result = expectedType.getName() + ""."" + enumValue.name();
                } catch (IllegalArgumentException iae) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Enum type ["" + expectedType.getName() + ""]"", iae);
                    // Continue and resolve the value at runtime
                }
            }
        // String
        } else if (String.class == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                result = ""\"""" + m.group(2) + ""\"""";
            }
        }

        if (result == null) {
            result = JspUtil.interpreterCall(isTagFile, expression, expectedType,
                    fnmapvar);
        }

        if (log.isDebugEnabled()) {
            log.debug(""Expression ["" + expression + ""], type ["" + expectedType.getName() + ""], returns ["" + result + ""]"");
        }

        return result;
    }",,
tomcat,16506,"log.trace(""HttpSession Properties"")",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L522,"private void printServletEnvironment(HttpServletRequest req) throws IOException {

        // Document the properties from ServletRequest
        log.trace(""ServletRequest Properties"");
        Enumeration<String> attrs = req.getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Request Attribute: "" + attr + "": [ "" + req.getAttribute(attr) +""]"");
        }
        log.trace(""Character Encoding: ["" + req.getCharacterEncoding() + ""]"");
        log.trace(""Content Length: ["" + req.getContentLengthLong() + ""]"");
        log.trace(""Content Type: ["" + req.getContentType() + ""]"");
        Enumeration<Locale> locales = req.getLocales();
        while (locales.hasMoreElements()) {
            Locale locale = locales.nextElement();
            log.trace(""Locale: ["" +locale + ""]"");
        }
        Enumeration<String> params = req.getParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            for (String value : req.getParameterValues(param)) {
                log.trace(""Request Parameter: "" + param + "":  ["" + value + ""]"");
            }
        }
        log.trace(""Protocol: ["" + req.getProtocol() + ""]"");
        log.trace(""Remote Address: ["" + req.getRemoteAddr() + ""]"");
        log.trace(""Remote Host: ["" + req.getRemoteHost() + ""]"");
        log.trace(""Scheme: ["" + req.getScheme() + ""]"");
        log.trace(""Secure: ["" + req.isSecure() + ""]"");
        log.trace(""Server Name: ["" + req.getServerName() + ""]"");
        log.trace(""Server Port: ["" + req.getServerPort() + ""]"");

        // Document the properties from HttpServletRequest
        log.trace(""HttpServletRequest Properties"");
        log.trace(""Auth Type: ["" + req.getAuthType() + ""]"");
        log.trace(""Context Path: ["" + req.getContextPath() + ""]"");
        Cookie cookies[] = req.getCookies();
        if (cookies != null) {
            for (Cookie cookie : cookies) {
                log.trace(""Cookie: "" + cookie.getName() + "": ["" + cookie.getValue() + ""]"");
            }
        }
        Enumeration<String> headers = req.getHeaderNames();
        while (headers.hasMoreElements()) {
            String header = headers.nextElement();
            log.trace(""HTTP Header: "" + header + "": ["" + req.getHeader(header) + ""]"");
        }
        log.trace(""Method: ["" + req.getMethod() + ""]"");
        log.trace(""Path Info: ["" + req.getPathInfo() + ""]"");
        log.trace(""Path Translated: ["" + req.getPathTranslated() + ""]"");
        log.trace(""Query String: ["" + req.getQueryString() + ""]"");
        log.trace(""Remote User: ["" + req.getRemoteUser() + ""]"");
        log.trace(""Requested Session ID: ["" + req.getRequestedSessionId() + ""]"");
        log.trace(""Requested Session ID From Cookie: ["" +
                req.isRequestedSessionIdFromCookie() + ""]"");
        log.trace(""Requested Session ID From URL: ["" + req.isRequestedSessionIdFromURL() + ""]"");
        log.trace(""Requested Session ID Valid: ["" + req.isRequestedSessionIdValid() + ""]"");
        log.trace(""Request URI: ["" + req.getRequestURI() + ""]"");
        log.trace(""Servlet Path: ["" + req.getServletPath() + ""]"");
        log.trace(""User Principal: ["" + req.getUserPrincipal() + ""]"");

        // Process the current session (if there is one)
        HttpSession session = req.getSession(false);
        if (session != null) {

            // Document the session properties
            
---------------Reference log start----------------
log.trace(""HttpSession Properties"")
---------------Reference log end----------------
            log.trace(""ID: ["" + session.getId() + ""]"");
            log.trace(""Creation Time: ["" + new Date(session.getCreationTime()) + ""]"");
            log.trace(""Last Accessed Time: ["" + new Date(session.getLastAccessedTime()) + ""]"");
            log.trace(""Max Inactive Interval: ["" + session.getMaxInactiveInterval() + ""]"");

            // Document the session attributes
            attrs = session.getAttributeNames();
            while (attrs.hasMoreElements()) {
                String attr = attrs.nextElement();
                log.trace(""Session Attribute: "" + attr + "": ["" + session.getAttribute(attr) + ""]"");
            }
        }

        // Document the servlet configuration properties
        log.trace(""ServletConfig Properties"");
        log.trace(""Servlet Name: ["" + getServletConfig().getServletName() + ""]"");

        // Document the servlet configuration initialization parameters
        params = getServletConfig().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletConfig().getInitParameter(param);
            log.trace(""Servlet Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context properties
        log.trace(""ServletContext Properties"");
        log.trace(""Major Version: ["" + getServletContext().getMajorVersion() + ""]"");
        log.trace(""Minor Version: ["" + getServletContext().getMinorVersion() + ""]"");
        log.trace(""Real Path for '/': ["" + getServletContext().getRealPath(""/"") + ""]"");
        log.trace(""Server Info: ["" + getServletContext().getServerInfo() + ""]"");

        // Document the servlet context initialization parameters
        log.trace(""ServletContext Initialization Parameters"");
        params = getServletContext().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletContext().getInitParameter(param);
            log.trace(""Servlet Context Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context attributes
        log.trace(""ServletContext Attributes"");
        attrs = getServletContext().getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Servlet Context Attribute: "" + attr +
                    "": ["" + getServletContext().getAttribute(attr) + ""]"");
        }
    }",,
tomcat,16334,"log.warn(sm.getString(""deltaManager.noContextManager"", getName(), new Date(beforeSendTime), Long.valueOf(reqNow - beforeSendTime)))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/session/DeltaManager.java/#L802,"protected void waitForSendAllSessions(long beforeSendTime) {
        long reqStart = System.currentTimeMillis();
        long reqNow = reqStart ;
        boolean isTimeout = false;
        if(getStateTransferTimeout() > 0) {
            // wait that state is transferred with timeout check
            do {
                try {
                    Thread.sleep(100);
                } catch (Exception sleep) {
                    //
                }
                reqNow = System.currentTimeMillis();
                isTimeout = ((reqNow - reqStart) > (1000L * getStateTransferTimeout()));
            } while ((!getStateTransferred()) && (!isTimeout) && (!isNoContextManagerReceived()));
        } else {
            if(getStateTransferTimeout() == -1) {
                // wait that state is transferred
                do {
                    try {
                        Thread.sleep(100);
                    } catch (Exception sleep) {
                    }
                } while ((!getStateTransferred())&& (!isNoContextManagerReceived()));
                reqNow = System.currentTimeMillis();
            }
        }
        if (isTimeout) {
            counterNoStateTransferred++ ;
            log.error(sm.getString(""deltaManager.noSessionState"", getName(),
                    new Date(beforeSendTime), Long.valueOf(reqNow - beforeSendTime)));
        }else if (isNoContextManagerReceived()) {
            if (log.isWarnEnabled()) {
                
---------------Reference log start----------------
log.warn(sm.getString(""deltaManager.noContextManager"", getName(), new Date(beforeSendTime), Long.valueOf(reqNow - beforeSendTime)))
---------------Reference log end----------------
            }
        } else {
            if (log.isInfoEnabled()) {
                log.info(sm.getString(""deltaManager.sessionReceived"", getName(),
                        new Date(beforeSendTime), Long.valueOf(reqNow - beforeSendTime)));
            }
        }
    }",,
tomcat,15264,"log.debug(sm.getString(""persistentManager.swapMaxIdle"", session.getIdInternal(), Integer.valueOf(timeIdle)))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/PersistentManagerBase.java/#L958,"protected void processMaxIdleSwaps() {

        if (!getState().isAvailable() || maxIdleSwap < 0) {
            return;
        }

        Session sessions[] = findSessions();

        // Swap out all sessions idle longer than maxIdleSwap
        if (maxIdleSwap >= 0) {
            for (Session value : sessions) {
                StandardSession session = (StandardSession) value;
                synchronized (session) {
                    if (!session.isValid()) {
                        continue;
                    }
                    int timeIdle = (int) (session.getIdleTimeInternal() / 1000L);
                    if (timeIdle >= maxIdleSwap && timeIdle >= minIdleSwap) {
                        if (session.accessCount != null &&
                                session.accessCount.get() > 0) {
                            // Session is currently being accessed - skip it
                            continue;
                        }
                        if (log.isDebugEnabled()) {
                            
---------------Reference log start----------------
log.debug(sm.getString(""persistentManager.swapMaxIdle"", session.getIdInternal(), Integer.valueOf(timeIdle)))
---------------Reference log end----------------
                        }
                        try {
                            swapOut(session);
                        } catch (IOException e) {
                            // This is logged in writeSession()
                        }
                    }
                }
            }
        }

    }",,
tomcat,16097,"log.fatal(sm.getString(""catalina.noServer""))",fatal,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/Catalina.java/#L787,"public void start() {

        if (getServer() == null) {
            load();
        }

        if (getServer() == null) {
            
---------------Reference log start----------------
log.fatal(sm.getString(""catalina.noServer""))
---------------Reference log end----------------
            return;
        }

        long t1 = System.nanoTime();

        // Start the new server
        try {
            getServer().start();
        } catch (LifecycleException e) {
            log.fatal(sm.getString(""catalina.serverStartFail""), e);
            try {
                getServer().destroy();
            } catch (LifecycleException e1) {
                log.debug(""destroy() failed for failed Server "", e1);
            }
            return;
        }

        if (log.isInfoEnabled()) {
            log.info(sm.getString(""catalina.startup"", Long.toString(TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - t1))));
        }

        if (generateCode) {
            // Generate loader which will load all generated classes
            generateLoader();
        }

        // Register shutdown hook
        if (useShutdownHook) {
            if (shutdownHook == null) {
                shutdownHook = new CatalinaShutdownHook();
            }
            Runtime.getRuntime().addShutdownHook(shutdownHook);

            // If JULI is being used, disable JULI's shutdown hook since
            // shutdown hooks run in parallel and log messages may be lost
            // if JULI's hook completes before the CatalinaShutdownHook()
            LogManager logManager = LogManager.getLogManager();
            if (logManager instanceof ClassLoaderLogManager) {
                ((ClassLoaderLogManager) logManager).setUseShutdownHook(
                        false);
            }
        }

        if (await) {
            await();
            stop();
        }
    }",,
tomcat,16024,"log.warn(sm.getString(""factory.storeNoDescriptor"", aTagElement.getClass()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/storeconfig/StoreFactoryBase.java/#L174,"protected void storeElement(PrintWriter aWriter, int indent,
            Object aTagElement) throws Exception {
        if (aTagElement != null) {
            IStoreFactory elementFactory = getRegistry().findStoreFactory(
                    aTagElement.getClass());

            if (elementFactory != null) {
                StoreDescription desc = getRegistry().findDescription(
                        aTagElement.getClass());
                if (!desc.isTransientChild(aTagElement.getClass().getName())) {
                    elementFactory.store(aWriter, indent, aTagElement);
                }
            } else {
                
---------------Reference log start----------------
log.warn(sm.getString(""factory.storeNoDescriptor"", aTagElement.getClass()))
---------------Reference log end----------------
            }
        }
    }",,
tomcat,15630,"containerLog.trace(sm.getString(""dataSourceRealm.authenticateFailure"", username))",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/DataSourceRealm.java/#L301,"protected Principal authenticate(Connection dbConnection,
                                     String username,
                                     String credentials) {
        // No user or no credentials
        // Can't possibly authenticate, don't bother the database then
        if (username == null || credentials == null) {
            if (containerLog.isTraceEnabled()) {
                
---------------Reference log start----------------
containerLog.trace(sm.getString(""dataSourceRealm.authenticateFailure"", username))
---------------Reference log end----------------
            }
            return null;
        }

        // Look up the user's credentials
        String dbCredentials = getPassword(dbConnection, username);

        if(dbCredentials == null) {
            // User was not found in the database.
            // Waste a bit of time as not to reveal that the user does not exist.
            getCredentialHandler().mutate(credentials);

            if (containerLog.isTraceEnabled()) {
                containerLog.trace(sm.getString(""dataSourceRealm.authenticateFailure"",
                                                username));
            }
            return null;
        }

        // Validate the user's credentials
        boolean validated = getCredentialHandler().matches(credentials, dbCredentials);

        if (validated) {
            if (containerLog.isTraceEnabled()) {
                containerLog.trace(sm.getString(""dataSourceRealm.authenticateSuccess"",
                                                username));
            }
        } else {
            if (containerLog.isTraceEnabled()) {
                containerLog.trace(sm.getString(""dataSourceRealm.authenticateFailure"",
                                                username));
            }
            return null;
        }

        ArrayList<String> list = getRoles(dbConnection, username);

        // Create and return a suitable Principal for this user
        return new GenericPrincipal(username, list);
    }",,
tomcat,15758,"log.error(sm.getString(""replicatedMap.unable.relocate"", entry.getKey()), x)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/tipis/ReplicatedMap.java/#L245,"@Override
    public void memberDisappeared(Member member) {
        boolean removed = false;
        Log log = getLog();
        synchronized (mapMembers) {
            removed = (mapMembers.remove(member) != null );
            if (!removed) {
                if (log.isDebugEnabled()) {
                    log.debug(""Member[""+member+""] disappeared, but was not present in the map."");
                }
                return; //the member was not part of our map.
            }
        }
        if (log.isInfoEnabled()) {
            log.info(sm.getString(""replicatedMap.member.disappeared"", member));
        }
        long start = System.currentTimeMillis();
        for (Entry<K, MapEntry<K, V>> e : innerMap.entrySet()) {
            MapEntry<K,V> entry = innerMap.get(e.getKey());
            if (entry==null) {
                continue;
            }
            if (entry.isPrimary()) {
                try {
                    Member[] backup = getMapMembers();
                    if (backup.length > 0) {
                        MapMessage msg = new MapMessage(getMapContextName(), MapMessage.MSG_NOTIFY_MAPMEMBER,false,
                                (Serializable)entry.getKey(),null,null,channel.getLocalMember(false),backup);
                        getChannel().send(backup, msg, getChannelSendOptions());
                    }
                    entry.setBackupNodes(backup);
                    entry.setPrimary(channel.getLocalMember(false));
                } catch (ChannelException x) {
                    log.error(sm.getString(""replicatedMap.unable.relocate"", entry.getKey()), x);
                }
            } else if (member.equals(entry.getPrimary())) {
                entry.setPrimary(null);
            }

            if ( entry.getPrimary() == null &&
                        entry.isCopy() &&
                        entry.getBackupNodes()!=null &&
                        entry.getBackupNodes().length > 0 &&
                        entry.getBackupNodes()[0].equals(channel.getLocalMember(false)) ) {
                try {
                    entry.setPrimary(channel.getLocalMember(false));
                    entry.setBackup(false);
                    entry.setProxy(false);
                    entry.setCopy(false);
                    Member[] backup = getMapMembers();
                    if (backup.length > 0) {
                        MapMessage msg = new MapMessage(getMapContextName(), MapMessage.MSG_NOTIFY_MAPMEMBER,false,
                                (Serializable)entry.getKey(),null,null,channel.getLocalMember(false),backup);
                        getChannel().send(backup, msg, getChannelSendOptions());
                    }
                    entry.setBackupNodes(backup);
                    if ( mapOwner!=null ) {
                        mapOwner.objectMadePrimary(entry.getKey(),entry.getValue());
                    }

                } catch (ChannelException x) {
                    
---------------Reference log start----------------
log.error(sm.getString(""replicatedMap.unable.relocate"", entry.getKey()), x)
---------------Reference log end----------------
                }
            }

        } //while
        long complete = System.currentTimeMillis() - start;
        if (log.isInfoEnabled()) {
            log.info(sm.getString(""replicatedMap.relocate.complete"",
                    Long.toString(complete)));
        }
    }",,
tomcat,17480,"log.debug(""Expression ["" + expression + ""], type ["" + expectedType.getName() + ""], returns ["" + result + ""]"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/optimizations/ELInterpreterTagSetters.java/#L263,"@Override
    public String interpreterCall(JspCompilationContext context,
            boolean isTagFile, String expression,
            Class<?> expectedType, String fnmapvar) {

        String result = null;

        // Boolean
        if (Boolean.TYPE == expectedType) {
            Matcher m = PATTERN_BOOLEAN.matcher(expression);
            if (m.matches()) {
                result = m.group(2);
            }
        } else if (Boolean.class == expectedType) {
            Matcher m = PATTERN_BOOLEAN.matcher(expression);
            if (m.matches()) {
                if (""true"".equals(m.group(2))) {
                    result = ""Boolean.TRUE"";
                } else {
                    result = ""Boolean.FALSE"";
                }
            }
        // Character
        } else if (Character.TYPE == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                return ""\'"" + m.group(2).charAt(0) + ""\'"";
            }
        } else if (Character.class == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                return ""Character.valueOf(\'"" + m.group(2).charAt(0) + ""\')"";
            }
        // Numeric - BigDecimal
        } else if (BigDecimal.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    BigDecimal unused = new BigDecimal(m.group(2));
                    result = ""new java.math.BigDecimal(\"""" + m.group(2) + ""\"")"";
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to BigDecimal"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - long/Long
        } else if (Long.TYPE == expectedType || Long.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Long unused = Long.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // Long requires explicit declaration as a long literal
                        result = m.group(2) + ""L"";
                    } else {
                        result = ""Long.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Long"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - int/Integer
        } else if (Integer.TYPE == expectedType || Integer.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Integer unused = Integer.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        result = m.group(2);
                    } else {
                        result = ""Integer.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Integer"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - short/Short
        } else if (Short.TYPE == expectedType || Short.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Short unused = Short.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // short requires a downcast
                        result = ""(short) "" + m.group(2);
                    } else {
                        result = ""Short.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Short"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - byte/Byte
        } else if (Byte.TYPE == expectedType || Byte.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Byte unused = Byte.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // byte requires a downcast
                        result = ""(byte) "" + m.group(2);
                    } else {
                        result = ""Byte.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Byte"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - double/Double
        } else if (Double.TYPE == expectedType || Double.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Double unused = Double.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        result = m.group(2);
                    } else {
                        result = ""Double.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Double"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - float/Float
        } else if (Float.TYPE == expectedType || Float.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Float unused = Float.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // Float requires explicit declaration as a float literal
                        result = m.group(2) + ""f"";
                    } else {
                        result = ""Float.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Float"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - BigInteger
        } else if (BigInteger.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    BigInteger unused = new BigInteger(m.group(2));
                    result = ""new java.math.BigInteger(\"""" + m.group(2) + ""\"")"";
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to BigInteger"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Enum
        } else if (expectedType.isEnum()){
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings({ ""unchecked"", ""rawtypes"" })
                    Enum<?> enumValue = Enum.valueOf((Class<? extends Enum>) expectedType, m.group(2));
                    result = expectedType.getName() + ""."" + enumValue.name();
                } catch (IllegalArgumentException iae) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Enum type ["" + expectedType.getName() + ""]"", iae);
                    // Continue and resolve the value at runtime
                }
            }
        // String
        } else if (String.class == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                result = ""\"""" + m.group(2) + ""\"""";
            }
        }

        if (result == null) {
            result = JspUtil.interpreterCall(isTagFile, expression, expectedType,
                    fnmapvar);
        }

        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Expression ["" + expression + ""], type ["" + expectedType.getName() + ""], returns ["" + result + ""]"")
---------------Reference log end----------------
        }

        return result;
    }",,
tomcat,15360,"log.error(sm.getString(""accessLogValve.openDirFail"", parent))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/valves/AccessLogValve.java/#L521,"private File getLogFile(boolean useDateStamp) {
        // Create the directory if necessary
        File dir = getDirectoryFile();
        if (!dir.mkdirs() && !dir.isDirectory()) {
            log.error(sm.getString(""accessLogValve.openDirFail"", dir));
        }

        // Calculate the current log file name
        File pathname;
        if (useDateStamp) {
            pathname = new File(dir.getAbsoluteFile(), prefix + dateStamp
                    + suffix);
        } else {
            pathname = new File(dir.getAbsoluteFile(), prefix + suffix);
        }
        File parent = pathname.getParentFile();
        if (!parent.mkdirs() && !parent.isDirectory()) {
            
---------------Reference log start----------------
log.error(sm.getString(""accessLogValve.openDirFail"", parent))
---------------Reference log end----------------
        }
        return pathname;
    }",,
tomcat,16890,"log.debug(sm.getString(""hpackdecoder.useStatic"", Integer.valueOf(index)))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/HpackDecoder.java/#L302,"private void addStaticTableEntry(int index) throws HpackException {
        //adds an entry from the static table.
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(sm.getString(""hpackdecoder.useStatic"", Integer.valueOf(index)))
---------------Reference log end----------------
        }
        Hpack.HeaderField entry = Hpack.STATIC_TABLE[index];
        emitHeader(entry.name, (entry.value == null) ? """" : entry.value);
    }",,
tomcat,17290,"log.warn(sm.getString(""jsseUtil.noDefaultProtocols""))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/jsse/JSSEUtil.java/#L133,"private void initialise() {
        if (!initialized) {
            synchronized (this) {
                if (!initialized) {
                    SSLContext context;
                    try {
                        context = new JSSESSLContext(sslHostConfig.getSslProtocol());
                        context.init(null,  null,  null);
                    } catch (NoSuchAlgorithmException | KeyManagementException e) {
                        // This is fatal for the connector so throw an exception to prevent
                        // it from starting
                        throw new IllegalArgumentException(e);
                    }

                    String[] implementedProtocolsArray = context.getSupportedSSLParameters().getProtocols();
                    implementedProtocols = new HashSet<>(implementedProtocolsArray.length);

                    // Filter out SSLv2 from the list of implemented protocols (just in case
                    // we are running on a JVM that supports it) since it is no longer
                    // considered secure but allow SSLv2Hello.
                    // Note SSLv3 is allowed despite known insecurities because some users
                    // still have a requirement for it.
                    for (String protocol : implementedProtocolsArray) {
                        String protocolUpper = protocol.toUpperCase(Locale.ENGLISH);
                        if (!""SSLV2HELLO"".equals(protocolUpper) && !""SSLV3"".equals(protocolUpper)) {
                            if (protocolUpper.contains(""SSL"")) {
                                log.debug(sm.getString(""jsseUtil.excludeProtocol"", protocol));
                                continue;
                            }
                        }
                        implementedProtocols.add(protocol);
                    }

                    if (implementedProtocols.size() == 0) {
                        
---------------Reference log start----------------
log.warn(sm.getString(""jsseUtil.noDefaultProtocols""))
---------------Reference log end----------------
                    }

                    String[] implementedCipherSuiteArray = context.getSupportedSSLParameters().getCipherSuites();
                    // The IBM JRE will accept cipher suites names SSL_xxx or TLS_xxx but
                    // only returns the SSL_xxx form for supported cipher suites. Therefore
                    // need to filter the requested cipher suites using both forms with an
                    // IBM JRE.
                    if (JreVendor.IS_IBM_JVM) {
                        implementedCiphers = new HashSet<>(implementedCipherSuiteArray.length * 2);
                        for (String name : implementedCipherSuiteArray) {
                            implementedCiphers.add(name);
                            if (name.startsWith(""SSL"")) {
                                implementedCiphers.add(""TLS"" + name.substring(3));
                            }
                        }
                    } else {
                        implementedCiphers = new HashSet<>(Arrays.asList(implementedCipherSuiteArray));
                    }
                    initialized = true;
                }
            }
        }
    }",,
tomcat,15878,"log.trace(""Registering key for read:"" + key)",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/NioReplicationTask.java/#L285,"protected void registerForRead(final SelectionKey key, ObjectReader reader) {
        if ( log.isTraceEnabled() ) {
            log.trace(""Adding key for read event:""+key);
        }
        reader.finish();
        //register our OP_READ interest
        Runnable r = () -> {
            try {
                if (key.isValid()) {
                    // cycle the selector so this key is active again
                    key.selector().wakeup();
                    // resume interest in OP_READ, OP_WRITE
                    int resumeOps = key.interestOps() | SelectionKey.OP_READ;
                    key.interestOps(resumeOps);
                    if ( log.isTraceEnabled() ) {
                        
---------------Reference log start----------------
log.trace(""Registering key for read:"" + key)
---------------Reference log end----------------
                    }
                }
            } catch (CancelledKeyException ckx ) {
                NioReceiver.cancelledKey(key);
                if ( log.isTraceEnabled() ) {
                    log.trace(""CKX Cancelling key:""+key);
                }

            } catch (Exception x) {
                log.error(sm.getString(""nioReplicationTask.error.register.key"", key),x);
            }
        };
        receiver.addEvent(r);
    }",,
tomcat,16696,"log.info(sm.getString(""jniLifecycleListener.load.name"", libraryName))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/JniLifecycleListener.java/#L53,"@Override
    public void lifecycleEvent(LifecycleEvent event) {

        if (Lifecycle.BEFORE_START_EVENT.equals(event.getType())) {

            if (!libraryName.isEmpty()) {
                System.loadLibrary(libraryName);
                
---------------Reference log start----------------
log.info(sm.getString(""jniLifecycleListener.load.name"", libraryName))
---------------Reference log end----------------
            } else if (!libraryPath.isEmpty()) {
                System.load(libraryPath);
                log.info(sm.getString(""jniLifecycleListener.load.path"", libraryPath));
            } else {
                throw new IllegalArgumentException(sm.getString(""jniLifecycleListener.missingPathOrName""));
            }
        }
    }",,
tomcat,16281,"log.error(sm.getString(""sessionIdGeneratorBase.randomAlgorithm"", secureRandomAlgorithm), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/util/SessionIdGeneratorBase.java/#L258,"private SecureRandom createSecureRandom() {

        SecureRandom result = null;

        long t1 = System.currentTimeMillis();
        if (secureRandomClass != null) {
            try {
                // Construct and seed a new random number generator
                Class<?> clazz = Class.forName(secureRandomClass);
                result = (SecureRandom) clazz.getConstructor().newInstance();
            } catch (Exception e) {
                log.error(sm.getString(""sessionIdGeneratorBase.random"",
                        secureRandomClass), e);
            }
        }

        boolean error = false;
        if (result == null) {
            // No secureRandomClass or creation failed. Use SecureRandom.
            try {
                if (secureRandomProvider != null &&
                        secureRandomProvider.length() > 0) {
                    result = SecureRandom.getInstance(secureRandomAlgorithm,
                            secureRandomProvider);
                } else if (secureRandomAlgorithm != null &&
                        secureRandomAlgorithm.length() > 0) {
                    result = SecureRandom.getInstance(secureRandomAlgorithm);
                }
            } catch (NoSuchAlgorithmException e) {
                error = true;
                log.error(sm.getString(""sessionIdGeneratorBase.randomAlgorithm"",
                        secureRandomAlgorithm), e);
            } catch (NoSuchProviderException e) {
                error = true;
                log.error(sm.getString(""sessionIdGeneratorBase.randomProvider"",
                        secureRandomProvider), e);
            }
        }

        if (result == null && error) {
            // Invalid provider / algorithm
            try {
                result = SecureRandom.getInstance(""SHA1PRNG"");
            } catch (NoSuchAlgorithmException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""sessionIdGeneratorBase.randomAlgorithm"", secureRandomAlgorithm), e)
---------------Reference log end----------------
            }
        }

        if (result == null) {
            // Nothing works - use platform default
            result = new SecureRandom();
        }

        // Force seeding to take place
        result.nextInt();

        long t2 = System.currentTimeMillis();
        if ((t2 - t1) > 100) {
            log.warn(sm.getString(""sessionIdGeneratorBase.createRandom"",
                    result.getAlgorithm(), Long.valueOf(t2 - t1)));
        }
        return result;
    }",,
tomcat,16489,"log.trace(""HttpServletRequest Properties"")",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L489,"private void printServletEnvironment(HttpServletRequest req) throws IOException {

        // Document the properties from ServletRequest
        log.trace(""ServletRequest Properties"");
        Enumeration<String> attrs = req.getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Request Attribute: "" + attr + "": [ "" + req.getAttribute(attr) +""]"");
        }
        log.trace(""Character Encoding: ["" + req.getCharacterEncoding() + ""]"");
        log.trace(""Content Length: ["" + req.getContentLengthLong() + ""]"");
        log.trace(""Content Type: ["" + req.getContentType() + ""]"");
        Enumeration<Locale> locales = req.getLocales();
        while (locales.hasMoreElements()) {
            Locale locale = locales.nextElement();
            log.trace(""Locale: ["" +locale + ""]"");
        }
        Enumeration<String> params = req.getParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            for (String value : req.getParameterValues(param)) {
                log.trace(""Request Parameter: "" + param + "":  ["" + value + ""]"");
            }
        }
        log.trace(""Protocol: ["" + req.getProtocol() + ""]"");
        log.trace(""Remote Address: ["" + req.getRemoteAddr() + ""]"");
        log.trace(""Remote Host: ["" + req.getRemoteHost() + ""]"");
        log.trace(""Scheme: ["" + req.getScheme() + ""]"");
        log.trace(""Secure: ["" + req.isSecure() + ""]"");
        log.trace(""Server Name: ["" + req.getServerName() + ""]"");
        log.trace(""Server Port: ["" + req.getServerPort() + ""]"");

        // Document the properties from HttpServletRequest
        
---------------Reference log start----------------
log.trace(""HttpServletRequest Properties"")
---------------Reference log end----------------
        log.trace(""Auth Type: ["" + req.getAuthType() + ""]"");
        log.trace(""Context Path: ["" + req.getContextPath() + ""]"");
        Cookie cookies[] = req.getCookies();
        if (cookies != null) {
            for (Cookie cookie : cookies) {
                log.trace(""Cookie: "" + cookie.getName() + "": ["" + cookie.getValue() + ""]"");
            }
        }
        Enumeration<String> headers = req.getHeaderNames();
        while (headers.hasMoreElements()) {
            String header = headers.nextElement();
            log.trace(""HTTP Header: "" + header + "": ["" + req.getHeader(header) + ""]"");
        }
        log.trace(""Method: ["" + req.getMethod() + ""]"");
        log.trace(""Path Info: ["" + req.getPathInfo() + ""]"");
        log.trace(""Path Translated: ["" + req.getPathTranslated() + ""]"");
        log.trace(""Query String: ["" + req.getQueryString() + ""]"");
        log.trace(""Remote User: ["" + req.getRemoteUser() + ""]"");
        log.trace(""Requested Session ID: ["" + req.getRequestedSessionId() + ""]"");
        log.trace(""Requested Session ID From Cookie: ["" +
                req.isRequestedSessionIdFromCookie() + ""]"");
        log.trace(""Requested Session ID From URL: ["" + req.isRequestedSessionIdFromURL() + ""]"");
        log.trace(""Requested Session ID Valid: ["" + req.isRequestedSessionIdValid() + ""]"");
        log.trace(""Request URI: ["" + req.getRequestURI() + ""]"");
        log.trace(""Servlet Path: ["" + req.getServletPath() + ""]"");
        log.trace(""User Principal: ["" + req.getUserPrincipal() + ""]"");

        // Process the current session (if there is one)
        HttpSession session = req.getSession(false);
        if (session != null) {

            // Document the session properties
            log.trace(""HttpSession Properties"");
            log.trace(""ID: ["" + session.getId() + ""]"");
            log.trace(""Creation Time: ["" + new Date(session.getCreationTime()) + ""]"");
            log.trace(""Last Accessed Time: ["" + new Date(session.getLastAccessedTime()) + ""]"");
            log.trace(""Max Inactive Interval: ["" + session.getMaxInactiveInterval() + ""]"");

            // Document the session attributes
            attrs = session.getAttributeNames();
            while (attrs.hasMoreElements()) {
                String attr = attrs.nextElement();
                log.trace(""Session Attribute: "" + attr + "": ["" + session.getAttribute(attr) + ""]"");
            }
        }

        // Document the servlet configuration properties
        log.trace(""ServletConfig Properties"");
        log.trace(""Servlet Name: ["" + getServletConfig().getServletName() + ""]"");

        // Document the servlet configuration initialization parameters
        params = getServletConfig().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletConfig().getInitParameter(param);
            log.trace(""Servlet Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context properties
        log.trace(""ServletContext Properties"");
        log.trace(""Major Version: ["" + getServletContext().getMajorVersion() + ""]"");
        log.trace(""Minor Version: ["" + getServletContext().getMinorVersion() + ""]"");
        log.trace(""Real Path for '/': ["" + getServletContext().getRealPath(""/"") + ""]"");
        log.trace(""Server Info: ["" + getServletContext().getServerInfo() + ""]"");

        // Document the servlet context initialization parameters
        log.trace(""ServletContext Initialization Parameters"");
        params = getServletContext().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletContext().getInitParameter(param);
            log.trace(""Servlet Context Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context attributes
        log.trace(""ServletContext Attributes"");
        attrs = getServletContext().getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Servlet Context Attribute: "" + attr +
                    "": ["" + getServletContext().getAttribute(attr) + ""]"");
        }
    }",,
tomcat,15959,"log.debug(""Request body too big to save during authentication"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/FormAuthenticator.java/#L224,"@Override
    protected boolean doAuthenticate(Request request, HttpServletResponse response)
            throws IOException {

        // References to objects we will need later
        Session session = null;
        Principal principal = null;

        // Have we authenticated this user before but have caching disabled?
        if (!cache) {
            session = request.getSessionInternal(true);
            if (log.isDebugEnabled()) {
                log.debug(""Checking for reauthenticate in session "" + session);
            }
            String username = (String) session.getNote(Constants.SESS_USERNAME_NOTE);
            String password = (String) session.getNote(Constants.SESS_PASSWORD_NOTE);
            if (username != null && password != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""Reauthenticating username '"" + username + ""'"");
                }
                principal = context.getRealm().authenticate(username, password);
                if (principal != null) {
                    register(request, response, principal, HttpServletRequest.FORM_AUTH, username, password);
                    if (!matchRequest(request)) {
                        return true;
                    }
                }
                if (log.isDebugEnabled()) {
                    log.debug(""Reauthentication failed, proceed normally"");
                }
            }
        }

        // Is this the re-submit of the original request URI after successful
        // authentication?  If so, forward the *original* request instead.
        if (matchRequest(request)) {
            session = request.getSessionInternal(true);
            if (log.isDebugEnabled()) {
                log.debug(""Restore request from session '"" + session.getIdInternal() + ""'"");
            }
            if (restoreRequest(request, session)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Proceed to restored request"");
                }
                return true;
            } else {
                if (log.isDebugEnabled()) {
                    log.debug(""Restore of original request failed"");
                }
                response.sendError(HttpServletResponse.SC_BAD_REQUEST);
                return false;
            }
        }

        // This check has to be after the previous check for a matching request
        // because that matching request may also include a cached Principal.
        if (checkForCachedAuthentication(request, response, true)) {
            return true;
        }

        // Acquire references to objects we will need to evaluate
        String contextPath = request.getContextPath();
        String requestURI = request.getDecodedRequestURI();

        // Is this the action request from the login page?
        boolean loginAction = requestURI.startsWith(contextPath) && requestURI.endsWith(Constants.FORM_ACTION);

        LoginConfig config = context.getLoginConfig();

        // No -- Save this request and redirect to the form login page
        if (!loginAction) {
            // If this request was to the root of the context without a trailing
            // '/', need to redirect to add it else the submit of the login form
            // may not go to the correct web application
            if (request.getServletPath().length() == 0 && request.getPathInfo() == null) {
                StringBuilder location = new StringBuilder(requestURI);
                location.append('/');
                if (request.getQueryString() != null) {
                    location.append('?');
                    location.append(request.getQueryString());
                }
                response.sendRedirect(response.encodeRedirectURL(location.toString()));
                return false;
            }

            session = request.getSessionInternal(true);
            if (log.isDebugEnabled()) {
                log.debug(""Save request in session '"" + session.getIdInternal() + ""'"");
            }
            try {
                saveRequest(request, session);
            } catch (IOException ioe) {
                
---------------Reference log start----------------
log.debug(""Request body too big to save during authentication"")
---------------Reference log end----------------
                response.sendError(HttpServletResponse.SC_FORBIDDEN, sm.getString(""authenticator.requestBodyTooBig""));
                return false;
            }
            forwardToLoginPage(request, response, config);
            return false;
        }

        // Yes -- Acknowledge the request, validate the specified credentials
        // and redirect to the error page if they are not correct
        request.getResponse().sendAcknowledgement(ContinueResponseTiming.ALWAYS);
        Realm realm = context.getRealm();
        if (characterEncoding != null) {
            request.setCharacterEncoding(characterEncoding);
        }
        String username = request.getParameter(Constants.FORM_USERNAME);
        String password = request.getParameter(Constants.FORM_PASSWORD);
        if (log.isDebugEnabled()) {
            log.debug(""Authenticating username '"" + username + ""'"");
        }
        principal = realm.authenticate(username, password);
        if (principal == null) {
            forwardToErrorPage(request, response, config);
            return false;
        }

        if (log.isDebugEnabled()) {
            log.debug(""Authentication of '"" + username + ""' was successful"");
        }

        if (session == null) {
            session = request.getSessionInternal(false);
        }
        if (session != null && getChangeSessionIdOnAuthentication()) {
            // Does session id match?
            String expectedSessionId = (String) session.getNote(Constants.SESSION_ID_NOTE);
            if (expectedSessionId == null || !expectedSessionId.equals(request.getRequestedSessionId())) {
                session.expire();
                session = null;
            }
        }
        if (session == null) {
            if (containerLog.isDebugEnabled()) {
                containerLog.debug(""User took so long to log on the session expired"");
            }
            if (landingPage == null) {
                response.sendError(
                        HttpServletResponse.SC_REQUEST_TIMEOUT, sm.getString(""authenticator.sessionExpired""));
            } else {
                // Make the authenticator think the user originally requested
                // the landing page
                String uri = request.getContextPath() + landingPage;
                SavedRequest saved = new SavedRequest();
                saved.setMethod(""GET"");
                saved.setRequestURI(uri);
                saved.setDecodedRequestURI(uri);
                request.getSessionInternal(true).setNote(Constants.FORM_REQUEST_NOTE, saved);
                response.sendRedirect(response.encodeRedirectURL(uri));
            }
            return false;
        }

        register(request, response, principal, HttpServletRequest.FORM_AUTH, username, password);

        // Redirect the user to the original request URI (which will cause
        // the original request to be restored)
        requestURI = savedRequestURL(session);
        if (log.isDebugEnabled()) {
            log.debug(""Redirecting to original '"" + requestURI + ""'"");
        }
        if (requestURI == null) {
            if (landingPage == null) {
                response.sendError(HttpServletResponse.SC_BAD_REQUEST, sm.getString(""authenticator.formlogin""));
            } else {
                // Make the authenticator think the user originally requested
                // the landing page
                String uri = request.getContextPath() + landingPage;
                SavedRequest saved = new SavedRequest();
                saved.setMethod(""GET"");
                saved.setRequestURI(uri);
                saved.setDecodedRequestURI(uri);
                session.setNote(Constants.FORM_REQUEST_NOTE, saved);
                response.sendRedirect(response.encodeRedirectURL(uri));
            }
        } else {
            // Until the Servlet API allows specifying the type of redirect to
            // use.
            Response internalResponse = request.getResponse();
            String location = response.encodeRedirectURL(requestURI);
            if (""HTTP/1.1"".equals(request.getProtocol())) {
                internalResponse.sendRedirect(location, HttpServletResponse.SC_SEE_OTHER);
            } else {
                internalResponse.sendRedirect(location, HttpServletResponse.SC_FOUND);
            }
        }
        return false;
    }",,
tomcat,17088,"log.warn(sm.getString(""endpoint.nio.perms.readFail"", file.getPath()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/NioEndpoint.java/#L232,"protected void initServerSocket() throws Exception {
        if (getUseInheritedChannel()) {
            // Retrieve the channel provided by the OS
            Channel ic = System.inheritedChannel();
            if (ic instanceof ServerSocketChannel) {
                serverSock = (ServerSocketChannel) ic;
            }
            if (serverSock == null) {
                throw new IllegalArgumentException(sm.getString(""endpoint.init.bind.inherited""));
            }
        } else if (getUnixDomainSocketPath() != null) {
            SocketAddress sa = JreCompat.getInstance().getUnixDomainSocketAddress(getUnixDomainSocketPath());
            serverSock = JreCompat.getInstance().openUnixDomainServerSocketChannel();
            serverSock.bind(sa, getAcceptCount());
            if (getUnixDomainSocketPathPermissions() != null) {
                Path path = Paths.get(getUnixDomainSocketPath());
                Set<PosixFilePermission> permissions =
                        PosixFilePermissions.fromString(getUnixDomainSocketPathPermissions());
                if (path.getFileSystem().supportedFileAttributeViews().contains(""posix"")) {
                    FileAttribute<Set<PosixFilePermission>> attrs = PosixFilePermissions.asFileAttribute(permissions);
                    Files.setAttribute(path, attrs.name(), attrs.value());
                } else {
                    java.io.File file = path.toFile();
                    if (permissions.contains(PosixFilePermission.OTHERS_READ) && !file.setReadable(true, false)) {
                        
---------------Reference log start----------------
log.warn(sm.getString(""endpoint.nio.perms.readFail"", file.getPath()))
---------------Reference log end----------------
                    }
                    if (permissions.contains(PosixFilePermission.OTHERS_WRITE) && !file.setWritable(true, false)) {
                        log.warn(sm.getString(""endpoint.nio.perms.writeFail"", file.getPath()));
                    }
                }
            }
        } else {
            serverSock = ServerSocketChannel.open();
            socketProperties.setProperties(serverSock.socket());
            InetSocketAddress addr = new InetSocketAddress(getAddress(), getPortWithOffset());
            serverSock.bind(addr, getAcceptCount());
        }
        serverSock.configureBlocking(true); //mimic APR behavior
    }",,
tomcat,15642,"log.debug(""Init"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JAASMemoryLoginModule.java/#L227,"@Override
    public void initialize(Subject subject, CallbackHandler callbackHandler,
                           Map<String,?> sharedState, Map<String,?> options) {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Init"")
---------------Reference log end----------------
        }

        // Save configuration values
        this.subject = subject;
        this.callbackHandler = callbackHandler;
        this.sharedState = sharedState;
        this.options = options;

        // Perform instance-specific initialization
        Object option = options.get(""pathname"");
        if (option instanceof String) {
            this.pathname = (String) option;
        }

        CredentialHandler credentialHandler = null;
        option = options.get(""credentialHandlerClassName"");
        if (option instanceof String) {
            try {
                Class<?> clazz = Class.forName((String) option);
                credentialHandler = (CredentialHandler) clazz.getConstructor().newInstance();
            } catch (ReflectiveOperationException e) {
                throw new IllegalArgumentException(e);
            }
        }
        if (credentialHandler == null) {
            credentialHandler = new MessageDigestCredentialHandler();
        }

        for (Entry<String,?> entry : options.entrySet()) {
            if (""pathname"".equals(entry.getKey())) {
                continue;
            }
            if (""credentialHandlerClassName"".equals(entry.getKey())) {
                continue;
            }
            // Skip any non-String values since any value we are interested in
            // will be a String.
            if (entry.getValue() instanceof String) {
                IntrospectionUtils.setProperty(credentialHandler, entry.getKey(),
                        (String) entry.getValue());
            }
        }
        setCredentialHandler(credentialHandler);

        // Load our defined Principals
        load();
    }",,
tomcat,17073,log.debug(message),debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/http/Parameters.java/#L472,"private void processParameters(byte bytes[], int start, int len, Charset charset) {

        if(log.isDebugEnabled()) {
            log.debug(sm.getString(""parameters.bytes"",
                    new String(bytes, start, len, DEFAULT_BODY_CHARSET)));
        }

        int decodeFailCount = 0;

        int pos = start;
        int end = start + len;

        while(pos < end) {
            int nameStart = pos;
            int nameEnd = -1;
            int valueStart = -1;
            int valueEnd = -1;

            boolean parsingName = true;
            boolean decodeName = false;
            boolean decodeValue = false;
            boolean parameterComplete = false;

            do {
                switch(bytes[pos]) {
                    case '=':
                        if (parsingName) {
                            // Name finished. Value starts from next character
                            nameEnd = pos;
                            parsingName = false;
                            valueStart = ++pos;
                        } else {
                            // Equals character in value
                            pos++;
                        }
                        break;
                    case '&':
                        if (parsingName) {
                            // Name finished. No value.
                            nameEnd = pos;
                        } else {
                            // Value finished
                            valueEnd  = pos;
                        }
                        parameterComplete = true;
                        pos++;
                        break;
                    case '%':
                    case '+':
                        // Decoding required
                        if (parsingName) {
                            decodeName = true;
                        } else {
                            decodeValue = true;
                        }
                        pos ++;
                        break;
                    default:
                        pos ++;
                        break;
                }
            } while (!parameterComplete && pos < end);

            if (pos == end) {
                if (nameEnd == -1) {
                    nameEnd = pos;
                } else if (valueStart > -1 && valueEnd == -1){
                    valueEnd = pos;
                }
            }

            if (log.isDebugEnabled() && valueStart == -1) {
                log.debug(sm.getString(""parameters.noequal"",
                        Integer.valueOf(nameStart), Integer.valueOf(nameEnd),
                        new String(bytes, nameStart, nameEnd-nameStart, DEFAULT_BODY_CHARSET)));
            }

            if (nameEnd <= nameStart ) {
                if (valueStart == -1) {
                    // &&
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""parameters.emptyChunk""));
                    }
                    // Do not flag as error
                    continue;
                }
                // &=foo&
                UserDataHelper.Mode logMode = userDataLog.getNextMode();
                if (logMode != null) {
                    String extract;
                    if (valueEnd > nameStart) {
                        extract = new String(bytes, nameStart, valueEnd - nameStart,
                                DEFAULT_BODY_CHARSET);
                    } else {
                        extract = """";
                    }
                    String message = sm.getString(""parameters.invalidChunk"",
                            Integer.valueOf(nameStart),
                            Integer.valueOf(valueEnd), extract);
                    switch (logMode) {
                        case INFO_THEN_DEBUG:
                            message += sm.getString(""parameters.fallToDebug"");
                            //$FALL-THROUGH$
                        case INFO:
                            log.info(message);
                            break;
                        case DEBUG:
                            log.debug(message);
                    }
                }
                setParseFailedReason(FailReason.NO_NAME);
                continue;
                // invalid chunk - it's better to ignore
            }

            tmpName.setBytes(bytes, nameStart, nameEnd - nameStart);
            if (valueStart >= 0) {
                tmpValue.setBytes(bytes, valueStart, valueEnd - valueStart);
            } else {
                tmpValue.setBytes(bytes, 0, 0);
            }

            // Take copies as if anything goes wrong originals will be
            // corrupted. This means original values can be logged.
            // For performance - only done for debug
            if (log.isDebugEnabled()) {
                try {
                    origName.append(bytes, nameStart, nameEnd - nameStart);
                    if (valueStart >= 0) {
                        origValue.append(bytes, valueStart, valueEnd - valueStart);
                    } else {
                        origValue.append(bytes, 0, 0);
                    }
                } catch (IOException ioe) {
                    // Should never happen...
                    log.error(sm.getString(""parameters.copyFail""), ioe);
                }
            }

            try {
                String name;
                String value;

                if (decodeName) {
                    urlDecode(tmpName);
                }
                tmpName.setCharset(charset);
                name = tmpName.toString();

                if (valueStart >= 0) {
                    if (decodeValue) {
                        urlDecode(tmpValue);
                    }
                    tmpValue.setCharset(charset);
                    value = tmpValue.toString();
                } else {
                    value = """";
                }

                try {
                    addParameter(name, value);
                } catch (IllegalStateException ise) {
                    // Hitting limit stops processing further params but does
                    // not cause request to fail.
                    UserDataHelper.Mode logMode = maxParamCountLog.getNextMode();
                    if (logMode != null) {
                        String message = ise.getMessage();
                        switch (logMode) {
                            case INFO_THEN_DEBUG:
                                message += sm.getString(
                                        ""parameters.maxCountFail.fallToDebug"");
                                //$FALL-THROUGH$
                            case INFO:
                                log.info(message);
                                break;
                            case DEBUG:
                                log.debug(message);
                        }
                    }
                    break;
                }
            } catch (IOException e) {
                setParseFailedReason(FailReason.URL_DECODING);
                decodeFailCount++;
                if (decodeFailCount == 1 || log.isDebugEnabled()) {
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""parameters.decodeFail.debug"",
                                origName.toString(), origValue.toString()), e);
                    } else if (log.isInfoEnabled()) {
                        UserDataHelper.Mode logMode = userDataLog.getNextMode();
                        if (logMode != null) {
                            String message = sm.getString(
                                    ""parameters.decodeFail.info"",
                                    tmpName.toString(), tmpValue.toString());
                            switch (logMode) {
                                case INFO_THEN_DEBUG:
                                    message += sm.getString(""parameters.fallToDebug"");
                                    //$FALL-THROUGH$
                                case INFO:
                                    log.info(message);
                                    break;
                                case DEBUG:
                                    log.debug(message);
                            }
                        }
                    }
                }
            }

            tmpName.recycle();
            tmpValue.recycle();
            // Only recycle copies if we used them
            if (log.isDebugEnabled()) {
                origName.recycle();
                origValue.recycle();
            }
        }

        if (decodeFailCount > 1 && !log.isDebugEnabled()) {
            UserDataHelper.Mode logMode = userDataLog.getNextMode();
            if (logMode != null) {
                String message = sm.getString(
                        ""parameters.multipleDecodingFail"",
                        Integer.valueOf(decodeFailCount));
                switch (logMode) {
                    case INFO_THEN_DEBUG:
                        message += sm.getString(""parameters.fallToDebug"");
                        //$FALL-THROUGH$
                    case INFO:
                        log.info(message);
                        break;
                    case DEBUG:
                        
---------------Reference log start----------------
log.debug(message)
---------------Reference log end----------------
                }
            }
        }
    }",,
tomcat,17703,"log.error(""Unable to reset autocommit state to connection."", x)",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/interceptor/ConnectionState.java/#L95,"@Override
    public void reset(ConnectionPool parent, PooledConnection con) {
        if (parent==null || con==null) {
            //we are resetting, reset our defaults
            autoCommit = null;
            transactionIsolation = null;
            readOnly = null;
            catalog = null;
            return;
        }
        PoolConfiguration poolProperties = parent.getPoolProperties();
        if (poolProperties.getDefaultTransactionIsolation()!=DataSourceFactory.UNKNOWN_TRANSACTIONISOLATION) {
            try {
                if (transactionIsolation==null || transactionIsolation.intValue()!=poolProperties.getDefaultTransactionIsolation()) {
                    con.getConnection().setTransactionIsolation(poolProperties.getDefaultTransactionIsolation());
                    transactionIsolation = Integer.valueOf(poolProperties.getDefaultTransactionIsolation());
                }
            }catch (SQLException x) {
                transactionIsolation = null;
                log.error(""Unable to reset transaction isolation state to connection."",x);
            }
        }
        if (poolProperties.getDefaultReadOnly()!=null) {
            try {
                if (readOnly==null || readOnly.booleanValue()!=poolProperties.getDefaultReadOnly().booleanValue()) {
                    con.getConnection().setReadOnly(poolProperties.getDefaultReadOnly().booleanValue());
                    readOnly = poolProperties.getDefaultReadOnly();
                }
            }catch (SQLException x) {
                readOnly = null;
                log.error(""Unable to reset readonly state to connection."",x);
            }
        }
        if (poolProperties.getDefaultAutoCommit()!=null) {
            try {
                if (autoCommit==null || autoCommit.booleanValue()!=poolProperties.getDefaultAutoCommit().booleanValue()) {
                    con.getConnection().setAutoCommit(poolProperties.getDefaultAutoCommit().booleanValue());
                    autoCommit = poolProperties.getDefaultAutoCommit();
                }
            }catch (SQLException x) {
                autoCommit = null;
                
---------------Reference log start----------------
log.error(""Unable to reset autocommit state to connection."", x)
---------------Reference log end----------------
            }
        }
        if (poolProperties.getDefaultCatalog()!=null) {
            try {
                if (catalog==null || (!catalog.equals(poolProperties.getDefaultCatalog()))) {
                    con.getConnection().setCatalog(poolProperties.getDefaultCatalog());
                    catalog = poolProperties.getDefaultCatalog();
                }
            }catch (SQLException x) {
                catalog = null;
                log.error(""Unable to reset default catalog state to connection."",x);
            }
        }

    }",,
tomcat,16898,"log.debug(msg, e)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/Http2UpgradeHandler.java/#L253,"@Override
    public void init(WebConnection webConnection) {
        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""upgradeHandler.init"", connectionId, connectionState.get()));
        }

        if (!connectionState.compareAndSet(ConnectionState.NEW, ConnectionState.CONNECTED)) {
            return;
        }

        // Init concurrency control if needed
        if (protocol.getMaxConcurrentStreamExecution() < localSettings.getMaxConcurrentStreams()) {
            streamConcurrency = new AtomicInteger(0);
            queuedRunnable = new ConcurrentLinkedQueue<>();
        }

        parser = getParser(connectionId);

        Stream stream = null;

        socketWrapper.setReadTimeout(protocol.getReadTimeout());
        socketWrapper.setWriteTimeout(protocol.getWriteTimeout());

        if (webConnection != null) {
            // HTTP/2 started via HTTP upgrade.
            // The initial HTTP/1.1 request is available as Stream 1.

            try {
                // Process the initial settings frame
                stream = getStream(1, true);
                String base64Settings = stream.getCoyoteRequest().getHeader(HTTP2_SETTINGS_HEADER);
                byte[] settings = Base64.decodeBase64URLSafe(base64Settings);

                // Settings are only valid on stream 0
                FrameType.SETTINGS.check(0, settings.length);

                for (int i = 0; i < settings.length % 6; i++) {
                    int id = ByteUtil.getTwoBytes(settings, i * 6);
                    long value = ByteUtil.getFourBytes(settings, (i * 6) + 2);
                    remoteSettings.set(Setting.valueOf(id), value);
                }
            } catch (Http2Exception e) {
                throw new ProtocolException(
                        sm.getString(""upgradeHandler.upgrade.fail"", connectionId));
            }
        }

        // Send the initial settings frame
        writeSettings();

        // Make sure the client has sent a valid connection preface before we
        // send the response to the original request over HTTP/2.
        try {
            parser.readConnectionPreface(webConnection, stream);
        } catch (Http2Exception e) {
            String msg = sm.getString(""upgradeHandler.invalidPreface"", connectionId);
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(msg, e)
---------------Reference log end----------------
            }
            throw new ProtocolException(msg);
        }
        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""upgradeHandler.prefaceReceived"", connectionId));
        }

        processConnection(webConnection, stream);
    }",,
tomcat,15138,"log.debug(""Chat Error: Failed to send message to client"", e)",debug,https://github.com/apache/tomcat/blob/main/webapps/examples/WEB-INF/classes/websocket/chat/ChatAnnotation.java/#L96,"private static void broadcast(String msg) {
        for (ChatAnnotation client : connections) {
            try {
                synchronized (client) {
                    client.session.getBasicRemote().sendText(msg);
                }
            } catch (IOException e) {
                
---------------Reference log start----------------
log.debug(""Chat Error: Failed to send message to client"", e)
---------------Reference log end----------------
                connections.remove(client);
                try {
                    client.session.close();
                } catch (IOException e1) {
                    // Ignore
                }
                String message = String.format(""* %s %s"",
                        client.nickname, ""has been disconnected."");
                broadcast(message);
            }
        }
    }",,
tomcat,15261,"log.error(sm.getString(""persistentManager.serializeError"", session.getIdInternal(), exception))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/PersistentManagerBase.java/#L853,"protected void writeSession(Session session) throws IOException {

        if (store == null || !session.isValid()) {
            return;
        }

        try {
            if (SecurityUtil.isPackageProtectionEnabled()){
                try{
                    AccessController.doPrivileged(new PrivilegedStoreSave(session));
                }catch(PrivilegedActionException ex){
                    Exception exception = ex.getException();
                    if (exception instanceof IOException) {
                        throw (IOException) exception;
                    }
                    
---------------Reference log start----------------
log.error(sm.getString(""persistentManager.serializeError"", session.getIdInternal(), exception))
---------------Reference log end----------------
                }
            } else {
                 store.save(session);
            }
        } catch (IOException e) {
            log.error(sm.getString(""persistentManager.serializeError"", session.getIdInternal(), e));
            throw e;
        }

    }",,
tomcat,16335,"log.error(sm.getString(""deltaManager.noSessionState"", getName(), new Date(beforeSendTime), Long.valueOf(reqNow - beforeSendTime)))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/session/DeltaManager.java/#L798,"protected void waitForSendAllSessions(long beforeSendTime) {
        long reqStart = System.currentTimeMillis();
        long reqNow = reqStart ;
        boolean isTimeout = false;
        if(getStateTransferTimeout() > 0) {
            // wait that state is transferred with timeout check
            do {
                try {
                    Thread.sleep(100);
                } catch (Exception sleep) {
                    //
                }
                reqNow = System.currentTimeMillis();
                isTimeout = ((reqNow - reqStart) > (1000L * getStateTransferTimeout()));
            } while ((!getStateTransferred()) && (!isTimeout) && (!isNoContextManagerReceived()));
        } else {
            if(getStateTransferTimeout() == -1) {
                // wait that state is transferred
                do {
                    try {
                        Thread.sleep(100);
                    } catch (Exception sleep) {
                    }
                } while ((!getStateTransferred())&& (!isNoContextManagerReceived()));
                reqNow = System.currentTimeMillis();
            }
        }
        if (isTimeout) {
            counterNoStateTransferred++ ;
            
---------------Reference log start----------------
log.error(sm.getString(""deltaManager.noSessionState"", getName(), new Date(beforeSendTime), Long.valueOf(reqNow - beforeSendTime)))
---------------Reference log end----------------
        }else if (isNoContextManagerReceived()) {
            if (log.isWarnEnabled()) {
                log.warn(sm.getString(""deltaManager.noContextManager"", getName(),
                        new Date(beforeSendTime), Long.valueOf(reqNow - beforeSendTime)));
            }
        } else {
            if (log.isInfoEnabled()) {
                log.info(sm.getString(""deltaManager.sessionReceived"", getName(),
                        new Date(beforeSendTime), Long.valueOf(reqNow - beforeSendTime)));
            }
        }
    }",,
tomcat,15580,"containerLog.debug(""Closing directory context"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JNDIRealm.java/#L2161,"protected void close(JNDIConnection connection) {

        // Do nothing if there is no opened connection
        if (connection == null || connection.context == null) {
            if (connectionPool == null) {
                singleConnectionLock.unlock();
            }
            return;
        }

        // Close tls startResponse if used
        if (tls != null) {
            try {
                tls.close();
            } catch (IOException e) {
                containerLog.error(sm.getString(""jndiRealm.tlsClose""), e);
            }
        }
        // Close our opened connection
        try {
            if (containerLog.isDebugEnabled()) {
                
---------------Reference log start----------------
containerLog.debug(""Closing directory context"")
---------------Reference log end----------------
            }
            connection.context.close();
        } catch (NamingException e) {
            containerLog.error(sm.getString(""jndiRealm.close""), e);
        }
        connection.context = null;
        // The lock will be reacquired before any manipulation of the connection
        if (connectionPool == null) {
            singleConnectionLock.unlock();
        }
    }",,
tomcat,17610,"log.warn(msg, ne)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/naming/factory/LookupFactory.java/#L131,"@Override
    public Object getObjectInstance(Object obj, Name name, Context nameCtx,
            Hashtable<?, ?> environment) throws Exception {

        String lookupName = null;
        Object result = null;

        if (obj instanceof LookupRef) {
            Reference ref = (Reference) obj;
            ObjectFactory factory = null;
            RefAddr lookupNameRefAddr = ref.get(LookupRef.LOOKUP_NAME);
            if (lookupNameRefAddr != null) {
                lookupName = lookupNameRefAddr.getContent().toString();
            }

            try {
                if (lookupName != null) {
                    if (!names.get().add(lookupName)) {
                        String msg = sm.getString(""lookupFactory.circularReference"", lookupName);
                        NamingException ne = new NamingException(msg);
                        log.warn(msg, ne);
                        throw ne;
                    }
                }
                RefAddr factoryRefAddr = ref.get(Constants.FACTORY);
                if (factoryRefAddr != null) {
                    // Using the specified factory
                    String factoryClassName = factoryRefAddr.getContent().toString();
                    // Loading factory
                    ClassLoader tcl = Thread.currentThread().getContextClassLoader();
                    Class<?> factoryClass = null;
                    if (tcl != null) {
                        try {
                            factoryClass = tcl.loadClass(factoryClassName);
                        } catch (ClassNotFoundException e) {
                            NamingException ex = new NamingException(
                                    sm.getString(""lookupFactory.loadFailed""));
                            ex.initCause(e);
                            throw ex;
                        }
                    } else {
                        try {
                            factoryClass = Class.forName(factoryClassName);
                        } catch (ClassNotFoundException e) {
                            NamingException ex = new NamingException(
                                    sm.getString(""lookupFactory.loadFailed""));
                            ex.initCause(e);
                            throw ex;
                        }
                    }
                    if (factoryClass != null) {
                        try {
                            factory = (ObjectFactory) factoryClass.getConstructor().newInstance();
                        } catch (Throwable t) {
                            if (t instanceof NamingException) {
                                throw (NamingException) t;
                            }
                            NamingException ex = new NamingException(
                                    sm.getString(""lookupFactory.createFailed""));
                            ex.initCause(t);
                            throw ex;
                        }
                    }
                }
                // Note: No defaults here
                if (factory != null) {
                    result = factory.getObjectInstance(obj, name, nameCtx, environment);
                } else {
                    if (lookupName == null) {
                        throw new NamingException(sm.getString(""lookupFactory.createFailed""));
                    } else {
                        result = new InitialContext().lookup(lookupName);
                    }
                }

                Class<?> clazz = Class.forName(ref.getClassName());
                if (result != null && !clazz.isAssignableFrom(result.getClass())) {
                    String msg = sm.getString(""lookupFactory.typeMismatch"",
                            name, ref.getClassName(), lookupName, result.getClass().getName());
                    NamingException ne = new NamingException(msg);
                    
---------------Reference log start----------------
log.warn(msg, ne)
---------------Reference log end----------------
                    // Close the resource we no longer need if we know how to do so
                    if (result instanceof AutoCloseable) {
                        try {
                            ((AutoCloseable) result).close();
                        } catch (Exception e) {
                            // Ignore
                        }
                    }
                    throw ne;
                }
            } finally {
                names.get().remove(lookupName);
            }
        }


        return result;
    }",,
tomcat,17012,"log.error(sm.getString(""wsHttpUpgradeHandler.destroyFailed""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/websocket/server/WsHttpUpgradeHandler.java/#L219,"@Override
    public void destroy() {
        if (connection != null) {
            try {
                connection.close();
            } catch (Exception e) {
                
---------------Reference log start----------------
log.error(sm.getString(""wsHttpUpgradeHandler.destroyFailed""), e)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,16566,"context.getLogger().warn(sm.getString(""applicationHttpRequest.fragmentInDispatchPath"", path))",getLogger,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/ApplicationHttpRequest.java/#L331,"@Override
    public RequestDispatcher getRequestDispatcher(String path) {

        if (context == null) {
            return null;
        }

        if (path == null) {
            return null;
        }

        int fragmentPos = path.indexOf('#');
        if (fragmentPos > -1) {
            
---------------Reference log start----------------
context.getLogger().warn(sm.getString(""applicationHttpRequest.fragmentInDispatchPath"", path))
---------------Reference log end----------------
            path = path.substring(0, fragmentPos);
        }

        // If the path is already context-relative, just pass it through
        if (path.startsWith(""/"")) {
            return context.getServletContext().getRequestDispatcher(path);
        }

        // Convert a request-relative path to a context-relative one
        String servletPath =
            (String) getAttribute(RequestDispatcher.INCLUDE_SERVLET_PATH);
        if (servletPath == null) {
            servletPath = getServletPath();
        }

        // Add the path info, if there is any
        String pathInfo = getPathInfo();
        String requestPath = null;

        if (pathInfo == null) {
            requestPath = servletPath;
        } else {
            requestPath = servletPath + pathInfo;
        }

        int pos = requestPath.lastIndexOf('/');
        String relative = null;
        if (context.getDispatchersUseEncodedPaths()) {
            if (pos >= 0) {
                relative = URLEncoder.DEFAULT.encode(
                        requestPath.substring(0, pos + 1), StandardCharsets.UTF_8) + path;
            } else {
                relative = URLEncoder.DEFAULT.encode(requestPath, StandardCharsets.UTF_8) + path;
            }
        } else {
            if (pos >= 0) {
                relative = requestPath.substring(0, pos + 1) + path;
            } else {
                relative = requestPath + path;
            }
        }

        return context.getServletContext().getRequestDispatcher(relative);

    }",,
tomcat,17536,"log.debug(""constant pool count: "" + constantPoolCount)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/SmapUtil.java/#L227,"void addSDE() throws UnsupportedEncodingException, IOException {
            copy(4 + 2 + 2); // magic min/maj version
            int constantPoolCountPos = genPos;
            int constantPoolCount = readU2();
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""constant pool count: "" + constantPoolCount)
---------------Reference log end----------------
            }
            writeU2(constantPoolCount);

            // copy old constant pool return index of SDE symbol, if found
            sdeIndex = copyConstantPool(constantPoolCount);
            if (sdeIndex < 0) {
                // if ""SourceDebugExtension"" symbol not there add it
                writeUtf8ForSDE();

                // increment the constantPoolCount
                sdeIndex = constantPoolCount;
                ++constantPoolCount;
                randomAccessWriteU2(constantPoolCountPos, constantPoolCount);

                if (log.isDebugEnabled()) {
                    log.debug(""SourceDebugExtension not found, installed at: "" + sdeIndex);
                }
            } else {
                if (log.isDebugEnabled()) {
                    log.debug(""SourceDebugExtension found at: "" + sdeIndex);
                }
            }
            copy(2 + 2 + 2); // access, this, super
            int interfaceCount = readU2();
            writeU2(interfaceCount);
            if (log.isDebugEnabled()) {
                log.debug(""interfaceCount: "" + interfaceCount);
            }
            copy(interfaceCount * 2);
            copyMembers(); // fields
            copyMembers(); // methods
            int attrCountPos = genPos;
            int attrCount = readU2();
            writeU2(attrCount);
            if (log.isDebugEnabled()) {
                log.debug(""class attrCount: "" + attrCount);
            }
            // copy the class attributes, return true if SDE attr found (not copied)
            if (!copyAttrs(attrCount)) {
                // we will be adding SDE and it isn't already counted
                ++attrCount;
                randomAccessWriteU2(attrCountPos, attrCount);
                if (log.isDebugEnabled()) {
                    log.debug(""class attrCount incremented"");
                }
            }
            writeAttrForSDE(sdeIndex);
        }",,
tomcat,17447,"digester.log.debug(""[SetPropertiesRule]{"" + digester.match + ""} Setting property '"" + name + ""' to '"" + value + ""'"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/SetPropertiesRule.java/#L92,"@Override
    public void begin(String namespace, String theName, Attributes attributes)
            throws Exception {

        // Populate the corresponding properties of the top object
        Object top = digester.peek();
        if (digester.log.isDebugEnabled()) {
            if (top != null) {
                digester.log.debug(""[SetPropertiesRule]{"" + digester.match +
                                   ""} Set "" + top.getClass().getName() +
                                   "" properties"");
            } else {
                digester.log.debug(""[SetPropertiesRule]{"" + digester.match +
                                   ""} Set NULL properties"");
            }
        }
        StringBuilder code = digester.getGeneratedCode();
        String variableName = null;
        if (code != null) {
            variableName = digester.toVariableName(top);
        }

        for (int i = 0; i < attributes.getLength(); i++) {
            String name = attributes.getLocalName(i);
            if (name.isEmpty()) {
                name = attributes.getQName(i);
            }
            String value = attributes.getValue(i);

            if (digester.log.isDebugEnabled()) {
                
---------------Reference log start----------------
digester.log.debug(""[SetPropertiesRule]{"" + digester.match + ""} Setting property '"" + name + ""' to '"" + value + ""'"")
---------------Reference log end----------------
            }
            if (!digester.isFakeAttribute(top, name) && (excludes == null || !excludes.containsKey(name))) {
                StringBuilder actualMethod = null;
                if (code != null) {
                    actualMethod = new StringBuilder();
                }
                if (!IntrospectionUtils.setProperty(top, name, value, true, actualMethod)) {
                    if (digester.getRulesValidation() && !""optional"".equals(name)) {
                        digester.log.warn(sm.getString(""rule.noProperty"", digester.match, name, value));
                    }
                } else {
                    if (code != null) {
                        code.append(variableName).append(""."").append(actualMethod).append(';');
                        code.append(System.lineSeparator());
                    }
                }
            }
        }

        if (top instanceof Listener) {
            ((Listener) top).endSetPropertiesRule();
            if (code != null) {
                code.append(""((org.apache.tomcat.util.digester.SetPropertiesRule.Listener) "");
                code.append(variableName).append("").endSetPropertiesRule();"");
                code.append(System.lineSeparator());
            }
        }

    }",,
tomcat,16647,"log.error(sm.getString(""standardContext.resourcesStop""), t)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardContext.java/#L4865,"public boolean resourcesStop() {

        boolean ok = true;

        Lock writeLock = resourcesLock.writeLock();
        writeLock.lock();
        try {
            if (resources != null) {
                resources.stop();
            }
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            
---------------Reference log start----------------
log.error(sm.getString(""standardContext.resourcesStop""), t)
---------------Reference log end----------------
            ok = false;
        } finally {
            writeLock.unlock();
        }

        return ok;
    }",,
tomcat,16217,"log.error(sm.getString(""hostConfig.deployDescriptor.error"", war.getAbsolutePath()), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/HostConfig.java/#L892,"protected void deployWAR(ContextName cn, File war) {

        File xml = new File(host.getAppBaseFile(), cn.getBaseName() + ""/"" + Constants.ApplicationContextXml);

        File warTracker = new File(host.getAppBaseFile(), cn.getBaseName() + Constants.WarTracker);

        boolean xmlInWar = false;
        try (JarFile jar = new JarFile(war)) {
            JarEntry entry = jar.getJarEntry(Constants.ApplicationContextXml);
            if (entry != null) {
                xmlInWar = true;
            }
        } catch (IOException e) {
            /* Ignore */
        }

        // If there is an expanded directory then any xml in that directory
        // should only be used if the directory is not out of date and
        // unpackWARs is true. Note the code below may apply further limits
        boolean useXml = false;
        // If the xml file exists then expandedDir must exists so no need to
        // test that here
        if (xml.exists() && unpackWARs && (!warTracker.exists() || warTracker.lastModified() == war.lastModified())) {
            useXml = true;
        }

        Context context = null;
        boolean deployThisXML = isDeployThisXML(war, cn);

        try {
            if (deployThisXML && useXml && !copyXML) {
                synchronized (digesterLock) {
                    try {
                        context = (Context) digester.parse(xml);
                    } catch (Exception e) {
                        log.error(sm.getString(""hostConfig.deployDescriptor.error"", war.getAbsolutePath()), e);
                    } finally {
                        digester.reset();
                        if (context == null) {
                            context = new FailedContext();
                        }
                    }
                }
                context.setConfigFile(xml.toURI().toURL());
            } else if (deployThisXML && xmlInWar) {
                synchronized (digesterLock) {
                    try (JarFile jar = new JarFile(war)) {
                        JarEntry entry = jar.getJarEntry(Constants.ApplicationContextXml);
                        try (InputStream istream = jar.getInputStream(entry)) {
                            context = (Context) digester.parse(istream);
                        }
                    } catch (Exception e) {
                        
---------------Reference log start----------------
log.error(sm.getString(""hostConfig.deployDescriptor.error"", war.getAbsolutePath()), e)
---------------Reference log end----------------
                    } finally {
                        digester.reset();
                        if (context == null) {
                            context = new FailedContext();
                        }
                        context.setConfigFile(UriUtil.buildJarUrl(war, Constants.ApplicationContextXml));
                    }
                }
            } else if (!deployThisXML && xmlInWar) {
                // Block deployment as META-INF/context.xml may contain security
                // configuration necessary for a secure deployment.
                log.error(sm.getString(""hostConfig.deployDescriptor.blocked"",
                        cn.getPath(), Constants.ApplicationContextXml,
                        new File(host.getConfigBaseFile(), cn.getBaseName() + "".xml"")));
            } else {
                context = (Context) Class.forName(contextClass).getConstructor().newInstance();
            }
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            log.error(sm.getString(""hostConfig.deployWar.error"", war.getAbsolutePath()), t);
        } finally {
            if (context == null) {
                context = new FailedContext();
            }
        }

        boolean copyThisXml = false;
        if (deployThisXML) {
            if (host instanceof StandardHost) {
                copyThisXml = ((StandardHost) host).isCopyXML();
            }

            // If Host is using default value Context can override it.
            if (!copyThisXml && context instanceof StandardContext) {
                copyThisXml = ((StandardContext) context).getCopyXML();
            }

            if (xmlInWar && copyThisXml) {
                // Change location of XML file to config base
                xml = new File(host.getConfigBaseFile(), cn.getBaseName() + "".xml"");
                try (JarFile jar = new JarFile(war)) {
                    JarEntry entry = jar.getJarEntry(Constants.ApplicationContextXml);
                    try (InputStream istream = jar.getInputStream(entry);
                            OutputStream ostream = new FileOutputStream(xml)) {
                        IOTools.flow(istream, ostream);
                    }
                } catch (IOException e) {
                    /* Ignore */
                }
            }
        }

        DeployedApplication deployedApp = new DeployedApplication(
                cn.getName(), xml.exists() && deployThisXML && copyThisXml);

        long startTime = 0;
        // Deploy the application in this WAR file
        if(log.isInfoEnabled()) {
            startTime = System.currentTimeMillis();
            log.info(sm.getString(""hostConfig.deployWar"", war.getAbsolutePath()));
        }

        try {
            // Populate redeploy resources with the WAR file
            deployedApp.redeployResources.put(war.getAbsolutePath(), Long.valueOf(war.lastModified()));

            if (deployThisXML && xml.exists() && copyThisXml) {
                deployedApp.redeployResources.put(xml.getAbsolutePath(), Long.valueOf(xml.lastModified()));
            } else {
                // In case an XML file is added to the config base later
                deployedApp.redeployResources.put(
                        (new File(host.getConfigBaseFile(), cn.getBaseName() + "".xml"")).getAbsolutePath(),
                        Long.valueOf(0));
            }

            Class<?> clazz = Class.forName(host.getConfigClass());
            LifecycleListener listener = (LifecycleListener) clazz.getConstructor().newInstance();
            context.addLifecycleListener(listener);

            context.setName(cn.getName());
            context.setPath(cn.getPath());
            context.setWebappVersion(cn.getVersion());
            context.setDocBase(cn.getBaseName() + "".war"");
            host.addChild(context);
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            log.error(sm.getString(""hostConfig.deployWar.error"", war.getAbsolutePath()), t);
        } finally {
            // If we're unpacking WARs, the docBase will be mutated after
            // starting the context
            boolean unpackWAR = unpackWARs;
            if (unpackWAR && context instanceof StandardContext) {
                unpackWAR = ((StandardContext) context).getUnpackWAR();
            }
            if (unpackWAR && context.getDocBase() != null) {
                File docBase = new File(host.getAppBaseFile(), cn.getBaseName());
                deployedApp.redeployResources.put(docBase.getAbsolutePath(), Long.valueOf(docBase.lastModified()));
                addWatchedResources(deployedApp, docBase.getAbsolutePath(), context);
                if (deployThisXML && !copyThisXml && (xmlInWar || xml.exists())) {
                    deployedApp.redeployResources.put(xml.getAbsolutePath(), Long.valueOf(xml.lastModified()));
                }
            } else {
                // Passing null for docBase means that no resources will be
                // watched. This will be logged at debug level.
                addWatchedResources(deployedApp, null, context);
            }
            // Add the global redeploy resources (which are never deleted) at
            // the end so they don't interfere with the deletion process
            addGlobalRedeployResources(deployedApp);
        }

        deployed.put(cn.getName(), deployedApp);

        if (log.isInfoEnabled()) {
            log.info(sm.getString(""hostConfig.deployWar.finished"",
                    war.getAbsolutePath(), Long.valueOf(System.currentTimeMillis() - startTime)));
        }
    }",,
tomcat,15576,"containerLog.trace(""  retrieving attribute "" + attrId)",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JNDIRealm.java/#L2067,"private String getAttributeValue(String attrId, Attributes attrs) throws NamingException {

        if (containerLog.isTraceEnabled()) {
            
---------------Reference log start----------------
containerLog.trace(""  retrieving attribute "" + attrId)
---------------Reference log end----------------
        }

        if (attrId == null || attrs == null) {
            return null;
        }

        Attribute attr = attrs.get(attrId);
        if (attr == null) {
            return null;
        }
        Object value = attr.get();
        if (value == null) {
            return null;
        }
        String valueString = null;
        if (value instanceof byte[]) {
            valueString = new String((byte[]) value);
        } else {
            valueString = value.toString();
        }

        return valueString;
    }",,
tomcat,15984,"log.debug(sm.getString(""authenticator.check.found"", principal.getName()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/AuthenticatorBase.java/#L1017,"protected boolean checkForCachedAuthentication(Request request, HttpServletResponse response, boolean useSSO) {

        // Has the user already been authenticated?
        Principal principal = request.getUserPrincipal();
        String ssoId = (String) request.getNote(Constants.REQ_SSOID_NOTE);
        if (principal != null) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""authenticator.check.found"", principal.getName()))
---------------Reference log end----------------
            }
            // Associate the session with any existing SSO session. Even if
            // useSSO is false, this will ensure coordinated session
            // invalidation at log out.
            if (ssoId != null) {
                associate(ssoId, request.getSessionInternal(true));
            }
            return true;
        }

        // Is there an SSO session against which we can try to reauthenticate?
        if (useSSO && ssoId != null) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""authenticator.check.sso"", ssoId));
            }
            /*
             * Try to reauthenticate using data cached by SSO. If this fails,
             * either the original SSO logon was of DIGEST or SSL (which we
             * can't reauthenticate ourselves because there is no cached
             * username and password), or the realm denied the user's
             * reauthentication for some reason. In either case we have to
             * prompt the user for a logon
             */
            if (reauthenticateFromSSO(ssoId, request)) {
                return true;
            }
        }

        // Has the Connector provided a pre-authenticated Principal that now
        // needs to be authorized?
        if (request.getCoyoteRequest().getRemoteUserNeedsAuthorization()) {
            String username = request.getCoyoteRequest().getRemoteUser().toString();
            if (username != null) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""authenticator.check.authorize"", username));
                }
                Principal authorized = context.getRealm().authenticate(username);
                if (authorized == null) {
                    // Realm doesn't recognise user. Create a user with no roles
                    // from the authenticated user name
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""authenticator.check.authorizeFail"", username));
                    }
                    authorized = new GenericPrincipal(username);
                }
                String authType = request.getAuthType();
                if (authType == null || authType.length() == 0) {
                    authType = getAuthMethod();
                }
                register(request, response, authorized, authType, username, null);
                return true;
            }
        }
        return false;
    }",,
tomcat,17085,"log.warn(sm.getString(""jre9Compat.invalidModuleUri"", uri), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/compat/Jre9Compat.java/#L193,"@Override
    public void addBootModulePath(Deque<URL> classPathUrlsToProcess) {
        try {
            Object bootLayer = bootMethod.invoke(null);
            Object bootConfiguration = configurationMethod.invoke(bootLayer);
            Set<?> resolvedModules = (Set<?>) modulesMethod.invoke(bootConfiguration);
            for (Object resolvedModule : resolvedModules) {
                Object moduleReference = referenceMethod.invoke(resolvedModule);
                Object optionalURI = locationMethod.invoke(moduleReference);
                Boolean isPresent = (Boolean) isPresentMethod.invoke(optionalURI);
                if (isPresent.booleanValue()) {
                    URI uri = (URI) getMethod.invoke(optionalURI);
                    try {
                        URL url = uri.toURL();
                        classPathUrlsToProcess.add(url);
                    } catch (MalformedURLException e) {
                        
---------------Reference log start----------------
log.warn(sm.getString(""jre9Compat.invalidModuleUri"", uri), e)
---------------Reference log end----------------
                    }
                }
            }
        } catch (ReflectiveOperationException e) {
            throw new UnsupportedOperationException(e);
        }
    }",,
tomcat,16160,"log.error(sm.getString(""contextConfig.noAntiLocking"", tmp, context.getName()))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/ContextConfig.java/#L905,"protected void antiLocking() {

        if ((context instanceof StandardContext)
                && ((StandardContext) context).getAntiResourceLocking()) {

            Host host = (Host) context.getParent();
            String docBase = context.getDocBase();
            if (docBase == null) {
                return;
            }
            originalDocBase = docBase;

            File docBaseFile = new File(docBase);
            if (!docBaseFile.isAbsolute()) {
                docBaseFile = new File(host.getAppBaseFile(), docBase);
            }

            String path = context.getPath();
            if (path == null) {
                return;
            }
            ContextName cn = new ContextName(path, context.getWebappVersion());
            docBase = cn.getBaseName();

            String tmp = System.getProperty(""java.io.tmpdir"");
            File tmpFile = new File(tmp);
            if (!tmpFile.isDirectory()) {
                
---------------Reference log start----------------
log.error(sm.getString(""contextConfig.noAntiLocking"", tmp, context.getName()))
---------------Reference log end----------------
                return;
            }

            if (originalDocBase.toLowerCase(Locale.ENGLISH).endsWith("".war"")) {
                antiLockingDocBase = new File(tmpFile, deploymentCount++ + ""-"" + docBase + "".war"");
            } else {
                antiLockingDocBase = new File(tmpFile, deploymentCount++ + ""-"" + docBase);
            }
            antiLockingDocBase = antiLockingDocBase.getAbsoluteFile();

            if (log.isDebugEnabled()) {
                log.debug(""Anti locking context["" + context.getName()
                        + ""] setting docBase to "" +
                        antiLockingDocBase.getPath());
            }

            // Cleanup just in case an old deployment is lying around
            ExpandWar.delete(antiLockingDocBase);
            if (ExpandWar.copy(docBaseFile, antiLockingDocBase)) {
                context.setDocBase(antiLockingDocBase.getPath());
            }
        }
    }",,
tomcat,17108,"log.debug(""Send file complete for: "" + sd.fileName)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/NioEndpoint.java/#L911,"public SendfileState processSendfile(SelectionKey sk, NioSocketWrapper socketWrapper,
                boolean calledByProcessor) {
            NioChannel sc = null;
            try {
                unreg(sk, socketWrapper, sk.readyOps());
                SendfileData sd = socketWrapper.getSendfileData();

                if (log.isTraceEnabled()) {
                    log.trace(""Processing send file for: "" + sd.fileName);
                }

                if (sd.fchannel == null) {
                    // Setup the file channel
                    File f = new File(sd.fileName);
                    @SuppressWarnings(""resource"") // Closed when channel is closed
                    FileInputStream fis = new FileInputStream(f);
                    sd.fchannel = fis.getChannel();
                }

                // Configure output channel
                sc = socketWrapper.getSocket();
                // TLS/SSL channel is slightly different
                WritableByteChannel wc = ((sc instanceof SecureNioChannel) ? sc : sc.getIOChannel());

                // We still have data in the buffer
                if (sc.getOutboundRemaining() > 0) {
                    if (sc.flushOutbound()) {
                        socketWrapper.updateLastWrite();
                    }
                } else {
                    long written = sd.fchannel.transferTo(sd.pos, sd.length, wc);
                    if (written > 0) {
                        sd.pos += written;
                        sd.length -= written;
                        socketWrapper.updateLastWrite();
                    } else {
                        // Unusual not to be able to transfer any bytes
                        // Check the length was set correctly
                        if (sd.fchannel.size() <= sd.pos) {
                            throw new IOException(sm.getString(""endpoint.sendfile.tooMuchData""));
                        }
                    }
                }
                if (sd.length <= 0 && sc.getOutboundRemaining()<=0) {
                    if (log.isDebugEnabled()) {
                        
---------------Reference log start----------------
log.debug(""Send file complete for: "" + sd.fileName)
---------------Reference log end----------------
                    }
                    socketWrapper.setSendfileData(null);
                    try {
                        sd.fchannel.close();
                    } catch (Exception ignore) {
                    }
                    // For calls from outside the Poller, the caller is
                    // responsible for registering the socket for the
                    // appropriate event(s) if sendfile completes.
                    if (!calledByProcessor) {
                        switch (sd.keepAliveState) {
                        case NONE: {
                            if (log.isDebugEnabled()) {
                                log.debug(""Send file connection is being closed"");
                            }
                            poller.cancelledKey(sk, socketWrapper);
                            break;
                        }
                        case PIPELINED: {
                            if (log.isDebugEnabled()) {
                                log.debug(""Connection is keep alive, processing pipe-lined data"");
                            }
                            if (!processSocket(socketWrapper, SocketEvent.OPEN_READ, true)) {
                                poller.cancelledKey(sk, socketWrapper);
                            }
                            break;
                        }
                        case OPEN: {
                            if (log.isDebugEnabled()) {
                                log.debug(""Connection is keep alive, registering back for OP_READ"");
                            }
                            reg(sk, socketWrapper, SelectionKey.OP_READ);
                            break;
                        }
                        }
                    }
                    return SendfileState.DONE;
                } else {
                    if (log.isDebugEnabled()) {
                        log.debug(""OP_WRITE for sendfile: "" + sd.fileName);
                    }
                    if (calledByProcessor) {
                        add(socketWrapper, SelectionKey.OP_WRITE);
                    } else {
                        reg(sk, socketWrapper, SelectionKey.OP_WRITE);
                    }
                    return SendfileState.PENDING;
                }
            } catch (IOException e) {
                if (log.isDebugEnabled()) {
                    log.debug(""Unable to complete sendfile request:"", e);
                }
                if (!calledByProcessor && sc != null) {
                    poller.cancelledKey(sk, socketWrapper);
                }
                return SendfileState.ERROR;
            } catch (Throwable t) {
                log.error(sm.getString(""endpoint.sendfile.error""), t);
                if (!calledByProcessor && sc != null) {
                    poller.cancelledKey(sk, socketWrapper);
                }
                return SendfileState.ERROR;
            }
        }",,
tomcat,16860,log.error(msg),error,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/ajp/AjpProcessor.java/#L596,"private boolean readMessage(AjpMessage message, boolean block)
        throws IOException {

        byte[] buf = message.getBuffer();

        if (!read(buf, 0, Constants.H_SIZE, block)) {
            return false;
        }

        int messageLength = message.processHeader(true);
        if (messageLength < 0) {
            // Invalid AJP header signature
            throw new IOException(sm.getString(""ajpmessage.invalidLength"",
                    Integer.valueOf(messageLength)));
        }
        else if (messageLength == 0) {
            // Zero length message.
            return true;
        } else {
            if (messageLength > message.getBuffer().length) {
                // Message too long for the buffer
                // Need to trigger a 400 response
                String msg = sm.getString(""ajpprocessor.header.tooLong"",
                        Integer.valueOf(messageLength), Integer.valueOf(buf.length));
                
---------------Reference log start----------------
log.error(msg)
---------------Reference log end----------------
                throw new IllegalArgumentException(msg);
            }
            read(buf, Constants.H_SIZE, messageLength, true);
            return true;
        }
    }",,
tomcat,16765,"log.error(sm.getString(""standardService.mapperListener.startFailed""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardService.java/#L162,"@Override
    public void setContainer(Engine engine) {
        Engine oldEngine = this.engine;
        if (oldEngine != null) {
            oldEngine.setService(null);
        }
        this.engine = engine;
        if (this.engine != null) {
            this.engine.setService(this);
        }
        if (getState().isAvailable()) {
            if (this.engine != null) {
                try {
                    this.engine.start();
                } catch (LifecycleException e) {
                    log.error(sm.getString(""standardService.engine.startFailed""), e);
                }
            }
            // Restart MapperListener to pick up new engine.
            try {
                mapperListener.stop();
            } catch (LifecycleException e) {
                log.error(sm.getString(""standardService.mapperListener.stopFailed""), e);
            }
            try {
                mapperListener.start();
            } catch (LifecycleException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""standardService.mapperListener.startFailed""), e)
---------------Reference log end----------------
            }
            if (oldEngine != null) {
                try {
                    oldEngine.stop();
                } catch (LifecycleException e) {
                    log.error(sm.getString(""standardService.engine.stopFailed""), e);
                }
            }
        }

        // Report this property change to interested listeners
        support.firePropertyChange(""container"", oldEngine, this.engine);
    }",,
tomcat,16094,"log.error(sm.getString(""catalina.stopError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/Catalina.java/#L706,"public void stopServer(String[] arguments) {

        if (arguments != null) {
            arguments(arguments);
        }

        Server s = getServer();
        if (s == null) {
            parseServerXml(false);
            if (getServer() == null) {
                log.error(sm.getString(""catalina.stopError""));
                System.exit(1);
            }
        } else {
            // Server object already present. Must be running as a service
            try {
                s.stop();
                s.destroy();
            } catch (LifecycleException e) {
                log.error(sm.getString(""catalina.stopError""), e);
            }
            return;
        }

        // Stop the existing server
        s = getServer();
        if (s.getPortWithOffset() > 0) {
            try (Socket socket = new Socket(s.getAddress(), s.getPortWithOffset());
                    OutputStream stream = socket.getOutputStream()) {
                String shutdown = s.getShutdown();
                for (int i = 0; i < shutdown.length(); i++) {
                    stream.write(shutdown.charAt(i));
                }
                stream.flush();
            } catch (ConnectException ce) {
                log.error(sm.getString(""catalina.stopServer.connectException"", s.getAddress(),
                        String.valueOf(s.getPortWithOffset()), String.valueOf(s.getPort()),
                        String.valueOf(s.getPortOffset())));
                log.error(sm.getString(""catalina.stopError""), ce);
                System.exit(1);
            } catch (IOException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""catalina.stopError""), e)
---------------Reference log end----------------
                System.exit(1);
            }
        } else {
            log.error(sm.getString(""catalina.stopServer""));
            System.exit(1);
        }
    }",,
tomcat,16060,"log.warn(sm.getString(""memoryUserDatabase.fileClose"", pathname), ioe)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/users/MemoryUserDatabase.java/#L693,"@Override
    public void backgroundProcess() {
        if (!watchSource) {
            return;
        }

        URI uri = ConfigFileLoader.getSource().getURI(getPathname());
        URLConnection uConn = null;
        try {
            URL url = uri.toURL();
            uConn = url.openConnection();

            if (this.lastModified != uConn.getLastModified()) {
                writeLock.lock();
                try {
                    long detectedLastModified = uConn.getLastModified();
                    // Last modified as a resolution of 1s. Ensure that a write
                    // to the file is not in progress by ensuring that the last
                    // modified time is at least 2 seconds ago.
                    if (this.lastModified != detectedLastModified &&
                            detectedLastModified + 2000 < System.currentTimeMillis()) {
                        log.info(sm.getString(""memoryUserDatabase.reload"", id, uri));
                        open();
                    }
                } finally {
                    writeLock.unlock();
                }
            }
        } catch (Exception ioe) {
            log.error(sm.getString(""memoryUserDatabase.reloadError"", id, uri), ioe);
        } finally {
            if (uConn != null) {
                try {
                    // Can't close a uConn directly. Have to do it like this.
                    uConn.getInputStream().close();
                } catch (FileNotFoundException fnfe) {
                    // The file doesn't exist.
                    // This has been logged above. No need to log again.
                    // Set the last modified time to avoid repeated log messages
                    this.lastModified = 0;
                } catch (IOException ioe) {
                    
---------------Reference log start----------------
log.warn(sm.getString(""memoryUserDatabase.fileClose"", pathname), ioe)
---------------Reference log end----------------
                }
            }
        }
    }",,
tomcat,17001,"log.warn(sm.getString(""wsRemoteEndpoint.flushOnCloseFailed""))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/websocket/WsRemoteEndpointImplBase.java/#L376,"void startMessage(byte opCode, ByteBuffer payload, boolean last,
            SendHandler handler) {

        wsSession.updateLastActiveWrite();

        List<MessagePart> messageParts = new ArrayList<>();
        messageParts.add(new MessagePart(last, 0, opCode, payload,
                intermediateMessageHandler,
                new EndMessageHandler(this, handler), -1));

        try {
            messageParts = transformation.sendMessagePart(messageParts);
        } catch (IOException ioe) {
            handler.onResult(new SendResult(ioe));
            return;
        }

        // Some extensions/transformations may buffer messages so it is possible
        // that no message parts will be returned. If this is the case the
        // trigger the supplied SendHandler
        if (messageParts.size() == 0) {
            handler.onResult(new SendResult());
            return;
        }

        MessagePart mp = messageParts.remove(0);

        boolean doWrite = false;
        synchronized (messagePartLock) {
            if (Constants.OPCODE_CLOSE == mp.getOpCode() && getBatchingAllowed()) {
                // Should not happen. To late to send batched messages now since
                // the session has been closed. Complain loudly.
                
---------------Reference log start----------------
log.warn(sm.getString(""wsRemoteEndpoint.flushOnCloseFailed""))
---------------Reference log end----------------
            }
            if (messagePartInProgress.tryAcquire()) {
                doWrite = true;
            } else {
                // When a control message is sent while another message is being
                // sent, the control message is queued. Chances are the
                // subsequent data message part will end up queued while the
                // control message is sent. The logic in this class (state
                // machine, EndMessageHandler, TextMessageSendHandler) ensures
                // that there will only ever be one data message part in the
                // queue. There could be multiple control messages in the queue.

                // Add it to the queue
                messagePartQueue.add(mp);
            }
            // Add any remaining messages to the queue
            messagePartQueue.addAll(messageParts);
        }
        if (doWrite) {
            // Actual write has to be outside sync block to avoid possible
            // deadlock between messagePartLock and writeLock in
            // o.a.coyote.http11.upgrade.AbstractServletOutputStream
            writeMessagePart(mp);
        }
    }",,
tomcat,16414,"log.error(sm.getString(""farmWarDeployer.fileCopyFail"", from, to), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/deploy/FarmWarDeployer.java/#L753,"protected boolean copy(File from, File to) {
        try {
            if (!to.exists()) {
                if (!to.createNewFile()) {
                    log.error(sm.getString(""fileNewFail"", to));
                    return false;
                }
            }
        } catch (IOException e) {
            
---------------Reference log start----------------
log.error(sm.getString(""farmWarDeployer.fileCopyFail"", from, to), e)
---------------Reference log end----------------
            return false;
        }

        try (java.io.FileInputStream is = new java.io.FileInputStream(from);
                java.io.FileOutputStream os = new java.io.FileOutputStream(to, false)) {
            byte[] buf = new byte[4096];
            while (true) {
                int len = is.read(buf);
                if (len < 0) {
                    break;
                }
                os.write(buf, 0, len);
            }
        } catch (IOException e) {
            log.error(sm.getString(""farmWarDeployer.fileCopyFail"",
                    from, to), e);
            return false;
        }
        return true;
    }",,
tomcat,17642,"log.warn(""maxActive is smaller than 1, setting maxActive to: "" + PoolProperties.DEFAULT_MAX_ACTIVE)",warn,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L523,"public void checkPoolConfiguration(PoolConfiguration properties) {
        //make sure the pool is properly configured
        if (properties.getMaxActive()<1) {
            
---------------Reference log start----------------
log.warn(""maxActive is smaller than 1, setting maxActive to: "" + PoolProperties.DEFAULT_MAX_ACTIVE)
---------------Reference log end----------------
            properties.setMaxActive(PoolProperties.DEFAULT_MAX_ACTIVE);
        }
        if (properties.getMaxActive()<properties.getInitialSize()) {
            log.warn(""initialSize is larger than maxActive, setting initialSize to: ""+properties.getMaxActive());
            properties.setInitialSize(properties.getMaxActive());
        }
        if (properties.getMinIdle()>properties.getMaxActive()) {
            log.warn(""minIdle is larger than maxActive, setting minIdle to: ""+properties.getMaxActive());
            properties.setMinIdle(properties.getMaxActive());
        }
        if (properties.getMaxIdle()>properties.getMaxActive()) {
            log.warn(""maxIdle is larger than maxActive, setting maxIdle to: ""+properties.getMaxActive());
            properties.setMaxIdle(properties.getMaxActive());
        }
        if (properties.getMaxIdle()<properties.getMinIdle()) {
            log.warn(""maxIdle is smaller than minIdle, setting maxIdle to: ""+properties.getMinIdle());
            properties.setMaxIdle(properties.getMinIdle());
        }
        if (properties.getMaxAge()>0 && properties.isPoolSweeperEnabled() &&
                properties.getTimeBetweenEvictionRunsMillis()>properties.getMaxAge()) {
            log.warn(""timeBetweenEvictionRunsMillis is larger than maxAge, setting timeBetweenEvictionRunsMillis to: "" + properties.getMaxAge());
            properties.setTimeBetweenEvictionRunsMillis((int)properties.getMaxAge());
        }
    }",,
tomcat,15980,"log.warn(sm.getString(""authenticator.jaspicSecureResponseFail""), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/AuthenticatorBase.java/#L764,"private void secureResponseJspic(Request request, Response response, JaspicState state) {
        try {
            state.serverAuthContext.secureResponse(state.messageInfo, null);
            request.setRequest((HttpServletRequest) state.messageInfo.getRequestMessage());
            response.setResponse((HttpServletResponse) state.messageInfo.getResponseMessage());
        } catch (AuthException e) {
            
---------------Reference log start----------------
log.warn(sm.getString(""authenticator.jaspicSecureResponseFail""), e)
---------------Reference log end----------------
        }
    }",,
tomcat,15534,"log.debug(""Login context created "" + username)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JAASRealm.java/#L422,"protected Principal authenticate(String username,
            CallbackHandler callbackHandler) {

        // Establish a LoginContext to use for authentication
        try {
            LoginContext loginContext = null;
            if( appName==null ) {
                appName=""Tomcat"";
            }

            if( log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.beginLogin"", username, appName));
            }

            // What if the LoginModule is in the container class loader ?
            ClassLoader ocl = null;

            if (!isUseContextClassLoader()) {
                ocl = Thread.currentThread().getContextClassLoader();
                Thread.currentThread().setContextClassLoader(
                        this.getClass().getClassLoader());
            }

            try {
                Configuration config = getConfig();
                loginContext = new LoginContext(
                        appName, null, callbackHandler, config);
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                log.error(sm.getString(""jaasRealm.unexpectedError""), e);
                // There is configuration issue with JAAS so mark the realm as
                // unavailable
                invocationSuccess = false;
                return null;
            } finally {
                if(!isUseContextClassLoader()) {
                    Thread.currentThread().setContextClassLoader(ocl);
                }
            }

            if( log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Login context created "" + username)
---------------Reference log end----------------
            }

            // Negotiate a login via this LoginContext
            Subject subject = null;
            try {
                loginContext.login();
                subject = loginContext.getSubject();
                // We were able to perform login successfully so mark JAAS realm as
                // available as it could have been set to false in prior attempts.
                // Change invocationSuccess variable only when we know the outcome
                // of the JAAS operation to keep variable consistent.
                invocationSuccess = true;
                if (subject == null) {
                    if( log.isDebugEnabled()) {
                        log.debug(sm.getString(""jaasRealm.failedLogin"", username));
                    }
                    return null;
                }
            } catch (AccountExpiredException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.accountExpired"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (CredentialExpiredException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.credentialExpired"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (FailedLoginException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.failedLogin"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (LoginException e) {
                log.warn(sm.getString(""jaasRealm.loginException"", username), e);
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                log.error(sm.getString(""jaasRealm.unexpectedError""), e);
                // JAAS throws exception different than LoginException so mark the
                // realm as unavailable
                invocationSuccess = false;
                return null;
            }

            if( log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.loginContextCreated"", username));
            }

            // Return the appropriate Principal for this authenticated Subject
            Principal principal = createPrincipal(username, subject, loginContext);
            if (principal == null) {
                log.debug(sm.getString(""jaasRealm.authenticateFailure"", username));
                return null;
            }
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.authenticateSuccess"", username, principal));
            }

            return principal;
        } catch( Throwable t) {
            log.error( ""error "", t);
            //JAAS throws exception different than LoginException so mark the realm as unavailable
            invocationSuccess = false;
            return null;
        }
    }",,
tomcat,17280,"log.debug(""Skip concurrent "" + (read ? ""read"" : ""write"") + "" notification"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/AprEndpoint.java/#L2717,"@Override
            public void run() {
                // Perform the IO operation
                // Called from the poller to continue the IO operation
                long nBytes = 0;
                if (getError() == null) {
                    try {
                        synchronized (this) {
                            if (!completionDone) {
                                // This filters out same notification until processing
                                // of the current one is done
                                if (log.isDebugEnabled()) {
                                    
---------------Reference log start----------------
log.debug(""Skip concurrent "" + (read ? ""read"" : ""write"") + "" notification"")
---------------Reference log end----------------
                                }
                                return;
                            }
                            // Find the buffer on which the operation will be performed (no vectoring with APR)
                            ByteBuffer buffer = null;
                            for (int i = 0; i < length; i++) {
                                if (buffers[i + offset].hasRemaining()) {
                                    buffer = buffers[i + offset];
                                    break;
                                }
                            }
                            if (buffer == null && flushBytes == 0) {
                                // Nothing to do
                                completion.completed(Long.valueOf(0), this);
                                return;
                            }
                            if (read) {
                                nBytes = read(false, buffer);
                            } else {
                                if (!flush(block == BlockingMode.BLOCK)) {
                                    if (flushBytes > 0) {
                                        // Flushing was done, continue processing
                                        nBytes = flushBytes;
                                        flushBytes = 0;
                                    } else {
                                        @SuppressWarnings(""null"") // Not possible
                                        int remaining = buffer.remaining();
                                        write(block == BlockingMode.BLOCK, buffer);
                                        nBytes = remaining - buffer.remaining();
                                        if (nBytes > 0 && flush(block == BlockingMode.BLOCK)) {
                                            // We have to flush and it's incomplete, save the bytes written until done
                                            inline = false;
                                            registerWriteInterest();
                                            flushBytes = nBytes;
                                            return;
                                        }
                                    }
                                } else {
                                    // Continue flushing
                                    inline = false;
                                    registerWriteInterest();
                                    return;
                                }
                            }
                            if (nBytes != 0) {
                                completionDone = false;
                            }
                        }
                    } catch (IOException e) {
                        setError(e);
                    }
                }
                if (nBytes > 0) {
                    // The bytes processed are only updated in the completion handler
                    completion.completed(Long.valueOf(nBytes), this);
                } else if (nBytes < 0 || getError() != null) {
                    IOException error = getError();
                    if (error == null) {
                        error = new EOFException();
                    }
                    completion.failed(error, this);
                } else {
                    // As soon as the operation uses the poller, it is no longer inline
                    inline = false;
                    if (read) {
                        registerReadInterest();
                    } else {
                        registerWriteInterest();
                    }
                }
            }",,
tomcat,17244,"log.error(sm.getString(""endpoint.process.fail""), t)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/AprEndpoint.java/#L750,"@Override
    protected boolean setSocketOptions(Long socket) {
        try {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""endpoint.debug.socket"", socket));
            }
            AprSocketWrapper wrapper = new AprSocketWrapper(socket, this);
            connections.put(socket, wrapper);
            wrapper.setKeepAliveLeft(getMaxKeepAliveRequests());
            wrapper.setReadTimeout(getConnectionTimeout());
            wrapper.setWriteTimeout(getConnectionTimeout());
            getExecutor().execute(new SocketWithOptionsProcessor(wrapper));
            return true;
        } catch (RejectedExecutionException x) {
            log.warn(sm.getString(""endpoint.rejectedExecution"", socket), x);
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            // This means we got an OOM or similar creating a thread, or that
            // the pool and its queue are full
            
---------------Reference log start----------------
log.error(sm.getString(""endpoint.process.fail""), t)
---------------Reference log end----------------
        }
        return false;
    }",,
tomcat,16465,"log.warn(sm.getString(""cache.objectMaxSizeTooBig"", Integer.valueOf(objectMaxSize / 1024), Integer.valueOf((int) limit / 1024)))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/webresources/Cache.java/#L314,"void enforceObjectMaxSizeLimit() {
        long limit = maxSize / OBJECT_MAX_SIZE_FACTOR;
        if (limit > Integer.MAX_VALUE) {
            return;
        }
        if (objectMaxSize > limit) {
            
---------------Reference log start----------------
log.warn(sm.getString(""cache.objectMaxSizeTooBig"", Integer.valueOf(objectMaxSize / 1024), Integer.valueOf((int) limit / 1024)))
---------------Reference log end----------------
            objectMaxSize = (int) limit;
        }
    }",,
tomcat,17158,"log.debug(sm.getString(""channel.nio.ssl.closeSilentError""), ioe)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/SecureNio2Channel.java/#L695,"private void closeSilently() {
        try {
            close(true);
        } catch (IOException ioe) {
            // This is expected - swallowing the exception is the reason this
            // method exists. Log at debug in case someone is interested.
            
---------------Reference log start----------------
log.debug(sm.getString(""channel.nio.ssl.closeSilentError""), ioe)
---------------Reference log end----------------
        }
    }",,
tomcat,16676,"log.error(sm.getString(""standardContext.threadBindingListenerError"", getName()), t)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardContext.java/#L5850,"@Override
    public void unbind(boolean usePrivilegedAction, ClassLoader originalClassLoader) {
        if (originalClassLoader == null) {
            return;
        }

        if (threadBindingListener != null) {
            try {
                threadBindingListener.unbind();
            } catch (Throwable t) {
                ExceptionUtils.handleThrowable(t);
                
---------------Reference log start----------------
log.error(sm.getString(""standardContext.threadBindingListenerError"", getName()), t)
---------------Reference log end----------------
            }
        }

        if (usePrivilegedAction) {
            PrivilegedAction<Void> pa = new PrivilegedSetTccl(originalClassLoader);
            AccessController.doPrivileged(pa);
        } else {
            Thread.currentThread().setContextClassLoader(originalClassLoader);
        }
    }",,
tomcat,17415,"saxLog.debug(""resolveEntity('"" + publicId + ""', '"" + systemId + ""', '"" + baseURI + ""')"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/Digester.java/#L1373,"@Override
    public InputSource resolveEntity(String name, String publicId, String baseURI, String systemId)
            throws SAXException, IOException {

        if (saxLog.isDebugEnabled()) {
            
---------------Reference log start----------------
saxLog.debug(""resolveEntity('"" + publicId + ""', '"" + systemId + ""', '"" + baseURI + ""')"")
---------------Reference log end----------------
        }

        // Has this system identifier been registered?
        String entityURL = null;
        if (publicId != null) {
            entityURL = entityValidator.get(publicId);
        }

        if (entityURL == null) {
            if (systemId == null) {
                // cannot resolve
                if (log.isDebugEnabled()) {
                    log.debug("" Cannot resolve entity: '"" + publicId + ""'"");
                }
                return null;

            } else {
                // try to resolve using system ID
                if (log.isDebugEnabled()) {
                    log.debug("" Trying to resolve using system ID '"" + systemId + ""'"");
                }
                entityURL = systemId;
                // resolve systemId against baseURI if it is not absolute
                if (baseURI != null) {
                    try {
                        URI uri = new URI(systemId);
                        if (!uri.isAbsolute()) {
                            entityURL = new URI(baseURI).resolve(uri).toString();
                        }
                    } catch (URISyntaxException e) {
                        if (log.isDebugEnabled()) {
                            log.debug(""Invalid URI '"" + baseURI + ""' or '"" + systemId + ""'"");
                        }
                    }
                }
            }
        }

        // Return an input source to our alternative URL
        if (log.isDebugEnabled()) {
            log.debug("" Resolving to alternate DTD '"" + entityURL + ""'"");
        }

        try {
            return new InputSource(entityURL);
        } catch (Exception e) {
            throw createSAXException(e);
        }
    }",,
tomcat,17564,"log.warn(Localizer.getMessage(""jsp.warning.compiler.classfile.delete.fail"", classFile.getAbsolutePath()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/Compiler.java/#L608,"public void removeGeneratedClassFiles() {
        try {
            File classFile = new File(ctxt.getClassFileName());
            if (log.isDebugEnabled()) {
                log.debug(""Deleting "" + classFile);
            }
            if (classFile.exists()) {
                if (!classFile.delete()) {
                    
---------------Reference log start----------------
log.warn(Localizer.getMessage(""jsp.warning.compiler.classfile.delete.fail"", classFile.getAbsolutePath()))
---------------Reference log end----------------
                }
            }
        } catch (Exception e) {
            // Remove as much as possible, log possible exceptions
            log.warn(Localizer.getMessage(""jsp.warning.compiler.classfile.delete.fail.unknown""),
                     e);
        }
    }",,
tomcat,17220,"log.warn(sm.getString(""endpoint.warn.noRemotePort"", getSocket()), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/Nio2Endpoint.java/#L1474,"@Override
        protected void populateRemotePort() {
            AsynchronousSocketChannel sc = getSocket().getIOChannel();
            if (sc != null) {
                SocketAddress socketAddress = null;
                try {
                    socketAddress = sc.getRemoteAddress();
                } catch (IOException e) {
                    
---------------Reference log start----------------
log.warn(sm.getString(""endpoint.warn.noRemotePort"", getSocket()), e)
---------------Reference log end----------------
                }
                if (socketAddress instanceof InetSocketAddress) {
                    remotePort = ((InetSocketAddress) socketAddress).getPort();
                }
            }
        }",,
tomcat,15511,"log.debug(sm.getString(""combinedRealm.authFail"", username, realm.getClass().getName()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/CombinedRealm.java/#L194,"@Override
    public Principal authenticate(String username, String credentials) {
        Principal authenticatedUser = null;

        for (Realm realm : realms) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""combinedRealm.authStart"", username,
                        realm.getClass().getName()));
            }

            authenticatedUser = realm.authenticate(username, credentials);

            if (authenticatedUser == null) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""combinedRealm.authFail"", username, realm.getClass().getName()))
---------------Reference log end----------------
                }
            } else {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""combinedRealm.authSuccess"",
                            username, realm.getClass().getName()));
                }
                break;
            }
        }
        return authenticatedUser;
    }",,
tomcat,17532,"log.error(Localizer.getMessage(""jsp.error.compilation.jdtProblemError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/JDTCompiler.java/#L410,"@Override
                public void acceptResult(CompilationResult result) {
                    try {
                        if (result.hasProblems()) {
                            IProblem[] problems = result.getProblems();
                            for (IProblem problem : problems) {
                                if (problem.isError()) {
                                    String name =
                                            new String(problem.getOriginatingFileName());
                                    try {
                                        problemList.add(ErrorDispatcher.createJavacError
                                                (name, pageNodes, new StringBuilder(problem.getMessage()),
                                                        problem.getSourceLineNumber(), ctxt));
                                    } catch (JasperException e) {
                                        
---------------Reference log start----------------
log.error(Localizer.getMessage(""jsp.error.compilation.jdtProblemError""), e)
---------------Reference log end----------------
                                    }
                                }
                            }
                        }
                        if (problemList.isEmpty()) {
                            ClassFile[] classFiles = result.getClassFiles();
                            for (ClassFile classFile : classFiles) {
                                char[][] compoundName =
                                        classFile.getCompoundName();
                                StringBuilder classFileName = new StringBuilder(outputDir).append('/');
                                for (int j = 0;
                                     j < compoundName.length; j++) {
                                    if (j > 0) {
                                        classFileName.append('/');
                                    }
                                    classFileName.append(compoundName[j]);
                                }
                                byte[] bytes = classFile.getBytes();
                                classFileName.append("".class"");
                                try (FileOutputStream fout = new FileOutputStream(classFileName.toString());
                                        BufferedOutputStream bos = new BufferedOutputStream(fout)) {
                                    bos.write(bytes);
                                }
                            }
                        }
                    } catch (IOException exc) {
                        log.error(Localizer.getMessage(""jsp.error.compilation.jdt""), exc);
                    }
                }",,
tomcat,16189,"log.error(sm.getString(""contextConfig.inputStreamWebResource"", webResource.getWebappPath()), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/ContextConfig.java/#L2251,"protected void processAnnotationsWebResource(WebResource webResource,
            WebXml fragment, boolean handlesTypesOnly,
            Map<String,JavaClassCacheEntry> javaClassCache) {

        if (webResource.isDirectory()) {
            WebResource[] webResources =
                    webResource.getWebResourceRoot().listResources(
                            webResource.getWebappPath());
            if (webResources.length > 0) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(
                            ""contextConfig.processAnnotationsWebDir.debug"",
                            webResource.getURL()));
                }
                for (WebResource r : webResources) {
                    processAnnotationsWebResource(r, fragment, handlesTypesOnly, javaClassCache);
                }
            }
        } else if (webResource.isFile() &&
                webResource.getName().endsWith("".class"")) {
            try (InputStream is = webResource.getInputStream()) {
                processAnnotationsStream(is, fragment, handlesTypesOnly, javaClassCache);
            } catch (IOException | ClassFormatException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""contextConfig.inputStreamWebResource"", webResource.getWebappPath()), e)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,16078,"log.warn(sm.getString(""namingResources.mbeanDestroyFail"", ce.getName()), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/deploy/NamingResourcesImpl.java/#L1105,"@Override
    protected void destroyInternal() throws LifecycleException {

        // Set this before we de-register currently known naming resources to
        // avoid timing issues. Duplication de-registration is not an issue.
        resourceRequireExplicitRegistration = false;

        // Destroy in reverse order to create, although it should not matter
        for (ContextResourceLink crl : resourceLinks.values()) {
            try {
                MBeanUtils.destroyMBean(crl);
            } catch (Exception e) {
                log.warn(sm.getString(
                        ""namingResources.mbeanDestroyFail"", crl.getName()), e);
            }
        }

        for (ContextEnvironment ce : envs.values()) {
            try {
                MBeanUtils.destroyMBean(ce);
            } catch (Exception e) {
                
---------------Reference log start----------------
log.warn(sm.getString(""namingResources.mbeanDestroyFail"", ce.getName()), e)
---------------Reference log end----------------
            }
        }

        for (ContextResource cr : resources.values()) {
            try {
                MBeanUtils.destroyMBean(cr);
            } catch (Exception e) {
                log.warn(sm.getString(
                        ""namingResources.mbeanDestroyFail"", cr.getName()), e);
            }
        }

        super.destroyInternal();
    }",,
tomcat,16768,"log.error(sm.getString(""standardService.executor.start""), x)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardService.java/#L360,"@Override
    public void addExecutor(Executor ex) {
        synchronized (executors) {
            if (!executors.contains(ex)) {
                executors.add(ex);
                if (getState().isAvailable()) {
                    try {
                        ex.start();
                    } catch (LifecycleException x) {
                        
---------------Reference log start----------------
log.error(sm.getString(""standardService.executor.start""), x)
---------------Reference log end----------------
                    }
                }
            }
        }
    }",,
tomcat,17570,"log.debug(""Compiled "" + ctxt.getServletJavaFileName() + "" "" + (t2 - t1) + ""ms"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/AntCompiler.java/#L274,"@Override
    protected void generateClass(Map<String,SmapStratum> smaps)
        throws FileNotFoundException, JasperException, Exception {

        long t1 = 0;
        if (log.isDebugEnabled()) {
            t1 = System.currentTimeMillis();
        }

        String javaEncoding = ctxt.getOptions().getJavaEncoding();
        String javaFileName = ctxt.getServletJavaFileName();
        String classpath = ctxt.getClassPath();

        StringBuilder errorReport = new StringBuilder();

        StringBuilder info=new StringBuilder();
        info.append(""Compile: javaFileName="" + javaFileName + ""\n"" );
        info.append(""    classpath="" + classpath + ""\n"" );

        // Start capturing the System.err output for this thread
        SystemLogHandler.setThread();

        // Initializing javac task
        getProject();
        Javac javac = (Javac) project.createTask(""javac"");

        // Initializing classpath
        Path path = new Path(project);
        path.setPath(System.getProperty(""java.class.path""));
        info.append(""    cp="" + System.getProperty(""java.class.path"") + ""\n"");
        StringTokenizer tokenizer = new StringTokenizer(classpath, File.pathSeparator);
        while (tokenizer.hasMoreElements()) {
            String pathElement = tokenizer.nextToken();
            File repository = new File(pathElement);
            path.setLocation(repository);
            info.append(""    cp="" + repository + ""\n"");
        }

        if (log.isDebugEnabled()) {
            log.debug( ""Using classpath: "" + System.getProperty(""java.class.path"") +
                    File.pathSeparator + classpath);
        }

        // Initializing sourcepath
        Path srcPath = new Path(project);
        srcPath.setLocation(options.getScratchDir());

        info.append(""    work dir="" + options.getScratchDir() + ""\n"");

        // Initialize and set java extensions
        String exts = System.getProperty(""java.ext.dirs"");
        if (exts != null) {
            Path extdirs = new Path(project);
            extdirs.setPath(exts);
            javac.setExtdirs(extdirs);
            info.append(""    extension dir="" + exts + ""\n"");
        }

        // Add endorsed directories if any are specified and we're forking
        // See Bugzilla 31257
        if(ctxt.getOptions().getFork()) {
            String endorsed = System.getProperty(""java.endorsed.dirs"");
            if(endorsed != null) {
                Javac.ImplementationSpecificArgument endorsedArg =
                    javac.createCompilerArg();
                endorsedArg.setLine(""-J-Djava.endorsed.dirs="" +
                        quotePathList(endorsed));
                info.append(""    endorsed dir="" + quotePathList(endorsed) +
                        ""\n"");
            } else {
                info.append(""    no endorsed dirs specified\n"");
            }
        }

        // Configure the compiler object
        javac.setEncoding(javaEncoding);
        javac.setClasspath(path);
        javac.setDebug(ctxt.getOptions().getClassDebugInfo());
        javac.setSrcdir(srcPath);
        javac.setTempdir(options.getScratchDir());
        javac.setFork(ctxt.getOptions().getFork());
        info.append(""    srcDir="" + srcPath + ""\n"" );

        // Set the Java compiler to use
        if (options.getCompiler() != null) {
            javac.setCompiler(options.getCompiler());
            info.append(""    compiler="" + options.getCompiler() + ""\n"");
        }

        if (options.getCompilerTargetVM() != null) {
            javac.setTarget(options.getCompilerTargetVM());
            info.append(""   compilerTargetVM="" + options.getCompilerTargetVM() + ""\n"");
        }

        if (options.getCompilerSourceVM() != null) {
            javac.setSource(options.getCompilerSourceVM());
            info.append(""   compilerSourceVM="" + options.getCompilerSourceVM() + ""\n"");
        }

        // Build includes path
        PatternSet.NameEntry includes = javac.createInclude();

        includes.setName(ctxt.getJavaPath());
        info.append(""    include=""+ ctxt.getJavaPath() + ""\n"" );

        BuildException be = null;

        try {
            if (ctxt.getOptions().getFork()) {
                javac.execute();
            } else {
                synchronized(javacLock) {
                    javac.execute();
                }
            }
        } catch (BuildException e) {
            be = e;
            log.error(Localizer.getMessage(""jsp.error.javac""), e);
            log.error(Localizer.getMessage(""jsp.error.javac.env"") + info.toString());
        }

        errorReport.append(logger.getReport());

        // Stop capturing the System.err output for this thread
        String errorCapture = SystemLogHandler.unsetThread();
        if (errorCapture != null) {
            errorReport.append(System.lineSeparator());
            errorReport.append(errorCapture);
        }

        if (!ctxt.keepGenerated()) {
            File javaFile = new File(javaFileName);
            if (!javaFile.delete()) {
                throw new JasperException(Localizer.getMessage(
                        ""jsp.warning.compiler.javafile.delete.fail"", javaFile));
            }
        }

        if (be != null) {
            String errorReportString = errorReport.toString();
            log.error(Localizer.getMessage(""jsp.error.compilation"", javaFileName, errorReportString));
            JavacErrorDetail[] javacErrors = ErrorDispatcher.parseJavacErrors(
                    errorReportString, javaFileName, pageNodes);
            if (javacErrors != null) {
                errDispatcher.javacError(javacErrors);
            } else {
                errDispatcher.javacError(errorReportString, be);
            }
        }

        if( log.isDebugEnabled() ) {
            long t2 = System.currentTimeMillis();
            
---------------Reference log start----------------
log.debug(""Compiled "" + ctxt.getServletJavaFileName() + "" "" + (t2 - t1) + ""ms"")
---------------Reference log end----------------
        }

        logger = null;
        project = null;

        if (ctxt.isPrototypeMode()) {
            return;
        }

        // JSR45 Support
        if (!options.isSmapSuppressed()) {
            SmapUtil.installSmap(smaps);
        }
    }",,
tomcat,15888,"log.trace(""Adding event to selector:"" + event)",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/NioReceiver.java/#L159,"public void addEvent(Runnable event) {
        Selector selector = this.selector.get();
        if (selector != null) {
            events.add(event);
            if (log.isTraceEnabled()) {
                
---------------Reference log start----------------
log.trace(""Adding event to selector:"" + event)
---------------Reference log end----------------
            }
            if (isListening()) {
                selector.wakeup();
            }
        }
    }",,
tomcat,16718,"log.warn(sm.getString(""standardServer.accept.timeout"", Long.valueOf(System.currentTimeMillis() - acceptStartTime)), ste)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardServer.java/#L615,"@Override
    public void await() {
        // Negative values - don't wait on port - tomcat is embedded or we just don't like ports
        if (getPortWithOffset() == -2) {
            // undocumented yet - for embedding apps that are around, alive.
            return;
        }
        if (getPortWithOffset() == -1) {
            try {
                awaitThread = Thread.currentThread();
                while(!stopAwait) {
                    try {
                        Thread.sleep( 10000 );
                    } catch( InterruptedException ex ) {
                        // continue and check the flag
                    }
                }
            } finally {
                awaitThread = null;
            }
            return;
        }

        // Set up a server socket to wait on
        try {
            awaitSocket = new ServerSocket(getPortWithOffset(), 1,
                    InetAddress.getByName(address));
        } catch (IOException e) {
            log.error(sm.getString(""standardServer.awaitSocket.fail"", address,
                    String.valueOf(getPortWithOffset()), String.valueOf(getPort()),
                    String.valueOf(getPortOffset())), e);
            return;
        }

        try {
            awaitThread = Thread.currentThread();

            // Loop waiting for a connection and a valid command
            while (!stopAwait) {
                ServerSocket serverSocket = awaitSocket;
                if (serverSocket == null) {
                    break;
                }

                // Wait for the next connection
                Socket socket = null;
                StringBuilder command = new StringBuilder();
                try {
                    InputStream stream;
                    long acceptStartTime = System.currentTimeMillis();
                    try {
                        socket = serverSocket.accept();
                        socket.setSoTimeout(10 * 1000);  // Ten seconds
                        stream = socket.getInputStream();
                    } catch (SocketTimeoutException ste) {
                        // This should never happen but bug 56684 suggests that
                        // it does.
                        
---------------Reference log start----------------
log.warn(sm.getString(""standardServer.accept.timeout"", Long.valueOf(System.currentTimeMillis() - acceptStartTime)), ste)
---------------Reference log end----------------
                        continue;
                    } catch (AccessControlException ace) {
                        log.warn(sm.getString(""standardServer.accept.security""), ace);
                        continue;
                    } catch (IOException e) {
                        if (stopAwait) {
                            // Wait was aborted with socket.close()
                            break;
                        }
                        log.error(sm.getString(""standardServer.accept.error""), e);
                        break;
                    }

                    // Read a set of characters from the socket
                    int expected = 1024; // Cut off to avoid DoS attack
                    while (expected < shutdown.length()) {
                        if (random == null) {
                            random = new Random();
                        }
                        expected += (random.nextInt() % 1024);
                    }
                    while (expected > 0) {
                        int ch = -1;
                        try {
                            ch = stream.read();
                        } catch (IOException e) {
                            log.warn(sm.getString(""standardServer.accept.readError""), e);
                            ch = -1;
                        }
                        // Control character or EOF (-1) terminates loop
                        if (ch < 32 || ch == 127) {
                            break;
                        }
                        command.append((char) ch);
                        expected--;
                    }
                } finally {
                    // Close the socket now that we are done with it
                    try {
                        if (socket != null) {
                            socket.close();
                        }
                    } catch (IOException e) {
                        // Ignore
                    }
                }

                // Match against our command string
                boolean match = command.toString().equals(shutdown);
                if (match) {
                    log.info(sm.getString(""standardServer.shutdownViaPort""));
                    break;
                } else {
                    log.warn(sm.getString(""standardServer.invalidShutdownCommand"", command.toString()));
                }
            }
        } finally {
            ServerSocket serverSocket = awaitSocket;
            awaitThread = null;
            awaitSocket = null;

            // Close the server socket and return
            if (serverSocket != null) {
                try {
                    serverSocket.close();
                } catch (IOException e) {
                    // Ignore
                }
            }
        }
    }",,
tomcat,15188,"log.debug(""Start: Loading persisted sessions"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/StandardManager.java/#L178,"protected void doLoad() throws ClassNotFoundException, IOException {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Start: Loading persisted sessions"")
---------------Reference log end----------------
        }

        // Initialize our internal data structures
        sessions.clear();

        // Open an input stream to the specified pathname, if any
        File file = file();
        if (file == null) {
            return;
        }
        if (log.isDebugEnabled()) {
            log.debug(sm.getString(""standardManager.loading"", pathname));
        }
        Loader loader = null;
        ClassLoader classLoader = null;
        Log logger = null;
        try (FileInputStream fis = new FileInputStream(file.getAbsolutePath());
                BufferedInputStream bis = new BufferedInputStream(fis)) {
            Context c = getContext();
            loader = c.getLoader();
            logger = c.getLogger();
            if (loader != null) {
                classLoader = loader.getClassLoader();
            }
            if (classLoader == null) {
                classLoader = getClass().getClassLoader();
            }

            // Load the previously unloaded active sessions
            synchronized (sessions) {
                try (ObjectInputStream ois = new CustomObjectInputStream(bis, classLoader, logger,
                        getSessionAttributeValueClassNamePattern(),
                        getWarnOnSessionAttributeFilterFailure())) {
                    Integer count = (Integer) ois.readObject();
                    int n = count.intValue();
                    if (log.isDebugEnabled()) {
                        log.debug(""Loading "" + n + "" persisted sessions"");
                    }
                    for (int i = 0; i < n; i++) {
                        StandardSession session = getNewSession();
                        session.readObjectData(ois);
                        session.setManager(this);
                        sessions.put(session.getIdInternal(), session);
                        session.activate();
                        if (!session.isValidInternal()) {
                            // If session is already invalid,
                            // expire session to prevent memory leak.
                            session.setValid(true);
                            session.expire();
                        }
                        sessionCounter++;
                    }
                } finally {
                    // Delete the persistent storage file
                    if (file.exists()) {
                        if (!file.delete()) {
                            log.warn(sm.getString(""standardManager.deletePersistedFileFail"", file));
                        }
                    }
                }
            }
        } catch (FileNotFoundException e) {
            if (log.isDebugEnabled()) {
                log.debug(""No persisted data file found"");
            }
            return;
        }

        if (log.isDebugEnabled()) {
            log.debug(""Finish: Loading persisted sessions"");
        }
    }",,
tomcat,17452,"log.error(""Could not set logger level for logger '"" + loggerName + ""' to '"" + levelName + ""', got '"" + checkValue + ""' instead"")",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/Diagnostics.java/#L185,"public static void setLoggerLevel(String loggerName, String levelName) {
        loggingMXBean.setLoggerLevel(loggerName, levelName);
        String checkValue = loggingMXBean.getLoggerLevel(loggerName);
        if (!checkValue.equals(levelName)) {
            
---------------Reference log start----------------
log.error(""Could not set logger level for logger '"" + loggerName + ""' to '"" + levelName + ""', got '"" + checkValue + ""' instead"")
---------------Reference log end----------------
        }
    }",,
tomcat,15805,"log.trace(""Data published:"" + msg + "" msg Id:"" + id)",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/tipis/LazyReplicatedMap.java/#L191,"@Override
    protected Member[] publishEntryInfo(Object key, Object value) throws ChannelException {
        Log log = getLog();
        if  (! (key instanceof Serializable && value instanceof Serializable)  ) {
            return new Member[0];
        }
        Member[] members = getMapMembers();
        int firstIdx = getNextBackupIndex();
        int nextIdx = firstIdx;
        Member[] backup = new Member[0];

        //there are no backups
        if ( members.length == 0 || firstIdx == -1 ) {
            return backup;
        }

        boolean success = false;
        do {
            //select a backup node
            Member next = members[nextIdx];

            //increment for the next round of back up selection
            nextIdx = nextIdx + 1;
            if ( nextIdx >= members.length ) {
                nextIdx = 0;
            }

            if (next == null) {
                continue;
            }
            MapMessage msg = null;
            try {
                Member[] tmpBackup = wrap(next);
                //publish the backup data to one node
                msg = new MapMessage(getMapContextName(), MapMessage.MSG_BACKUP, false,
                                     (Serializable) key, (Serializable) value, null, channel.getLocalMember(false), tmpBackup);
                if ( log.isTraceEnabled() ) {
                    log.trace(""Publishing backup data:""+msg+"" to: ""+next.getName());
                }
                UniqueId id = getChannel().send(tmpBackup, msg, getChannelSendOptions());
                if ( log.isTraceEnabled() ) {
                    
---------------Reference log start----------------
log.trace(""Data published:"" + msg + "" msg Id:"" + id)
---------------Reference log end----------------
                }
                //we published out to a backup, mark the test success
                success = true;
                backup = tmpBackup;
            }catch ( ChannelException x ) {
                log.error(sm.getString(""lazyReplicatedMap.unableReplicate.backup"", key, next, x.getMessage()), x);
                continue;
            }
            try {
                //publish the data out to all nodes
                Member[] proxies = excludeFromSet(backup, getMapMembers());
                if (success && proxies.length > 0 ) {
                    msg = new MapMessage(getMapContextName(), MapMessage.MSG_PROXY, false,
                                         (Serializable) key, null, null, channel.getLocalMember(false),backup);
                    if ( log.isTraceEnabled() ) {
                        log.trace(""Publishing proxy data:""+msg+"" to: ""+Arrays.toNameString(proxies));
                    }
                    getChannel().send(proxies, msg, getChannelSendOptions());
                }
            }catch  ( ChannelException x ) {
                //log the error, but proceed, this should only happen if a node went down,
                //and if the node went down, then it can't receive the message, the others
                //should still get it.
                log.error(sm.getString(""lazyReplicatedMap.unableReplicate.proxy"", key, next, x.getMessage()), x);
            }
        } while ( !success && (firstIdx!=nextIdx));
        return backup;
    }",,
tomcat,16766,"log.error(sm.getString(""standardService.engine.stopFailed""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardService.java/#L168,"@Override
    public void setContainer(Engine engine) {
        Engine oldEngine = this.engine;
        if (oldEngine != null) {
            oldEngine.setService(null);
        }
        this.engine = engine;
        if (this.engine != null) {
            this.engine.setService(this);
        }
        if (getState().isAvailable()) {
            if (this.engine != null) {
                try {
                    this.engine.start();
                } catch (LifecycleException e) {
                    log.error(sm.getString(""standardService.engine.startFailed""), e);
                }
            }
            // Restart MapperListener to pick up new engine.
            try {
                mapperListener.stop();
            } catch (LifecycleException e) {
                log.error(sm.getString(""standardService.mapperListener.stopFailed""), e);
            }
            try {
                mapperListener.start();
            } catch (LifecycleException e) {
                log.error(sm.getString(""standardService.mapperListener.startFailed""), e);
            }
            if (oldEngine != null) {
                try {
                    oldEngine.stop();
                } catch (LifecycleException e) {
                    
---------------Reference log start----------------
log.error(sm.getString(""standardService.engine.stopFailed""), e)
---------------Reference log end----------------
                }
            }
        }

        // Report this property change to interested listeners
        support.firePropertyChange(""container"", oldEngine, this.engine);
    }",,
tomcat,15548,"log.debug(sm.getString(""jaasRealm.userPrincipalFailure""))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JAASRealm.java/#L577,"protected Principal createPrincipal(String username, Subject subject,
            LoginContext loginContext) {
        // Prepare to scan the Principals for this Subject

        List<String> roles = new ArrayList<>();
        Principal userPrincipal = null;

        // Scan the Principals for this Subject
        for (Principal principal : subject.getPrincipals()) {
            String principalClass = principal.getClass().getName();

            if( log.isDebugEnabled() ) {
                log.debug(sm.getString(""jaasRealm.checkPrincipal"", principal, principalClass));
            }

            if (userPrincipal == null && userClasses.contains(principalClass)) {
                userPrincipal = principal;
                if( log.isDebugEnabled() ) {
                    log.debug(sm.getString(""jaasRealm.userPrincipalSuccess"", principal.getName()));
                }
            }

            if (roleClasses.contains(principalClass)) {
                roles.add(principal.getName());
                if( log.isDebugEnabled() ) {
                    log.debug(sm.getString(""jaasRealm.rolePrincipalAdd"", principal.getName()));
                }
            }
        }

        // Print failure message if needed
        if (userPrincipal == null) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""jaasRealm.userPrincipalFailure""))
---------------Reference log end----------------
                log.debug(sm.getString(""jaasRealm.rolePrincipalFailure""));
            }
            return null;
        } else {
            if (roles.size() == 0) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.rolePrincipalFailure""));
                }
            }
        }

        // Return the resulting Principal for our authenticated user
        return new GenericPrincipal(username, roles, userPrincipal,
                loginContext);
    }",,
tomcat,15172,"manager.getContext().getLogger().error(sm.getString(getStoreName() + "".SQLException"", e))",getContext,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/DataSourceStore.java/#L434,"@Override
    public int getSize() throws IOException {
        int size = 0;
        String sizeSql = ""SELECT COUNT("" + sessionIdCol
                + "") FROM "" + sessionTable + "" WHERE ""
                + sessionAppCol + "" = ?"";

        int numberOfTries = 2;
        while (numberOfTries > 0) {
            Connection _conn = getConnection();

            if (_conn == null) {
                return size;
            }

            try (PreparedStatement preparedSizeSql = _conn.prepareStatement(sizeSql)){
                preparedSizeSql.setString(1, getName());
                try (ResultSet rst = preparedSizeSql.executeQuery()) {
                    if (rst.next()) {
                        size = rst.getInt(1);
                    }
                    // Break out after the finally block
                    numberOfTries = 0;
                }
            } catch (SQLException e) {
                
---------------Reference log start----------------
manager.getContext().getLogger().error(sm.getString(getStoreName() + "".SQLException"", e))
---------------Reference log end----------------
            } finally {
                release(_conn);
            }
            numberOfTries--;
        }
        return size;
    }",,
tomcat,16074,"log.debug(sm.getString(""namingResources.cleanupNoClose"", name, container, closeMethod))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/deploy/NamingResourcesImpl.java/#L1067,"private void cleanUp(Object resource, String name, String closeMethod) {
        // Look for a zero-arg close() method
        Method m = null;
        try {
            m = resource.getClass().getMethod(closeMethod, (Class<?>[]) null);
        } catch (SecurityException e) {
            log.debug(sm.getString(""namingResources.cleanupCloseSecurity"",
                    closeMethod, name, container));
            return;
        } catch (NoSuchMethodException e) {
            
---------------Reference log start----------------
log.debug(sm.getString(""namingResources.cleanupNoClose"", name, container, closeMethod))
---------------Reference log end----------------
            return;
        }
        try {
            m.invoke(resource, (Object[]) null);
        } catch (IllegalArgumentException | IllegalAccessException e) {
            log.warn(sm.getString(""namingResources.cleanupCloseFailed"",
                    closeMethod, name, container), e);
        } catch (InvocationTargetException e) {
            Throwable t = ExceptionUtils.unwrapInvocationTargetException(e);
            ExceptionUtils.handleThrowable(t);
            log.warn(sm.getString(""namingResources.cleanupCloseFailed"",
                    closeMethod, name, container), t);
        }
    }",,
tomcat,15256,"log.error(sm.getString(""persistentManager.swapInInvalid"", id))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/PersistentManagerBase.java/#L731,"protected Session swapIn(String id) throws IOException {

        if (store == null) {
            return null;
        }

        Object swapInLock = null;

        /*
         * The purpose of this sync and these locks is to make sure that a
         * session is only loaded once. It doesn't matter if the lock is removed
         * and then another thread enters this method and tries to load the same
         * session. That thread will re-create a swapIn lock for that session,
         * quickly find that the session is already in sessions, use it and
         * carry on.
         */
        synchronized (this) {
            swapInLock = sessionSwapInLocks.get(id);
            if (swapInLock == null) {
                swapInLock = new Object();
                sessionSwapInLocks.put(id, swapInLock);
            }
        }

        Session session = null;

        synchronized (swapInLock) {
            // First check to see if another thread has loaded the session into
            // the manager
            session = sessions.get(id);

            if (session == null) {
                Session currentSwapInSession = sessionToSwapIn.get();
                try {
                    if (currentSwapInSession == null || !id.equals(currentSwapInSession.getId())) {
                        session = loadSessionFromStore(id);
                        sessionToSwapIn.set(session);

                        if (session != null && !session.isValid()) {
                            
---------------Reference log start----------------
log.error(sm.getString(""persistentManager.swapInInvalid"", id))
---------------Reference log end----------------
                            session.expire();
                            removeSession(id);
                            session = null;
                        }

                        if (session != null) {
                            reactivateLoadedSession(id, session);
                        }
                    }
                } finally {
                    sessionToSwapIn.remove();
                }
            }
        }

        // Make sure the lock is removed
        synchronized (this) {
            sessionSwapInLocks.remove(id);
        }

        return session;

    }",,
tomcat,15158,"log.info(""Writing data."")",info,https://github.com/apache/tomcat/blob/main/webapps/examples/WEB-INF/classes/async/Async2.java/#L50,"@Override
            public void run() {
                try {
                    Thread.currentThread().setName(""Async2-Thread"");
                    log.info(""Putting AsyncThread to sleep"");
                    Thread.sleep(2*1000);
                    
---------------Reference log start----------------
log.info(""Writing data."")
---------------Reference log end----------------
                    Date date = new Date(System.currentTimeMillis());
                    SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss Z"");
                    actx.getResponse().getWriter().write(
                            ""Output from background thread. Time: "" + sdf.format(date) + ""\n"");
                    actx.complete();
                }catch (InterruptedException x) {
                    log.error(""Async2"",x);
                }catch (IllegalStateException x) {
                    log.error(""Async2"",x);
                }catch (IOException x) {
                    log.error(""Async2"",x);
                }
            }",,
tomcat,16975,"log.debug(sm.getString(""http11processor.request.prepare"") + "" Unsupported HTTP version \"""" + protocolMB + ""\"""")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http11/Http11Processor.java/#L584,"private void prepareRequestProtocol() {

        MessageBytes protocolMB = request.protocol();
        if (protocolMB.equals(Constants.HTTP_11)) {
            http09 = false;
            http11 = true;
            protocolMB.setString(Constants.HTTP_11);
        } else if (protocolMB.equals(Constants.HTTP_10)) {
            http09 = false;
            http11 = false;
            keepAlive = false;
            protocolMB.setString(Constants.HTTP_10);
        } else if (protocolMB.equals("""")) {
            // HTTP/0.9
            http09 = true;
            http11 = false;
            keepAlive = false;
        } else {
            // Unsupported protocol
            http09 = false;
            http11 = false;
            // Send 505; Unsupported HTTP version
            response.setStatus(505);
            setErrorState(ErrorState.CLOSE_CLEAN, null);
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""http11processor.request.prepare"") + "" Unsupported HTTP version \"""" + protocolMB + ""\"""")
---------------Reference log end----------------
            }
        }
    }",,
tomcat,15746,"log.error(sm.getString(""jmxRegistry.registerJmx.failed"", bean, oNameStr), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/jmx/JmxRegistry.java/#L127,"public ObjectName registerJmx(String keyprop, Object bean) {
        if (mbserver == null) {
            return null;
        }
        String oNameStr = baseOname.toString() + keyprop;
        ObjectName oName = null;
        try {
            oName = new ObjectName(oNameStr);
            if (mbserver.isRegistered(oName)) {
                mbserver.unregisterMBean(oName);
            }
            mbserver.registerMBean(bean, oName);
        } catch (NotCompliantMBeanException e) {
            log.warn(sm.getString(""jmxRegistry.registerJmx.notCompliant"", bean), e);
            return null;
        } catch (MalformedObjectNameException e) {
            log.error(sm.getString(""jmxRegistry.objectName.failed"", oNameStr), e);
            return null;
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(sm.getString(""jmxRegistry.registerJmx.failed"", bean, oNameStr), e)
---------------Reference log end----------------
            return null;
        }
        return oName;
    }",,
tomcat,15801,"log.trace(""Requesting id:"" + key + "" result:"" + entry.getValue())",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/tipis/AbstractReplicatedMap.java/#L1127,"@SuppressWarnings(""unchecked"")
    @Override
    public V get(Object key) {
        MapEntry<K,V> entry = innerMap.get(key);
        if (log.isTraceEnabled()) {
            log.trace(""Requesting id:""+key+"" entry:""+entry);
        }
        if ( entry == null ) {
            return null;
        }
        if ( !entry.isPrimary() ) {
            //if the message is not primary, we need to retrieve the latest value
            try {
                Member[] backup = null;
                MapMessage msg = null;
                if (entry.isBackup()) {
                    //select a new backup node
                    backup = publishEntryInfo(key, entry.getValue());
                } else if ( entry.isProxy() ) {
                    //make sure we don't retrieve from ourselves
                    msg = new MapMessage(getMapContextName(), MapMessage.MSG_RETRIEVE_BACKUP, false,
                                         (Serializable) key, null, null, null,null);
                    Response[] resp = getRpcChannel().send(entry.getBackupNodes(),msg, RpcChannel.FIRST_REPLY, getChannelSendOptions(), getRpcTimeout());
                    if (resp == null || resp.length == 0 || resp[0].getMessage() == null) {
                        //no responses
                        log.warn(sm.getString(""abstractReplicatedMap.unable.retrieve"", key));
                        return null;
                    }
                    msg = (MapMessage) resp[0].getMessage();
                    msg.deserialize(getExternalLoaders());
                    backup = entry.getBackupNodes();
                    if ( msg.getValue()!=null ) {
                        entry.setValue((V) msg.getValue());
                    }

                    // notify member
                    msg = new MapMessage(getMapContextName(), MapMessage.MSG_NOTIFY_MAPMEMBER,false,
                            (Serializable)entry.getKey(), null, null, channel.getLocalMember(false), backup);
                    if ( backup != null && backup.length > 0) {
                        getChannel().send(backup, msg, getChannelSendOptions());
                    }

                    //invalidate the previous primary
                    msg = new MapMessage(getMapContextName(),MapMessage.MSG_PROXY,false,(Serializable)key,null,null,channel.getLocalMember(false),backup);
                    Member[] dest = getMapMembersExcl(backup);
                    if ( dest!=null && dest.length >0) {
                        getChannel().send(dest, msg, getChannelSendOptions());
                    }
                    if (entry.getValue() instanceof ReplicatedMapEntry) {
                        ReplicatedMapEntry val = (ReplicatedMapEntry)entry.getValue();
                        val.setOwner(getMapOwner());
                    }
                } else if ( entry.isCopy() ) {
                    backup = getMapMembers();
                    if (backup.length > 0) {
                        msg = new MapMessage(getMapContextName(), MapMessage.MSG_NOTIFY_MAPMEMBER,false,
                                (Serializable)key,null,null,channel.getLocalMember(false),backup);
                        getChannel().send(backup, msg, getChannelSendOptions());
                    }
                }
                entry.setPrimary(channel.getLocalMember(false));
                entry.setBackupNodes(backup);
                entry.setBackup(false);
                entry.setProxy(false);
                entry.setCopy(false);
                if ( getMapOwner()!=null ) {
                    getMapOwner().objectMadePrimary(key, entry.getValue());
                }

            } catch (RuntimeException | ChannelException | ClassNotFoundException | IOException x) {
                log.error(sm.getString(""abstractReplicatedMap.unable.get""), x);
                return null;
            }
        }
        if (log.isTraceEnabled()) {
            
---------------Reference log start----------------
log.trace(""Requesting id:"" + key + "" result:"" + entry.getValue())
---------------Reference log end----------------
        }
        return entry.getValue();
    }",,
tomcat,17660,"log.debug(""Connection ["" + con + ""] will be closed and not returned to the pool."")",debug,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L1030,"protected void returnConnection(PooledConnection con) {
        if (isClosed()) {
            //if the connection pool is closed
            //close the connection instead of returning it
            release(con);
            return;
        } //end if

        if (con != null) {
            try {
                returnedCount.incrementAndGet();
                con.lock();
                if (con.isSuspect()) {
                    if (poolProperties.isLogAbandoned() && log.isInfoEnabled()) {
                        log.info(""Connection("" + con + "") that has been marked suspect was returned.""
                                + "" The processing time is "" + (System.currentTimeMillis()-con.getTimestamp()) + "" ms."");
                    }
                    if (jmxPool!=null) {
                        jmxPool.notify(org.apache.tomcat.jdbc.pool.jmx.ConnectionPool.SUSPECT_RETURNED_NOTIFICATION,
                                ""Connection("" + con + "") that has been marked suspect was returned."");
                    }
                }
                if (busy.remove(con)) {

                    if (!shouldClose(con,PooledConnection.VALIDATE_RETURN) && reconnectIfExpired(con)) {
                        con.clearWarnings();
                        con.setStackTrace(null);
                        con.setTimestamp(System.currentTimeMillis());
                        if (((idle.size()>=poolProperties.getMaxIdle()) && !poolProperties.isPoolSweeperEnabled()) || (!idle.offer(con))) {
                            if (log.isDebugEnabled()) {
                                log.debug(""Connection [""+con+""] will be closed and not returned to the pool, idle[""+idle.size()+""]>=maxIdle[""+poolProperties.getMaxIdle()+""] idle.offer failed."");
                            }
                            release(con);
                        }
                    } else {
                        if (log.isDebugEnabled()) {
                            
---------------Reference log start----------------
log.debug(""Connection ["" + con + ""] will be closed and not returned to the pool."")
---------------Reference log end----------------
                        }
                        release(con);
                    } //end if
                } else {
                    if (log.isDebugEnabled()) {
                        log.debug(""Connection [""+con+""] will be closed and not returned to the pool, busy.remove failed."");
                    }
                    release(con);
                }
            } finally {
                con.unlock();
            }
        } //end if
    }",,
tomcat,16725,"log.error(sm.getString(""standardServer.storeConfig.notAvailable"", sname))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardServer.java/#L860,"public synchronized void storeConfig() throws InstanceNotFoundException, MBeanException {
        try {
            // Note: Hard-coded domain used since this object is per Server/JVM
            ObjectName sname = new ObjectName(""Catalina:type=StoreConfig"");
            MBeanServer server = Registry.getRegistry(null, null).getMBeanServer();
            if (server.isRegistered(sname)) {
                server.invoke(sname, ""storeConfig"", null, null);
            } else {
                
---------------Reference log start----------------
log.error(sm.getString(""standardServer.storeConfig.notAvailable"", sname))
---------------Reference log end----------------
            }
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            log.error(sm.getString(""standardServer.storeConfig.error""), t);
        }
    }",,
tomcat,15489,"log.debug(""Skip RemoteIpFilter for request "" + request.getRequestURI() + "" with originalRemoteAddr '"" + request.getRemoteAddr() + ""'"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/filters/RemoteIpFilter.java/#L935,"public void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException {

        boolean isInternal = internalProxies != null &&
                internalProxies.matcher(request.getRemoteAddr()).matches();

        if (isInternal || (trustedProxies != null &&
                trustedProxies.matcher(request.getRemoteAddr()).matches())) {
            String remoteIp = null;
            // In java 6, proxiesHeaderValue should be declared as a java.util.Deque
            LinkedList<String> proxiesHeaderValue = new LinkedList<>();
            StringBuilder concatRemoteIpHeaderValue = new StringBuilder();

            for (Enumeration<String> e = request.getHeaders(remoteIpHeader); e.hasMoreElements();) {
                if (concatRemoteIpHeaderValue.length() > 0) {
                    concatRemoteIpHeaderValue.append("", "");
                }

                concatRemoteIpHeaderValue.append(e.nextElement());
            }

            String[] remoteIpHeaderValue = commaDelimitedListToStringArray(concatRemoteIpHeaderValue.toString());
            int idx;
            if (!isInternal) {
                proxiesHeaderValue.addFirst(request.getRemoteAddr());
            }
            // loop on remoteIpHeaderValue to find the first trusted remote ip and to build the proxies chain
            for (idx = remoteIpHeaderValue.length - 1; idx >= 0; idx--) {
                String currentRemoteIp = remoteIpHeaderValue[idx];
                remoteIp = currentRemoteIp;
                if (internalProxies !=null && internalProxies.matcher(currentRemoteIp).matches()) {
                    // do nothing, internalProxies IPs are not appended to the
                } else if (trustedProxies != null &&
                        trustedProxies.matcher(currentRemoteIp).matches()) {
                    proxiesHeaderValue.addFirst(currentRemoteIp);
                } else {
                    idx--; // decrement idx because break statement doesn't do it
                    break;
                }
            }
            // continue to loop on remoteIpHeaderValue to build the new value of the remoteIpHeader
            LinkedList<String> newRemoteIpHeaderValue = new LinkedList<>();
            for (; idx >= 0; idx--) {
                String currentRemoteIp = remoteIpHeaderValue[idx];
                newRemoteIpHeaderValue.addFirst(currentRemoteIp);
            }

            XForwardedRequest xRequest = new XForwardedRequest(request);
            if (remoteIp != null) {

                xRequest.setRemoteAddr(remoteIp);
                if (getEnableLookups()) {
                    // This isn't a lazy lookup but that would be a little more
                    // invasive - mainly in XForwardedRequest - and if
                    // enableLookups is true is seems reasonable that the
                    // hostname will be required so look it up here.
                    try {
                        InetAddress inetAddress = InetAddress.getByName(remoteIp);
                        // We know we need a DNS look up so use getCanonicalHostName()
                        xRequest.setRemoteHost(inetAddress.getCanonicalHostName());
                    } catch (UnknownHostException e) {
                        log.debug(sm.getString(""remoteIpFilter.invalidRemoteAddress"", remoteIp), e);
                        xRequest.setRemoteHost(remoteIp);
                    }
                } else {
                    xRequest.setRemoteHost(remoteIp);
                }

                if (proxiesHeaderValue.size() == 0) {
                    xRequest.removeHeader(proxiesHeader);
                } else {
                    String commaDelimitedListOfProxies = listToCommaDelimitedString(proxiesHeaderValue);
                    xRequest.setHeader(proxiesHeader, commaDelimitedListOfProxies);
                }
                if (newRemoteIpHeaderValue.size() == 0) {
                    xRequest.removeHeader(remoteIpHeader);
                } else {
                    String commaDelimitedRemoteIpHeaderValue = listToCommaDelimitedString(newRemoteIpHeaderValue);
                    xRequest.setHeader(remoteIpHeader, commaDelimitedRemoteIpHeaderValue);
                }
            }

            if (protocolHeader != null) {
                String protocolHeaderValue = request.getHeader(protocolHeader);
                if (protocolHeaderValue == null) {
                    // Don't modify the secure, scheme and serverPort attributes
                    // of the request
                } else if (isForwardedProtoHeaderValueSecure(protocolHeaderValue)) {
                    xRequest.setSecure(true);
                    xRequest.setScheme(""https"");
                    setPorts(xRequest, httpsServerPort);
                } else {
                    xRequest.setSecure(false);
                    xRequest.setScheme(""http"");
                    setPorts(xRequest, httpServerPort);
                }
            }

            if (hostHeader != null) {
                String hostHeaderValue = request.getHeader(hostHeader);
                if (hostHeaderValue != null) {
                    try {
                        int portIndex = Host.parse(hostHeaderValue);
                        if (portIndex > -1) {
                            log.debug(sm.getString(""remoteIpFilter.invalidHostWithPort"", hostHeaderValue, hostHeader));
                            hostHeaderValue = hostHeaderValue.substring(0, portIndex);
                        }

                        xRequest.setServerName(hostHeaderValue);
                        if (isChangeLocalName()) {
                            xRequest.setLocalName(hostHeaderValue);
                        }

                    } catch (IllegalArgumentException iae) {
                        log.debug(sm.getString(""remoteIpFilter.invalidHostHeader"", hostHeaderValue, hostHeader));
                    }
                }
            }
            request.setAttribute(Globals.REQUEST_FORWARDED_ATTRIBUTE, Boolean.TRUE);

            if (log.isDebugEnabled()) {
                log.debug(""Incoming request "" + request.getRequestURI() + "" with originalRemoteAddr ["" + request.getRemoteAddr() +
                        ""], originalRemoteHost=["" + request.getRemoteHost() + ""], originalSecure=["" + request.isSecure() +
                        ""], originalScheme=["" + request.getScheme() + ""], originalServerName=["" + request.getServerName() +
                        ""], originalServerPort=["" + request.getServerPort() +
                        ""] will be seen as newRemoteAddr=["" + xRequest.getRemoteAddr() +
                        ""], newRemoteHost=["" + xRequest.getRemoteHost() + ""], newSecure=["" + xRequest.isSecure() +
                        ""], newScheme=["" + xRequest.getScheme() + ""], newServerName=["" + xRequest.getServerName() +
                        ""], newServerPort=["" + xRequest.getServerPort() + ""]"");
            }
            if (requestAttributesEnabled) {
                request.setAttribute(AccessLog.REMOTE_ADDR_ATTRIBUTE,
                        xRequest.getRemoteAddr());
                request.setAttribute(Globals.REMOTE_ADDR_ATTRIBUTE,
                        xRequest.getRemoteAddr());
                request.setAttribute(AccessLog.REMOTE_HOST_ATTRIBUTE,
                        xRequest.getRemoteHost());
                request.setAttribute(AccessLog.PROTOCOL_ATTRIBUTE,
                        xRequest.getProtocol());
                request.setAttribute(AccessLog.SERVER_NAME_ATTRIBUTE,
                        xRequest.getServerName());
                request.setAttribute(AccessLog.SERVER_PORT_ATTRIBUTE,
                        Integer.valueOf(xRequest.getServerPort()));
            }
            chain.doFilter(xRequest, response);
        } else {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Skip RemoteIpFilter for request "" + request.getRequestURI() + "" with originalRemoteAddr '"" + request.getRemoteAddr() + ""'"")
---------------Reference log end----------------
            }
            chain.doFilter(request, response);
        }

    }",,
tomcat,16959,"log.debug(sm.getString(""upgradeProcessor.stop""))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http11/upgrade/UpgradeProcessorExternal.java/#L98,"@Override
    public final SocketState dispatch(SocketEvent status) {
        if (status == SocketEvent.OPEN_READ) {
            upgradeServletInputStream.onDataAvailable();
        } else if (status == SocketEvent.OPEN_WRITE) {
            upgradeServletOutputStream.onWritePossible();
        } else if (status == SocketEvent.STOP) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""upgradeProcessor.stop""))
---------------Reference log end----------------
            }
            try {
                upgradeServletInputStream.close();
            } catch (IOException ioe) {
                log.debug(sm.getString(""upgradeProcessor.isCloseFail"", ioe));
            }
            try {
                upgradeServletOutputStream.close();
            } catch (IOException ioe) {
                log.debug(sm.getString(""upgradeProcessor.osCloseFail"", ioe));
            }
            return SocketState.CLOSED;
        } else {
            // Unexpected state
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""upgradeProcessor.unexpectedState""));
            }
            return SocketState.CLOSED;
        }
        if (upgradeServletInputStream.isClosed() &&
                upgradeServletOutputStream.isClosed()) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""upgradeProcessor.requiredClose"",
                        Boolean.valueOf(upgradeServletInputStream.isClosed()),
                        Boolean.valueOf(upgradeServletOutputStream.isClosed())));
            }
            return SocketState.CLOSED;
        }
        return SocketState.UPGRADED;
    }",,
tomcat,16870,"log.debug(sm.getString(""windowAllocationManager.waitForNonBlocking.stream"", stream.getConnectionId(), stream.getIdAsString()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/WindowAllocationManager.java/#L90,"void waitForStreamNonBlocking() {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(sm.getString(""windowAllocationManager.waitForNonBlocking.stream"", stream.getConnectionId(), stream.getIdAsString()))
---------------Reference log end----------------
        }

        waitForNonBlocking(STREAM);
    }",,
tomcat,17200,"log.debug(sm.getString(""opensslCipherConfigurationParser.effectiveCiphers"", displayResult(ciphers, true, "","")))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/openssl/ciphers/OpenSSLCipherConfigurationParser.java/#L768,"public static List<String> convertForJSSE(Collection<Cipher> ciphers) {
        List<String> result = new ArrayList<>(ciphers.size());
        for (Cipher cipher : ciphers) {
            result.addAll(cipher.getJsseNames());
        }
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(sm.getString(""opensslCipherConfigurationParser.effectiveCiphers"", displayResult(ciphers, true, "","")))
---------------Reference log end----------------
        }
        return result;
    }",,
tomcat,15436,"log.debug(""  Loading class from parent"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/loader/WebappClassLoaderBase.java/#L1431,"@Override
    public Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {

        synchronized (JreCompat.isGraalAvailable() ? this : getClassLoadingLock(name)) {
            if (log.isDebugEnabled()) {
                log.debug(""loadClass("" + name + "", "" + resolve + "")"");
            }
            Class<?> clazz = null;

            // Log access to stopped class loader
            checkStateForClassLoading(name);

            // (0) Check our previously loaded local class cache
            clazz = findLoadedClass0(name);
            if (clazz != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""  Returning class from cache"");
                }
                if (resolve) {
                    resolveClass(clazz);
                }
                return clazz;
            }

            // (0.1) Check our previously loaded class cache
            clazz = JreCompat.isGraalAvailable() ? null : findLoadedClass(name);
            if (clazz != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""  Returning class from cache"");
                }
                if (resolve) {
                    resolveClass(clazz);
                }
                return clazz;
            }

            // (0.2) Try loading the class with the system class loader, to prevent
            //       the webapp from overriding Java SE classes. This implements
            //       SRV.10.7.2
            String resourceName = binaryNameToPath(name, false);

            ClassLoader javaseLoader = getJavaseClassLoader();
            boolean tryLoadingFromJavaseLoader;
            try {
                // Use getResource as it won't trigger an expensive
                // ClassNotFoundException if the resource is not available from
                // the Java SE class loader. However (see
                // https://bz.apache.org/bugzilla/show_bug.cgi?id=58125 for
                // details) when running under a security manager in rare cases
                // this call may trigger a ClassCircularityError.
                // See https://bz.apache.org/bugzilla/show_bug.cgi?id=61424 for
                // details of how this may trigger a StackOverflowError
                // Given these reported errors, catch Throwable to ensure any
                // other edge cases are also caught
                URL url;
                if (securityManager != null) {
                    PrivilegedAction<URL> dp = new PrivilegedJavaseGetResource(resourceName);
                    url = AccessController.doPrivileged(dp);
                } else {
                    url = javaseLoader.getResource(resourceName);
                }
                tryLoadingFromJavaseLoader = (url != null);
            } catch (Throwable t) {
                // Swallow all exceptions apart from those that must be re-thrown
                ExceptionUtils.handleThrowable(t);
                // The getResource() trick won't work for this class. We have to
                // try loading it directly and accept that we might get a
                // ClassNotFoundException.
                tryLoadingFromJavaseLoader = true;
            }

            if (tryLoadingFromJavaseLoader) {
                try {
                    clazz = javaseLoader.loadClass(name);
                    if (clazz != null) {
                        if (resolve) {
                            resolveClass(clazz);
                        }
                        return clazz;
                    }
                } catch (ClassNotFoundException e) {
                    // Ignore
                }
            }

            // (0.5) Permission to access this class when using a SecurityManager
            if (securityManager != null) {
                int i = name.lastIndexOf('.');
                if (i >= 0) {
                    try {
                        securityManager.checkPackageAccess(name.substring(0,i));
                    } catch (SecurityException se) {
                        String error = sm.getString(""webappClassLoader.restrictedPackage"", name);
                        log.info(error, se);
                        throw new ClassNotFoundException(error, se);
                    }
                }
            }

            boolean delegateLoad = delegate || filter(name, true);

            // (1) Delegate to our parent if requested
            if (delegateLoad) {
                if (log.isDebugEnabled()) {
                    log.debug(""  Delegating to parent classloader1 "" + parent);
                }
                try {
                    clazz = Class.forName(name, false, parent);
                    if (clazz != null) {
                        if (log.isDebugEnabled()) {
                            log.debug(""  Loading class from parent"");
                        }
                        if (resolve) {
                            resolveClass(clazz);
                        }
                        return clazz;
                    }
                } catch (ClassNotFoundException e) {
                    // Ignore
                }
            }

            // (2) Search local repositories
            if (log.isDebugEnabled()) {
                log.debug(""  Searching local repositories"");
            }
            try {
                clazz = findClass(name);
                if (clazz != null) {
                    if (log.isDebugEnabled()) {
                        log.debug(""  Loading class from local repository"");
                    }
                    if (resolve) {
                        resolveClass(clazz);
                    }
                    return clazz;
                }
            } catch (ClassNotFoundException e) {
                // Ignore
            }

            // (3) Delegate to parent unconditionally
            if (!delegateLoad) {
                if (log.isDebugEnabled()) {
                    log.debug(""  Delegating to parent classloader at end: "" + parent);
                }
                try {
                    clazz = Class.forName(name, false, parent);
                    if (clazz != null) {
                        if (log.isDebugEnabled()) {
                            
---------------Reference log start----------------
log.debug(""  Loading class from parent"")
---------------Reference log end----------------
                        }
                        if (resolve) {
                            resolveClass(clazz);
                        }
                        return clazz;
                    }
                } catch (ClassNotFoundException e) {
                    // Ignore
                }
            }
        }

        throw new ClassNotFoundException(name);
    }",,
tomcat,16254,"log.debug(""Creating new class loader"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/ClassLoaderFactory.java/#L158,"public static ClassLoader createClassLoader(List<Repository> repositories,
                                                final ClassLoader parent)
        throws Exception {

        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Creating new class loader"")
---------------Reference log end----------------
        }

        // Construct the ""class path"" for this class loader
        Set<URL> set = new LinkedHashSet<>();

        if (repositories != null) {
            for (Repository repository : repositories)  {
                if (repository.getType() == RepositoryType.URL) {
                    URL url = buildClassLoaderUrl(repository.getLocation());
                    if (log.isDebugEnabled()) {
                        log.debug(""  Including URL "" + url);
                    }
                    set.add(url);
                } else if (repository.getType() == RepositoryType.DIR) {
                    File directory = new File(repository.getLocation());
                    directory = directory.getCanonicalFile();
                    if (!validateFile(directory, RepositoryType.DIR)) {
                        continue;
                    }
                    URL url = buildClassLoaderUrl(directory);
                    if (log.isDebugEnabled()) {
                        log.debug(""  Including directory "" + url);
                    }
                    set.add(url);
                } else if (repository.getType() == RepositoryType.JAR) {
                    File file=new File(repository.getLocation());
                    file = file.getCanonicalFile();
                    if (!validateFile(file, RepositoryType.JAR)) {
                        continue;
                    }
                    URL url = buildClassLoaderUrl(file);
                    if (log.isDebugEnabled()) {
                        log.debug(""  Including jar file "" + url);
                    }
                    set.add(url);
                } else if (repository.getType() == RepositoryType.GLOB) {
                    File directory=new File(repository.getLocation());
                    directory = directory.getCanonicalFile();
                    if (!validateFile(directory, RepositoryType.GLOB)) {
                        continue;
                    }
                    if (log.isDebugEnabled()) {
                        log.debug(""  Including directory glob ""
                            + directory.getAbsolutePath());
                    }
                    String filenames[] = directory.list();
                    if (filenames == null) {
                        continue;
                    }
                    for (String s : filenames) {
                        String filename = s.toLowerCase(Locale.ENGLISH);
                        if (!filename.endsWith("".jar"")) {
                            continue;
                        }
                        File file = new File(directory, s);
                        file = file.getCanonicalFile();
                        if (!validateFile(file, RepositoryType.JAR)) {
                            continue;
                        }
                        if (log.isDebugEnabled()) {
                            log.debug(""    Including glob jar file ""
                                    + file.getAbsolutePath());
                        }
                        URL url = buildClassLoaderUrl(file);
                        set.add(url);
                    }
                }
            }
        }

        // Construct the class loader itself
        final URL[] array = set.toArray(new URL[0]);
        if (log.isDebugEnabled()) {
            for (int i = 0; i < array.length; i++) {
                log.debug(""  location "" + i + "" is "" + array[i]);
            }
        }

        return AccessController.doPrivileged(
                (PrivilegedAction<URLClassLoader>) () -> {
                    if (parent == null) {
                        return new URLClassLoader(array);
                    } else {
                        return new URLClassLoader(array, parent);
                    }
                });
    }",,
tomcat,16747,"container.getLogger().error(sm.getString(""standardHostValue.customStatusFailed"", errorPage.getLocation()))",getLogger,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardHostValve.java/#L368,"private boolean custom(Request request, Response response,
                             ErrorPage errorPage) {

        if (container.getLogger().isDebugEnabled()) {
            container.getLogger().debug(""Processing "" + errorPage);
        }

        try {
            // Forward control to the specified location
            ServletContext servletContext =
                request.getContext().getServletContext();
            RequestDispatcher rd =
                servletContext.getRequestDispatcher(errorPage.getLocation());

            if (rd == null) {
                
---------------Reference log start----------------
container.getLogger().error(sm.getString(""standardHostValue.customStatusFailed"", errorPage.getLocation()))
---------------Reference log end----------------
                return false;
            }

            if (response.isCommitted()) {
                // Response is committed - including the error page is the
                // best we can do
                rd.include(request.getRequest(), response.getResponse());
            } else {
                // Reset the response (keeping the real error code and message)
                response.resetBuffer(true);
                response.setContentLength(-1);

                rd.forward(request.getRequest(), response.getResponse());

                // If we forward, the response is suspended again
                response.setSuspended(false);
            }

            // Indicate that we have successfully processed this custom page
            return true;

        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            // Report our failure to process this custom page
            container.getLogger().error(""Exception Processing "" + errorPage, t);
            return false;
        }
    }",,
tomcat,16893,"log.debug(sm.getString(""hpackdecoder.emitHeader"", name, value))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/HpackDecoder.java/#L443,"private void emitHeader(String name, String value) throws HpackException {
        // Header names are forced to lower case
        if (""cookie"".equals(name)) {
            // Only count the cookie header once since HTTP/2 splits it into
            // multiple headers to aid compression
            if (!countedCookie) {
                headerCount ++;
                countedCookie = true;
            }
        } else {
            headerCount ++;
        }
        // Overhead will vary. The main concern is that lots of small headers
        // trigger the limiting mechanism correctly. Therefore, use an overhead
        // estimate of 3 which is the worst case for small headers.
        int inc = 3 + name.length() + value.length();
        headerSize += inc;
        if (!isHeaderCountExceeded() && !isHeaderSizeExceeded(0)) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""hpackdecoder.emitHeader"", name, value))
---------------Reference log end----------------
            }
            headerEmitter.emitHeader(name, value);
        }
    }",,
tomcat,16123,"engine.getLogger().debug(sm.getString(""engineConfig.stop""))",getLogger,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/EngineConfig.java/#L107,"protected void stop() {

        if (engine.getLogger().isDebugEnabled()) {
            
---------------Reference log start----------------
engine.getLogger().debug(sm.getString(""engineConfig.stop""))
---------------Reference log end----------------
        }

    }",,
tomcat,15857,"log.error(sm.getString(""nonBlockingCoordinator.processCoordinationMessage.failed""), x)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/group/interceptors/NonBlockingCoordinator.java/#L540,"@Override
    public void messageReceived(ChannelMessage msg) {
        if ( Arrays.contains(msg.getMessage().getBytesDirect(),0,COORD_ALIVE,0,COORD_ALIVE.length) ) {
            //ignore message, its an alive message
            fireInterceptorEvent(new CoordinationEvent(CoordinationEvent.EVT_MSG_ARRIVE,this,""Alive Message""));

        } else if ( Arrays.contains(msg.getMessage().getBytesDirect(),0,COORD_HEADER,0,COORD_HEADER.length) ) {
            try {
                CoordinationMessage cmsg = new CoordinationMessage(msg.getMessage());
                Member[] cmbr = cmsg.getMembers();
                fireInterceptorEvent(new CoordinationEvent(CoordinationEvent.EVT_MSG_ARRIVE,this,""Coord Msg Arrived(""+Arrays.toNameString(cmbr)+"")""));
                processCoordMessage(cmsg);
            }catch ( ChannelException x ) {
                
---------------Reference log start----------------
log.error(sm.getString(""nonBlockingCoordinator.processCoordinationMessage.failed""), x)
---------------Reference log end----------------
            }
        } else {
            super.messageReceived(msg);
        }
    }",,
tomcat,15278,"log.warn(sm.getString(""request.fragmentInDispatchPath"", path))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/connector/Request.java/#L1379,"@Override
    public RequestDispatcher getRequestDispatcher(String path) {

        Context context = getContext();
        if (context == null) {
            return null;
        }

        if (path == null) {
            return null;
        }

        int fragmentPos = path.indexOf('#');
        if (fragmentPos > -1) {
            
---------------Reference log start----------------
log.warn(sm.getString(""request.fragmentInDispatchPath"", path))
---------------Reference log end----------------
            path = path.substring(0, fragmentPos);
        }

        // If the path is already context-relative, just pass it through
        if (path.startsWith(""/"")) {
            return context.getServletContext().getRequestDispatcher(path);
        }

        /*
         * Relative to what, exactly?
         *
         * From the Servlet 4.0 Javadoc:
         * - The pathname specified may be relative, although it cannot extend
         *   outside the current servlet context.
         * - If it is relative, it must be relative against the current servlet
         *
         * From Section 9.1 of the spec:
         * - The servlet container uses information in the request object to
         *   transform the given relative path against the current servlet to a
         *   complete path.
         *
         * It is undefined whether the requestURI is used or whether servletPath
         * and pathInfo are used. Given that the RequestURI includes the
         * contextPath (and extracting that is messy) , using the servletPath and
         * pathInfo looks to be the more reasonable choice.
         */

        // Convert a request-relative path to a context-relative one
        String servletPath = (String) getAttribute(
                RequestDispatcher.INCLUDE_SERVLET_PATH);
        if (servletPath == null) {
            servletPath = getServletPath();
        }

        // Add the path info, if there is any
        String pathInfo = getPathInfo();
        String requestPath = null;

        if (pathInfo == null) {
            requestPath = servletPath;
        } else {
            requestPath = servletPath + pathInfo;
        }

        int pos = requestPath.lastIndexOf('/');
        String relative = null;
        if (context.getDispatchersUseEncodedPaths()) {
            if (pos >= 0) {
                relative = URLEncoder.DEFAULT.encode(
                        requestPath.substring(0, pos + 1), StandardCharsets.UTF_8) + path;
            } else {
                relative = URLEncoder.DEFAULT.encode(requestPath, StandardCharsets.UTF_8) + path;
            }
        } else {
            if (pos >= 0) {
                relative = requestPath.substring(0, pos + 1) + path;
            } else {
                relative = requestPath + path;
            }
        }

        return context.getServletContext().getRequestDispatcher(relative);
    }",,
tomcat,16476,"log.trace(""Request Attribute: "" + attr + "": [ "" + req.getAttribute(attr) + ""]"")",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L463,"private void printServletEnvironment(HttpServletRequest req) throws IOException {

        // Document the properties from ServletRequest
        log.trace(""ServletRequest Properties"");
        Enumeration<String> attrs = req.getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            
---------------Reference log start----------------
log.trace(""Request Attribute: "" + attr + "": [ "" + req.getAttribute(attr) + ""]"")
---------------Reference log end----------------
        }
        log.trace(""Character Encoding: ["" + req.getCharacterEncoding() + ""]"");
        log.trace(""Content Length: ["" + req.getContentLengthLong() + ""]"");
        log.trace(""Content Type: ["" + req.getContentType() + ""]"");
        Enumeration<Locale> locales = req.getLocales();
        while (locales.hasMoreElements()) {
            Locale locale = locales.nextElement();
            log.trace(""Locale: ["" +locale + ""]"");
        }
        Enumeration<String> params = req.getParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            for (String value : req.getParameterValues(param)) {
                log.trace(""Request Parameter: "" + param + "":  ["" + value + ""]"");
            }
        }
        log.trace(""Protocol: ["" + req.getProtocol() + ""]"");
        log.trace(""Remote Address: ["" + req.getRemoteAddr() + ""]"");
        log.trace(""Remote Host: ["" + req.getRemoteHost() + ""]"");
        log.trace(""Scheme: ["" + req.getScheme() + ""]"");
        log.trace(""Secure: ["" + req.isSecure() + ""]"");
        log.trace(""Server Name: ["" + req.getServerName() + ""]"");
        log.trace(""Server Port: ["" + req.getServerPort() + ""]"");

        // Document the properties from HttpServletRequest
        log.trace(""HttpServletRequest Properties"");
        log.trace(""Auth Type: ["" + req.getAuthType() + ""]"");
        log.trace(""Context Path: ["" + req.getContextPath() + ""]"");
        Cookie cookies[] = req.getCookies();
        if (cookies != null) {
            for (Cookie cookie : cookies) {
                log.trace(""Cookie: "" + cookie.getName() + "": ["" + cookie.getValue() + ""]"");
            }
        }
        Enumeration<String> headers = req.getHeaderNames();
        while (headers.hasMoreElements()) {
            String header = headers.nextElement();
            log.trace(""HTTP Header: "" + header + "": ["" + req.getHeader(header) + ""]"");
        }
        log.trace(""Method: ["" + req.getMethod() + ""]"");
        log.trace(""Path Info: ["" + req.getPathInfo() + ""]"");
        log.trace(""Path Translated: ["" + req.getPathTranslated() + ""]"");
        log.trace(""Query String: ["" + req.getQueryString() + ""]"");
        log.trace(""Remote User: ["" + req.getRemoteUser() + ""]"");
        log.trace(""Requested Session ID: ["" + req.getRequestedSessionId() + ""]"");
        log.trace(""Requested Session ID From Cookie: ["" +
                req.isRequestedSessionIdFromCookie() + ""]"");
        log.trace(""Requested Session ID From URL: ["" + req.isRequestedSessionIdFromURL() + ""]"");
        log.trace(""Requested Session ID Valid: ["" + req.isRequestedSessionIdValid() + ""]"");
        log.trace(""Request URI: ["" + req.getRequestURI() + ""]"");
        log.trace(""Servlet Path: ["" + req.getServletPath() + ""]"");
        log.trace(""User Principal: ["" + req.getUserPrincipal() + ""]"");

        // Process the current session (if there is one)
        HttpSession session = req.getSession(false);
        if (session != null) {

            // Document the session properties
            log.trace(""HttpSession Properties"");
            log.trace(""ID: ["" + session.getId() + ""]"");
            log.trace(""Creation Time: ["" + new Date(session.getCreationTime()) + ""]"");
            log.trace(""Last Accessed Time: ["" + new Date(session.getLastAccessedTime()) + ""]"");
            log.trace(""Max Inactive Interval: ["" + session.getMaxInactiveInterval() + ""]"");

            // Document the session attributes
            attrs = session.getAttributeNames();
            while (attrs.hasMoreElements()) {
                String attr = attrs.nextElement();
                log.trace(""Session Attribute: "" + attr + "": ["" + session.getAttribute(attr) + ""]"");
            }
        }

        // Document the servlet configuration properties
        log.trace(""ServletConfig Properties"");
        log.trace(""Servlet Name: ["" + getServletConfig().getServletName() + ""]"");

        // Document the servlet configuration initialization parameters
        params = getServletConfig().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletConfig().getInitParameter(param);
            log.trace(""Servlet Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context properties
        log.trace(""ServletContext Properties"");
        log.trace(""Major Version: ["" + getServletContext().getMajorVersion() + ""]"");
        log.trace(""Minor Version: ["" + getServletContext().getMinorVersion() + ""]"");
        log.trace(""Real Path for '/': ["" + getServletContext().getRealPath(""/"") + ""]"");
        log.trace(""Server Info: ["" + getServletContext().getServerInfo() + ""]"");

        // Document the servlet context initialization parameters
        log.trace(""ServletContext Initialization Parameters"");
        params = getServletContext().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletContext().getInitParameter(param);
            log.trace(""Servlet Context Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context attributes
        log.trace(""ServletContext Attributes"");
        attrs = getServletContext().getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Servlet Context Attribute: "" + attr +
                    "": ["" + getServletContext().getAttribute(attr) + ""]"");
        }
    }",,
tomcat,17089,"log.warn(sm.getString(""endpoint.nio.perms.writeFail"", file.getPath()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/NioEndpoint.java/#L235,"protected void initServerSocket() throws Exception {
        if (getUseInheritedChannel()) {
            // Retrieve the channel provided by the OS
            Channel ic = System.inheritedChannel();
            if (ic instanceof ServerSocketChannel) {
                serverSock = (ServerSocketChannel) ic;
            }
            if (serverSock == null) {
                throw new IllegalArgumentException(sm.getString(""endpoint.init.bind.inherited""));
            }
        } else if (getUnixDomainSocketPath() != null) {
            SocketAddress sa = JreCompat.getInstance().getUnixDomainSocketAddress(getUnixDomainSocketPath());
            serverSock = JreCompat.getInstance().openUnixDomainServerSocketChannel();
            serverSock.bind(sa, getAcceptCount());
            if (getUnixDomainSocketPathPermissions() != null) {
                Path path = Paths.get(getUnixDomainSocketPath());
                Set<PosixFilePermission> permissions =
                        PosixFilePermissions.fromString(getUnixDomainSocketPathPermissions());
                if (path.getFileSystem().supportedFileAttributeViews().contains(""posix"")) {
                    FileAttribute<Set<PosixFilePermission>> attrs = PosixFilePermissions.asFileAttribute(permissions);
                    Files.setAttribute(path, attrs.name(), attrs.value());
                } else {
                    java.io.File file = path.toFile();
                    if (permissions.contains(PosixFilePermission.OTHERS_READ) && !file.setReadable(true, false)) {
                        log.warn(sm.getString(""endpoint.nio.perms.readFail"", file.getPath()));
                    }
                    if (permissions.contains(PosixFilePermission.OTHERS_WRITE) && !file.setWritable(true, false)) {
                        
---------------Reference log start----------------
log.warn(sm.getString(""endpoint.nio.perms.writeFail"", file.getPath()))
---------------Reference log end----------------
                    }
                }
            }
        } else {
            serverSock = ServerSocketChannel.open();
            socketProperties.setProperties(serverSock.socket());
            InetSocketAddress addr = new InetSocketAddress(getAddress(), getPortWithOffset());
            serverSock.bind(addr, getAcceptCount());
        }
        serverSock.configureBlocking(true); //mimic APR behavior
    }",,
tomcat,17551,"log.warn(Localizer.getMessage(""jsp.warning.loadSmap"", className), ioe)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/SmapUtil.java/#L821,"private static String getSmap(String className, ClassLoader cl) {
        Charset encoding = StandardCharsets.ISO_8859_1;
        boolean found = false;
        String smap = null;

        InputStream is = null;
        try {
            is = cl.getResourceAsStream(className.replaceAll(""\\."",""/"") + "".smap"");
            if (is != null) {
                encoding = SMAP_ENCODING;
                found = true;
            } else {
                is = cl.getResourceAsStream(className.replaceAll(""\\."",""/"") + "".class"");
                // Alternative approach would be to read the class file as per the
                // JLS. That would require duplicating a lot of BCEL functionality.
                int b = is.read();
                while (b != -1) {
                    if (b == 'S') {
                        if ((b = is.read()) != 'M') {
                            continue;
                        }
                        if ((b = is.read()) != 'A') {
                            continue;
                        }
                        if ((b = is.read()) != 'P') {
                            continue;
                        }
                        if ((b = is.read()) != '\n') {
                            continue;
                        }
                        found = true;
                        break;
                    }
                    b = is.read();
                }
            }

            if (found) {
                ByteArrayOutputStream baos = new ByteArrayOutputStream(1024);
                byte[] buf = new byte[1024];
                int numRead;
                while ( (numRead = is.read(buf) ) >= 0) {
                    baos.write(buf, 0, numRead);
                }

                smap = new String(baos.toByteArray(), encoding);
            }
        } catch (IOException ioe) {
            Log log = LogFactory.getLog(SmapUtil.class);
            
---------------Reference log start----------------
log.warn(Localizer.getMessage(""jsp.warning.loadSmap"", className), ioe)
---------------Reference log end----------------
        } finally {
            if (is != null) {
                try {
                    is.close();
                } catch (IOException ioe) {
                    Log log = LogFactory.getLog(SmapUtil.class);
                    log.warn(Localizer.getMessage(""jsp.warning.loadSmap"", className), ioe);
                }
            }
        }
        return smap;
    }",,
tomcat,17676,"log.warn(""Not loading a JDBC driver as driverClassName property is null."")",warn,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/PooledConnection.java/#L302,"protected void connectUsingDriver() throws SQLException {

        try {
            if (driver==null) {
                if (log.isDebugEnabled()) {
                    log.debug(""Instantiating driver using class: ""+poolProperties.getDriverClassName()+"" [url=""+poolProperties.getUrl()+""]"");
                }
                if (poolProperties.getDriverClassName()==null) {
                    //rely on DriverManager
                    
---------------Reference log start----------------
log.warn(""Not loading a JDBC driver as driverClassName property is null."")
---------------Reference log end----------------
                } else {
                    driver = (java.sql.Driver)
                        ClassLoaderUtil.loadClass(
                            poolProperties.getDriverClassName(),
                            PooledConnection.class.getClassLoader(),
                            Thread.currentThread().getContextClassLoader()
                        ).getConstructor().newInstance();
                }
            }
        } catch (java.lang.Exception cn) {
            if (log.isDebugEnabled()) {
                log.debug(""Unable to instantiate JDBC driver."", cn);
            }
            SQLException ex = new SQLException(cn.getMessage());
            ex.initCause(cn);
            throw ex;
        }
        String driverURL = poolProperties.getUrl();
        String usr = null;
        String pwd = null;
        if (getAttributes().containsKey(PROP_USER)) {
            usr = (String) getAttributes().get(PROP_USER);
        } else {
            usr = poolProperties.getUsername();
            getAttributes().put(PROP_USER, usr);
        }
        if (getAttributes().containsKey(PROP_PASSWORD)) {
            pwd = (String) getAttributes().get(PROP_PASSWORD);
        } else {
            pwd = poolProperties.getPassword();
            getAttributes().put(PROP_PASSWORD, pwd);
        }
        Properties properties = PoolUtilities.clone(poolProperties.getDbProperties());
        if (usr != null) {
          properties.setProperty(PROP_USER, usr);
        }
        if (pwd != null) {
          properties.setProperty(PROP_PASSWORD, pwd);
        }

        try {
            if (driver==null) {
                connection = DriverManager.getConnection(driverURL, properties);
            } else {
                connection = driver.connect(driverURL, properties);
            }
        } catch (Exception x) {
            if (log.isDebugEnabled()) {
                log.debug(""Unable to connect to database."", x);
            }
            if (parent.jmxPool!=null) {
                parent.jmxPool.notify(org.apache.tomcat.jdbc.pool.jmx.ConnectionPool.NOTIFY_CONNECT,
                        ConnectionPool.getStackTrace(x));
            }
            if (x instanceof SQLException) {
                throw (SQLException)x;
            } else {
                SQLException ex = new SQLException(x.getMessage());
                ex.initCause(x);
                throw ex;
            }
        }
        if (connection==null) {
            throw new SQLException(""Driver:""+driver+"" returned null for URL:""+driverURL);
        }
    }",,
tomcat,16300,"log.info(sm.getString(""jvmRoute.valve.started""))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/session/JvmRouteBinderValve.java/#L377,"@Override
    protected synchronized void startInternal() throws LifecycleException {

        if (cluster == null) {
            Cluster containerCluster = getContainer().getCluster();
            if (containerCluster instanceof CatalinaCluster) {
                setCluster((CatalinaCluster)containerCluster);
            }
        }

        if (log.isInfoEnabled()) {
            
---------------Reference log start----------------
log.info(sm.getString(""jvmRoute.valve.started""))
---------------Reference log end----------------
            if (cluster == null) {
                log.info(sm.getString(""jvmRoute.noCluster""));
            }
        }

        super.startInternal();
    }",,
tomcat,16514,"log.trace(""Servlet Init Param: "" + param + "": ["" + value + ""]"")",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L545,"private void printServletEnvironment(HttpServletRequest req) throws IOException {

        // Document the properties from ServletRequest
        log.trace(""ServletRequest Properties"");
        Enumeration<String> attrs = req.getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Request Attribute: "" + attr + "": [ "" + req.getAttribute(attr) +""]"");
        }
        log.trace(""Character Encoding: ["" + req.getCharacterEncoding() + ""]"");
        log.trace(""Content Length: ["" + req.getContentLengthLong() + ""]"");
        log.trace(""Content Type: ["" + req.getContentType() + ""]"");
        Enumeration<Locale> locales = req.getLocales();
        while (locales.hasMoreElements()) {
            Locale locale = locales.nextElement();
            log.trace(""Locale: ["" +locale + ""]"");
        }
        Enumeration<String> params = req.getParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            for (String value : req.getParameterValues(param)) {
                log.trace(""Request Parameter: "" + param + "":  ["" + value + ""]"");
            }
        }
        log.trace(""Protocol: ["" + req.getProtocol() + ""]"");
        log.trace(""Remote Address: ["" + req.getRemoteAddr() + ""]"");
        log.trace(""Remote Host: ["" + req.getRemoteHost() + ""]"");
        log.trace(""Scheme: ["" + req.getScheme() + ""]"");
        log.trace(""Secure: ["" + req.isSecure() + ""]"");
        log.trace(""Server Name: ["" + req.getServerName() + ""]"");
        log.trace(""Server Port: ["" + req.getServerPort() + ""]"");

        // Document the properties from HttpServletRequest
        log.trace(""HttpServletRequest Properties"");
        log.trace(""Auth Type: ["" + req.getAuthType() + ""]"");
        log.trace(""Context Path: ["" + req.getContextPath() + ""]"");
        Cookie cookies[] = req.getCookies();
        if (cookies != null) {
            for (Cookie cookie : cookies) {
                log.trace(""Cookie: "" + cookie.getName() + "": ["" + cookie.getValue() + ""]"");
            }
        }
        Enumeration<String> headers = req.getHeaderNames();
        while (headers.hasMoreElements()) {
            String header = headers.nextElement();
            log.trace(""HTTP Header: "" + header + "": ["" + req.getHeader(header) + ""]"");
        }
        log.trace(""Method: ["" + req.getMethod() + ""]"");
        log.trace(""Path Info: ["" + req.getPathInfo() + ""]"");
        log.trace(""Path Translated: ["" + req.getPathTranslated() + ""]"");
        log.trace(""Query String: ["" + req.getQueryString() + ""]"");
        log.trace(""Remote User: ["" + req.getRemoteUser() + ""]"");
        log.trace(""Requested Session ID: ["" + req.getRequestedSessionId() + ""]"");
        log.trace(""Requested Session ID From Cookie: ["" +
                req.isRequestedSessionIdFromCookie() + ""]"");
        log.trace(""Requested Session ID From URL: ["" + req.isRequestedSessionIdFromURL() + ""]"");
        log.trace(""Requested Session ID Valid: ["" + req.isRequestedSessionIdValid() + ""]"");
        log.trace(""Request URI: ["" + req.getRequestURI() + ""]"");
        log.trace(""Servlet Path: ["" + req.getServletPath() + ""]"");
        log.trace(""User Principal: ["" + req.getUserPrincipal() + ""]"");

        // Process the current session (if there is one)
        HttpSession session = req.getSession(false);
        if (session != null) {

            // Document the session properties
            log.trace(""HttpSession Properties"");
            log.trace(""ID: ["" + session.getId() + ""]"");
            log.trace(""Creation Time: ["" + new Date(session.getCreationTime()) + ""]"");
            log.trace(""Last Accessed Time: ["" + new Date(session.getLastAccessedTime()) + ""]"");
            log.trace(""Max Inactive Interval: ["" + session.getMaxInactiveInterval() + ""]"");

            // Document the session attributes
            attrs = session.getAttributeNames();
            while (attrs.hasMoreElements()) {
                String attr = attrs.nextElement();
                log.trace(""Session Attribute: "" + attr + "": ["" + session.getAttribute(attr) + ""]"");
            }
        }

        // Document the servlet configuration properties
        log.trace(""ServletConfig Properties"");
        log.trace(""Servlet Name: ["" + getServletConfig().getServletName() + ""]"");

        // Document the servlet configuration initialization parameters
        params = getServletConfig().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletConfig().getInitParameter(param);
            
---------------Reference log start----------------
log.trace(""Servlet Init Param: "" + param + "": ["" + value + ""]"")
---------------Reference log end----------------
        }

        // Document the servlet context properties
        log.trace(""ServletContext Properties"");
        log.trace(""Major Version: ["" + getServletContext().getMajorVersion() + ""]"");
        log.trace(""Minor Version: ["" + getServletContext().getMinorVersion() + ""]"");
        log.trace(""Real Path for '/': ["" + getServletContext().getRealPath(""/"") + ""]"");
        log.trace(""Server Info: ["" + getServletContext().getServerInfo() + ""]"");

        // Document the servlet context initialization parameters
        log.trace(""ServletContext Initialization Parameters"");
        params = getServletContext().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletContext().getInitParameter(param);
            log.trace(""Servlet Context Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context attributes
        log.trace(""ServletContext Attributes"");
        attrs = getServletContext().getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Servlet Context Attribute: "" + attr +
                    "": ["" + getServletContext().getAttribute(attr) + ""]"");
        }
    }",,
tomcat,15470,"log.debug(""Creating new session to store CSRF nonce cache"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/filters/CsrfPreventionFilter.java/#L188,"@Override
    public void doFilter(ServletRequest request, ServletResponse response,
            FilterChain chain) throws IOException, ServletException {

        ServletResponse wResponse = null;

        if (request instanceof HttpServletRequest &&
                response instanceof HttpServletResponse) {

            HttpServletRequest req = (HttpServletRequest) request;
            HttpServletResponse res = (HttpServletResponse) response;

            boolean skipNonceCheck = false;

            if (Constants.METHOD_GET.equals(req.getMethod())
                    && entryPoints.contains(getRequestedPath(req))) {
                if(log.isTraceEnabled()) {
                    log.trace(""Skipping CSRF nonce-check for GET request to entry point "" + getRequestedPath(req));
                }

                skipNonceCheck = true;
            }

            HttpSession session = req.getSession(false);

            @SuppressWarnings(""unchecked"")
            LruCache<String> nonceCache = (session == null) ? null
                    : (LruCache<String>) session.getAttribute(
                            Constants.CSRF_NONCE_SESSION_ATTR_NAME);

            if (!skipNonceCheck) {
                String previousNonce =
                    req.getParameter(nonceRequestParameterName);

                if(previousNonce == null) {
                    if(log.isDebugEnabled()) {
                        log.debug(""Rejecting request for "" + getRequestedPath(req)
                                  + "", session ""
                                  + (null == session ? ""(none)"" : session.getId())
                                  + "" with no CSRF nonce found in request"");
                    }

                    res.sendError(getDenyStatus());
                    return;
                } else if(nonceCache == null) {
                    if(log.isDebugEnabled()) {
                        log.debug(""Rejecting request for "" + getRequestedPath(req)
                                  + "", session ""
                                  + (null == session ? ""(none)"" : session.getId())
                                  + "" due to empty / missing nonce cache"");
                    }

                    res.sendError(getDenyStatus());
                    return;
                } else if(!nonceCache.contains(previousNonce)) {
                    if(log.isDebugEnabled()) {
                        log.debug(""Rejecting request for "" + getRequestedPath(req)
                                  + "", session ""
                                  + (null == session ? ""(none)"" : session.getId())
                                  + "" due to invalid nonce "" + previousNonce);
                    }

                    res.sendError(getDenyStatus());
                    return;
                }
                if(log.isTraceEnabled()) {
                    log.trace(""Allowing request to "" + getRequestedPath(req)
                               + "" with valid CSRF nonce "" + previousNonce);
                }
            }

            if (nonceCache == null) {
                if(log.isDebugEnabled()) {
                    log.debug(""Creating new CSRF nonce cache with size="" + nonceCacheSize + "" for session "" + (null == session ? ""(will create)"" : session.getId()));
                }

                nonceCache = new LruCache<>(nonceCacheSize);
                if (session == null) {
                    if(log.isDebugEnabled()) {
                         
---------------Reference log start----------------
log.debug(""Creating new session to store CSRF nonce cache"")
---------------Reference log end----------------
                    }

                    session = req.getSession(true);
                }
                session.setAttribute(
                        Constants.CSRF_NONCE_SESSION_ATTR_NAME, nonceCache);
            }

            String newNonce = generateNonce();

            nonceCache.add(newNonce);

            // Take this request's nonce and put it into the request
            // attributes so pages can make direct use of it, rather than
            // requiring the use of response.encodeURL.
            request.setAttribute(Constants.CSRF_NONCE_REQUEST_ATTR_NAME, newNonce);

            wResponse = new CsrfResponseWrapper(res, nonceRequestParameterName, newNonce);
        } else {
            wResponse = response;
        }

        chain.doFilter(request, wResponse);
    }",,
tomcat,17537,"log.debug(""SourceDebugExtension found at: "" + sdeIndex)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/SmapUtil.java/#L247,"void addSDE() throws UnsupportedEncodingException, IOException {
            copy(4 + 2 + 2); // magic min/maj version
            int constantPoolCountPos = genPos;
            int constantPoolCount = readU2();
            if (log.isDebugEnabled()) {
                log.debug(""constant pool count: "" + constantPoolCount);
            }
            writeU2(constantPoolCount);

            // copy old constant pool return index of SDE symbol, if found
            sdeIndex = copyConstantPool(constantPoolCount);
            if (sdeIndex < 0) {
                // if ""SourceDebugExtension"" symbol not there add it
                writeUtf8ForSDE();

                // increment the constantPoolCount
                sdeIndex = constantPoolCount;
                ++constantPoolCount;
                randomAccessWriteU2(constantPoolCountPos, constantPoolCount);

                if (log.isDebugEnabled()) {
                    log.debug(""SourceDebugExtension not found, installed at: "" + sdeIndex);
                }
            } else {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""SourceDebugExtension found at: "" + sdeIndex)
---------------Reference log end----------------
                }
            }
            copy(2 + 2 + 2); // access, this, super
            int interfaceCount = readU2();
            writeU2(interfaceCount);
            if (log.isDebugEnabled()) {
                log.debug(""interfaceCount: "" + interfaceCount);
            }
            copy(interfaceCount * 2);
            copyMembers(); // fields
            copyMembers(); // methods
            int attrCountPos = genPos;
            int attrCount = readU2();
            writeU2(attrCount);
            if (log.isDebugEnabled()) {
                log.debug(""class attrCount: "" + attrCount);
            }
            // copy the class attributes, return true if SDE attr found (not copied)
            if (!copyAttrs(attrCount)) {
                // we will be adding SDE and it isn't already counted
                ++attrCount;
                randomAccessWriteU2(attrCountPos, attrCount);
                if (log.isDebugEnabled()) {
                    log.debug(""class attrCount incremented"");
                }
            }
            writeAttrForSDE(sdeIndex);
        }",,
tomcat,17490,"log.debug(jspUri + "" is out dated, compiling..."")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/JspC.java/#L1363,"protected void processFile(String file) throws JasperException {

        if (log.isDebugEnabled()) {
            log.debug(""Processing file: "" + file);
        }

        ClassLoader originalClassLoader = null;

        try {
            // set up a scratch/output dir if none is provided
            if (scratchDir == null) {
                String temp = System.getProperty(""java.io.tmpdir"");
                if (temp == null) {
                    temp = """";
                }
                scratchDir = new File(temp).getAbsoluteFile();
            }

            String jspUri=file.replace('\\','/');
            JspCompilationContext clctxt = new JspCompilationContext
                ( jspUri, this, context, null, rctxt );

            /* Override the defaults */
            if ((targetClassName != null) && (targetClassName.length() > 0)) {
                clctxt.setServletClassName(targetClassName);
                targetClassName = null;
            }
            if (targetPackage != null) {
                clctxt.setBasePackageName(targetPackage);
            }

            originalClassLoader = Thread.currentThread().getContextClassLoader();
            Thread.currentThread().setContextClassLoader(loader);

            clctxt.setClassLoader(loader);
            clctxt.setClassPath(classPath);

            Compiler clc = clctxt.createCompiler();

            // If compile is set, generate both .java and .class, if
            // .jsp file is newer than .class file;
            // Otherwise only generate .java, if .jsp file is newer than
            // the .java file
            if( clc.isOutDated(compile) ) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(jspUri + "" is out dated, compiling..."")
---------------Reference log end----------------
                }

                clc.compile(compile, true);
            }

            // Generate mapping
            generateWebMapping( file, clctxt );
            if ( showSuccess ) {
                log.info( ""Built File: "" + file );
            }

        } catch (JasperException je) {
            Throwable rootCause = je;
            while (rootCause instanceof JasperException
                    && ((JasperException) rootCause).getRootCause() != null) {
                rootCause = ((JasperException) rootCause).getRootCause();
            }
            if (rootCause != je) {
                log.error(Localizer.getMessage(""jspc.error.generalException"",
                                               file),
                          rootCause);
            }
            throw je;
        } catch (Exception e) {
            if ((e instanceof FileNotFoundException) && log.isWarnEnabled()) {
                log.warn(Localizer.getMessage(""jspc.error.fileDoesNotExist"",
                                              e.getMessage()));
            }
            throw new JasperException(e);
        } finally {
            if(originalClassLoader != null) {
                Thread.currentThread().setContextClassLoader(originalClassLoader);
            }
        }
    }",,
tomcat,17277,"log.warn(sm.getString(""endpoint.warn.noLocalName""), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/AprEndpoint.java/#L2535,"@Override
        protected void populateLocalName() {
            if (isClosed()) {
                return;
            }
            try {
                long socket = getSocket().longValue();
                long sa = Address.get(Socket.APR_LOCAL, socket);
                localName =Address.getnameinfo(sa, 0);
            } catch (Exception e) {
                
---------------Reference log start----------------
log.warn(sm.getString(""endpoint.warn.noLocalName""), e)
---------------Reference log end----------------
            }
        }",,
tomcat,15515,"log.debug(sm.getString(""combinedRealm.authFail"", username, realm.getClass().getName()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/CombinedRealm.java/#L330,"@Override
    public Principal authenticate(X509Certificate[] certs) {
        Principal authenticatedUser = null;
        String username = null;
        if (certs != null && certs.length >0) {
            username = certs[0].getSubjectDN().getName();
        }

        for (Realm realm : realms) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""combinedRealm.authStart"", username,
                        realm.getClass().getName()));
            }

            authenticatedUser = realm.authenticate(certs);

            if (authenticatedUser == null) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""combinedRealm.authFail"", username, realm.getClass().getName()))
---------------Reference log end----------------
                }
            } else {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""combinedRealm.authSuccess"",
                            username, realm.getClass().getName()));
                }
                break;
            }
        }
        return authenticatedUser;
    }",,
tomcat,17575,"log.trace(Localizer.getMessage(""jsp.message.jsp_added"", jsw.getJspUri(), context.getContextPath()))",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/JspRuntimeContext.java/#L227,"public FastRemovalDequeue<JspServletWrapper>.Entry push(JspServletWrapper jsw) {
        if (log.isTraceEnabled()) {
            
---------------Reference log start----------------
log.trace(Localizer.getMessage(""jsp.message.jsp_added"", jsw.getJspUri(), context.getContextPath()))
---------------Reference log end----------------
        }
        FastRemovalDequeue<JspServletWrapper>.Entry entry = jspQueue.push(jsw);
        JspServletWrapper replaced = entry.getReplaced();
        if (replaced != null) {
            if (log.isDebugEnabled()) {
                log.debug(Localizer.getMessage(""jsp.message.jsp_removed_excess"",
                                               replaced.getJspUri(), context.getContextPath()));
            }
            unloadJspServletWrapper(replaced);
            entry.clearReplaced();
        }
        return entry;
    }",,
tomcat,17619,"log.warn(msg, e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/naming/NamingContext.java/#L891,"protected Object lookup(Name name, boolean resolveLinks)
        throws NamingException {

        // Removing empty parts
        while ((!name.isEmpty()) && (name.get(0).length() == 0)) {
            name = name.getSuffix(1);
        }
        if (name.isEmpty()) {
            // If name is empty, a newly allocated naming context is returned
            return new NamingContext(env, this.name, bindings);
        }

        NamingEntry entry = bindings.get(name.get(0));

        if (entry == null) {
            throw new NameNotFoundException
                (sm.getString(""namingContext.nameNotBound"", name, name.get(0)));
        }

        if (name.size() > 1) {
            // If the size of the name is greater that 1, then we go through a
            // number of subcontexts.
            if (entry.type != NamingEntry.CONTEXT) {
                throw new NamingException
                    (sm.getString(""namingContext.contextExpected""));
            }
            return ((Context) entry.value).lookup(name.getSuffix(1));
        } else {
            if ((resolveLinks) && (entry.type == NamingEntry.LINK_REF)) {
                String link = ((LinkRef) entry.value).getLinkName();
                if (link.startsWith(""."")) {
                    // Link relative to this context
                    return lookup(link.substring(1));
                } else {
                    return new InitialContext(env).lookup(link);
                }
            } else if (entry.type == NamingEntry.REFERENCE) {
                try {
                    Object obj = null;
                    if (!GRAAL) {
                        obj = NamingManager.getObjectInstance(entry.value, name, this, env);
                    } else {
                        // NamingManager.getObjectInstance would simply return the reference here
                        // Use the configured object factory to resolve it directly if possible
                        // Note: This may need manual constructor reflection configuration
                        Reference reference = (Reference) entry.value;
                        Class<?> factoryClass = getClass().getClassLoader().loadClass(reference.getFactoryClassName());
                        ObjectFactory factory = (ObjectFactory) factoryClass.newInstance();
                        obj = factory.getObjectInstance(entry.value, name, this, env);
                    }
                    if (entry.value instanceof ResourceRef) {
                        boolean singleton = Boolean.parseBoolean(
                                    (String) ((ResourceRef) entry.value).get(
                                        ""singleton"").getContent());
                        if (singleton) {
                            entry.type = NamingEntry.ENTRY;
                            entry.value = obj;
                        }
                    }
                    if (obj == null) {
                        throw new NamingException(sm.getString(""namingContext.failResolvingReference""));
                    }
                    return obj;
                } catch (NamingException e) {
                    throw e;
                } catch (Exception e) {
                    String msg = sm.getString(""namingContext.failResolvingReference"");
                    
---------------Reference log start----------------
log.warn(msg, e)
---------------Reference log end----------------
                    NamingException ne = new NamingException(msg);
                    ne.initCause(e);
                    throw ne;
                }
            } else {
                return entry.value;
            }
        }

    }",,
tomcat,17445,"digester.log.debug(""[SetPropertiesRule]{"" + digester.match + ""} Set NULL properties"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/SetPropertiesRule.java/#L74,"@Override
    public void begin(String namespace, String theName, Attributes attributes)
            throws Exception {

        // Populate the corresponding properties of the top object
        Object top = digester.peek();
        if (digester.log.isDebugEnabled()) {
            if (top != null) {
                digester.log.debug(""[SetPropertiesRule]{"" + digester.match +
                                   ""} Set "" + top.getClass().getName() +
                                   "" properties"");
            } else {
                
---------------Reference log start----------------
digester.log.debug(""[SetPropertiesRule]{"" + digester.match + ""} Set NULL properties"")
---------------Reference log end----------------
            }
        }
        StringBuilder code = digester.getGeneratedCode();
        String variableName = null;
        if (code != null) {
            variableName = digester.toVariableName(top);
        }

        for (int i = 0; i < attributes.getLength(); i++) {
            String name = attributes.getLocalName(i);
            if (name.isEmpty()) {
                name = attributes.getQName(i);
            }
            String value = attributes.getValue(i);

            if (digester.log.isDebugEnabled()) {
                digester.log.debug(""[SetPropertiesRule]{"" + digester.match +
                        ""} Setting property '"" + name + ""' to '"" +
                        value + ""'"");
            }
            if (!digester.isFakeAttribute(top, name) && (excludes == null || !excludes.containsKey(name))) {
                StringBuilder actualMethod = null;
                if (code != null) {
                    actualMethod = new StringBuilder();
                }
                if (!IntrospectionUtils.setProperty(top, name, value, true, actualMethod)) {
                    if (digester.getRulesValidation() && !""optional"".equals(name)) {
                        digester.log.warn(sm.getString(""rule.noProperty"", digester.match, name, value));
                    }
                } else {
                    if (code != null) {
                        code.append(variableName).append(""."").append(actualMethod).append(';');
                        code.append(System.lineSeparator());
                    }
                }
            }
        }

        if (top instanceof Listener) {
            ((Listener) top).endSetPropertiesRule();
            if (code != null) {
                code.append(""((org.apache.tomcat.util.digester.SetPropertiesRule.Listener) "");
                code.append(variableName).append("").endSetPropertiesRule();"");
                code.append(System.lineSeparator());
            }
        }

    }",,
tomcat,17031,"log.warn(""The requested JMX name ["" + requestedName + ""] was not valid and will be ignored."")",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/dbcp/dbcp2/BasicDataSource.java/#L1539,"@Override
    public ObjectName preRegister(final MBeanServer server, final ObjectName objectName) {
        final String requestedName = getJmxName();
        if (requestedName != null) {
            try {
                registeredJmxObjectName = ObjectNameWrapper.wrap(requestedName);
            } catch (final MalformedObjectNameException e) {
                
---------------Reference log start----------------
log.warn(""The requested JMX name ["" + requestedName + ""] was not valid and will be ignored."")
---------------Reference log end----------------
            }
        }
        if (registeredJmxObjectName == null) {
            registeredJmxObjectName = ObjectNameWrapper.wrap(objectName);
        }
        return ObjectNameWrapper.unwrap(registeredJmxObjectName);
    }",,
tomcat,16018,"log.info(sm.getString(""standardContextSF.storeContextWithBackup"", aContext.getPath(), mover.getConfigSave()))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/storeconfig/StandardContextSF.java/#L166,"protected void storeWithBackup(StandardContext aContext) throws Exception {
        StoreFileMover mover = getConfigFileWriter(aContext);
        if (mover != null) {
            // Bugzilla 37781 Check to make sure we can write this output file
            if ((mover.getConfigOld() == null)
                    || (mover.getConfigOld().isDirectory())
                    || (mover.getConfigOld().exists() &&
                            !mover.getConfigOld().canWrite())) {
                throw new IOException(sm.getString(""standardContextSF.moveFailed"", mover.getConfigOld()));
            }
            File dir = mover.getConfigSave().getParentFile();
            if (dir != null && dir.isDirectory() && (!dir.canWrite())) {
                throw new IOException(sm.getString(""standardContextSF.cannotWriteFile"", mover.getConfigSave()));
            }
            if (log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""standardContextSF.storeContextWithBackup"", aContext.getPath(), mover.getConfigSave()))
---------------Reference log end----------------
            }
            try (PrintWriter writer = mover.getWriter()) {
                storeXMLHead(writer);
                super.store(writer, -2, aContext);
            }
            mover.move();
        }
    }",,
tomcat,15640,"log.debug(""Abort"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JAASMemoryLoginModule.java/#L164,"@Override
    public boolean abort() throws LoginException {

        // If our authentication was not successful, just return false
        if (principal == null) {
            return false;
        }

        // Clean up if overall authentication failed
        if (committed) {
            logout();
        } else {
            committed = false;
            principal = null;
        }
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Abort"")
---------------Reference log end----------------
        }
        return true;
    }",,
tomcat,15542,"log.debug(sm.getString(""jaasRealm.authenticateFailure"", username))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JAASRealm.java/#L487,"protected Principal authenticate(String username,
            CallbackHandler callbackHandler) {

        // Establish a LoginContext to use for authentication
        try {
            LoginContext loginContext = null;
            if( appName==null ) {
                appName=""Tomcat"";
            }

            if( log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.beginLogin"", username, appName));
            }

            // What if the LoginModule is in the container class loader ?
            ClassLoader ocl = null;

            if (!isUseContextClassLoader()) {
                ocl = Thread.currentThread().getContextClassLoader();
                Thread.currentThread().setContextClassLoader(
                        this.getClass().getClassLoader());
            }

            try {
                Configuration config = getConfig();
                loginContext = new LoginContext(
                        appName, null, callbackHandler, config);
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                log.error(sm.getString(""jaasRealm.unexpectedError""), e);
                // There is configuration issue with JAAS so mark the realm as
                // unavailable
                invocationSuccess = false;
                return null;
            } finally {
                if(!isUseContextClassLoader()) {
                    Thread.currentThread().setContextClassLoader(ocl);
                }
            }

            if( log.isDebugEnabled()) {
                log.debug(""Login context created "" + username);
            }

            // Negotiate a login via this LoginContext
            Subject subject = null;
            try {
                loginContext.login();
                subject = loginContext.getSubject();
                // We were able to perform login successfully so mark JAAS realm as
                // available as it could have been set to false in prior attempts.
                // Change invocationSuccess variable only when we know the outcome
                // of the JAAS operation to keep variable consistent.
                invocationSuccess = true;
                if (subject == null) {
                    if( log.isDebugEnabled()) {
                        log.debug(sm.getString(""jaasRealm.failedLogin"", username));
                    }
                    return null;
                }
            } catch (AccountExpiredException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.accountExpired"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (CredentialExpiredException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.credentialExpired"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (FailedLoginException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.failedLogin"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (LoginException e) {
                log.warn(sm.getString(""jaasRealm.loginException"", username), e);
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                log.error(sm.getString(""jaasRealm.unexpectedError""), e);
                // JAAS throws exception different than LoginException so mark the
                // realm as unavailable
                invocationSuccess = false;
                return null;
            }

            if( log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.loginContextCreated"", username));
            }

            // Return the appropriate Principal for this authenticated Subject
            Principal principal = createPrincipal(username, subject, loginContext);
            if (principal == null) {
                
---------------Reference log start----------------
log.debug(sm.getString(""jaasRealm.authenticateFailure"", username))
---------------Reference log end----------------
                return null;
            }
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.authenticateSuccess"", username, principal));
            }

            return principal;
        } catch( Throwable t) {
            log.error( ""error "", t);
            //JAAS throws exception different than LoginException so mark the realm as unavailable
            invocationSuccess = false;
            return null;
        }
    }",,
tomcat,15705,"log.warn(sm.getString(""staticMembershipProvider.heartbeat.failed""), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/membership/StaticMembershipProvider.java/#L281,"@Override
    public void heartbeat() {
        try {
            if (!useThread) {
                ping();
            }
        } catch (ChannelException e) {
            
---------------Reference log start----------------
log.warn(sm.getString(""staticMembershipProvider.heartbeat.failed""), e)
---------------Reference log end----------------
        }
    }",,
tomcat,16547,"log.warn(sm.getString(""cgiServlet.runInvalidStatus"", value))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L1808,"private int getSCFromCGIStatusHeader(String value) {
            if (value.length() < 3) {
                // Not a valid status value
                
---------------Reference log start----------------
log.warn(sm.getString(""cgiServlet.runInvalidStatus"", value))
---------------Reference log end----------------
                return HttpServletResponse.SC_INTERNAL_SERVER_ERROR;
            }

            String status = value.substring(0, 3);

            int statusCode;
            try {
                statusCode = Integer.parseInt(status);
            } catch (NumberFormatException nfe) {
                // Not a valid status code
                log.warn(sm.getString(""cgiServlet.runInvalidStatus"", status));
                return HttpServletResponse.SC_INTERNAL_SERVER_ERROR;
            }

            return statusCode;
        }",,
tomcat,17655,"log.warn(""Unable to terminate transaction, connection will be closed."", x)",warn,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L929,"protected boolean terminateTransaction(PooledConnection con) {
        try {
            if (Boolean.FALSE.equals(con.getPoolProperties().getDefaultAutoCommit())) {
                if (this.getPoolProperties().getRollbackOnReturn()) {
                    boolean autocommit = con.getConnection().getAutoCommit();
                    if (!autocommit) {
                      con.getConnection().rollback();
                    }
                } else if (this.getPoolProperties().getCommitOnReturn()) {
                    boolean autocommit = con.getConnection().getAutoCommit();
                    if (!autocommit) {
                      con.getConnection().commit();
                    }
                }
            }
            return true;
        } catch (SQLException x) {
            
---------------Reference log start----------------
log.warn(""Unable to terminate transaction, connection will be closed."", x)
---------------Reference log end----------------
            return false;
        }

    }",,
tomcat,16425,"log.debug(sm.getString(""ReplicationValve.crossContext.remove""))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/tcp/ReplicationValve.java/#L350,"@Override
    public void invoke(Request request, Response response)
        throws IOException, ServletException
    {
        long totalstart = 0;

        //this happens before the request
        if(doStatistics()) {
            totalstart = System.currentTimeMillis();
        }
        if (primaryIndicator) {
            createPrimaryIndicator(request) ;
        }
        Context context = request.getContext();
        boolean isCrossContext = context != null
                && context instanceof StandardContext
                && context.getCrossContext();
        try {
            if(isCrossContext) {
                if(log.isDebugEnabled()) {
                    log.debug(sm.getString(""ReplicationValve.crossContext.add""));
                }
                //FIXME add Pool of Arraylists
                crossContextSessions.set(new ArrayList<>());
            }
            getNext().invoke(request, response);
            if(context != null && cluster != null
                    && context.getManager() instanceof ClusterManager) {
                ClusterManager clusterManager = (ClusterManager) context.getManager();

                // valve cluster can access manager - other cluster handle replication
                // at host level - hopefully!
                if(cluster.getManager(clusterManager.getName()) == null) {
                    return ;
                }
                if(cluster.hasMembers()) {
                    sendReplicationMessage(request, totalstart, isCrossContext, clusterManager);
                } else {
                    resetReplicationRequest(request,isCrossContext);
                }
            }
        } finally {
            // Array must be remove: Current master request send endAccess at recycle.
            // Don't register this request session again!
            if(isCrossContext) {
                if(log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""ReplicationValve.crossContext.remove""))
---------------Reference log end----------------
                }
                // crossContextSessions.remove() only exist at Java 5
                // register ArrayList at a pool
                crossContextSessions.set(null);
            }
        }
    }",,
tomcat,16177,"log.error(sm.getString(""contextConfig.tomcatWebXmlError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/ContextConfig.java/#L1661,"private WebXml getTomcatWebXmlFragment(WebXmlParser webXmlParser) {

        WebXml webXmlTomcatFragment = createWebXml();
        webXmlTomcatFragment.setOverridable(true);

        // Set to distributable else every app will be prevented from being
        // distributable when the Tomcat fragment is merged with the main
        // web.xml
        webXmlTomcatFragment.setDistributable(true);
        // When merging, the default welcome files are only used if the app has
        // not defined any welcomes files.
        webXmlTomcatFragment.setAlwaysAddWelcomeFiles(false);

        WebResource resource = context.getResources().getResource(Constants.TomcatWebXml);
        if (resource.isFile()) {
            try {
                InputSource source = new InputSource(resource.getURL().toURI().toString());
                source.setByteStream(resource.getInputStream());
                if (!webXmlParser.parseWebXml(source, webXmlTomcatFragment, false)) {
                    ok = false;
                }
            } catch (URISyntaxException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""contextConfig.tomcatWebXmlError""), e)
---------------Reference log end----------------
            }
        }
        return webXmlTomcatFragment;
    }",,
tomcat,16794,"log.error(sm.getString(""globalResources.createError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/mbeans/GlobalResourcesLifecycleListener.java/#L102,"protected void createMBeans() {
        // Look up our global naming context
        Context context = null;
        try {
            context = (Context) (new InitialContext()).lookup(""java:/"");
        } catch (NamingException e) {
            log.error(sm.getString(""globalResources.noNamingContext""));
            return;
        }

        // Recurse through the defined global JNDI resources context
        try {
            createMBeans("""", context);
        } catch (NamingException e) {
            
---------------Reference log start----------------
log.error(sm.getString(""globalResources.createError""), e)
---------------Reference log end----------------
        }
    }",,
tomcat,15727,"log.debug(""Invalid member mcast package."", ax)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/membership/McastServiceImpl.java/#L572,"@Override
        public void run() {
            while ( doRunReceiver ) {
                try {
                    receive();
                    errorCounter=0;
                } catch ( ArrayIndexOutOfBoundsException ax ) {
                    //we can ignore this, as it means we have an invalid package
                    //but we will log it to debug
                    if ( log.isDebugEnabled() ) {
                        
---------------Reference log start----------------
log.debug(""Invalid member mcast package."", ax)
---------------Reference log end----------------
                    }
                } catch ( Exception x ) {
                    if (errorCounter==0 && doRunReceiver) {
                        log.warn(sm.getString(""mcastServiceImpl.error.receiving""),x);
                    } else if (log.isDebugEnabled()) {
                        log.debug(""Error receiving mcast package""+(doRunReceiver?"". Sleeping 500ms"":"".""),x);
                    }
                    if (doRunReceiver) {
                        try { Thread.sleep(500); } catch ( Exception ignore ){}
                        if ( (++errorCounter)>=recoveryCounter ) {
                            errorCounter=0;
                            RecoveryThread.recover(McastServiceImpl.this);
                        }
                    }
                }
            }
        }",,
tomcat,15437,"log.info(msg, ise)",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/loader/WebappClassLoaderBase.java/#L1465,"protected void checkStateForResourceLoading(String resource) throws IllegalStateException {
        // It is not permitted to load resources once the web application has
        // been stopped.
        if (!state.isAvailable()) {
            String msg = sm.getString(""webappClassLoader.stopped"", resource);
            IllegalStateException ise = new IllegalStateException(msg);
            
---------------Reference log start----------------
log.info(msg, ise)
---------------Reference log end----------------
            throw ise;
        }
    }",,
tomcat,15408,"log.debug(""    --> Resource not found, returning null"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/loader/WebappClassLoaderBase.java/#L965,"@Override
    public URL findResource(final String name) {

        if (log.isDebugEnabled()) {
            log.debug(""    findResource("" + name + "")"");
        }

        checkStateForResourceLoading(name);

        URL url = null;

        String path = nameToPath(name);

        WebResource resource = resources.getClassLoaderResource(path);
        if (resource.exists()) {
            url = resource.getURL();
            trackLastModified(path, resource);
        }

        if ((url == null) && hasExternalRepositories) {
            url = super.findResource(name);
        }

        if (log.isDebugEnabled()) {
            if (url != null) {
                log.debug(""    --> Returning '"" + url.toString() + ""'"");
            } else {
                
---------------Reference log start----------------
log.debug(""    --> Resource not found, returning null"")
---------------Reference log end----------------
            }
        }
        return url;
    }",,
tomcat,16262,log.warn(msg),warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/ClassLoaderFactory.java/#L270,"private static boolean validateFile(File file,
            RepositoryType type) throws IOException {
        if (RepositoryType.DIR == type || RepositoryType.GLOB == type) {
            if (!file.isDirectory() || !file.canRead()) {
                String msg = ""Problem with directory ["" + file +
                        ""], exists: ["" + file.exists() +
                        ""], isDirectory: ["" + file.isDirectory() +
                        ""], canRead: ["" + file.canRead() + ""]"";

                File home = new File (Bootstrap.getCatalinaHome());
                home = home.getCanonicalFile();
                File base = new File (Bootstrap.getCatalinaBase());
                base = base.getCanonicalFile();
                File defaultValue = new File(base, ""lib"");

                // Existence of ${catalina.base}/lib directory is optional.
                // Hide the warning if Tomcat runs with separate catalina.home
                // and catalina.base and that directory is absent.
                if (!home.getPath().equals(base.getPath())
                        && file.getPath().equals(defaultValue.getPath())
                        && !file.exists()) {
                    log.debug(msg);
                } else {
                    
---------------Reference log start----------------
log.warn(msg)
---------------Reference log end----------------
                }
                return false;
            }
        } else if (RepositoryType.JAR == type) {
            if (!file.canRead()) {
                log.warn(""Problem with JAR file ["" + file +
                        ""], exists: ["" + file.exists() +
                        ""], canRead: ["" + file.canRead() + ""]"");
                return false;
            }
        }
        return true;
    }",,
tomcat,16553,"log.info(sm.getString(""aprListener.aprDestroy""))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/AprLifecycleListener.java/#L156,"@Override
    public void lifecycleEvent(LifecycleEvent event) {

        if (Lifecycle.BEFORE_INIT_EVENT.equals(event.getType())) {
            synchronized (lock) {
                init();
                for (String msg : initInfoLogMessages) {
                    log.info(msg);
                }
                initInfoLogMessages.clear();
                if (AprStatus.isAprAvailable()) {
                    try {
                        initializeSSL();
                    } catch (Throwable t) {
                        t = ExceptionUtils.unwrapInvocationTargetException(t);
                        ExceptionUtils.handleThrowable(t);
                        log.error(sm.getString(""aprListener.sslInit""), t);
                    }
                }
                // Failure to initialize FIPS mode is fatal
                if (!(null == FIPSMode || ""off"".equalsIgnoreCase(FIPSMode)) && !isFIPSModeActive()) {
                    String errorMessage = sm.getString(""aprListener.initializeFIPSFailed"");
                    Error e = new Error(errorMessage);
                    // Log here, because thrown error might be not logged
                    log.fatal(errorMessage, e);
                    throw e;
                }
            }
        } else if (Lifecycle.AFTER_DESTROY_EVENT.equals(event.getType())) {
            synchronized (lock) {
                if (!AprStatus.isAprAvailable()) {
                    return;
                }
                try {
                    terminateAPR();
                } catch (Throwable t) {
                    t = ExceptionUtils.unwrapInvocationTargetException(t);
                    ExceptionUtils.handleThrowable(t);
                    
---------------Reference log start----------------
log.info(sm.getString(""aprListener.aprDestroy""))
---------------Reference log end----------------
                }
            }
        }

    }",,
tomcat,17528,"log.error(Localizer.getMessage(""jsp.error.compilation.dependent"", className), exc)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/JDTCompiler.java/#L208,"private NameEnvironmentAnswer findType(String className) {

                    if (className.equals(targetClassName)) {
                        ICompilationUnit compilationUnit = new CompilationUnit(sourceFile, className);
                        return new NameEnvironmentAnswer(compilationUnit, null);
                    }

                    String resourceName = className.replace('.', '/') + "".class"";

                    try (InputStream is = classLoader.getResourceAsStream(resourceName)) {
                        if (is != null) {
                            byte[] classBytes;
                            byte[] buf = new byte[8192];
                            ByteArrayOutputStream baos = new ByteArrayOutputStream(buf.length);
                            int count;
                            while ((count = is.read(buf, 0, buf.length)) > 0) {
                                baos.write(buf, 0, count);
                            }
                            baos.flush();
                            classBytes = baos.toByteArray();
                            char[] fileName = className.toCharArray();
                            ClassFileReader classFileReader = new ClassFileReader(classBytes, fileName, true);
                            return new NameEnvironmentAnswer(classFileReader, null);
                        }
                    } catch (IOException | ClassFormatException exc) {
                        
---------------Reference log start----------------
log.error(Localizer.getMessage(""jsp.error.compilation.dependent"", className), exc)
---------------Reference log end----------------
                    }
                    return null;
                }",,
tomcat,16380,"log.error(sm.getString(""farmWarDeployer.hostOnly""))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/deploy/FarmWarDeployer.java/#L142,"@Override
    public void start() throws Exception {
        if (started) {
            return;
        }
        Container hcontainer = getCluster().getContainer();
        if(!(hcontainer instanceof Host)) {
            
---------------Reference log start----------------
log.error(sm.getString(""farmWarDeployer.hostOnly""))
---------------Reference log end----------------
            return ;
        }
        host = (Host) hcontainer;

        // Check to correct engine and host setup
        Container econtainer = host.getParent();
        if(!(econtainer instanceof Engine)) {
            log.error(sm.getString(""farmWarDeployer.hostParentEngine"",
                    host.getName()));
            return ;
        }
        Engine engine = (Engine) econtainer;
        String hostname = null;
        hostname = host.getName();
        try {
            oname = new ObjectName(engine.getName() + "":type=Deployer,host=""
                    + hostname);
        } catch (Exception e) {
            log.error(sm.getString(""farmWarDeployer.mbeanNameFail"",
                    engine.getName(), hostname),e);
            return;
        }
        if (watchEnabled) {
            watcher = new WarWatcher(this, getWatchDirFile());
            if (log.isInfoEnabled()) {
                log.info(sm.getString(
                        ""farmWarDeployer.watchDir"", getWatchDir()));
            }
        }

        configBase = host.getConfigBaseFile();

        // Retrieve the MBean server
        mBeanServer = Registry.getRegistry(null, null).getMBeanServer();

        started = true;
        count = 0;

        getCluster().addClusterListener(this);

        if (log.isInfoEnabled()) {
            log.info(sm.getString(""farmWarDeployer.started""));
        }
    }",,
tomcat,17184,"log.error(sm.getString(""opensslconf.checkFailed""))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/openssl/OpenSSLConf.java/#L79,"public boolean check(long cctx) throws Exception {
        boolean result = true;
        OpenSSLConfCmd cmd;
        String name;
        String value;
        int rc;
        for (OpenSSLConfCmd command : commands) {
            cmd = command;
            name = cmd.getName();
            value = cmd.getValue();
            if (name == null) {
                log.error(sm.getString(""opensslconf.noCommandName"", value));
                result = false;
                continue;
            }
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""opensslconf.checkCommand"", name, value));
            }
            try {
                rc = SSLConf.check(cctx, name, value);
            } catch (Exception e) {
                log.error(sm.getString(""opensslconf.checkFailed""));
                return false;
            }
            if (rc <= 0) {
                log.error(sm.getString(""opensslconf.failedCommand"", name, value,
                        Integer.toString(rc)));
                result = false;
            } else if (log.isDebugEnabled()) {
                log.debug(sm.getString(""opensslconf.resultCommand"", name, value,
                        Integer.toString(rc)));
            }
        }
        if (!result) {
            
---------------Reference log start----------------
log.error(sm.getString(""opensslconf.checkFailed""))
---------------Reference log end----------------
        }
        return result;
    }",,
tomcat,17460,"log.debug(""IntrospectionUtils: Unknown type "" + paramType.getName())",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/IntrospectionUtils.java/#L144,"@SuppressWarnings(""null"") // setPropertyMethodVoid is not null when used
    public static boolean setProperty(Object o, String name, String value,
            boolean invokeSetProperty, StringBuilder actualMethod) {
        if (log.isDebugEnabled()) {
            log.debug(""IntrospectionUtils: setProperty("" +
                    o.getClass() + "" "" + name + ""="" + value + "")"");
        }

        if (actualMethod == null && XReflectionIntrospectionUtils.isEnabled()) {
            return XReflectionIntrospectionUtils.setPropertyInternal(o, name, value, invokeSetProperty);
        }

        String setter = ""set"" + capitalize(name);

        try {
            Method methods[] = findMethods(o.getClass());
            Method setPropertyMethodVoid = null;
            Method setPropertyMethodBool = null;

            // First, the ideal case - a setFoo( String ) method
            for (Method item : methods) {
                Class<?> paramT[] = item.getParameterTypes();
                if (setter.equals(item.getName()) && paramT.length == 1
                        && ""java.lang.String"".equals(paramT[0].getName())) {
                    item.invoke(o, new Object[]{value});
                    if (actualMethod != null) {
                        actualMethod.append(item.getName()).append(""(\"""").append(escape(value)).append(""\"")"");
                    }
                    return true;
                }
            }

            // Try a setFoo ( int ) or ( boolean )
            for (Method method : methods) {
                boolean ok = true;
                if (setter.equals(method.getName())
                        && method.getParameterTypes().length == 1) {

                    // match - find the type and invoke it
                    Class<?> paramType = method.getParameterTypes()[0];
                    Object params[] = new Object[1];

                    // Try a setFoo ( int )
                    if (""java.lang.Integer"".equals(paramType.getName())
                            || ""int"".equals(paramType.getName())) {
                        try {
                            params[0] = Integer.valueOf(value);
                        } catch (NumberFormatException ex) {
                            ok = false;
                        }
                        if (actualMethod != null) {
                            actualMethod.append(method.getName()).append(""(Integer.valueOf(\"""").append(value).append(""\""))"");
                        }
                        // Try a setFoo ( long )
                    } else if (""java.lang.Long"".equals(paramType.getName())
                            || ""long"".equals(paramType.getName())) {
                        try {
                            params[0] = Long.valueOf(value);
                        } catch (NumberFormatException ex) {
                            ok = false;
                        }
                        if (actualMethod != null) {
                            actualMethod.append(method.getName()).append(""(Long.valueOf(\"""").append(value).append(""\""))"");
                        }
                        // Try a setFoo ( boolean )
                    } else if (""java.lang.Boolean"".equals(paramType.getName())
                            || ""boolean"".equals(paramType.getName())) {
                        params[0] = Boolean.valueOf(value);
                        if (actualMethod != null) {
                            actualMethod.append(method.getName()).append(""(Boolean.valueOf(\"""").append(value).append(""\""))"");
                        }
                        // Try a setFoo ( InetAddress )
                    } else if (""java.net.InetAddress"".equals(paramType
                            .getName())) {
                        try {
                            params[0] = InetAddress.getByName(value);
                        } catch (UnknownHostException exc) {
                            if (log.isDebugEnabled()) {
                                log.debug(""IntrospectionUtils: Unable to resolve host name:"" + value);
                            }
                            ok = false;
                        }
                        if (actualMethod != null) {
                            actualMethod.append(method.getName()).append(""(InetAddress.getByName(\"""").append(value).append(""\""))"");
                        }
                        // Unknown type
                    } else {
                        if (log.isDebugEnabled()) {
                            
---------------Reference log start----------------
log.debug(""IntrospectionUtils: Unknown type "" + paramType.getName())
---------------Reference log end----------------
                        }
                    }

                    if (ok) {
                        method.invoke(o, params);
                        return true;
                    }
                }

                // save ""setProperty"" for later
                if (""setProperty"".equals(method.getName())) {
                    if (method.getReturnType() == Boolean.TYPE) {
                        setPropertyMethodBool = method;
                    } else {
                        setPropertyMethodVoid = method;
                    }

                }
            }

            // Ok, no setXXX found, try a setProperty(""name"", ""value"")
            if (invokeSetProperty && (setPropertyMethodBool != null ||
                    setPropertyMethodVoid != null)) {
                if (actualMethod != null) {
                    actualMethod.append(""setProperty(\"""").append(name).append(""\"", \"""").append(escape(value)).append(""\"")"");
                }
                Object params[] = new Object[2];
                params[0] = name;
                params[1] = value;
                if (setPropertyMethodBool != null) {
                    try {
                        return ((Boolean) setPropertyMethodBool.invoke(o,
                                params)).booleanValue();
                    }catch (IllegalArgumentException biae) {
                        //the boolean method had the wrong
                        //parameter types. lets try the other
                        if (setPropertyMethodVoid!=null) {
                            setPropertyMethodVoid.invoke(o, params);
                            return true;
                        }else {
                            throw biae;
                        }
                    }
                } else {
                    setPropertyMethodVoid.invoke(o, params);
                    return true;
                }
            }

        } catch (IllegalArgumentException | SecurityException | IllegalAccessException e) {
            log.warn(sm.getString(""introspectionUtils.setPropertyError"", name, value, o.getClass()), e);
        } catch (InvocationTargetException e) {
            ExceptionUtils.handleThrowable(e.getCause());
            log.warn(sm.getString(""introspectionUtils.setPropertyError"", name, value, o.getClass()), e);
        }
        return false;
    }",,
tomcat,15332,"log.error(sm.getString(""sslValve.invalidProvider"", providerName), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/valves/SSLValve.java/#L183,"@Override
    public void invoke(Request request, Response response) throws IOException, ServletException {
        /*
         * Known behaviours of reverse proxies that are handled by the
         * processing below:
         * - mod_header converts the '\n' into ' '
         * - nginx converts the '\n' into multiple ' '
         * - nginx ssl_client_escaped_cert uses ""uri component"" escaping,
         *   keeping only ALPHA, DIGIT, ""-"", ""."", ""_"", ""~""
         *
         * The code assumes that the trimmed header value starts with
         * '-----BEGIN CERTIFICATE-----' and ends with
         * '-----END CERTIFICATE-----'.
         *
         * Note: As long as the BEGIN marker and the rest of the content are on
         *       separate lines, the CertificateFactory is tolerant of any
         *       additional whitespace.
         */
        String headerValue;
        String headerEscapedValue = mygetHeader(request, sslClientEscapedCertHeader);
        if (headerEscapedValue != null) {
            headerValue = UDecoder.URLDecode(headerEscapedValue, null);
        } else {
            headerValue = mygetHeader(request, sslClientCertHeader);
        }
        if (headerValue != null) {
            headerValue = headerValue.trim();
            if (headerValue.length() > 27) {
                String body = headerValue.substring(27);
                String header = ""-----BEGIN CERTIFICATE-----\n"";
                String strcerts = header.concat(body);
                ByteArrayInputStream bais = new ByteArrayInputStream(
                        strcerts.getBytes(StandardCharsets.ISO_8859_1));
                X509Certificate jsseCerts[] = null;
                String providerName = (String) request.getConnector().getProperty(
                        ""clientCertProvider"");
                try {
                    CertificateFactory cf;
                    if (providerName == null) {
                        cf = CertificateFactory.getInstance(""X.509"");
                    } else {
                        cf = CertificateFactory.getInstance(""X.509"", providerName);
                    }
                    X509Certificate cert = (X509Certificate) cf.generateCertificate(bais);
                    jsseCerts = new X509Certificate[1];
                    jsseCerts[0] = cert;
                } catch (java.security.cert.CertificateException e) {
                    log.warn(sm.getString(""sslValve.certError"", strcerts), e);
                } catch (NoSuchProviderException e) {
                    
---------------Reference log start----------------
log.error(sm.getString(""sslValve.invalidProvider"", providerName), e)
---------------Reference log end----------------
                }
                request.setAttribute(Globals.CERTIFICATES_ATTR, jsseCerts);
            }
        }
        headerValue = mygetHeader(request, sslCipherHeader);
        if (headerValue != null) {
            request.setAttribute(Globals.CIPHER_SUITE_ATTR, headerValue);
        }
        headerValue = mygetHeader(request, sslSessionIdHeader);
        if (headerValue != null) {
            request.setAttribute(Globals.SSL_SESSION_ID_ATTR, headerValue);
        }
        headerValue = mygetHeader(request, sslCipherUserKeySizeHeader);
        if (headerValue != null) {
            request.setAttribute(Globals.KEY_SIZE_ATTR, Integer.valueOf(headerValue));
        }
        getNext().invoke(request, response);
    }",,
tomcat,17650,"log.warn(""Failed to add a new connection to the pool after releasing a connection "" + ""when at least one thread was waiting for a connection."")",warn,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L650,"protected void release(PooledConnection con) {
        if (con == null) {
          return;
        }
        try {
            con.lock();
            if (con.release()) {
                //counter only decremented once
                size.addAndGet(-1);
                con.setHandler(null);
            }
            releasedCount.incrementAndGet();
        } finally {
            con.unlock();
        }
        // we've asynchronously reduced the number of connections
        // we could have threads stuck in idle.poll(timeout) that will never be
        // notified
        if (waitcount.get() > 0) {
            if (!idle.offer(create(true))) {
                
---------------Reference log start----------------
log.warn(""Failed to add a new connection to the pool after releasing a connection "" + ""when at least one thread was waiting for a connection."")
---------------Reference log end----------------
            }
        }
    }",,
tomcat,15553,"containerLog.debug(""Returning null principal."")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JNDIRealm.java/#L1282,"@Override
    public Principal authenticate(String username, String credentials) {

        JNDIConnection connection = null;
        Principal principal = null;

        try {

            // Ensure that we have a directory context available
            connection = get();

            try {

                // Occasionally the directory context will timeout.  Try one more
                // time before giving up.

                // Authenticate the specified username if possible
                principal = authenticate(connection, username, credentials);

            } catch (NullPointerException | NamingException e) {
                /*
                 * BZ 61313
                 * NamingException may or may not indicate an error that is
                 * recoverable via fail over. Therefore a decision needs to be
                 * made whether to fail over or not. Generally, attempting to
                 * fail over when it is not appropriate is better than not
                 * failing over when it is appropriate so the code always
                 * attempts to fail over for NamingExceptions.
                 */

                /*
                 * BZ 42449
                 * Catch NPE - Kludge Sun's LDAP provider with broken SSL.
                 */

                // log the exception so we know it's there.
                containerLog.info(sm.getString(""jndiRealm.exception.retry""), e);

                // close the connection so we know it will be reopened.
                close(connection);
                closePooledConnections();

                // open a new directory context.
                connection = get();

                // Try the authentication again.
                principal = authenticate(connection, username, credentials);
            }


            // Release this context
            release(connection);

            // Return the authenticated Principal (if any)
            return principal;

        } catch (NamingException e) {

            // Log the problem for posterity
            containerLog.error(sm.getString(""jndiRealm.exception""), e);

            // close the connection so we know it will be reopened.
            close(connection);
            closePooledConnections();

            // Return ""not authenticated"" for this request
            if (containerLog.isDebugEnabled()) {
                
---------------Reference log start----------------
containerLog.debug(""Returning null principal."")
---------------Reference log end----------------
            }
            return null;
        }
    }",,
tomcat,16779,"wrapper.getLogger().debug("" Disabling the response for further output"")",getLogger,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/ApplicationDispatcher.java/#L378,"private void doForward(ServletRequest request, ServletResponse response)
        throws ServletException, IOException
    {

        // Reset any output that has been buffered, but keep headers/cookies
        if (response.isCommitted()) {
            throw new IllegalStateException
                (sm.getString(""applicationDispatcher.forward.ise""));
        }
        try {
            response.resetBuffer();
        } catch (IllegalStateException e) {
            throw e;
        }

        // Set up to handle the specified request and response
        State state = new State(request, response, false);

        if (context.getDispatcherWrapsSameObject()) {
            // Check SRV.8.2 / SRV.14.2.5.1 compliance
            checkSameObjects(request, response);
        }

        wrapResponse(state);
        // Handle an HTTP named dispatcher forward
        if ((servletPath == null) && (pathInfo == null)) {

            ApplicationHttpRequest wrequest =
                (ApplicationHttpRequest) wrapRequest(state);
            HttpServletRequest hrequest = state.hrequest;
            wrequest.setRequestURI(hrequest.getRequestURI());
            wrequest.setContextPath(hrequest.getContextPath());
            wrequest.setServletPath(hrequest.getServletPath());
            wrequest.setPathInfo(hrequest.getPathInfo());
            wrequest.setQueryString(hrequest.getQueryString());

            processRequest(request,response,state);
        }

        // Handle an HTTP path-based forward
        else {

            ApplicationHttpRequest wrequest = (ApplicationHttpRequest) wrapRequest(state);
            HttpServletRequest hrequest = state.hrequest;
            if (hrequest.getAttribute(RequestDispatcher.FORWARD_REQUEST_URI) == null) {
                wrequest.setAttribute(RequestDispatcher.FORWARD_REQUEST_URI,
                                      hrequest.getRequestURI());
                wrequest.setAttribute(RequestDispatcher.FORWARD_CONTEXT_PATH,
                                      hrequest.getContextPath());
                wrequest.setAttribute(RequestDispatcher.FORWARD_SERVLET_PATH,
                                      hrequest.getServletPath());
                wrequest.setAttribute(RequestDispatcher.FORWARD_PATH_INFO,
                                      hrequest.getPathInfo());
                wrequest.setAttribute(RequestDispatcher.FORWARD_QUERY_STRING,
                                      hrequest.getQueryString());
                wrequest.setAttribute(RequestDispatcher.FORWARD_MAPPING, hrequest.getHttpServletMapping());
            }

            wrequest.setContextPath(context.getEncodedPath());
            wrequest.setRequestURI(requestURI);
            wrequest.setServletPath(servletPath);
            wrequest.setPathInfo(pathInfo);
            if (queryString != null) {
                wrequest.setQueryString(queryString);
                wrequest.setQueryParams(queryString);
            }
            wrequest.setMapping(mapping);

            processRequest(request,response,state);
        }

        if (request.isAsyncStarted()) {
            // An async request was started during the forward, don't close the
            // response as it may be written to during the async handling
            return;
        }

        // This is not a real close in order to support error processing
        if (wrapper.getLogger().isDebugEnabled() ) {
            
---------------Reference log start----------------
wrapper.getLogger().debug("" Disabling the response for further output"")
---------------Reference log end----------------
        }

        if  (response instanceof ResponseFacade) {
            ((ResponseFacade) response).finish();
        } else {
            // Servlet SRV.6.2.2. The Request/Response may have been wrapped
            // and may no longer be instance of RequestFacade
            if (wrapper.getLogger().isDebugEnabled()){
                wrapper.getLogger().debug( "" The Response is vehiculed using a wrapper: ""
                           + response.getClass().getName() );
            }

            // Close anyway
            try {
                PrintWriter writer = response.getWriter();
                writer.close();
            } catch (IllegalStateException e) {
                try {
                    ServletOutputStream stream = response.getOutputStream();
                    stream.close();
                } catch (IllegalStateException | IOException f) {
                    // Ignore
                }
            } catch (IOException e) {
                // Ignore
            }
        }

    }",,
tomcat,16652,"log.error(sm.getString(""standardContext.extensionValidationError""), ioe)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardContext.java/#L4995,"@Override
    protected synchronized void startInternal() throws LifecycleException {

        if(log.isDebugEnabled()) {
            log.debug(""Starting "" + getBaseName());
        }

        // Send j2ee.state.starting notification
        if (this.getObjectName() != null) {
            Notification notification = new Notification(""j2ee.state.starting"",
                    this.getObjectName(), sequenceNumber.getAndIncrement());
            broadcaster.sendNotification(notification);
        }

        setConfigured(false);
        boolean ok = true;

        // Currently this is effectively a NO-OP but needs to be called to
        // ensure the NamingResources follows the correct lifecycle
        if (namingResources != null) {
            namingResources.start();
        }

        // Post work directory
        postWorkDirectory();

        // Add missing components as necessary
        if (getResources() == null) {   // (1) Required by Loader
            if (log.isDebugEnabled()) {
                log.debug(""Configuring default Resources"");
            }

            try {
                setResources(new StandardRoot(this));
            } catch (IllegalArgumentException e) {
                log.error(sm.getString(""standardContext.resourcesInit""), e);
                ok = false;
            }
        }
        if (ok) {
            resourcesStart();
        }

        if (getLoader() == null) {
            WebappLoader webappLoader = new WebappLoader();
            webappLoader.setDelegate(getDelegate());
            setLoader(webappLoader);
        }

        // An explicit cookie processor hasn't been specified; use the default
        if (cookieProcessor == null) {
            cookieProcessor = new Rfc6265CookieProcessor();
        }

        // Initialize character set mapper
        getCharsetMapper();

        // Validate required extensions
        boolean dependencyCheck = true;
        try {
            dependencyCheck = ExtensionValidator.validateApplication
                (getResources(), this);
        } catch (IOException ioe) {
            
---------------Reference log start----------------
log.error(sm.getString(""standardContext.extensionValidationError""), ioe)
---------------Reference log end----------------
            dependencyCheck = false;
        }

        if (!dependencyCheck) {
            // do not make application available if dependency check fails
            ok = false;
        }

        // Reading the ""catalina.useNaming"" environment variable
        String useNamingProperty = System.getProperty(""catalina.useNaming"");
        if ((useNamingProperty != null)
            && (useNamingProperty.equals(""false""))) {
            useNaming = false;
        }

        if (ok && isUseNaming()) {
            if (getNamingContextListener() == null) {
                NamingContextListener ncl = new NamingContextListener();
                ncl.setName(getNamingContextName());
                ncl.setExceptionOnFailedWrite(getJndiExceptionOnFailedWrite());
                addLifecycleListener(ncl);
                setNamingContextListener(ncl);
            }
        }

        // Standard container startup
        if (log.isDebugEnabled()) {
            log.debug(""Processing standard container startup"");
        }


        // Binding thread
        ClassLoader oldCCL = bindThread();

        try {
            if (ok) {
                // Start our subordinate components, if any
                Loader loader = getLoader();
                if (loader instanceof Lifecycle) {
                    ((Lifecycle) loader).start();
                }

                // since the loader just started, the webapp classloader is now
                // created.
                if (loader.getClassLoader() instanceof WebappClassLoaderBase) {
                    WebappClassLoaderBase cl = (WebappClassLoaderBase) loader.getClassLoader();
                    cl.setClearReferencesRmiTargets(getClearReferencesRmiTargets());
                    cl.setClearReferencesStopThreads(getClearReferencesStopThreads());
                    cl.setClearReferencesStopTimerThreads(getClearReferencesStopTimerThreads());
                    cl.setClearReferencesHttpClientKeepAliveThread(getClearReferencesHttpClientKeepAliveThread());
                    cl.setClearReferencesObjectStreamClassCaches(getClearReferencesObjectStreamClassCaches());
                    cl.setClearReferencesThreadLocals(getClearReferencesThreadLocals());
                }

                // By calling unbindThread and bindThread in a row, we setup the
                // current Thread CCL to be the webapp classloader
                unbindThread(oldCCL);
                oldCCL = bindThread();

                // Initialize logger again. Other components might have used it
                // too early, so it should be reset.
                logger = null;
                getLogger();

                Realm realm = getRealmInternal();
                if(null != realm) {
                    if (realm instanceof Lifecycle) {
                        ((Lifecycle) realm).start();
                    }

                    // Place the CredentialHandler into the ServletContext so
                    // applications can have access to it. Wrap it in a ""safe""
                    // handler so application's can't modify it.
                    CredentialHandler safeHandler = new CredentialHandler() {
                        @Override
                        public boolean matches(String inputCredentials, String storedCredentials) {
                            return getRealmInternal().getCredentialHandler().matches(inputCredentials, storedCredentials);
                        }

                        @Override
                        public String mutate(String inputCredentials) {
                            return getRealmInternal().getCredentialHandler().mutate(inputCredentials);
                        }
                    };
                    context.setAttribute(Globals.CREDENTIAL_HANDLER, safeHandler);
                }

                // Notify our interested LifecycleListeners
                fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null);

                // Start our child containers, if not already started
                for (Container child : findChildren()) {
                    if (!child.getState().isAvailable()) {
                        child.start();
                    }
                }

                // Start the Valves in our pipeline (including the basic),
                // if any
                if (pipeline instanceof Lifecycle) {
                    ((Lifecycle) pipeline).start();
                }

                // Acquire clustered manager
                Manager contextManager = null;
                Manager manager = getManager();
                if (manager == null) {
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""standardContext.cluster.noManager"",
                                Boolean.valueOf((getCluster() != null)),
                                Boolean.valueOf(distributable)));
                    }
                    if ((getCluster() != null) && distributable) {
                        try {
                            contextManager = getCluster().createManager(getName());
                        } catch (Exception ex) {
                            log.error(sm.getString(""standardContext.cluster.managerError""), ex);
                            ok = false;
                        }
                    } else {
                        contextManager = new StandardManager();
                    }
                }

                // Configure default manager if none was specified
                if (contextManager != null) {
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""standardContext.manager"",
                                contextManager.getClass().getName()));
                    }
                    setManager(contextManager);
                }

                if (manager!=null && (getCluster() != null) && distributable) {
                    //let the cluster know that there is a context that is distributable
                    //and that it has its own manager
                    getCluster().registerManager(manager);
                }
            }

            if (!getConfigured()) {
                log.error(sm.getString(""standardContext.configurationFail""));
                ok = false;
            }

            // We put the resources into the servlet context
            if (ok) {
                getServletContext().setAttribute
                    (Globals.RESOURCES_ATTR, getResources());

                if (getInstanceManager() == null) {
                    setInstanceManager(createInstanceManager());
                }
                getServletContext().setAttribute(
                        InstanceManager.class.getName(), getInstanceManager());
                InstanceManagerBindings.bind(getLoader().getClassLoader(), getInstanceManager());

                // Create context attributes that will be required
                getServletContext().setAttribute(
                        JarScanner.class.getName(), getJarScanner());

                // Make the version info available
                getServletContext().setAttribute(Globals.WEBAPP_VERSION, getWebappVersion());
            }

            // Set up the context init params
            mergeParameters();

            // Call ServletContainerInitializers
            for (Map.Entry<ServletContainerInitializer, Set<Class<?>>> entry :
                initializers.entrySet()) {
                try {
                    entry.getKey().onStartup(entry.getValue(),
                            getServletContext());
                } catch (ServletException e) {
                    log.error(sm.getString(""standardContext.sciFail""), e);
                    ok = false;
                    break;
                }
            }

            // Configure and call application event listeners
            if (ok) {
                if (!listenerStart()) {
                    log.error(sm.getString(""standardContext.listenerFail""));
                    ok = false;
                }
            }

            // Check constraints for uncovered HTTP methods
            // Needs to be after SCIs and listeners as they may programmatically
            // change constraints
            if (ok) {
                checkConstraintsForUncoveredMethods(findConstraints());
            }

            try {
                // Start manager
                Manager manager = getManager();
                if (manager instanceof Lifecycle) {
                    ((Lifecycle) manager).start();
                }
            } catch(Exception e) {
                log.error(sm.getString(""standardContext.managerFail""), e);
                ok = false;
            }

            // Configure and call application filters
            if (ok) {
                if (!filterStart()) {
                    log.error(sm.getString(""standardContext.filterFail""));
                    ok = false;
                }
            }

            // Load and initialize all ""load on startup"" servlets
            if (ok) {
                if (!loadOnStartup(findChildren())){
                    log.error(sm.getString(""standardContext.servletFail""));
                    ok = false;
                }
            }

            // Start ContainerBackgroundProcessor thread
            super.threadStart();
        } finally {
            // Unbinding thread
            unbindThread(oldCCL);
        }

        // Set available status depending upon startup success
        if (ok) {
            if (log.isDebugEnabled()) {
                log.debug(""Starting completed"");
            }
        } else {
            log.error(sm.getString(""standardContext.startFailed"", getName()));
        }

        startTime=System.currentTimeMillis();

        // Send j2ee.state.running notification
        if (ok && (this.getObjectName() != null)) {
            Notification notification =
                new Notification(""j2ee.state.running"", this.getObjectName(),
                                 sequenceNumber.getAndIncrement());
            broadcaster.sendNotification(notification);
        }

        // The WebResources implementation caches references to JAR files. On
        // some platforms these references may lock the JAR files. Since web
        // application start is likely to have read from lots of JARs, trigger
        // a clean-up now.
        getResources().gc();

        // Reinitializing if something went wrong
        if (!ok) {
            setState(LifecycleState.FAILED);
            // Send j2ee.object.failed notification
            if (this.getObjectName() != null) {
                Notification notification = new Notification(""j2ee.object.failed"",
                        this.getObjectName(), sequenceNumber.getAndIncrement());
                broadcaster.sendNotification(notification);
            }
        } else {
            setState(LifecycleState.STARTING);
        }
    }",,
tomcat,15906,"log.warn(sm.getString(""parallelNioSender.send.fail"", sender.getDestination().getName()), x)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/ParallelNioSender.java/#L193,"private SendResult doLoop(long selectTimeOut, int maxAttempts, boolean waitForAck, ChannelMessage msg)
            throws ChannelException {
        SendResult result = new SendResult();
        int selectedKeys;
        try {
            selectedKeys = selector.select(selectTimeOut);
        } catch (IOException ioe) {
            throw new ChannelException(sm.getString(""parallelNioSender.send.failed""), ioe);
        }

        if (selectedKeys == 0) {
            return result;
        }

        Iterator<SelectionKey> it = selector.selectedKeys().iterator();
        while (it.hasNext()) {
            SelectionKey sk = it.next();
            it.remove();
            int readyOps = sk.readyOps();
            sk.interestOps(sk.interestOps() & ~readyOps);
            NioSender sender = (NioSender) sk.attachment();
            try {
                if (sender.process(sk,waitForAck)) {
                    sender.setComplete(true);
                    result.complete(sender);
                    if ( Logs.MESSAGES.isTraceEnabled() ) {
                        Logs.MESSAGES.trace(""ParallelNioSender - Sent msg:"" +
                                new UniqueId(msg.getUniqueId()) + "" at "" +
                                new java.sql.Timestamp(System.currentTimeMillis()) + "" to "" +
                                sender.getDestination().getName());
                    }
                    SenderState.getSenderState(sender.getDestination()).setReady();
                }//end if
            } catch (Exception x) {
                if (log.isTraceEnabled()) {
                    log.trace(""Error while processing send to "" + sender.getDestination().getName(),
                            x);
                }
                SenderState state = SenderState.getSenderState(sender.getDestination());
                int attempt = sender.getAttempt()+1;
                boolean retry = (attempt <= maxAttempts && maxAttempts>0);
                synchronized (state) {

                    //sk.cancel();
                    if (state.isSuspect()) {
                        state.setFailing();
                    }
                    if (state.isReady()) {
                        state.setSuspect();
                        if ( retry ) {
                            log.warn(sm.getString(""parallelNioSender.send.fail.retrying"", sender.getDestination().getName()));
                        } else {
                            
---------------Reference log start----------------
log.warn(sm.getString(""parallelNioSender.send.fail"", sender.getDestination().getName()), x)
---------------Reference log end----------------
                        }
                    }
                }
                if ( !isConnected() ) {
                    log.warn(sm.getString(""parallelNioSender.sender.disconnected.notRetry"", sender.getDestination().getName()));
                    ChannelException cx = new ChannelException(sm.getString(""parallelNioSender.sender.disconnected.sendFailed""), x);
                    cx.addFaultyMember(sender.getDestination(),x);
                    result.failed(cx);
                    break;
                }

                byte[] data = sender.getMessage();
                if (retry) {
                    try {
                        sender.disconnect();
                        sender.connect();
                        sender.setAttempt(attempt);
                        sender.setMessage(data);
                    } catch (Exception ignore){
                        state.setFailing();
                    }
                } else {
                    ChannelException cx = new ChannelException(
                            sm.getString(""parallelNioSender.sendFailed.attempt"",
                                    Integer.toString(sender.getAttempt()),
                                    Integer.toString(maxAttempts)), x);
                    cx.addFaultyMember(sender.getDestination(),x);
                    result.failed(cx);
                }//end if
            }
        }
        return result;
    }",,
tomcat,16062,"log.warn(sm.getString(""namingResources.mbeanCreateFail"", environment.getName()), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/deploy/NamingResourcesImpl.java/#L310,"@Override
    public void addEnvironment(ContextEnvironment environment) {

        if (entries.contains(environment.getName())) {
            ContextEnvironment ce = findEnvironment(environment.getName());
            ContextResourceLink rl = findResourceLink(environment.getName());
            if (ce != null) {
                if (ce.getOverride()) {
                    removeEnvironment(environment.getName());
                } else {
                    return;
                }
            } else if (rl != null) {
                // Link. Need to look at the global resources
                NamingResourcesImpl global = getServer().getGlobalNamingResources();
                if (global.findEnvironment(rl.getGlobal()) != null) {
                    if (global.findEnvironment(rl.getGlobal()).getOverride()) {
                        removeResourceLink(environment.getName());
                    } else {
                        return;
                    }
                }
            } else {
                // It exists but it isn't an env or a res link...
                return;
            }
        }

        List<InjectionTarget> injectionTargets = environment.getInjectionTargets();
        String value = environment.getValue();
        String lookupName = environment.getLookupName();

        // Entries with injection targets but no value are effectively ignored
        if (injectionTargets != null && injectionTargets.size() > 0 &&
                (value == null || value.length() == 0)) {
            return;
        }

        // Entries with lookup-name and value are an error (EE.5.4.1.3)
        if (value != null && value.length() > 0 && lookupName != null && lookupName.length() > 0) {
            throw new IllegalArgumentException(
                    sm.getString(""namingResources.envEntryLookupValue"", environment.getName()));
        }

        if (!checkResourceType(environment)) {
            throw new IllegalArgumentException(sm.getString(
                    ""namingResources.resourceTypeFail"", environment.getName(),
                    environment.getType()));
        }

        entries.add(environment.getName());

        synchronized (envs) {
            environment.setNamingResources(this);
            envs.put(environment.getName(), environment);
        }
        support.firePropertyChange(""environment"", null, environment);

        // Register with JMX
        if (resourceRequireExplicitRegistration) {
            try {
                MBeanUtils.createMBean(environment);
            } catch (Exception e) {
                
---------------Reference log start----------------
log.warn(sm.getString(""namingResources.mbeanCreateFail"", environment.getName()), e)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,17435,"digester.log.debug(""[FactoryCreateRule] Ignored exception:"", e)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/FactoryCreateRule.java/#L105,"@Override
    public void begin(String namespace, String name, Attributes attributes) throws Exception {

        if (ignoreCreateExceptions) {

            if (exceptionIgnoredStack == null) {
                exceptionIgnoredStack = new ArrayStack<>();
            }

            try {
                Object instance = creationFactory.createObject(attributes);

                if (digester.log.isDebugEnabled()) {
                    digester.log.debug(""[FactoryCreateRule]{"" + digester.match +
                            ""} New "" + instance.getClass().getName());
                }
                digester.push(instance);
                exceptionIgnoredStack.push(Boolean.FALSE);

            } catch (Exception e) {
                // log message and error
                if (digester.log.isInfoEnabled()) {
                    digester.log.info(sm.getString(""rule.createError"",
                        ((e.getMessage() == null) ? e.getClass().getName() : e.getMessage())));
                    if (digester.log.isDebugEnabled()) {
                        
---------------Reference log start----------------
digester.log.debug(""[FactoryCreateRule] Ignored exception:"", e)
---------------Reference log end----------------
                    }
                }
                exceptionIgnoredStack.push(Boolean.TRUE);
            }

        } else {
            Object instance = creationFactory.createObject(attributes);

            if (digester.log.isDebugEnabled()) {
                digester.log.debug(""[FactoryCreateRule]{"" + digester.match +
                        ""} New "" + instance.getClass().getName());
            }
            digester.push(instance);
        }
    }",,
tomcat,15907,"log.warn(sm.getString(""parallelNioSender.send.fail.retrying"", sender.getDestination().getName()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/ParallelNioSender.java/#L191,"private SendResult doLoop(long selectTimeOut, int maxAttempts, boolean waitForAck, ChannelMessage msg)
            throws ChannelException {
        SendResult result = new SendResult();
        int selectedKeys;
        try {
            selectedKeys = selector.select(selectTimeOut);
        } catch (IOException ioe) {
            throw new ChannelException(sm.getString(""parallelNioSender.send.failed""), ioe);
        }

        if (selectedKeys == 0) {
            return result;
        }

        Iterator<SelectionKey> it = selector.selectedKeys().iterator();
        while (it.hasNext()) {
            SelectionKey sk = it.next();
            it.remove();
            int readyOps = sk.readyOps();
            sk.interestOps(sk.interestOps() & ~readyOps);
            NioSender sender = (NioSender) sk.attachment();
            try {
                if (sender.process(sk,waitForAck)) {
                    sender.setComplete(true);
                    result.complete(sender);
                    if ( Logs.MESSAGES.isTraceEnabled() ) {
                        Logs.MESSAGES.trace(""ParallelNioSender - Sent msg:"" +
                                new UniqueId(msg.getUniqueId()) + "" at "" +
                                new java.sql.Timestamp(System.currentTimeMillis()) + "" to "" +
                                sender.getDestination().getName());
                    }
                    SenderState.getSenderState(sender.getDestination()).setReady();
                }//end if
            } catch (Exception x) {
                if (log.isTraceEnabled()) {
                    log.trace(""Error while processing send to "" + sender.getDestination().getName(),
                            x);
                }
                SenderState state = SenderState.getSenderState(sender.getDestination());
                int attempt = sender.getAttempt()+1;
                boolean retry = (attempt <= maxAttempts && maxAttempts>0);
                synchronized (state) {

                    //sk.cancel();
                    if (state.isSuspect()) {
                        state.setFailing();
                    }
                    if (state.isReady()) {
                        state.setSuspect();
                        if ( retry ) {
                            
---------------Reference log start----------------
log.warn(sm.getString(""parallelNioSender.send.fail.retrying"", sender.getDestination().getName()))
---------------Reference log end----------------
                        } else {
                            log.warn(sm.getString(""parallelNioSender.send.fail"", sender.getDestination().getName()), x);
                        }
                    }
                }
                if ( !isConnected() ) {
                    log.warn(sm.getString(""parallelNioSender.sender.disconnected.notRetry"", sender.getDestination().getName()));
                    ChannelException cx = new ChannelException(sm.getString(""parallelNioSender.sender.disconnected.sendFailed""), x);
                    cx.addFaultyMember(sender.getDestination(),x);
                    result.failed(cx);
                    break;
                }

                byte[] data = sender.getMessage();
                if (retry) {
                    try {
                        sender.disconnect();
                        sender.connect();
                        sender.setAttempt(attempt);
                        sender.setMessage(data);
                    } catch (Exception ignore){
                        state.setFailing();
                    }
                } else {
                    ChannelException cx = new ChannelException(
                            sm.getString(""parallelNioSender.sendFailed.attempt"",
                                    Integer.toString(sender.getAttempt()),
                                    Integer.toString(maxAttempts)), x);
                    cx.addFaultyMember(sender.getDestination(),x);
                    result.failed(cx);
                }//end if
            }
        }
        return result;
    }",,
tomcat,17386,"log.error(sm.getString(""digester.error.finish""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/Digester.java/#L943,"@Override
    public void endDocument() throws SAXException {

        if (saxLog.isDebugEnabled()) {
            if (getCount() > 1) {
                saxLog.debug(""endDocument():  "" + getCount() + "" elements left"");
            } else {
                saxLog.debug(""endDocument()"");
            }
        }

        while (getCount() > 1) {
            pop();
        }

        // Fire ""finish"" events for all defined rules
        for (Rule rule : getRules().rules()) {
            try {
                rule.finish();
            } catch (Exception e) {
                
---------------Reference log start----------------
log.error(sm.getString(""digester.error.finish""), e)
---------------Reference log end----------------
                throw createSAXException(e);
            } catch (Error e) {
                log.error(sm.getString(""digester.error.finish""), e);
                throw e;
            }
        }

        // Perform final cleanup
        clear();

    }",,
tomcat,17437,"digester.log.trace(""[FactoryCreateRule] No creation so no push so no pop"")",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/FactoryCreateRule.java/#L140,"@Override
    public void end(String namespace, String name) throws Exception {

        // check if object was created
        // this only happens if an exception was thrown and we're ignoring them
        if (
                ignoreCreateExceptions &&
                exceptionIgnoredStack != null &&
                !(exceptionIgnoredStack.empty())) {

            if ((exceptionIgnoredStack.pop()).booleanValue()) {
                // creation exception was ignored
                // nothing was put onto the stack
                if (digester.log.isTraceEnabled()) {
                    
---------------Reference log start----------------
digester.log.trace(""[FactoryCreateRule] No creation so no push so no pop"")
---------------Reference log end----------------
                }
                return;
            }
        }

        Object top = digester.pop();
        if (digester.log.isDebugEnabled()) {
            digester.log.debug(""[FactoryCreateRule]{"" + digester.match +
                    ""} Pop "" + top.getClass().getName());
        }

    }",,
tomcat,15274,"log.warn(sm.getString(""coyoteResponse.encoding.invalid"", charset), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/connector/Response.java/#L797,"@Override
    public void setCharacterEncoding(String charset) {

        if (isCommitted()) {
            return;
        }

        // Ignore any call from an included servlet
        if (included) {
            return;
        }

        // Ignore any call made after the getWriter has been invoked
        // The default should be used
        if (usingWriter) {
            return;
        }

        try {
            getCoyoteResponse().setCharacterEncoding(charset);
        } catch (UnsupportedEncodingException e) {
            
---------------Reference log start----------------
log.warn(sm.getString(""coyoteResponse.encoding.invalid"", charset), e)
---------------Reference log end----------------
            return;
        }
        if (charset == null) {
            isCharacterEncodingSet = false;
        } else {
            isCharacterEncodingSet = true;
        }
    }",,
tomcat,16405,"log.info(sm.getString(""farmWarDeployer.modInstall"", cn.getName(), deployWar.getAbsolutePath()))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/deploy/FarmWarDeployer.java/#L474,"@Override
    public void fileModified(File newWar) {
        try {
            File deployWar = new File(getDeployDirFile(), newWar.getName());
            ContextName cn = new ContextName(deployWar.getName(), true);
            if (deployWar.exists() && deployWar.lastModified() > newWar.lastModified()) {
                if (log.isInfoEnabled()) {
                    log.info(sm.getString(""farmWarDeployer.alreadyDeployed"", cn.getName()));
                }
                return;
            }
            if (log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""farmWarDeployer.modInstall"", cn.getName(), deployWar.getAbsolutePath()))
---------------Reference log end----------------
            }
            // install local
            if (tryAddServiced(cn.getName())) {
                try {
                    copy(newWar, deployWar);
                } finally {
                    removeServiced(cn.getName());
                }
                check(cn.getName());
            } else {
                log.error(sm.getString(""farmWarDeployer.servicingDeploy"",
                        cn.getName(), deployWar.getName()));
            }
            install(cn.getName(), deployWar);
        } catch (Exception x) {
            log.error(sm.getString(""farmWarDeployer.modInstallFail""), x);
        }
    }",,
tomcat,17171,"log.warn(sm.getString(""openssl.doubleInit""))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/openssl/OpenSSLContext.java/#L212,"@Override
    public synchronized void init(KeyManager[] kms, TrustManager[] tms, SecureRandom sr) {
        if (initialized) {
            
---------------Reference log start----------------
log.warn(sm.getString(""openssl.doubleInit""))
---------------Reference log end----------------
            return;
        }
        try {
            if (sslHostConfig.getInsecureRenegotiation()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION);
            }

            // Use server's preference order for ciphers (rather than
            // client's)
            if (sslHostConfig.getHonorCipherOrder()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_CIPHER_SERVER_PREFERENCE);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_CIPHER_SERVER_PREFERENCE);
            }

            // Disable compression if requested
            if (sslHostConfig.getDisableCompression()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_NO_COMPRESSION);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_NO_COMPRESSION);
            }

            // Disable TLS Session Tickets (RFC4507) to protect perfect forward secrecy
            if (sslHostConfig.getDisableSessionTickets()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_NO_TICKET);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_NO_TICKET);
            }

            // List the ciphers that the client is permitted to negotiate
            SSLContext.setCipherSuite(ctx, sslHostConfig.getCiphers());

            if (certificate.getCertificateFile() == null) {
                certificate.setCertificateKeyManager(OpenSSLUtil.chooseKeyManager(kms));
            }

            addCertificate(certificate);

            // Client certificate verification
            int value = 0;
            switch (sslHostConfig.getCertificateVerification()) {
            case NONE:
                value = SSL.SSL_CVERIFY_NONE;
                break;
            case OPTIONAL:
                value = SSL.SSL_CVERIFY_OPTIONAL;
                break;
            case OPTIONAL_NO_CA:
                value = SSL.SSL_CVERIFY_OPTIONAL_NO_CA;
                break;
            case REQUIRED:
                value = SSL.SSL_CVERIFY_REQUIRE;
                break;
            }
            SSLContext.setVerify(ctx, value, sslHostConfig.getCertificateVerificationDepth());

            if (tms != null) {
                // Client certificate verification based on custom trust managers
                x509TrustManager = chooseTrustManager(tms);
                SSLContext.setCertVerifyCallback(ctx, new CertificateVerifier() {
                    @Override
                    public boolean verify(long ssl, byte[][] chain, String auth) {
                        X509Certificate[] peerCerts = certificates(chain);
                        try {
                            x509TrustManager.checkClientTrusted(peerCerts, auth);
                            return true;
                        } catch (Exception e) {
                            log.debug(sm.getString(""openssl.certificateVerificationFailed""), e);
                        }
                        return false;
                    }
                });
                // Pass along the DER encoded certificates of the accepted client
                // certificate issuers, so that their subjects can be presented
                // by the server during the handshake to allow the client choosing
                // an acceptable certificate
                for (X509Certificate caCert : x509TrustManager.getAcceptedIssuers()) {
                    SSLContext.addClientCACertificateRaw(ctx, caCert.getEncoded());
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""openssl.addedClientCaCert"", caCert.toString()));
                    }
                }
            } else {
                // Client certificate verification based on trusted CA files and dirs
                SSLContext.setCACertificate(ctx,
                        SSLHostConfig.adjustRelativePath(sslHostConfig.getCaCertificateFile()),
                        SSLHostConfig.adjustRelativePath(sslHostConfig.getCaCertificatePath()));
            }

            if (negotiableProtocols != null && negotiableProtocols.size() > 0) {
                List<String> protocols = new ArrayList<>(negotiableProtocols);
                protocols.add(""http/1.1"");
                String[] protocolsArray = protocols.toArray(new String[0]);
                SSLContext.setAlpnProtos(ctx, protocolsArray, SSL.SSL_SELECTOR_FAILURE_NO_ADVERTISE);
                SSLContext.setNpnProtos(ctx, protocolsArray, SSL.SSL_SELECTOR_FAILURE_NO_ADVERTISE);
            }

            // Apply OpenSSLConfCmd if used
            OpenSSLConf openSslConf = sslHostConfig.getOpenSslConf();
            if (openSslConf != null && cctx != 0) {
                // Check OpenSSLConfCmd if used
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""openssl.checkConf""));
                }
                try {
                    if (!openSslConf.check(cctx)) {
                        log.error(sm.getString(""openssl.errCheckConf""));
                        throw new Exception(sm.getString(""openssl.errCheckConf""));
                    }
                } catch (Exception e) {
                    throw new Exception(sm.getString(""openssl.errCheckConf""), e);
                }
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""openssl.applyConf""));
                }
                try {
                    if (!openSslConf.apply(cctx, ctx)) {
                        log.error(sm.getString(""openssl.errApplyConf""));
                        throw new SSLException(sm.getString(""openssl.errApplyConf""));
                    }
                } catch (Exception e) {
                    throw new SSLException(sm.getString(""openssl.errApplyConf""), e);
                }
                // Reconfigure the enabled protocols
                int opts = SSLContext.getOptions(ctx);
                List<String> enabled = new ArrayList<>();
                // Seems like there is no way to explicitly disable SSLv2Hello
                // in OpenSSL so it is always enabled
                enabled.add(Constants.SSL_PROTO_SSLv2Hello);
                if ((opts & SSL.SSL_OP_NO_TLSv1) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1);
                }
                if ((opts & SSL.SSL_OP_NO_TLSv1_1) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1_1);
                }
                if ((opts & SSL.SSL_OP_NO_TLSv1_2) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1_2);
                }
                if ((opts & SSL.SSL_OP_NO_SSLv2) == 0) {
                    enabled.add(Constants.SSL_PROTO_SSLv2);
                }
                if ((opts & SSL.SSL_OP_NO_SSLv3) == 0) {
                    enabled.add(Constants.SSL_PROTO_SSLv3);
                }
                sslHostConfig.setEnabledProtocols(
                        enabled.toArray(new String[0]));
                // Reconfigure the enabled ciphers
                sslHostConfig.setEnabledCiphers(SSLContext.getCiphers(ctx));
            }

            sessionContext = new OpenSSLSessionContext(this);
            // If client authentication is being used, OpenSSL requires that
            // this is set so always set it in case an app is configured to
            // require it
            sessionContext.setSessionIdContext(SSLContext.DEFAULT_SESSION_ID_CONTEXT);
            sslHostConfig.setOpenSslContext(Long.valueOf(ctx));
            initialized = true;
        } catch (Exception e) {
            log.warn(sm.getString(""openssl.errorSSLCtxInit""), e);
            destroy();
        }
    }",,
tomcat,16556,"log.fatal(errorMessage, e)",fatal,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/AprLifecycleListener.java/#L142,"@Override
    public void lifecycleEvent(LifecycleEvent event) {

        if (Lifecycle.BEFORE_INIT_EVENT.equals(event.getType())) {
            synchronized (lock) {
                init();
                for (String msg : initInfoLogMessages) {
                    log.info(msg);
                }
                initInfoLogMessages.clear();
                if (AprStatus.isAprAvailable()) {
                    try {
                        initializeSSL();
                    } catch (Throwable t) {
                        t = ExceptionUtils.unwrapInvocationTargetException(t);
                        ExceptionUtils.handleThrowable(t);
                        log.error(sm.getString(""aprListener.sslInit""), t);
                    }
                }
                // Failure to initialize FIPS mode is fatal
                if (!(null == FIPSMode || ""off"".equalsIgnoreCase(FIPSMode)) && !isFIPSModeActive()) {
                    String errorMessage = sm.getString(""aprListener.initializeFIPSFailed"");
                    Error e = new Error(errorMessage);
                    // Log here, because thrown error might be not logged
                    
---------------Reference log start----------------
log.fatal(errorMessage, e)
---------------Reference log end----------------
                    throw e;
                }
            }
        } else if (Lifecycle.AFTER_DESTROY_EVENT.equals(event.getType())) {
            synchronized (lock) {
                if (!AprStatus.isAprAvailable()) {
                    return;
                }
                try {
                    terminateAPR();
                } catch (Throwable t) {
                    t = ExceptionUtils.unwrapInvocationTargetException(t);
                    ExceptionUtils.handleThrowable(t);
                    log.info(sm.getString(""aprListener.aprDestroy""));
                }
            }
        }

    }",,
tomcat,15204,"manager.getContext().getLogger().error(sm.getString(""standardSession.sessionEvent""), t)",getContext,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/StandardSession.java/#L390,"public void tellNew() {

        // Notify interested session event listeners
        fireSessionEvent(Session.SESSION_CREATED_EVENT, null);

        // Notify interested application event listeners
        Context context = manager.getContext();
        Object listeners[] = context.getApplicationLifecycleListeners();
        if (listeners != null && listeners.length > 0) {
            HttpSessionEvent event =
                new HttpSessionEvent(getSession());
            for (Object o : listeners) {
                if (!(o instanceof HttpSessionListener)) {
                    continue;
                }
                HttpSessionListener listener = (HttpSessionListener) o;
                try {
                    context.fireContainerEvent(""beforeSessionCreated"", listener);
                    listener.sessionCreated(event);
                    context.fireContainerEvent(""afterSessionCreated"", listener);
                } catch (Throwable t) {
                    ExceptionUtils.handleThrowable(t);
                    try {
                        context.fireContainerEvent(""afterSessionCreated"", listener);
                    } catch (Exception e) {
                        // Ignore
                    }
                    
---------------Reference log start----------------
manager.getContext().getLogger().error(sm.getString(""standardSession.sessionEvent""), t)
---------------Reference log end----------------
                }
            }
        }

    }",,
tomcat,16637,"log.debug(""Configuring application event listeners"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardContext.java/#L4626,"public boolean listenerStart() {

        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Configuring application event listeners"")
---------------Reference log end----------------
        }

        // Instantiate the required listeners
        String listeners[] = findApplicationListeners();
        Object results[] = new Object[listeners.length];
        boolean ok = true;
        for (int i = 0; i < results.length; i++) {
            if (getLogger().isDebugEnabled()) {
                getLogger().debug("" Configuring event listener class '"" +
                    listeners[i] + ""'"");
            }
            try {
                String listener = listeners[i];
                results[i] = getInstanceManager().newInstance(listener);
            } catch (Throwable t) {
                t = ExceptionUtils.unwrapInvocationTargetException(t);
                ExceptionUtils.handleThrowable(t);
                getLogger().error(sm.getString(
                        ""standardContext.applicationListener"", listeners[i]), t);
                ok = false;
            }
        }
        if (!ok) {
            getLogger().error(sm.getString(""standardContext.applicationSkipped""));
            return false;
        }

        // Sort listeners in two arrays
        List<Object> eventListeners = new ArrayList<>();
        List<Object> lifecycleListeners = new ArrayList<>();
        for (Object result : results) {
            if ((result instanceof ServletContextAttributeListener)
                    || (result instanceof ServletRequestAttributeListener)
                    || (result instanceof ServletRequestListener)
                    || (result instanceof HttpSessionIdListener)
                    || (result instanceof HttpSessionAttributeListener)) {
                eventListeners.add(result);
            }
            if ((result instanceof ServletContextListener)
                    || (result instanceof HttpSessionListener)) {
                lifecycleListeners.add(result);
            }
        }

        // Listener instances may have been added directly to this Context by
        // ServletContextInitializers and other code via the pluggability APIs.
        // Put them these listeners after the ones defined in web.xml and/or
        // annotations then overwrite the list of instances with the new, full
        // list.
        eventListeners.addAll(Arrays.asList(getApplicationEventListeners()));
        setApplicationEventListeners(eventListeners.toArray());
        for (Object lifecycleListener: getApplicationLifecycleListeners()) {
            lifecycleListeners.add(lifecycleListener);
            if (lifecycleListener instanceof ServletContextListener) {
                noPluggabilityListeners.add(lifecycleListener);
            }
        }
        setApplicationLifecycleListeners(lifecycleListeners.toArray());

        // Send application start events

        if (getLogger().isDebugEnabled()) {
            getLogger().debug(""Sending application start events"");
        }

        // Ensure context is not null
        getServletContext();
        context.setNewServletContextListenerAllowed(false);

        Object instances[] = getApplicationLifecycleListeners();
        if (instances == null || instances.length == 0) {
            return ok;
        }

        ServletContextEvent event = new ServletContextEvent(getServletContext());
        ServletContextEvent tldEvent = null;
        if (noPluggabilityListeners.size() > 0) {
            noPluggabilityServletContext = new NoPluggabilityServletContext(getServletContext());
            tldEvent = new ServletContextEvent(noPluggabilityServletContext);
        }
        for (Object instance : instances) {
            if (!(instance instanceof ServletContextListener)) {
                continue;
            }
            ServletContextListener listener = (ServletContextListener) instance;
            try {
                fireContainerEvent(""beforeContextInitialized"", listener);
                if (noPluggabilityListeners.contains(listener)) {
                    listener.contextInitialized(tldEvent);
                } else {
                    listener.contextInitialized(event);
                }
                fireContainerEvent(""afterContextInitialized"", listener);
            } catch (Throwable t) {
                ExceptionUtils.handleThrowable(t);
                fireContainerEvent(""afterContextInitialized"", listener);
                getLogger().error(sm.getString(""standardContext.listenerStart"",
                        instance.getClass().getName()), t);
                ok = false;
            }
        }
        return ok;

    }",,
tomcat,15865,"log.error(sm.getString(""nioReplicationTask.exception.drainChannel""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/NioReplicationTask.java/#L119,"@Override
    public synchronized void run() {
        if ( buffer == null ) {
            int size = getRxBufSize();
            if (key.channel() instanceof DatagramChannel) {
                size = ChannelReceiver.MAX_UDP_SIZE;
            }
            if ( (getOptions() & OPTION_DIRECT_BUFFER) == OPTION_DIRECT_BUFFER) {
                buffer = ByteBuffer.allocateDirect(size);
            } else {
                buffer = ByteBuffer.allocate(size);
            }
        } else {
            buffer.clear();
        }
        if (key == null) {
            return; // just in case
        }
        if ( log.isTraceEnabled() ) {
            log.trace(""Servicing key:""+key);
        }

        try {
            ObjectReader reader = (ObjectReader)key.attachment();
            if ( reader == null ) {
                if ( log.isTraceEnabled() ) {
                    log.trace(""No object reader, cancelling:""+key);
                }
                cancelKey(key);
            } else {
                if ( log.isTraceEnabled() ) {
                    log.trace(""Draining channel:""+key);
                }

                drainChannel(key, reader);
            }
        } catch (Exception e) {
            //this is common, since the sockets on the other
            //end expire after a certain time.
            if ( e instanceof CancelledKeyException ) {
                //do nothing
            } else if ( e instanceof IOException ) {
                //don't spew out stack traces for IO exceptions unless debug is enabled.
                if (log.isDebugEnabled()) {
                    log.debug (""IOException in replication worker, unable to drain channel. Probable cause: Keep alive socket closed[""+e.getMessage()+""]."", e);
                } else {
                    log.warn (sm.getString(""nioReplicationTask.unable.drainChannel.ioe"", e.getMessage()));
                }
            } else if ( log.isErrorEnabled() ) {
                //this is a real error, log it.
                
---------------Reference log start----------------
log.error(sm.getString(""nioReplicationTask.exception.drainChannel""), e)
---------------Reference log end----------------
            }
            cancelKey(key);
        }
        key = null;
        // done, ready for more, return to pool
        getTaskPool().returnWorker (this);
    }",,
tomcat,15425,"log.debug(""  --> Returning stream from parent"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/loader/WebappClassLoaderBase.java/#L1227,"@Override
    public InputStream getResourceAsStream(String name) {

        if (log.isDebugEnabled()) {
            log.debug(""getResourceAsStream("" + name + "")"");
        }

        checkStateForResourceLoading(name);

        InputStream stream = null;

        boolean delegateFirst = delegate || filter(name, false);

        // (1) Delegate to parent if requested
        if (delegateFirst) {
            if (log.isDebugEnabled()) {
                log.debug(""  Delegating to parent classloader "" + parent);
            }
            stream = parent.getResourceAsStream(name);
            if (stream != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""  --> Returning stream from parent"");
                }
                return stream;
            }
        }

        // (2) Search local repositories
        if (log.isDebugEnabled()) {
            log.debug(""  Searching local repositories"");
        }
        String path = nameToPath(name);
        WebResource resource = resources.getClassLoaderResource(path);
        if (resource.exists()) {
            stream = resource.getInputStream();
            // Filter out .class resources through the ClassFileTranformer
            if (name.endsWith(CLASS_FILE_SUFFIX) && transformers.size() > 0) {
                // If the resource is a class, decorate it with any attached transformers
                ByteArrayOutputStream baos = new ByteArrayOutputStream();
                byte[] buf = new byte[8192];
                int numRead;
                try {
                    while ((numRead = stream.read(buf)) >= 0) {
                        baos.write(buf, 0, numRead);
                    }
                } catch (IOException e) {
                    log.error(sm.getString(""webappClassLoader.transformError"", name), e);
                    return null;
                } finally {
                    try {
                        stream.close();
                    } catch (IOException e) {
                    }
                }
                byte[] binaryContent = baos.toByteArray();
                String internalName = path.substring(1, path.length() - CLASS_FILE_SUFFIX.length());
                for (ClassFileTransformer transformer : this.transformers) {
                    try {
                        byte[] transformed = transformer.transform(
                                this, internalName, null, null, binaryContent);
                        if (transformed != null) {
                            binaryContent = transformed;
                        }
                    } catch (IllegalClassFormatException e) {
                        log.error(sm.getString(""webappClassLoader.transformError"", name), e);
                        return null;
                    }
                }
                stream = new ByteArrayInputStream(binaryContent);
            }
            trackLastModified(path, resource);
        }
        try {
            if (hasExternalRepositories && stream == null) {
                URL url = super.findResource(name);
                if (url != null) {
                    stream = url.openStream();
                }
            }
        } catch (IOException e) {
            // Ignore
        }
        if (stream != null) {
            if (log.isDebugEnabled()) {
                log.debug(""  --> Returning stream from local"");
            }
            return stream;
        }

        // (3) Delegate to parent unconditionally
        if (!delegateFirst) {
            if (log.isDebugEnabled()) {
                log.debug(""  Delegating to parent classloader unconditionally "" + parent);
            }
            stream = parent.getResourceAsStream(name);
            if (stream != null) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""  --> Returning stream from parent"")
---------------Reference log end----------------
                }
                return stream;
            }
        }

        // (4) Resource was not found
        if (log.isDebugEnabled()) {
            log.debug(""  --> Resource not found, returning null"");
        }
        return null;
    }",,
tomcat,15208,"manager.getContext().getLogger().error(sm.getString(""standardSession.attributeEvent""), t)",getContext,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/StandardSession.java/#L884,"public void passivate() {

        // Notify interested session event listeners
        fireSessionEvent(Session.SESSION_PASSIVATED_EVENT, null);

        // Notify ActivationListeners
        HttpSessionEvent event = null;
        String keys[] = keys();
        for (String key : keys) {
            Object attribute = attributes.get(key);
            if (attribute instanceof HttpSessionActivationListener) {
                if (event == null) {
                    event = new HttpSessionEvent(getSession());
                }
                try {
                    ((HttpSessionActivationListener) attribute).sessionWillPassivate(event);
                } catch (Throwable t) {
                    ExceptionUtils.handleThrowable(t);
                    
---------------Reference log start----------------
manager.getContext().getLogger().error(sm.getString(""standardSession.attributeEvent""), t)
---------------Reference log end----------------
                }
            }
        }

    }",,
tomcat,16733,"log.error(sm.getString(""jreLeakListener.jarUrlConnCacheFail""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/JreMemoryLeakPreventionListener.java/#L341,"@Override
    public void lifecycleEvent(LifecycleEvent event) {
        // Initialise these classes when Tomcat starts
        if (Lifecycle.BEFORE_INIT_EVENT.equals(event.getType())) {

            /*
             * First call to this loads all drivers visible to the current class
             * loader and its parents.
             *
             * Note: This is called before the context class loader is changed
             *       because we want any drivers located in CATALINA_HOME/lib
             *       and/or CATALINA_HOME/lib to be visible to DriverManager.
             *       Users wishing to avoid having JDBC drivers loaded by this
             *       class loader should add the JDBC driver(s) to the class
             *       path so they are loaded by the system class loader.
             */
            if (driverManagerProtection) {
                DriverManager.getDrivers();
            }

            ClassLoader loader = Thread.currentThread().getContextClassLoader();

            try
            {
                // Use the system classloader as the victim for all this
                // ClassLoader pinning we're about to do.
                Thread.currentThread().setContextClassLoader(
                        ClassLoader.getSystemClassLoader());

                /*
                 * Several components end up calling:
                 * sun.awt.AppContext.getAppContext()
                 *
                 * Those libraries / components known to trigger memory leaks
                 * due to eventual calls to getAppContext() are:
                 * - Google Web Toolkit via its use of javax.imageio
                 * - Batik
                 * - others TBD
                 *
                 * Note tha a call to sun.awt.AppContext.getAppContext() results
                 * in a thread being started named AWT-AppKit that requires a
                 * graphical environment to be available.
                 */

                // Trigger a call to sun.awt.AppContext.getAppContext(). This
                // will pin the system class loader in memory but that shouldn't
                // be an issue.
                if (appContextProtection) {
                    ImageIO.getCacheDirectory();
                }

                // Trigger the creation of the AWT (AWT-Windows, AWT-XAWT,
                // etc.) thread.
                // Note this issue is fixed in Java 8 update 05 onwards.
                if (awtThreadProtection && !JreCompat.isJre9Available()) {
                    java.awt.Toolkit.getDefaultToolkit();
                }

                /*
                 * Several components end up calling
                 * sun.misc.GC.requestLatency(long) which creates a daemon
                 * thread without setting the TCCL.
                 *
                 * Those libraries / components known to trigger memory leaks
                 * due to eventual calls to requestLatency(long) are:
                 * - javax.management.remote.rmi.RMIConnectorServer.start()
                 *
                 * Note: Long.MAX_VALUE is a special case that causes the thread
                 *       to terminate
                 *
                 * Fixed in Java 9 onwards (from early access build 130)
                 */
                if (gcDaemonProtection && !JreCompat.isJre9Available()) {
                    try {
                        Class<?> clazz = Class.forName(""sun.misc.GC"");
                        Method method = clazz.getDeclaredMethod(
                                ""requestLatency"",
                                new Class[] {long.class});
                        method.invoke(null, Long.valueOf(Long.MAX_VALUE - 1));
                    } catch (ClassNotFoundException e) {
                        if (JreVendor.IS_ORACLE_JVM) {
                            log.error(sm.getString(
                                    ""jreLeakListener.gcDaemonFail""), e);
                        } else {
                            log.debug(sm.getString(
                                    ""jreLeakListener.gcDaemonFail""), e);
                        }
                    } catch (SecurityException | NoSuchMethodException | IllegalArgumentException |
                            IllegalAccessException e) {
                        log.error(sm.getString(""jreLeakListener.gcDaemonFail""),
                                e);
                    } catch (InvocationTargetException e) {
                        ExceptionUtils.handleThrowable(e.getCause());
                        log.error(sm.getString(""jreLeakListener.gcDaemonFail""),
                                e);
                    }
                }

                /*
                 * Creating a MessageDigest during web application startup
                 * initializes the Java Cryptography Architecture. Under certain
                 * conditions this starts a Token poller thread with TCCL equal
                 * to the web application class loader.
                 *
                 * Instead we initialize JCA right now.
                 *
                 * Fixed in Java 9 onwards (from early access build 133)
                 */
                if (tokenPollerProtection && !JreCompat.isJre9Available()) {
                    java.security.Security.getProviders();
                }

                /*
                 * Several components end up opening JarURLConnections without
                 * first disabling caching. This effectively locks the file.
                 * Whilst more noticeable and harder to ignore on Windows, it
                 * affects all operating systems.
                 *
                 * Those libraries/components known to trigger this issue
                 * include:
                 * - log4j versions 1.2.15 and earlier
                 * - javax.xml.bind.JAXBContext.newInstance()
                 *
                 * https://bugs.openjdk.java.net/browse/JDK-8163449
                 *
                 * Java 9 onwards disables caching for JAR URLConnections
                 * Java 8 and earlier disables caching for all URLConnections
                 */

                // Set the default URL caching policy to not to cache
                if (urlCacheProtection) {
                    try {
                        JreCompat.getInstance().disableCachingForJarUrlConnections();
                    } catch (IOException e) {
                        
---------------Reference log start----------------
log.error(sm.getString(""jreLeakListener.jarUrlConnCacheFail""), e)
---------------Reference log end----------------
                    }
                }

                /*
                 * Fixed in Java 9 onwards (from early access build 133)
                 */
                if (xmlParsingProtection && !JreCompat.isJre9Available()) {
                    // There are two known issues with XML parsing that affect
                    // Java 8+. The issues both relate to cached Exception
                    // instances that retain a link to the TCCL via the
                    // backtrace field. Note that YourKit only shows this field
                    // when using the HPROF format memory snapshots.
                    // https://bz.apache.org/bugzilla/show_bug.cgi?id=58486
                    // https://bugs.openjdk.java.net/browse/JDK-8146961
                    DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();
                    try {
                        DocumentBuilder documentBuilder = factory.newDocumentBuilder();
                        // Issue 1
                        // com.sun.org.apache.xml.internal.serialize.DOMSerializerImpl
                        Document document = documentBuilder.newDocument();
                        document.createElement(""dummy"");
                        DOMImplementationLS implementation =
                                (DOMImplementationLS)document.getImplementation();
                        implementation.createLSSerializer().writeToString(document);
                        // Issue 1
                        // com.sun.org.apache.xerces.internal.dom.DOMNormalizer
                        document.normalize();
                    } catch (ParserConfigurationException e) {
                        log.error(sm.getString(""jreLeakListener.xmlParseFail""),
                                e);
                    }
                }

                /*
                 * Fixed in Java 9 onwards (from early access build 130)
                 */
                if (ldapPoolProtection && !JreCompat.isJre9Available()) {
                    try {
                        Class.forName(""com.sun.jndi.ldap.LdapPoolManager"");
                    } catch (ClassNotFoundException e) {
                        if (JreVendor.IS_ORACLE_JVM) {
                            log.error(sm.getString(
                                    ""jreLeakListener.ldapPoolManagerFail""), e);
                        } else {
                            log.debug(sm.getString(
                                    ""jreLeakListener.ldapPoolManagerFail""), e);
                        }
                    }
                }

                /*
                 * Present in Java 7 onwards
                 * Fixed in Java 9 (from early access build 156)
                 */
                if (forkJoinCommonPoolProtection && !JreCompat.isJre9Available()) {
                    // Don't override any explicitly set property
                    if (System.getProperty(FORK_JOIN_POOL_THREAD_FACTORY_PROPERTY) == null) {
                        System.setProperty(FORK_JOIN_POOL_THREAD_FACTORY_PROPERTY,
                                SafeForkJoinWorkerThreadFactory.class.getName());
                    }
                }

                if (classesToInitialize != null) {
                    StringTokenizer strTok =
                        new StringTokenizer(classesToInitialize, "", \r\n\t"");
                    while (strTok.hasMoreTokens()) {
                        String classNameToLoad = strTok.nextToken();
                        try {
                            Class.forName(classNameToLoad);
                        } catch (ClassNotFoundException e) {
                            log.error(
                                sm.getString(""jreLeakListener.classToInitializeFail"",
                                    classNameToLoad), e);
                            // continue with next class to load
                        }
                    }
                }

            } finally {
                Thread.currentThread().setContextClassLoader(loader);
            }
        }
    }",,
tomcat,15897,"log.error(sm.getString(""nioReceiver.requestError""), t)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/NioReceiver.java/#L339,"protected void listen() throws Exception {
        if (doListen()) {
            log.warn(sm.getString(""nioReceiver.alreadyStarted""));
            return;
        }

        setListen(true);

        // Avoid NPEs if selector is set to null on stop.
        Selector selector = this.selector.get();

        if (selector!=null && datagramChannel!=null) {
            ObjectReader oreader = new ObjectReader(MAX_UDP_SIZE); //max size for a datagram packet
            registerChannel(selector,datagramChannel,SelectionKey.OP_READ,oreader);
        }

        while (doListen() && selector != null) {
            // this may block for a long time, upon return the
            // selected set contains keys of the ready channels
            try {
                events();
                socketTimeouts();
                int n = selector.select(getSelectorTimeout());
                if (n == 0) {
                    //there is a good chance that we got here
                    //because the TcpReplicationThread called
                    //selector wakeup().
                    //if that happens, we must ensure that that
                    //thread has enough time to call interestOps
//                    synchronized (interestOpsMutex) {
                        //if we got the lock, means there are no
                        //keys trying to register for the
                        //interestOps method
//                    }
                    continue; // nothing to do
                }
                // get an iterator over the set of selected keys
                Iterator<SelectionKey> it = selector.selectedKeys().iterator();
                // look at each key in the selected set
                while (it!=null && it.hasNext()) {
                    SelectionKey key = it.next();
                    // Is a new connection coming in?
                    if (key.isAcceptable()) {
                        ServerSocketChannel server = (ServerSocketChannel) key.channel();
                        SocketChannel channel = server.accept();
                        channel.socket().setReceiveBufferSize(getRxBufSize());
                        channel.socket().setSendBufferSize(getTxBufSize());
                        channel.socket().setTcpNoDelay(getTcpNoDelay());
                        channel.socket().setKeepAlive(getSoKeepAlive());
                        channel.socket().setOOBInline(getOoBInline());
                        channel.socket().setReuseAddress(getSoReuseAddress());
                        channel.socket().setSoLinger(getSoLingerOn(),getSoLingerTime());
                        channel.socket().setSoTimeout(getTimeout());
                        Object attach = new ObjectReader(channel);
                        registerChannel(selector,
                                        channel,
                                        SelectionKey.OP_READ,
                                        attach);
                    }
                    // is there data to read on this channel?
                    if (key.isReadable()) {
                        readDataFromSocket(key);
                    } else {
                        key.interestOps(key.interestOps() & (~SelectionKey.OP_WRITE));
                    }

                    // remove key from selected set, it's been handled
                    it.remove();
                }
            } catch (java.nio.channels.ClosedSelectorException cse) {
                // ignore is normal at shutdown or stop listen socket
            } catch (java.nio.channels.CancelledKeyException nx) {
                log.warn(sm.getString(""nioReceiver.clientDisconnect""));
            } catch (Throwable t) {
                ExceptionUtils.handleThrowable(t);
                
---------------Reference log start----------------
log.error(sm.getString(""nioReceiver.requestError""), t)
---------------Reference log end----------------
            }

        }
        serverChannel.close();
        if (datagramChannel!=null) {
            try {
                datagramChannel.close();
            }catch (Exception iox) {
                if (log.isDebugEnabled()) {
                    log.debug(""Unable to close datagram channel."",iox);
                }
            }
            datagramChannel=null;
        }
        closeSelector();
    }",,
tomcat,15156,"log.error(""Async2"", x)",error,https://github.com/apache/tomcat/blob/main/webapps/examples/WEB-INF/classes/async/Async2.java/#L61,"@Override
            public void run() {
                try {
                    Thread.currentThread().setName(""Async2-Thread"");
                    log.info(""Putting AsyncThread to sleep"");
                    Thread.sleep(2*1000);
                    log.info(""Writing data."");
                    Date date = new Date(System.currentTimeMillis());
                    SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss Z"");
                    actx.getResponse().getWriter().write(
                            ""Output from background thread. Time: "" + sdf.format(date) + ""\n"");
                    actx.complete();
                }catch (InterruptedException x) {
                    log.error(""Async2"",x);
                }catch (IllegalStateException x) {
                    log.error(""Async2"",x);
                }catch (IOException x) {
                    
---------------Reference log start----------------
log.error(""Async2"", x)
---------------Reference log end----------------
                }
            }",,
tomcat,16884,"log.warn(sm.getString(""upgradeHandler.unexpectedAck"", connectionId, getIdAsString()))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http2/Http2AsyncUpgradeHandler.java/#L274,"@Override
    public void settingsEnd(boolean ack) throws IOException {
        if (ack) {
            if (!localSettings.ack()) {
                // Ack was unexpected
                
---------------Reference log start----------------
log.warn(sm.getString(""upgradeHandler.unexpectedAck"", connectionId, getIdAsString()))
---------------Reference log end----------------
            }
        } else {
            socketWrapper.write(BlockingMode.SEMI_BLOCK, protocol.getWriteTimeout(),
                    TimeUnit.MILLISECONDS, null, SocketWrapperBase.COMPLETE_WRITE, errorCompletion,
                    ByteBuffer.wrap(SETTINGS_ACK));
        }
        handleAsyncException();
    }",,
tomcat,15617,"log.debug(""Passing all authenticated users"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/RealmBase.java/#L846,"@Override
    public boolean hasResourcePermission(Request request,
                                         Response response,
                                         SecurityConstraint []constraints,
                                         Context context)
        throws IOException {

        if (constraints == null || constraints.length == 0) {
            return true;
        }

        // Which user principal have we already authenticated?
        Principal principal = request.getPrincipal();
        boolean status = false;
        boolean denyfromall = false;
        for (SecurityConstraint constraint : constraints) {
            String roles[];
            if (constraint.getAllRoles()) {
                // * means all roles defined in web.xml
                roles = request.getContext().findSecurityRoles();
            } else {
                roles = constraint.findAuthRoles();
            }

            if (roles == null) {
                roles = new String[0];
            }

            if (log.isDebugEnabled()) {
                log.debug(""  Checking roles "" + principal);
            }

            if (constraint.getAuthenticatedUsers() && principal != null) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""Passing all authenticated users"")
---------------Reference log end----------------
                }
                status = true;
            }
            else if (roles.length == 0 && !constraint.getAllRoles() &&
                    !constraint.getAuthenticatedUsers()) {
                if (constraint.getAuthConstraint()) {
                    if (log.isDebugEnabled()) {
                        log.debug(""No roles"");
                    }
                    status = false; // No listed roles means no access at all
                    denyfromall = true;
                    break;
                }

                if (log.isDebugEnabled()) {
                    log.debug(""Passing all access"");
                }
                status = true;
            } else if (principal == null) {
                if (log.isDebugEnabled()) {
                    log.debug(""  No user authenticated, cannot grant access"");
                }
            } else {
                for (String role : roles) {
                    if (hasRole(request.getWrapper(), principal, role)) {
                        status = true;
                        if (log.isDebugEnabled()) {
                            log.debug(""Role found:  "" + role);
                        }
                    } else if (log.isDebugEnabled()) {
                        log.debug(""No role found:  "" + role);
                    }
                }
            }
        }

        if (!denyfromall && allRolesMode != AllRolesMode.STRICT_MODE &&
                !status && principal != null) {
            if (log.isDebugEnabled()) {
                log.debug(""Checking for all roles mode: "" + allRolesMode);
            }
            // Check for an all roles(role-name=""*"")
            for (SecurityConstraint constraint : constraints) {
                String roles[];
                // If the all roles mode exists, sets
                if (constraint.getAllRoles()) {
                    if (allRolesMode == AllRolesMode.AUTH_ONLY_MODE) {
                        if (log.isDebugEnabled()) {
                            log.debug(""Granting access for role-name=*, auth-only"");
                        }
                        status = true;
                        break;
                    }

                    // For AllRolesMode.STRICT_AUTH_ONLY_MODE there must be zero roles
                    roles = request.getContext().findSecurityRoles();
                    if (roles.length == 0 && allRolesMode == AllRolesMode.STRICT_AUTH_ONLY_MODE) {
                        if (log.isDebugEnabled()) {
                            log.debug(""Granting access for role-name=*, strict auth-only"");
                        }
                        status = true;
                        break;
                    }
                }
            }
        }

        // Return a ""Forbidden"" message denying access to this resource
        if(!status) {
            response.sendError
                (HttpServletResponse.SC_FORBIDDEN,
                 sm.getString(""realmBase.forbidden""));
        }
        return status;

    }",,
tomcat,15301,"log.debug(request.hashCode() + "": Bot found. IP="" + clientIp)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/valves/CrawlerSessionManagerValve.java/#L219,"@Override
    public void invoke(Request request, Response response) throws IOException, ServletException {

        boolean isBot = false;
        String sessionId = null;
        String clientIp = request.getRemoteAddr();
        String clientIdentifier = getClientIdentifier(request.getHost(), request.getContext(), clientIp);

        if (log.isDebugEnabled()) {
            log.debug(request.hashCode() + "": ClientIdentifier="" + clientIdentifier + "", RequestedSessionId=""
                    + request.getRequestedSessionId());
        }

        // If the incoming request has a valid session ID, no action is required
        if (request.getSession(false) == null) {

            // Is this a crawler - check the UA headers
            Enumeration<String> uaHeaders = request.getHeaders(""user-agent"");
            String uaHeader = null;
            if (uaHeaders.hasMoreElements()) {
                uaHeader = uaHeaders.nextElement();
            }

            // If more than one UA header - assume not a bot
            if (uaHeader != null && !uaHeaders.hasMoreElements()) {

                if (log.isDebugEnabled()) {
                    log.debug(request.hashCode() + "": UserAgent="" + uaHeader);
                }

                if (uaPattern.matcher(uaHeader).matches()) {
                    isBot = true;

                    if (log.isDebugEnabled()) {
                        log.debug(request.hashCode() + "": Bot found. UserAgent="" + uaHeader);
                    }
                }
            }

            if (ipPattern != null && ipPattern.matcher(clientIp).matches()) {
                isBot = true;

                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(request.hashCode() + "": Bot found. IP="" + clientIp)
---------------Reference log end----------------
                }
            }

            // If this is a bot, is the session ID known?
            if (isBot) {
                sessionId = clientIdSessionId.get(clientIdentifier);
                if (sessionId != null) {
                    request.setRequestedSessionId(sessionId);
                    if (log.isDebugEnabled()) {
                        log.debug(request.hashCode() + "": SessionID="" + sessionId);
                    }
                }
            }
        }

        getNext().invoke(request, response);

        if (isBot) {
            if (sessionId == null) {
                // Has bot just created a session, if so make a note of it
                HttpSession s = request.getSession(false);
                if (s != null) {
                    clientIdSessionId.put(clientIdentifier, s.getId());
                    sessionIdClientId.put(s.getId(), clientIdentifier);
                    // #valueUnbound() will be called on session expiration
                    s.setAttribute(this.getClass().getName(),
                            new CrawlerHttpSessionBindingListener(clientIdSessionId, clientIdentifier));
                    s.setMaxInactiveInterval(sessionInactiveInterval);

                    if (log.isDebugEnabled()) {
                        log.debug(request.hashCode() + "": New bot session. SessionID="" + s.getId());
                    }
                }
            } else {
                if (log.isDebugEnabled()) {
                    log.debug(
                            request.hashCode() + "": Bot session accessed. SessionID="" + sessionId);
                }
            }
        }
    }",,
tomcat,15143,"log.error(""Unexpected exception: "" + ex.toString(), ex)",error,https://github.com/apache/tomcat/blob/main/webapps/examples/WEB-INF/classes/websocket/drawboard/DrawboardEndpoint.java/#L227,"@Override
                public void run() {
                    try {

                        // Currently, the only types of messages the client will send
                        // are draw messages prefixed by a Message ID
                        // (starting with char '1'), and pong messages (starting
                        // with char '0').
                        // Draw messages should look like this:
                        // ID|type,colR,colB,colG,colA,thickness,x1,y1,x2,y2,lastInChain

                        boolean dontSwallowException = false;
                        try {
                            char messageType = message.charAt(0);
                            String messageContent = message.substring(1);
                            switch (messageType) {
                            case '0':
                                // Pong message.
                                // Do nothing.
                                break;

                            case '1':
                                // Draw message
                                int indexOfChar = messageContent.indexOf('|');
                                long msgId = Long.parseLong(
                                        messageContent.substring(0, indexOfChar));

                                DrawMessage msg = DrawMessage.parseFromString(
                                        messageContent.substring(indexOfChar + 1));

                                // Don't ignore RuntimeExceptions thrown by
                                // this method
                                // TODO: Find a better solution than this variable
                                dontSwallowException = true;
                                if (player != null) {
                                    player.handleDrawMessage(msg, msgId);
                                }
                                dontSwallowException = false;

                                break;
                            }
                        } catch (ParseException e) {
                            // Client sent invalid data
                            // Ignore, TODO: maybe close connection
                        } catch (RuntimeException e) {
                            // Client sent invalid data.
                            // Ignore, TODO: maybe close connection
                            if (dontSwallowException) {
                                throw e;
                            }
                        }

                    } catch (RuntimeException ex) {
                        
---------------Reference log start----------------
log.error(""Unexpected exception: "" + ex.toString(), ex)
---------------Reference log end----------------
                    }
                }",,
tomcat,17534,"log.warn(Localizer.getMessage(""jsp.warning.unsupported.targetVM"", requestedTarget, actualTarget))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/JDTCompiler.java/#L464,"@Override
    protected void generateClass(Map<String,SmapStratum> smaps)
        throws FileNotFoundException, JasperException, Exception {

        long t1 = 0;
        if (log.isDebugEnabled()) {
            t1 = System.currentTimeMillis();
        }

        final String sourceFile = ctxt.getServletJavaFileName();
        final String outputDir = ctxt.getOptions().getScratchDir().getAbsolutePath();
        String packageName = ctxt.getServletPackageName();
        final String targetClassName =
                ((packageName.length() != 0) ? (packageName + ""."") : """") + ctxt.getServletClassName();
        final ClassLoader classLoader = ctxt.getJspLoader();
        String[] fileNames = new String[] {sourceFile};
        String[] classNames = new String[] {targetClassName};
        final List<JavacErrorDetail> problemList = new ArrayList<>();

        class CompilationUnit implements ICompilationUnit {

            private final String className;
            private final String sourceFile;

            CompilationUnit(String sourceFile, String className) {
                this.className = className;
                this.sourceFile = sourceFile;
            }

            @Override
            public char[] getFileName() {
                return sourceFile.toCharArray();
            }

            @Override
            public char[] getContents() {
                char[] result = null;
                try (FileInputStream is = new FileInputStream(sourceFile);
                        InputStreamReader isr = new InputStreamReader(is, ctxt.getOptions().getJavaEncoding());
                        Reader reader = new BufferedReader(isr)) {
                    char[] chars = new char[8192];
                    StringBuilder buf = new StringBuilder();
                    int count;
                    while ((count = reader.read(chars, 0, chars.length)) > 0) {
                        buf.append(chars, 0, count);
                    }
                    result = new char[buf.length()];
                    buf.getChars(0, result.length, result, 0);
                } catch (IOException e) {
                    log.error(Localizer.getMessage(""jsp.error.compilation.source"", sourceFile), e);
                }
                return result;
            }

            @Override
            public char[] getMainTypeName() {
                int dot = className.lastIndexOf('.');
                if (dot > 0) {
                    return className.substring(dot + 1).toCharArray();
                }
                return className.toCharArray();
            }

            @Override
            public char[][] getPackageName() {
                StringTokenizer izer = new StringTokenizer(className, ""."");
                char[][] result = new char[izer.countTokens()-1][];
                for (int i = 0; i < result.length; i++) {
                    String tok = izer.nextToken();
                    result[i] = tok.toCharArray();
                }
                return result;
            }

            @Override
            public boolean ignoreOptionalProblems() {
                return false;
            }
        }

        final INameEnvironment env = new INameEnvironment() {

                @Override
                public NameEnvironmentAnswer findType(char[][] compoundTypeName) {
                    StringBuilder result = new StringBuilder();
                    for (int i = 0; i < compoundTypeName.length; i++) {
                        if (i > 0) {
                            result.append('.');
                        }
                        result.append(compoundTypeName[i]);
                    }
                    return findType(result.toString());
                }

                @Override
                public NameEnvironmentAnswer findType(char[] typeName, char[][] packageName) {
                    StringBuilder result = new StringBuilder();
                    int i=0;
                    for (; i < packageName.length; i++) {
                        if (i > 0) {
                            result.append('.');
                        }
                        result.append(packageName[i]);
                    }
                    if (i > 0) {
                        result.append('.');
                    }
                    result.append(typeName);
                    return findType(result.toString());
                }

                private NameEnvironmentAnswer findType(String className) {

                    if (className.equals(targetClassName)) {
                        ICompilationUnit compilationUnit = new CompilationUnit(sourceFile, className);
                        return new NameEnvironmentAnswer(compilationUnit, null);
                    }

                    String resourceName = className.replace('.', '/') + "".class"";

                    try (InputStream is = classLoader.getResourceAsStream(resourceName)) {
                        if (is != null) {
                            byte[] classBytes;
                            byte[] buf = new byte[8192];
                            ByteArrayOutputStream baos = new ByteArrayOutputStream(buf.length);
                            int count;
                            while ((count = is.read(buf, 0, buf.length)) > 0) {
                                baos.write(buf, 0, count);
                            }
                            baos.flush();
                            classBytes = baos.toByteArray();
                            char[] fileName = className.toCharArray();
                            ClassFileReader classFileReader = new ClassFileReader(classBytes, fileName, true);
                            return new NameEnvironmentAnswer(classFileReader, null);
                        }
                    } catch (IOException | ClassFormatException exc) {
                        log.error(Localizer.getMessage(""jsp.error.compilation.dependent"", className), exc);
                    }
                    return null;
                }

                private boolean isPackage(String result) {
                    if (result.equals(targetClassName) || result.startsWith(targetClassName + '$')) {
                        return false;
                    }
                    String resourceName = result.replace('.', '/') + "".class"";
                    try (InputStream is =
                        classLoader.getResourceAsStream(resourceName)) {
                        return is == null;
                    } catch (IOException e) {
                        // we are here, since close on is failed. That means it was not null
                        return false;
                    }
                }

                @Override
                public boolean isPackage(char[][] parentPackageName, char[] packageName) {
                    StringBuilder result = new StringBuilder();
                    int i = 0;
                    if (parentPackageName != null) {
                        for (; i < parentPackageName.length; i++) {
                            if (i > 0) {
                                result.append('.');
                            }
                            result.append(parentPackageName[i]);
                        }
                    }

                    if (Character.isUpperCase(packageName[0])) {
                        if (!isPackage(result.toString())) {
                            return false;
                        }
                    }
                    if (i > 0) {
                        result.append('.');
                    }
                    result.append(packageName);

                    return isPackage(result.toString());
                }

                @Override
                public void cleanup() {
                }

            };

        final IErrorHandlingPolicy policy = DefaultErrorHandlingPolicies.proceedWithAllProblems();

        final Map<String,String> settings = new HashMap<>();
        settings.put(CompilerOptions.OPTION_LineNumberAttribute,
                     CompilerOptions.GENERATE);
        settings.put(CompilerOptions.OPTION_SourceFileAttribute,
                     CompilerOptions.GENERATE);
        settings.put(CompilerOptions.OPTION_ReportDeprecation,
                     CompilerOptions.IGNORE);
        if (ctxt.getOptions().getJavaEncoding() != null) {
            settings.put(CompilerOptions.OPTION_Encoding,
                    ctxt.getOptions().getJavaEncoding());
        }
        if (ctxt.getOptions().getClassDebugInfo()) {
            settings.put(CompilerOptions.OPTION_LocalVariableAttribute,
                         CompilerOptions.GENERATE);
        }

        // Source JVM
        if(ctxt.getOptions().getCompilerSourceVM() != null) {
            String opt = ctxt.getOptions().getCompilerSourceVM();
            if(opt.equals(""1.1"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_1);
            } else if(opt.equals(""1.2"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_2);
            } else if(opt.equals(""1.3"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_3);
            } else if(opt.equals(""1.4"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_4);
            } else if(opt.equals(""1.5"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_5);
            } else if(opt.equals(""1.6"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_6);
            } else if(opt.equals(""1.7"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_7);
            } else if(opt.equals(""1.8"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
            // Version format changed from Java 9 onwards.
            // Support old format that was used in EA implementation as well
            } else if(opt.equals(""9"") || opt.equals(""1.9"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_9);
            } else if(opt.equals(""10"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_10);
            } else if(opt.equals(""11"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_11);
            } else if(opt.equals(""12"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_12);
            } else if(opt.equals(""13"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_13);
            } else if(opt.equals(""14"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_14);
            } else if(opt.equals(""15"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_15);
            } else if(opt.equals(""16"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_16);
            } else if(opt.equals(""17"")) {
                // Constant not available in latest ECJ version shipped with
                // Tomcat. May be supported in a snapshot build.
                // This is checked against the actual version below.
                settings.put(CompilerOptions.OPTION_Source, ""17"");
            } else {
                log.warn(Localizer.getMessage(""jsp.warning.unknown.sourceVM"", opt));
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
            }
        } else {
            // Default to 1.8
            settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
        }

        // Target JVM
        if(ctxt.getOptions().getCompilerTargetVM() != null) {
            String opt = ctxt.getOptions().getCompilerTargetVM();
            if(opt.equals(""1.1"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_1);
            } else if(opt.equals(""1.2"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_2);
            } else if(opt.equals(""1.3"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_3);
            } else if(opt.equals(""1.4"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_4);
            } else if(opt.equals(""1.5"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_5);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_5);
            } else if(opt.equals(""1.6"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_6);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_6);
            } else if(opt.equals(""1.7"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_7);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_7);
            } else if(opt.equals(""1.8"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_8);
            // Version format changed from Java 9 onwards.
            // Support old format that was used in EA implementation as well
            } else if(opt.equals(""9"") || opt.equals(""1.9"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_9);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_9);
            } else if(opt.equals(""10"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_10);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_10);
            } else if(opt.equals(""11"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_11);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_11);
            } else if(opt.equals(""12"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_12);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_12);
            } else if(opt.equals(""13"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_13);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_13);
            } else if(opt.equals(""14"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_14);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_14);
            } else if(opt.equals(""15"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_15);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_15);
            } else if(opt.equals(""16"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_16);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_16);
            } else if(opt.equals(""17"")) {
                // Constant not available in latest ECJ version shipped with
                // Tomcat. May be supported in a snapshot build.
                // This is checked against the actual version below.
                settings.put(CompilerOptions.OPTION_TargetPlatform, ""17"");
                settings.put(CompilerOptions.OPTION_Compliance, ""17"");
            } else {
                log.warn(Localizer.getMessage(""jsp.warning.unknown.targetVM"", opt));
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
            }
        } else {
            // Default to 1.8
            settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
            settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_8);
        }

        final IProblemFactory problemFactory = new DefaultProblemFactory(Locale.getDefault());

        final ICompilerRequestor requestor = new ICompilerRequestor() {
                @Override
                public void acceptResult(CompilationResult result) {
                    try {
                        if (result.hasProblems()) {
                            IProblem[] problems = result.getProblems();
                            for (IProblem problem : problems) {
                                if (problem.isError()) {
                                    String name =
                                            new String(problem.getOriginatingFileName());
                                    try {
                                        problemList.add(ErrorDispatcher.createJavacError
                                                (name, pageNodes, new StringBuilder(problem.getMessage()),
                                                        problem.getSourceLineNumber(), ctxt));
                                    } catch (JasperException e) {
                                        log.error(Localizer.getMessage(""jsp.error.compilation.jdtProblemError""), e);
                                    }
                                }
                            }
                        }
                        if (problemList.isEmpty()) {
                            ClassFile[] classFiles = result.getClassFiles();
                            for (ClassFile classFile : classFiles) {
                                char[][] compoundName =
                                        classFile.getCompoundName();
                                StringBuilder classFileName = new StringBuilder(outputDir).append('/');
                                for (int j = 0;
                                     j < compoundName.length; j++) {
                                    if (j > 0) {
                                        classFileName.append('/');
                                    }
                                    classFileName.append(compoundName[j]);
                                }
                                byte[] bytes = classFile.getBytes();
                                classFileName.append("".class"");
                                try (FileOutputStream fout = new FileOutputStream(classFileName.toString());
                                        BufferedOutputStream bos = new BufferedOutputStream(fout)) {
                                    bos.write(bytes);
                                }
                            }
                        }
                    } catch (IOException exc) {
                        log.error(Localizer.getMessage(""jsp.error.compilation.jdt""), exc);
                    }
                }
            };

        ICompilationUnit[] compilationUnits =
            new ICompilationUnit[classNames.length];
        for (int i = 0; i < compilationUnits.length; i++) {
            String className = classNames[i];
            compilationUnits[i] = new CompilationUnit(fileNames[i], className);
        }
        CompilerOptions cOptions = new CompilerOptions(settings);

        // Check source/target JDK versions as the newest versions are allowed
        // in Tomcat configuration but may not be supported by the ECJ version
        // being used.
        String requestedSource = ctxt.getOptions().getCompilerSourceVM();
        if (requestedSource != null) {
            String actualSource = CompilerOptions.versionFromJdkLevel(cOptions.sourceLevel);
            if (!requestedSource.equals(actualSource)) {
                log.warn(Localizer.getMessage(""jsp.warning.unsupported.sourceVM"", requestedSource, actualSource));
            }
        }
        String requestedTarget = ctxt.getOptions().getCompilerTargetVM();
        if (requestedTarget != null) {
            String actualTarget = CompilerOptions.versionFromJdkLevel(cOptions.targetJDK);
            if (!requestedTarget.equals(actualTarget)) {
                
---------------Reference log start----------------
log.warn(Localizer.getMessage(""jsp.warning.unsupported.targetVM"", requestedTarget, actualTarget))
---------------Reference log end----------------
            }
        }

        cOptions.parseLiteralExpressionsAsConstants = true;
        Compiler compiler = new Compiler(env,
                                         policy,
                                         cOptions,
                                         requestor,
                                         problemFactory);
        compiler.compile(compilationUnits);

        if (!ctxt.keepGenerated()) {
            File javaFile = new File(ctxt.getServletJavaFileName());
            if (!javaFile.delete()) {
                throw new JasperException(Localizer.getMessage(
                        ""jsp.warning.compiler.javafile.delete.fail"", javaFile));
            }
        }

        if (!problemList.isEmpty()) {
            JavacErrorDetail[] jeds =
                problemList.toArray(new JavacErrorDetail[0]);
            errDispatcher.javacError(jeds);
        }

        if( log.isDebugEnabled() ) {
            long t2=System.currentTimeMillis();
            log.debug(""Compiled "" + ctxt.getServletJavaFileName() + "" ""
                      + (t2-t1) + ""ms"");
        }

        if (ctxt.isPrototypeMode()) {
            return;
        }

        // JSR45 Support
        if (! options.isSmapSuppressed()) {
            SmapUtil.installSmap(smaps);
        }
    }",,
tomcat,17182,"log.debug(sm.getString(""opensslconf.resultCommand"", name, value, Integer.toString(rc)))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/openssl/OpenSSLConf.java/#L74,"public boolean check(long cctx) throws Exception {
        boolean result = true;
        OpenSSLConfCmd cmd;
        String name;
        String value;
        int rc;
        for (OpenSSLConfCmd command : commands) {
            cmd = command;
            name = cmd.getName();
            value = cmd.getValue();
            if (name == null) {
                log.error(sm.getString(""opensslconf.noCommandName"", value));
                result = false;
                continue;
            }
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""opensslconf.checkCommand"", name, value));
            }
            try {
                rc = SSLConf.check(cctx, name, value);
            } catch (Exception e) {
                log.error(sm.getString(""opensslconf.checkFailed""));
                return false;
            }
            if (rc <= 0) {
                log.error(sm.getString(""opensslconf.failedCommand"", name, value,
                        Integer.toString(rc)));
                result = false;
            } else if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""opensslconf.resultCommand"", name, value, Integer.toString(rc)))
---------------Reference log end----------------
            }
        }
        if (!result) {
            log.error(sm.getString(""opensslconf.checkFailed""));
        }
        return result;
    }",,
tomcat,15496,"log.warn(sm.getString(""pbeCredentialHandler.invalidKeySpec""), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/SecretKeyCredentialHandler.java/#L89,"@Override
    protected String mutate(String inputCredentials, byte[] salt, int iterations, int keyLength) {
        try {
            KeySpec spec = new PBEKeySpec(inputCredentials.toCharArray(), salt, iterations, keyLength);
            return HexUtils.toHexString(secretKeyFactory.generateSecret(spec).getEncoded());
        } catch (InvalidKeySpecException | IllegalArgumentException e) {
            
---------------Reference log start----------------
log.warn(sm.getString(""pbeCredentialHandler.invalidKeySpec""), e)
---------------Reference log end----------------
            return null;
        }
    }",,
tomcat,17166,"log.warn(sm.getString(""sslUtilBase.noVerificationDepth"", algorithm))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/SSLUtilBase.java/#L445,"@Override
    public TrustManager[] getTrustManagers() throws Exception {

        String className = sslHostConfig.getTrustManagerClassName();
        if(className != null && className.length() > 0) {
             ClassLoader classLoader = getClass().getClassLoader();
             Class<?> clazz = classLoader.loadClass(className);
             if(!(TrustManager.class.isAssignableFrom(clazz))){
                throw new InstantiationException(sm.getString(
                        ""sslUtilBase.invalidTrustManagerClassName"", className));
             }
             Object trustManagerObject = clazz.getConstructor().newInstance();
             TrustManager trustManager = (TrustManager) trustManagerObject;
             return new TrustManager[]{ trustManager };
        }

        TrustManager[] tms = null;

        KeyStore trustStore = sslHostConfig.getTruststore();
        if (trustStore != null) {
            checkTrustStoreEntries(trustStore);
            String algorithm = sslHostConfig.getTruststoreAlgorithm();
            String crlf = sslHostConfig.getCertificateRevocationListFile();
            boolean revocationEnabled = sslHostConfig.getRevocationEnabled();

            if (""PKIX"".equalsIgnoreCase(algorithm)) {
                TrustManagerFactory tmf = TrustManagerFactory.getInstance(algorithm);
                CertPathParameters params = getParameters(crlf, trustStore, revocationEnabled);
                ManagerFactoryParameters mfp = new CertPathTrustManagerParameters(params);
                tmf.init(mfp);
                tms = tmf.getTrustManagers();
            } else {
                TrustManagerFactory tmf = TrustManagerFactory.getInstance(algorithm);
                tmf.init(trustStore);
                tms = tmf.getTrustManagers();
                if (crlf != null && crlf.length() > 0) {
                    throw new CRLException(sm.getString(""sslUtilBase.noCrlSupport"", algorithm));
                }
                // Only warn if the attribute has been explicitly configured
                if (sslHostConfig.isCertificateVerificationDepthConfigured()) {
                    
---------------Reference log start----------------
log.warn(sm.getString(""sslUtilBase.noVerificationDepth"", algorithm))
---------------Reference log end----------------
                }
            }
        }

        return tms;
    }",,
tomcat,16767,"log.error(sm.getString(""standardService.connector.stopFailed"", connectors[j]), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardService.java/#L304,"@Override
    public void removeConnector(Connector connector) {

        synchronized (connectorsLock) {
            int j = -1;
            for (int i = 0; i < connectors.length; i++) {
                if (connector == connectors[i]) {
                    j = i;
                    break;
                }
            }
            if (j < 0) {
                return;
            }
            if (connectors[j].getState().isAvailable()) {
                try {
                    connectors[j].stop();
                } catch (LifecycleException e) {
                    
---------------Reference log start----------------
log.error(sm.getString(""standardService.connector.stopFailed"", connectors[j]), e)
---------------Reference log end----------------
                }
            }
            connector.setService(null);
            int k = 0;
            Connector results[] = new Connector[connectors.length - 1];
            for (int i = 0; i < connectors.length; i++) {
                if (i != j) {
                    results[k++] = connectors[i];
                }
            }
            connectors = results;

            // Report this property change to interested listeners
            support.firePropertyChange(""connector"", connector, null);
        }
    }",,
tomcat,15237,"log.info(sm.getString(""managerBase.sessionNotFound"", sessionId))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/ManagerBase.java/#L1260,"public String getThisAccessedTime( String sessionId ) {
        Session s = sessions.get(sessionId);
        if (s == null) {
            if (log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""managerBase.sessionNotFound"", sessionId))
---------------Reference log end----------------
            }
            return """";
        }
        return new Date(s.getThisAccessedTime()).toString();
    }",,
tomcat,16500,"log.trace(""Requested Session ID From Cookie: ["" + req.isRequestedSessionIdFromCookie() + ""]"")",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L509,"private void printServletEnvironment(HttpServletRequest req) throws IOException {

        // Document the properties from ServletRequest
        log.trace(""ServletRequest Properties"");
        Enumeration<String> attrs = req.getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Request Attribute: "" + attr + "": [ "" + req.getAttribute(attr) +""]"");
        }
        log.trace(""Character Encoding: ["" + req.getCharacterEncoding() + ""]"");
        log.trace(""Content Length: ["" + req.getContentLengthLong() + ""]"");
        log.trace(""Content Type: ["" + req.getContentType() + ""]"");
        Enumeration<Locale> locales = req.getLocales();
        while (locales.hasMoreElements()) {
            Locale locale = locales.nextElement();
            log.trace(""Locale: ["" +locale + ""]"");
        }
        Enumeration<String> params = req.getParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            for (String value : req.getParameterValues(param)) {
                log.trace(""Request Parameter: "" + param + "":  ["" + value + ""]"");
            }
        }
        log.trace(""Protocol: ["" + req.getProtocol() + ""]"");
        log.trace(""Remote Address: ["" + req.getRemoteAddr() + ""]"");
        log.trace(""Remote Host: ["" + req.getRemoteHost() + ""]"");
        log.trace(""Scheme: ["" + req.getScheme() + ""]"");
        log.trace(""Secure: ["" + req.isSecure() + ""]"");
        log.trace(""Server Name: ["" + req.getServerName() + ""]"");
        log.trace(""Server Port: ["" + req.getServerPort() + ""]"");

        // Document the properties from HttpServletRequest
        log.trace(""HttpServletRequest Properties"");
        log.trace(""Auth Type: ["" + req.getAuthType() + ""]"");
        log.trace(""Context Path: ["" + req.getContextPath() + ""]"");
        Cookie cookies[] = req.getCookies();
        if (cookies != null) {
            for (Cookie cookie : cookies) {
                log.trace(""Cookie: "" + cookie.getName() + "": ["" + cookie.getValue() + ""]"");
            }
        }
        Enumeration<String> headers = req.getHeaderNames();
        while (headers.hasMoreElements()) {
            String header = headers.nextElement();
            log.trace(""HTTP Header: "" + header + "": ["" + req.getHeader(header) + ""]"");
        }
        log.trace(""Method: ["" + req.getMethod() + ""]"");
        log.trace(""Path Info: ["" + req.getPathInfo() + ""]"");
        log.trace(""Path Translated: ["" + req.getPathTranslated() + ""]"");
        log.trace(""Query String: ["" + req.getQueryString() + ""]"");
        log.trace(""Remote User: ["" + req.getRemoteUser() + ""]"");
        log.trace(""Requested Session ID: ["" + req.getRequestedSessionId() + ""]"");
        
---------------Reference log start----------------
log.trace(""Requested Session ID From Cookie: ["" + req.isRequestedSessionIdFromCookie() + ""]"")
---------------Reference log end----------------
        log.trace(""Requested Session ID From URL: ["" + req.isRequestedSessionIdFromURL() + ""]"");
        log.trace(""Requested Session ID Valid: ["" + req.isRequestedSessionIdValid() + ""]"");
        log.trace(""Request URI: ["" + req.getRequestURI() + ""]"");
        log.trace(""Servlet Path: ["" + req.getServletPath() + ""]"");
        log.trace(""User Principal: ["" + req.getUserPrincipal() + ""]"");

        // Process the current session (if there is one)
        HttpSession session = req.getSession(false);
        if (session != null) {

            // Document the session properties
            log.trace(""HttpSession Properties"");
            log.trace(""ID: ["" + session.getId() + ""]"");
            log.trace(""Creation Time: ["" + new Date(session.getCreationTime()) + ""]"");
            log.trace(""Last Accessed Time: ["" + new Date(session.getLastAccessedTime()) + ""]"");
            log.trace(""Max Inactive Interval: ["" + session.getMaxInactiveInterval() + ""]"");

            // Document the session attributes
            attrs = session.getAttributeNames();
            while (attrs.hasMoreElements()) {
                String attr = attrs.nextElement();
                log.trace(""Session Attribute: "" + attr + "": ["" + session.getAttribute(attr) + ""]"");
            }
        }

        // Document the servlet configuration properties
        log.trace(""ServletConfig Properties"");
        log.trace(""Servlet Name: ["" + getServletConfig().getServletName() + ""]"");

        // Document the servlet configuration initialization parameters
        params = getServletConfig().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletConfig().getInitParameter(param);
            log.trace(""Servlet Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context properties
        log.trace(""ServletContext Properties"");
        log.trace(""Major Version: ["" + getServletContext().getMajorVersion() + ""]"");
        log.trace(""Minor Version: ["" + getServletContext().getMinorVersion() + ""]"");
        log.trace(""Real Path for '/': ["" + getServletContext().getRealPath(""/"") + ""]"");
        log.trace(""Server Info: ["" + getServletContext().getServerInfo() + ""]"");

        // Document the servlet context initialization parameters
        log.trace(""ServletContext Initialization Parameters"");
        params = getServletContext().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletContext().getInitParameter(param);
            log.trace(""Servlet Context Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context attributes
        log.trace(""ServletContext Attributes"");
        attrs = getServletContext().getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Servlet Context Attribute: "" + attr +
                    "": ["" + getServletContext().getAttribute(attr) + ""]"");
        }
    }",,
tomcat,15478,"log.debug(sm.getString(""expiresFilter.filterInitialized"", this.toString()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/filters/ExpiresFilter.java/#L1434,"@Override
    public void init(FilterConfig filterConfig) throws ServletException {
        for (Enumeration<String> names = filterConfig.getInitParameterNames(); names.hasMoreElements();) {
            String name = names.nextElement();
            String value = filterConfig.getInitParameter(name);

            try {
                if (name.startsWith(PARAMETER_EXPIRES_BY_TYPE)) {
                    String contentType = name.substring(
                            PARAMETER_EXPIRES_BY_TYPE.length()).trim().toLowerCase(Locale.ENGLISH);
                    ExpiresConfiguration expiresConfiguration = parseExpiresConfiguration(value);
                    this.expiresConfigurationByContentType.put(contentType,
                            expiresConfiguration);
                } else if (name.equalsIgnoreCase(PARAMETER_EXPIRES_DEFAULT)) {
                    ExpiresConfiguration expiresConfiguration = parseExpiresConfiguration(value);
                    this.defaultExpiresConfiguration = expiresConfiguration;
                } else if (name.equalsIgnoreCase(PARAMETER_EXPIRES_EXCLUDED_RESPONSE_STATUS_CODES)) {
                    this.excludedResponseStatusCodes = commaDelimitedListToIntArray(value);
                } else {
                    log.warn(sm.getString(
                            ""expiresFilter.unknownParameterIgnored"", name,
                            value));
                }
            } catch (RuntimeException e) {
                throw new ServletException(sm.getString(
                        ""expiresFilter.exceptionProcessingParameter"", name,
                        value), e);
            }
        }

        
---------------Reference log start----------------
log.debug(sm.getString(""expiresFilter.filterInitialized"", this.toString()))
---------------Reference log end----------------
    }
    }",,
tomcat,15210,"manager.getContext().getLogger().error(sm.getString(""standardSession.bindingEvent""), t)",getContext,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/session/StandardSession.java/#L1437,"public void setAttribute(String name, Object value, boolean notify) {

        // Name cannot be null
        if (name == null) {
            throw new IllegalArgumentException(
                    sm.getString(""standardSession.setAttribute.namenull""));
        }

        // Null value is the same as removeAttribute()
        if (value == null) {
            removeAttribute(name);
            return;
        }

        // Validate our current state
        if (!isValidInternal()) {
            throw new IllegalStateException(
                    sm.getString(""standardSession.setAttribute.ise"", getIdInternal()));
        }

        Context context = manager.getContext();

        if (context.getDistributable() && !isAttributeDistributable(name, value) && !exclude(name, value)) {
            throw new IllegalArgumentException(sm.getString(""standardSession.setAttribute.iae"", name));
        }
        // Construct an event with the new value
        HttpSessionBindingEvent event = null;

        // Call the valueBound() method if necessary
        if (notify && value instanceof HttpSessionBindingListener) {
            // Don't call any notification if replacing with the same value
            // unless configured to do so
            Object oldValue = attributes.get(name);
            if (value != oldValue || manager.getNotifyBindingListenerOnUnchangedValue()) {
                event = new HttpSessionBindingEvent(getSession(), name, value);
                try {
                    ((HttpSessionBindingListener) value).valueBound(event);
                } catch (Throwable t){
                    
---------------Reference log start----------------
manager.getContext().getLogger().error(sm.getString(""standardSession.bindingEvent""), t)
---------------Reference log end----------------
                }
            }
        }

        // Replace or add this attribute
        Object unbound = attributes.put(name, value);

        // Call the valueUnbound() method if necessary
        if (notify && unbound instanceof HttpSessionBindingListener) {
            // Don't call any notification if replacing with the same value
            // unless configured to do so
            if (unbound != value || manager.getNotifyBindingListenerOnUnchangedValue()) {
                try {
                    ((HttpSessionBindingListener) unbound).valueUnbound
                        (new HttpSessionBindingEvent(getSession(), name));
                } catch (Throwable t) {
                    ExceptionUtils.handleThrowable(t);
                    manager.getContext().getLogger().error
                        (sm.getString(""standardSession.bindingEvent""), t);
                }
            }
        }

        if (!notify) {
            return;
        }

        // Notify interested application event listeners
        Object listeners[] = context.getApplicationEventListeners();
        if (listeners == null) {
            return;
        }
        for (Object o : listeners) {
            if (!(o instanceof HttpSessionAttributeListener)) {
                continue;
            }
            HttpSessionAttributeListener listener = (HttpSessionAttributeListener) o;
            try {
                if (unbound != null) {
                    if (unbound != value || manager.getNotifyAttributeListenerOnUnchangedValue()) {
                        context.fireContainerEvent(""beforeSessionAttributeReplaced"", listener);
                        if (event == null) {
                            event = new HttpSessionBindingEvent(getSession(), name, unbound);
                        }
                        listener.attributeReplaced(event);
                        context.fireContainerEvent(""afterSessionAttributeReplaced"", listener);
                    }
                } else {
                    context.fireContainerEvent(""beforeSessionAttributeAdded"", listener);
                    if (event == null) {
                        event = new HttpSessionBindingEvent(getSession(), name, value);
                    }
                    listener.attributeAdded(event);
                    context.fireContainerEvent(""afterSessionAttributeAdded"", listener);
                }
            } catch (Throwable t) {
                ExceptionUtils.handleThrowable(t);
                try {
                    if (unbound != null) {
                        if (unbound != value ||
                                manager.getNotifyAttributeListenerOnUnchangedValue()) {
                            context.fireContainerEvent(""afterSessionAttributeReplaced"", listener);
                        }
                    } else {
                        context.fireContainerEvent(""afterSessionAttributeAdded"", listener);
                    }
                } catch (Exception e) {
                    // Ignore
                }
                manager.getContext().getLogger().error(
                        sm.getString(""standardSession.attributeEvent""), t);
            }
        }
    }",,
tomcat,15782,"log.trace(""Map["" + mapname + ""] accepting...."" + msg)",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/tipis/AbstractReplicatedMap.java/#L813,"@Override
    public boolean accept(Serializable msg, Member sender) {
        boolean result = false;
        if (msg instanceof MapMessage) {
            if ( log.isTraceEnabled() ) {
                
---------------Reference log start----------------
log.trace(""Map["" + mapname + ""] accepting...."" + msg)
---------------Reference log end----------------
            }
            result = Arrays.equals(mapContextName, ( (MapMessage) msg).getMapId());
            if ( log.isTraceEnabled() ) {
                log.trace(""Msg[""+mapname+""] accepted[""+result+""]....""+msg);
            }
        }
        return result;
    }",,
tomcat,17418,"log.debug("" Cannot resolve entity: '"" + publicId + ""'"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/Digester.java/#L1387,"@Override
    public InputSource resolveEntity(String name, String publicId, String baseURI, String systemId)
            throws SAXException, IOException {

        if (saxLog.isDebugEnabled()) {
            saxLog.debug(
                    ""resolveEntity('"" + publicId + ""', '"" + systemId + ""', '"" + baseURI + ""')"");
        }

        // Has this system identifier been registered?
        String entityURL = null;
        if (publicId != null) {
            entityURL = entityValidator.get(publicId);
        }

        if (entityURL == null) {
            if (systemId == null) {
                // cannot resolve
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug("" Cannot resolve entity: '"" + publicId + ""'"")
---------------Reference log end----------------
                }
                return null;

            } else {
                // try to resolve using system ID
                if (log.isDebugEnabled()) {
                    log.debug("" Trying to resolve using system ID '"" + systemId + ""'"");
                }
                entityURL = systemId;
                // resolve systemId against baseURI if it is not absolute
                if (baseURI != null) {
                    try {
                        URI uri = new URI(systemId);
                        if (!uri.isAbsolute()) {
                            entityURL = new URI(baseURI).resolve(uri).toString();
                        }
                    } catch (URISyntaxException e) {
                        if (log.isDebugEnabled()) {
                            log.debug(""Invalid URI '"" + baseURI + ""' or '"" + systemId + ""'"");
                        }
                    }
                }
            }
        }

        // Return an input source to our alternative URL
        if (log.isDebugEnabled()) {
            log.debug("" Resolving to alternate DTD '"" + entityURL + ""'"");
        }

        try {
            return new InputSource(entityURL);
        } catch (Exception e) {
            throw createSAXException(e);
        }
    }",,
tomcat,16237,"log.warn(sm.getString(""hostConfig.context.remove"", app.name), t)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/HostConfig.java/#L1508,"private void undeploy(DeployedApplication app) {
        if (log.isInfoEnabled()) {
            log.info(sm.getString(""hostConfig.undeploy"", app.name));
        }
        Container context = host.findChild(app.name);
        try {
            host.removeChild(context);
        } catch (Throwable t) {
            ExceptionUtils.handleThrowable(t);
            
---------------Reference log start----------------
log.warn(sm.getString(""hostConfig.context.remove"", app.name), t)
---------------Reference log end----------------
        }
        deployed.remove(app.name);
    }",,
tomcat,15537,"log.debug(sm.getString(""jaasRealm.failedLogin"", username))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JAASRealm.java/#L459,"protected Principal authenticate(String username,
            CallbackHandler callbackHandler) {

        // Establish a LoginContext to use for authentication
        try {
            LoginContext loginContext = null;
            if( appName==null ) {
                appName=""Tomcat"";
            }

            if( log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.beginLogin"", username, appName));
            }

            // What if the LoginModule is in the container class loader ?
            ClassLoader ocl = null;

            if (!isUseContextClassLoader()) {
                ocl = Thread.currentThread().getContextClassLoader();
                Thread.currentThread().setContextClassLoader(
                        this.getClass().getClassLoader());
            }

            try {
                Configuration config = getConfig();
                loginContext = new LoginContext(
                        appName, null, callbackHandler, config);
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                log.error(sm.getString(""jaasRealm.unexpectedError""), e);
                // There is configuration issue with JAAS so mark the realm as
                // unavailable
                invocationSuccess = false;
                return null;
            } finally {
                if(!isUseContextClassLoader()) {
                    Thread.currentThread().setContextClassLoader(ocl);
                }
            }

            if( log.isDebugEnabled()) {
                log.debug(""Login context created "" + username);
            }

            // Negotiate a login via this LoginContext
            Subject subject = null;
            try {
                loginContext.login();
                subject = loginContext.getSubject();
                // We were able to perform login successfully so mark JAAS realm as
                // available as it could have been set to false in prior attempts.
                // Change invocationSuccess variable only when we know the outcome
                // of the JAAS operation to keep variable consistent.
                invocationSuccess = true;
                if (subject == null) {
                    if( log.isDebugEnabled()) {
                        log.debug(sm.getString(""jaasRealm.failedLogin"", username));
                    }
                    return null;
                }
            } catch (AccountExpiredException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.accountExpired"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (CredentialExpiredException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.credentialExpired"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (FailedLoginException e) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""jaasRealm.failedLogin"", username))
---------------Reference log end----------------
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (LoginException e) {
                log.warn(sm.getString(""jaasRealm.loginException"", username), e);
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                log.error(sm.getString(""jaasRealm.unexpectedError""), e);
                // JAAS throws exception different than LoginException so mark the
                // realm as unavailable
                invocationSuccess = false;
                return null;
            }

            if( log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.loginContextCreated"", username));
            }

            // Return the appropriate Principal for this authenticated Subject
            Principal principal = createPrincipal(username, subject, loginContext);
            if (principal == null) {
                log.debug(sm.getString(""jaasRealm.authenticateFailure"", username));
                return null;
            }
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.authenticateSuccess"", username, principal));
            }

            return principal;
        } catch( Throwable t) {
            log.error( ""error "", t);
            //JAAS throws exception different than LoginException so mark the realm as unavailable
            invocationSuccess = false;
            return null;
        }
    }",,
tomcat,17348,"log.error(sm.getString(""webXml.mergeConflictResource"", resourceName, fragment.getName(), fragment.getURL()))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/descriptor/web/WebXml.java/#L1982,"private <T extends ResourceBase> boolean mergeResourceMap(
            Map<String, T> fragmentResources, Map<String, T> mainResources,
            Map<String, T> tempResources, WebXml fragment) {
        for (T resource : fragmentResources.values()) {
            String resourceName = resource.getName();
            if (mainResources.containsKey(resourceName)) {
                mainResources.get(resourceName).getInjectionTargets().addAll(
                        resource.getInjectionTargets());
            } else {
                // Not defined in main web.xml
                T existingResource = tempResources.get(resourceName);
                if (existingResource != null) {
                    if (!existingResource.equals(resource)) {
                        
---------------Reference log start----------------
log.error(sm.getString(""webXml.mergeConflictResource"", resourceName, fragment.getName(), fragment.getURL()))
---------------Reference log end----------------
                        return false;
                    }
                } else {
                    tempResources.put(resourceName, resource);
                }
            }
        }
        return true;
    }",,
tomcat,17684,"log.error(""SQL Validation error"", ex)",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/PooledConnection.java/#L590,"public boolean validate(int validateAction,String sql) {
        if (this.isDiscarded()) {
            return false;
        }

        if (!doValidate(validateAction)) {
            //no validation required, no init sql and props not set
            return true;
        }

        //Don't bother validating if already have recently enough
        long now = System.currentTimeMillis();
        if (validateAction!=VALIDATE_INIT &&
            poolProperties.getValidationInterval() > 0 &&
            (now - this.lastValidated) <
            poolProperties.getValidationInterval()) {
            return true;
        }

        if (poolProperties.getValidator() != null) {
            if (poolProperties.getValidator().validate(connection, validateAction)) {
                this.lastValidated = now;
                return true;
            } else {
                if (getPoolProperties().getLogValidationErrors()) {
                    log.error(""Custom validation through ""+poolProperties.getValidator()+"" failed."");
                }
                return false;
            }
        }

        String query = sql;

        if (validateAction == VALIDATE_INIT && poolProperties.getInitSQL() != null) {
            query = poolProperties.getInitSQL();
        }

        if (query == null) {
            query = poolProperties.getValidationQuery();
        }

        if (query == null) {
            boolean transactionCommitted = false;
            int validationQueryTimeout = poolProperties.getValidationQueryTimeout();
            if (validationQueryTimeout < 0) {
              validationQueryTimeout = 0;
            }
            try {
                if (connection.isValid(validationQueryTimeout)) {
                    this.lastValidated = now;
                    transactionCommitted = silentlyCommitTransactionIfNeeded();
                    return true;
                } else {
                    if (getPoolProperties().getLogValidationErrors()) {
                        log.error(""isValid() returned false."");
                    }
                    return false;
                }
            } catch (SQLException e) {
                if (getPoolProperties().getLogValidationErrors()) {
                    log.error(""isValid() failed."", e);
                } else if (log.isDebugEnabled()) {
                    log.debug(""isValid() failed."", e);
                }
                return false;
            } finally {
                if (!transactionCommitted) {
                    silentlyRollbackTransactionIfNeeded();
                }
            }
        }

        boolean transactionCommitted = false;
        Statement stmt = null;
        try {
            stmt = connection.createStatement();

            int validationQueryTimeout = poolProperties.getValidationQueryTimeout();
            if (validationQueryTimeout > 0) {
                stmt.setQueryTimeout(validationQueryTimeout);
            }

            stmt.execute(query);
            stmt.close();
            this.lastValidated = now;
            transactionCommitted = silentlyCommitTransactionIfNeeded();
            return true;
        } catch (Exception ex) {
            if (getPoolProperties().getLogValidationErrors()) {
                
---------------Reference log start----------------
log.error(""SQL Validation error"", ex)
---------------Reference log end----------------
            } else if (log.isDebugEnabled()) {
                log.debug(""Unable to validate object:"",ex);
            }
            if (stmt!=null) {
              try { stmt.close();} catch (Exception ignore2){/*NOOP*/}
            }

        } finally {
            if (!transactionCommitted) {
                silentlyRollbackTransactionIfNeeded();
            }
        }
        return false;
    }",,
tomcat,17533,"log.warn(Localizer.getMessage(""jsp.warning.unsupported.sourceVM"", requestedSource, actualSource))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/compiler/JDTCompiler.java/#L457,"@Override
    protected void generateClass(Map<String,SmapStratum> smaps)
        throws FileNotFoundException, JasperException, Exception {

        long t1 = 0;
        if (log.isDebugEnabled()) {
            t1 = System.currentTimeMillis();
        }

        final String sourceFile = ctxt.getServletJavaFileName();
        final String outputDir = ctxt.getOptions().getScratchDir().getAbsolutePath();
        String packageName = ctxt.getServletPackageName();
        final String targetClassName =
                ((packageName.length() != 0) ? (packageName + ""."") : """") + ctxt.getServletClassName();
        final ClassLoader classLoader = ctxt.getJspLoader();
        String[] fileNames = new String[] {sourceFile};
        String[] classNames = new String[] {targetClassName};
        final List<JavacErrorDetail> problemList = new ArrayList<>();

        class CompilationUnit implements ICompilationUnit {

            private final String className;
            private final String sourceFile;

            CompilationUnit(String sourceFile, String className) {
                this.className = className;
                this.sourceFile = sourceFile;
            }

            @Override
            public char[] getFileName() {
                return sourceFile.toCharArray();
            }

            @Override
            public char[] getContents() {
                char[] result = null;
                try (FileInputStream is = new FileInputStream(sourceFile);
                        InputStreamReader isr = new InputStreamReader(is, ctxt.getOptions().getJavaEncoding());
                        Reader reader = new BufferedReader(isr)) {
                    char[] chars = new char[8192];
                    StringBuilder buf = new StringBuilder();
                    int count;
                    while ((count = reader.read(chars, 0, chars.length)) > 0) {
                        buf.append(chars, 0, count);
                    }
                    result = new char[buf.length()];
                    buf.getChars(0, result.length, result, 0);
                } catch (IOException e) {
                    log.error(Localizer.getMessage(""jsp.error.compilation.source"", sourceFile), e);
                }
                return result;
            }

            @Override
            public char[] getMainTypeName() {
                int dot = className.lastIndexOf('.');
                if (dot > 0) {
                    return className.substring(dot + 1).toCharArray();
                }
                return className.toCharArray();
            }

            @Override
            public char[][] getPackageName() {
                StringTokenizer izer = new StringTokenizer(className, ""."");
                char[][] result = new char[izer.countTokens()-1][];
                for (int i = 0; i < result.length; i++) {
                    String tok = izer.nextToken();
                    result[i] = tok.toCharArray();
                }
                return result;
            }

            @Override
            public boolean ignoreOptionalProblems() {
                return false;
            }
        }

        final INameEnvironment env = new INameEnvironment() {

                @Override
                public NameEnvironmentAnswer findType(char[][] compoundTypeName) {
                    StringBuilder result = new StringBuilder();
                    for (int i = 0; i < compoundTypeName.length; i++) {
                        if (i > 0) {
                            result.append('.');
                        }
                        result.append(compoundTypeName[i]);
                    }
                    return findType(result.toString());
                }

                @Override
                public NameEnvironmentAnswer findType(char[] typeName, char[][] packageName) {
                    StringBuilder result = new StringBuilder();
                    int i=0;
                    for (; i < packageName.length; i++) {
                        if (i > 0) {
                            result.append('.');
                        }
                        result.append(packageName[i]);
                    }
                    if (i > 0) {
                        result.append('.');
                    }
                    result.append(typeName);
                    return findType(result.toString());
                }

                private NameEnvironmentAnswer findType(String className) {

                    if (className.equals(targetClassName)) {
                        ICompilationUnit compilationUnit = new CompilationUnit(sourceFile, className);
                        return new NameEnvironmentAnswer(compilationUnit, null);
                    }

                    String resourceName = className.replace('.', '/') + "".class"";

                    try (InputStream is = classLoader.getResourceAsStream(resourceName)) {
                        if (is != null) {
                            byte[] classBytes;
                            byte[] buf = new byte[8192];
                            ByteArrayOutputStream baos = new ByteArrayOutputStream(buf.length);
                            int count;
                            while ((count = is.read(buf, 0, buf.length)) > 0) {
                                baos.write(buf, 0, count);
                            }
                            baos.flush();
                            classBytes = baos.toByteArray();
                            char[] fileName = className.toCharArray();
                            ClassFileReader classFileReader = new ClassFileReader(classBytes, fileName, true);
                            return new NameEnvironmentAnswer(classFileReader, null);
                        }
                    } catch (IOException | ClassFormatException exc) {
                        log.error(Localizer.getMessage(""jsp.error.compilation.dependent"", className), exc);
                    }
                    return null;
                }

                private boolean isPackage(String result) {
                    if (result.equals(targetClassName) || result.startsWith(targetClassName + '$')) {
                        return false;
                    }
                    String resourceName = result.replace('.', '/') + "".class"";
                    try (InputStream is =
                        classLoader.getResourceAsStream(resourceName)) {
                        return is == null;
                    } catch (IOException e) {
                        // we are here, since close on is failed. That means it was not null
                        return false;
                    }
                }

                @Override
                public boolean isPackage(char[][] parentPackageName, char[] packageName) {
                    StringBuilder result = new StringBuilder();
                    int i = 0;
                    if (parentPackageName != null) {
                        for (; i < parentPackageName.length; i++) {
                            if (i > 0) {
                                result.append('.');
                            }
                            result.append(parentPackageName[i]);
                        }
                    }

                    if (Character.isUpperCase(packageName[0])) {
                        if (!isPackage(result.toString())) {
                            return false;
                        }
                    }
                    if (i > 0) {
                        result.append('.');
                    }
                    result.append(packageName);

                    return isPackage(result.toString());
                }

                @Override
                public void cleanup() {
                }

            };

        final IErrorHandlingPolicy policy = DefaultErrorHandlingPolicies.proceedWithAllProblems();

        final Map<String,String> settings = new HashMap<>();
        settings.put(CompilerOptions.OPTION_LineNumberAttribute,
                     CompilerOptions.GENERATE);
        settings.put(CompilerOptions.OPTION_SourceFileAttribute,
                     CompilerOptions.GENERATE);
        settings.put(CompilerOptions.OPTION_ReportDeprecation,
                     CompilerOptions.IGNORE);
        if (ctxt.getOptions().getJavaEncoding() != null) {
            settings.put(CompilerOptions.OPTION_Encoding,
                    ctxt.getOptions().getJavaEncoding());
        }
        if (ctxt.getOptions().getClassDebugInfo()) {
            settings.put(CompilerOptions.OPTION_LocalVariableAttribute,
                         CompilerOptions.GENERATE);
        }

        // Source JVM
        if(ctxt.getOptions().getCompilerSourceVM() != null) {
            String opt = ctxt.getOptions().getCompilerSourceVM();
            if(opt.equals(""1.1"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_1);
            } else if(opt.equals(""1.2"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_2);
            } else if(opt.equals(""1.3"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_3);
            } else if(opt.equals(""1.4"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_4);
            } else if(opt.equals(""1.5"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_5);
            } else if(opt.equals(""1.6"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_6);
            } else if(opt.equals(""1.7"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_7);
            } else if(opt.equals(""1.8"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
            // Version format changed from Java 9 onwards.
            // Support old format that was used in EA implementation as well
            } else if(opt.equals(""9"") || opt.equals(""1.9"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_9);
            } else if(opt.equals(""10"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_10);
            } else if(opt.equals(""11"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_11);
            } else if(opt.equals(""12"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_12);
            } else if(opt.equals(""13"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_13);
            } else if(opt.equals(""14"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_14);
            } else if(opt.equals(""15"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_15);
            } else if(opt.equals(""16"")) {
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_16);
            } else if(opt.equals(""17"")) {
                // Constant not available in latest ECJ version shipped with
                // Tomcat. May be supported in a snapshot build.
                // This is checked against the actual version below.
                settings.put(CompilerOptions.OPTION_Source, ""17"");
            } else {
                log.warn(Localizer.getMessage(""jsp.warning.unknown.sourceVM"", opt));
                settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
            }
        } else {
            // Default to 1.8
            settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_8);
        }

        // Target JVM
        if(ctxt.getOptions().getCompilerTargetVM() != null) {
            String opt = ctxt.getOptions().getCompilerTargetVM();
            if(opt.equals(""1.1"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_1);
            } else if(opt.equals(""1.2"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_2);
            } else if(opt.equals(""1.3"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_3);
            } else if(opt.equals(""1.4"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_4);
            } else if(opt.equals(""1.5"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_5);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_5);
            } else if(opt.equals(""1.6"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_6);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_6);
            } else if(opt.equals(""1.7"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_7);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_7);
            } else if(opt.equals(""1.8"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_8);
            // Version format changed from Java 9 onwards.
            // Support old format that was used in EA implementation as well
            } else if(opt.equals(""9"") || opt.equals(""1.9"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_9);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_9);
            } else if(opt.equals(""10"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_10);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_10);
            } else if(opt.equals(""11"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_11);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_11);
            } else if(opt.equals(""12"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_12);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_12);
            } else if(opt.equals(""13"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_13);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_13);
            } else if(opt.equals(""14"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_14);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_14);
            } else if(opt.equals(""15"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_15);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_15);
            } else if(opt.equals(""16"")) {
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_16);
                settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_16);
            } else if(opt.equals(""17"")) {
                // Constant not available in latest ECJ version shipped with
                // Tomcat. May be supported in a snapshot build.
                // This is checked against the actual version below.
                settings.put(CompilerOptions.OPTION_TargetPlatform, ""17"");
                settings.put(CompilerOptions.OPTION_Compliance, ""17"");
            } else {
                log.warn(Localizer.getMessage(""jsp.warning.unknown.targetVM"", opt));
                settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
            }
        } else {
            // Default to 1.8
            settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_8);
            settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_8);
        }

        final IProblemFactory problemFactory = new DefaultProblemFactory(Locale.getDefault());

        final ICompilerRequestor requestor = new ICompilerRequestor() {
                @Override
                public void acceptResult(CompilationResult result) {
                    try {
                        if (result.hasProblems()) {
                            IProblem[] problems = result.getProblems();
                            for (IProblem problem : problems) {
                                if (problem.isError()) {
                                    String name =
                                            new String(problem.getOriginatingFileName());
                                    try {
                                        problemList.add(ErrorDispatcher.createJavacError
                                                (name, pageNodes, new StringBuilder(problem.getMessage()),
                                                        problem.getSourceLineNumber(), ctxt));
                                    } catch (JasperException e) {
                                        log.error(Localizer.getMessage(""jsp.error.compilation.jdtProblemError""), e);
                                    }
                                }
                            }
                        }
                        if (problemList.isEmpty()) {
                            ClassFile[] classFiles = result.getClassFiles();
                            for (ClassFile classFile : classFiles) {
                                char[][] compoundName =
                                        classFile.getCompoundName();
                                StringBuilder classFileName = new StringBuilder(outputDir).append('/');
                                for (int j = 0;
                                     j < compoundName.length; j++) {
                                    if (j > 0) {
                                        classFileName.append('/');
                                    }
                                    classFileName.append(compoundName[j]);
                                }
                                byte[] bytes = classFile.getBytes();
                                classFileName.append("".class"");
                                try (FileOutputStream fout = new FileOutputStream(classFileName.toString());
                                        BufferedOutputStream bos = new BufferedOutputStream(fout)) {
                                    bos.write(bytes);
                                }
                            }
                        }
                    } catch (IOException exc) {
                        log.error(Localizer.getMessage(""jsp.error.compilation.jdt""), exc);
                    }
                }
            };

        ICompilationUnit[] compilationUnits =
            new ICompilationUnit[classNames.length];
        for (int i = 0; i < compilationUnits.length; i++) {
            String className = classNames[i];
            compilationUnits[i] = new CompilationUnit(fileNames[i], className);
        }
        CompilerOptions cOptions = new CompilerOptions(settings);

        // Check source/target JDK versions as the newest versions are allowed
        // in Tomcat configuration but may not be supported by the ECJ version
        // being used.
        String requestedSource = ctxt.getOptions().getCompilerSourceVM();
        if (requestedSource != null) {
            String actualSource = CompilerOptions.versionFromJdkLevel(cOptions.sourceLevel);
            if (!requestedSource.equals(actualSource)) {
                
---------------Reference log start----------------
log.warn(Localizer.getMessage(""jsp.warning.unsupported.sourceVM"", requestedSource, actualSource))
---------------Reference log end----------------
            }
        }
        String requestedTarget = ctxt.getOptions().getCompilerTargetVM();
        if (requestedTarget != null) {
            String actualTarget = CompilerOptions.versionFromJdkLevel(cOptions.targetJDK);
            if (!requestedTarget.equals(actualTarget)) {
                log.warn(Localizer.getMessage(""jsp.warning.unsupported.targetVM"", requestedTarget, actualTarget));
            }
        }

        cOptions.parseLiteralExpressionsAsConstants = true;
        Compiler compiler = new Compiler(env,
                                         policy,
                                         cOptions,
                                         requestor,
                                         problemFactory);
        compiler.compile(compilationUnits);

        if (!ctxt.keepGenerated()) {
            File javaFile = new File(ctxt.getServletJavaFileName());
            if (!javaFile.delete()) {
                throw new JasperException(Localizer.getMessage(
                        ""jsp.warning.compiler.javafile.delete.fail"", javaFile));
            }
        }

        if (!problemList.isEmpty()) {
            JavacErrorDetail[] jeds =
                problemList.toArray(new JavacErrorDetail[0]);
            errDispatcher.javacError(jeds);
        }

        if( log.isDebugEnabled() ) {
            long t2=System.currentTimeMillis();
            log.debug(""Compiled "" + ctxt.getServletJavaFileName() + "" ""
                      + (t2-t1) + ""ms"");
        }

        if (ctxt.isPrototypeMode()) {
            return;
        }

        // JSR45 Support
        if (! options.isSmapSuppressed()) {
            SmapUtil.installSmap(smaps);
        }
    }",,
tomcat,16399,"log.info(sm.getString(""farmWarDeployer.removeStart"", contextName))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/deploy/FarmWarDeployer.java/#L423,"@Override
    public void remove(String contextName, boolean undeploy)
            throws IOException {
        if (getCluster().getMembers().length > 0) {
            if (log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""farmWarDeployer.removeStart"", contextName))
---------------Reference log end----------------
            }
            Member localMember = getCluster().getLocalMember();
            UndeployMessage msg = new UndeployMessage(localMember, System
                    .currentTimeMillis(), ""Undeploy:"" + contextName + "":""
                    + System.currentTimeMillis(), contextName);
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""farmWarDeployer.removeTxMsg"", contextName));
            }
            cluster.send(msg);
        }
        // remove locally
        if (undeploy) {
            try {
                if (tryAddServiced(contextName)) {
                    try {
                        remove(contextName);
                    } finally {
                        removeServiced(contextName);
                    }
                    check(contextName);
                } else {
                    log.error(sm.getString(""farmWarDeployer.removeFailRemote"",
                            contextName));
                }

            } catch (Exception ex) {
                log.error(sm.getString(""farmWarDeployer.removeFailLocal"",
                        contextName), ex);
            }
        }

    }",,
tomcat,17713,"log.warn(PROP_MAXOPENPREPAREDSTATEMENTS + "" is not a valid setting, it will have no effect."")",warn,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/DataSourceFactory.java/#L419,"public static PoolConfiguration parsePoolProperties(Properties properties) {
        PoolConfiguration poolProperties = new PoolProperties();
        String value = null;

        value = properties.getProperty(PROP_DEFAULTAUTOCOMMIT);
        if (value != null) {
            poolProperties.setDefaultAutoCommit(Boolean.valueOf(value));
        }

        value = properties.getProperty(PROP_DEFAULTREADONLY);
        if (value != null) {
            poolProperties.setDefaultReadOnly(Boolean.valueOf(value));
        }

        value = properties.getProperty(PROP_DEFAULTTRANSACTIONISOLATION);
        if (value != null) {
            int level = UNKNOWN_TRANSACTIONISOLATION;
            if (""NONE"".equalsIgnoreCase(value)) {
                level = Connection.TRANSACTION_NONE;
            } else if (""READ_COMMITTED"".equalsIgnoreCase(value)) {
                level = Connection.TRANSACTION_READ_COMMITTED;
            } else if (""READ_UNCOMMITTED"".equalsIgnoreCase(value)) {
                level = Connection.TRANSACTION_READ_UNCOMMITTED;
            } else if (""REPEATABLE_READ"".equalsIgnoreCase(value)) {
                level = Connection.TRANSACTION_REPEATABLE_READ;
            } else if (""SERIALIZABLE"".equalsIgnoreCase(value)) {
                level = Connection.TRANSACTION_SERIALIZABLE;
            } else {
                try {
                    level = Integer.parseInt(value);
                } catch (NumberFormatException e) {
                    System.err.println(""Could not parse defaultTransactionIsolation: "" + value);
                    System.err.println(""WARNING: defaultTransactionIsolation not set"");
                    System.err.println(""using default value of database driver"");
                    level = UNKNOWN_TRANSACTIONISOLATION;
                }
            }
            poolProperties.setDefaultTransactionIsolation(level);
        }

        value = properties.getProperty(PROP_DEFAULTCATALOG);
        if (value != null) {
            poolProperties.setDefaultCatalog(value);
        }

        value = properties.getProperty(PROP_DRIVERCLASSNAME);
        if (value != null) {
            poolProperties.setDriverClassName(value);
        }

        value = properties.getProperty(PROP_MAXACTIVE);
        if (value != null) {
            poolProperties.setMaxActive(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_MAXIDLE);
        if (value != null) {
            poolProperties.setMaxIdle(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_MINIDLE);
        if (value != null) {
            poolProperties.setMinIdle(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_INITIALSIZE);
        if (value != null) {
            poolProperties.setInitialSize(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_MAXWAIT);
        if (value != null) {
            poolProperties.setMaxWait(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_TESTONBORROW);
        if (value != null) {
            poolProperties.setTestOnBorrow(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_TESTONRETURN);
        if (value != null) {
            poolProperties.setTestOnReturn(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_TESTONCONNECT);
        if (value != null) {
            poolProperties.setTestOnConnect(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_TIMEBETWEENEVICTIONRUNSMILLIS);
        if (value != null) {
            poolProperties.setTimeBetweenEvictionRunsMillis(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_NUMTESTSPEREVICTIONRUN);
        if (value != null) {
            poolProperties.setNumTestsPerEvictionRun(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_MINEVICTABLEIDLETIMEMILLIS);
        if (value != null) {
            poolProperties.setMinEvictableIdleTimeMillis(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_TESTWHILEIDLE);
        if (value != null) {
            poolProperties.setTestWhileIdle(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_PASSWORD);
        if (value != null) {
            poolProperties.setPassword(value);
        }

        value = properties.getProperty(PROP_URL);
        if (value != null) {
            poolProperties.setUrl(value);
        }

        value = properties.getProperty(PROP_USERNAME);
        if (value != null) {
            poolProperties.setUsername(value);
        }

        value = properties.getProperty(PROP_VALIDATIONQUERY);
        if (value != null) {
            poolProperties.setValidationQuery(value);
        }

        value = properties.getProperty(PROP_VALIDATIONQUERY_TIMEOUT);
        if (value != null) {
            poolProperties.setValidationQueryTimeout(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_VALIDATOR_CLASS_NAME);
        if (value != null) {
            poolProperties.setValidatorClassName(value);
        }

        value = properties.getProperty(PROP_VALIDATIONINTERVAL);
        if (value != null) {
            poolProperties.setValidationInterval(Long.parseLong(value));
        }

        value = properties.getProperty(PROP_ACCESSTOUNDERLYINGCONNECTIONALLOWED);
        if (value != null) {
            poolProperties.setAccessToUnderlyingConnectionAllowed(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_REMOVEABANDONED);
        if (value != null) {
            poolProperties.setRemoveAbandoned(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_REMOVEABANDONEDTIMEOUT);
        if (value != null) {
            poolProperties.setRemoveAbandonedTimeout(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_LOGABANDONED);
        if (value != null) {
            poolProperties.setLogAbandoned(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_POOLPREPAREDSTATEMENTS);
        if (value != null) {
            log.warn(PROP_POOLPREPAREDSTATEMENTS + "" is not a valid setting, it will have no effect."");
        }

        value = properties.getProperty(PROP_MAXOPENPREPAREDSTATEMENTS);
        if (value != null) {
            
---------------Reference log start----------------
log.warn(PROP_MAXOPENPREPAREDSTATEMENTS + "" is not a valid setting, it will have no effect."")
---------------Reference log end----------------
        }

        value = properties.getProperty(PROP_CONNECTIONPROPERTIES);
        if (value != null) {
            Properties p = getProperties(value);
            poolProperties.setDbProperties(p);
        } else {
            poolProperties.setDbProperties(new Properties());
        }

        if (poolProperties.getUsername()!=null) {
            poolProperties.getDbProperties().setProperty(""user"",poolProperties.getUsername());
        }
        if (poolProperties.getPassword()!=null) {
            poolProperties.getDbProperties().setProperty(""password"",poolProperties.getPassword());
        }

        value = properties.getProperty(PROP_INITSQL);
        if (value != null) {
            poolProperties.setInitSQL(value);
        }

        value = properties.getProperty(PROP_INTERCEPTORS);
        if (value != null) {
            poolProperties.setJdbcInterceptors(value);
        }

        value = properties.getProperty(PROP_JMX_ENABLED);
        if (value != null) {
            poolProperties.setJmxEnabled(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_FAIR_QUEUE);
        if (value != null) {
            poolProperties.setFairQueue(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_USE_EQUALS);
        if (value != null) {
            poolProperties.setUseEquals(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(OBJECT_NAME);
        if (value != null) {
            poolProperties.setName(ObjectName.quote(value));
        }

        value = properties.getProperty(PROP_ABANDONWHENPERCENTAGEFULL);
        if (value != null) {
            poolProperties.setAbandonWhenPercentageFull(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_MAXAGE);
        if (value != null) {
            poolProperties.setMaxAge(Long.parseLong(value));
        }

        value = properties.getProperty(PROP_USE_CON_LOCK);
        if (value != null) {
            poolProperties.setUseLock(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_DATASOURCE);
        if (value != null) {
            //this should never happen
            throw new IllegalArgumentException(""Can't set dataSource property as a string, this must be a javax.sql.DataSource object."");

        }

        value = properties.getProperty(PROP_DATASOURCE_JNDI);
        if (value != null) {
            poolProperties.setDataSourceJNDI(value);
        }

        value = properties.getProperty(PROP_SUSPECT_TIMEOUT);
        if (value != null) {
            poolProperties.setSuspectTimeout(Integer.parseInt(value));
        }

        value = properties.getProperty(PROP_ALTERNATE_USERNAME_ALLOWED);
        if (value != null) {
            poolProperties.setAlternateUsernameAllowed(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_COMMITONRETURN);
        if (value != null) {
            poolProperties.setCommitOnReturn(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_ROLLBACKONRETURN);
        if (value != null) {
            poolProperties.setRollbackOnReturn(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_USEDISPOSABLECONNECTIONFACADE);
        if (value != null) {
            poolProperties.setUseDisposableConnectionFacade(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_LOGVALIDATIONERRORS);
        if (value != null) {
            poolProperties.setLogValidationErrors(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_PROPAGATEINTERRUPTSTATE);
        if (value != null) {
            poolProperties.setPropagateInterruptState(Boolean.parseBoolean(value));
        }

        value = properties.getProperty(PROP_IGNOREEXCEPTIONONPRELOAD);
        if (value != null) {
            poolProperties.setIgnoreExceptionOnPreLoad(Boolean.parseBoolean(value));
        }
        value = properties.getProperty(PROP_USESTATEMENTFACADE);
        if (value != null) {
            poolProperties.setUseStatementFacade(Boolean.parseBoolean(value));
        }
        return poolProperties;
    }",,
tomcat,15551,"containerLog.warn(sm.getString(""jndiRealm.emptyCipherSuites""))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JNDIRealm.java/#L1031,"private String[] getCipherSuitesArray() {
        if (cipherSuites == null || cipherSuitesArray != null) {
            return cipherSuitesArray;
        }
        if (this.cipherSuites.trim().isEmpty()) {
            
---------------Reference log start----------------
containerLog.warn(sm.getString(""jndiRealm.emptyCipherSuites""))
---------------Reference log end----------------
            this.cipherSuitesArray = null;
        } else {
            this.cipherSuitesArray = cipherSuites.trim().split(""\\s*,\\s*"");
            containerLog.debug(sm.getString(""jndiRealm.cipherSuites"",
                    Arrays.toString(this.cipherSuitesArray)));
        }
        return this.cipherSuitesArray;
    }",,
tomcat,17178,"log.error(sm.getString(""openssl.errApplyConf""))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/openssl/OpenSSLContext.java/#L332,"@Override
    public synchronized void init(KeyManager[] kms, TrustManager[] tms, SecureRandom sr) {
        if (initialized) {
            log.warn(sm.getString(""openssl.doubleInit""));
            return;
        }
        try {
            if (sslHostConfig.getInsecureRenegotiation()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION);
            }

            // Use server's preference order for ciphers (rather than
            // client's)
            if (sslHostConfig.getHonorCipherOrder()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_CIPHER_SERVER_PREFERENCE);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_CIPHER_SERVER_PREFERENCE);
            }

            // Disable compression if requested
            if (sslHostConfig.getDisableCompression()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_NO_COMPRESSION);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_NO_COMPRESSION);
            }

            // Disable TLS Session Tickets (RFC4507) to protect perfect forward secrecy
            if (sslHostConfig.getDisableSessionTickets()) {
                SSLContext.setOptions(ctx, SSL.SSL_OP_NO_TICKET);
            } else {
                SSLContext.clearOptions(ctx, SSL.SSL_OP_NO_TICKET);
            }

            // List the ciphers that the client is permitted to negotiate
            SSLContext.setCipherSuite(ctx, sslHostConfig.getCiphers());

            if (certificate.getCertificateFile() == null) {
                certificate.setCertificateKeyManager(OpenSSLUtil.chooseKeyManager(kms));
            }

            addCertificate(certificate);

            // Client certificate verification
            int value = 0;
            switch (sslHostConfig.getCertificateVerification()) {
            case NONE:
                value = SSL.SSL_CVERIFY_NONE;
                break;
            case OPTIONAL:
                value = SSL.SSL_CVERIFY_OPTIONAL;
                break;
            case OPTIONAL_NO_CA:
                value = SSL.SSL_CVERIFY_OPTIONAL_NO_CA;
                break;
            case REQUIRED:
                value = SSL.SSL_CVERIFY_REQUIRE;
                break;
            }
            SSLContext.setVerify(ctx, value, sslHostConfig.getCertificateVerificationDepth());

            if (tms != null) {
                // Client certificate verification based on custom trust managers
                x509TrustManager = chooseTrustManager(tms);
                SSLContext.setCertVerifyCallback(ctx, new CertificateVerifier() {
                    @Override
                    public boolean verify(long ssl, byte[][] chain, String auth) {
                        X509Certificate[] peerCerts = certificates(chain);
                        try {
                            x509TrustManager.checkClientTrusted(peerCerts, auth);
                            return true;
                        } catch (Exception e) {
                            log.debug(sm.getString(""openssl.certificateVerificationFailed""), e);
                        }
                        return false;
                    }
                });
                // Pass along the DER encoded certificates of the accepted client
                // certificate issuers, so that their subjects can be presented
                // by the server during the handshake to allow the client choosing
                // an acceptable certificate
                for (X509Certificate caCert : x509TrustManager.getAcceptedIssuers()) {
                    SSLContext.addClientCACertificateRaw(ctx, caCert.getEncoded());
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""openssl.addedClientCaCert"", caCert.toString()));
                    }
                }
            } else {
                // Client certificate verification based on trusted CA files and dirs
                SSLContext.setCACertificate(ctx,
                        SSLHostConfig.adjustRelativePath(sslHostConfig.getCaCertificateFile()),
                        SSLHostConfig.adjustRelativePath(sslHostConfig.getCaCertificatePath()));
            }

            if (negotiableProtocols != null && negotiableProtocols.size() > 0) {
                List<String> protocols = new ArrayList<>(negotiableProtocols);
                protocols.add(""http/1.1"");
                String[] protocolsArray = protocols.toArray(new String[0]);
                SSLContext.setAlpnProtos(ctx, protocolsArray, SSL.SSL_SELECTOR_FAILURE_NO_ADVERTISE);
                SSLContext.setNpnProtos(ctx, protocolsArray, SSL.SSL_SELECTOR_FAILURE_NO_ADVERTISE);
            }

            // Apply OpenSSLConfCmd if used
            OpenSSLConf openSslConf = sslHostConfig.getOpenSslConf();
            if (openSslConf != null && cctx != 0) {
                // Check OpenSSLConfCmd if used
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""openssl.checkConf""));
                }
                try {
                    if (!openSslConf.check(cctx)) {
                        log.error(sm.getString(""openssl.errCheckConf""));
                        throw new Exception(sm.getString(""openssl.errCheckConf""));
                    }
                } catch (Exception e) {
                    throw new Exception(sm.getString(""openssl.errCheckConf""), e);
                }
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""openssl.applyConf""));
                }
                try {
                    if (!openSslConf.apply(cctx, ctx)) {
                        
---------------Reference log start----------------
log.error(sm.getString(""openssl.errApplyConf""))
---------------Reference log end----------------
                        throw new SSLException(sm.getString(""openssl.errApplyConf""));
                    }
                } catch (Exception e) {
                    throw new SSLException(sm.getString(""openssl.errApplyConf""), e);
                }
                // Reconfigure the enabled protocols
                int opts = SSLContext.getOptions(ctx);
                List<String> enabled = new ArrayList<>();
                // Seems like there is no way to explicitly disable SSLv2Hello
                // in OpenSSL so it is always enabled
                enabled.add(Constants.SSL_PROTO_SSLv2Hello);
                if ((opts & SSL.SSL_OP_NO_TLSv1) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1);
                }
                if ((opts & SSL.SSL_OP_NO_TLSv1_1) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1_1);
                }
                if ((opts & SSL.SSL_OP_NO_TLSv1_2) == 0) {
                    enabled.add(Constants.SSL_PROTO_TLSv1_2);
                }
                if ((opts & SSL.SSL_OP_NO_SSLv2) == 0) {
                    enabled.add(Constants.SSL_PROTO_SSLv2);
                }
                if ((opts & SSL.SSL_OP_NO_SSLv3) == 0) {
                    enabled.add(Constants.SSL_PROTO_SSLv3);
                }
                sslHostConfig.setEnabledProtocols(
                        enabled.toArray(new String[0]));
                // Reconfigure the enabled ciphers
                sslHostConfig.setEnabledCiphers(SSLContext.getCiphers(ctx));
            }

            sessionContext = new OpenSSLSessionContext(this);
            // If client authentication is being used, OpenSSL requires that
            // this is set so always set it in case an app is configured to
            // require it
            sessionContext.setSessionIdContext(SSLContext.DEFAULT_SESSION_ID_CONTEXT);
            sslHostConfig.setOpenSslContext(Long.valueOf(ctx));
            initialized = true;
        } catch (Exception e) {
            log.warn(sm.getString(""openssl.errorSSLCtxInit""), e);
            destroy();
        }
    }",,
tomcat,16518,"log.trace(""Real Path for '/': ["" + getServletContext().getRealPath(""/"") + ""]"")",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L552,"private void printServletEnvironment(HttpServletRequest req) throws IOException {

        // Document the properties from ServletRequest
        log.trace(""ServletRequest Properties"");
        Enumeration<String> attrs = req.getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Request Attribute: "" + attr + "": [ "" + req.getAttribute(attr) +""]"");
        }
        log.trace(""Character Encoding: ["" + req.getCharacterEncoding() + ""]"");
        log.trace(""Content Length: ["" + req.getContentLengthLong() + ""]"");
        log.trace(""Content Type: ["" + req.getContentType() + ""]"");
        Enumeration<Locale> locales = req.getLocales();
        while (locales.hasMoreElements()) {
            Locale locale = locales.nextElement();
            log.trace(""Locale: ["" +locale + ""]"");
        }
        Enumeration<String> params = req.getParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            for (String value : req.getParameterValues(param)) {
                log.trace(""Request Parameter: "" + param + "":  ["" + value + ""]"");
            }
        }
        log.trace(""Protocol: ["" + req.getProtocol() + ""]"");
        log.trace(""Remote Address: ["" + req.getRemoteAddr() + ""]"");
        log.trace(""Remote Host: ["" + req.getRemoteHost() + ""]"");
        log.trace(""Scheme: ["" + req.getScheme() + ""]"");
        log.trace(""Secure: ["" + req.isSecure() + ""]"");
        log.trace(""Server Name: ["" + req.getServerName() + ""]"");
        log.trace(""Server Port: ["" + req.getServerPort() + ""]"");

        // Document the properties from HttpServletRequest
        log.trace(""HttpServletRequest Properties"");
        log.trace(""Auth Type: ["" + req.getAuthType() + ""]"");
        log.trace(""Context Path: ["" + req.getContextPath() + ""]"");
        Cookie cookies[] = req.getCookies();
        if (cookies != null) {
            for (Cookie cookie : cookies) {
                log.trace(""Cookie: "" + cookie.getName() + "": ["" + cookie.getValue() + ""]"");
            }
        }
        Enumeration<String> headers = req.getHeaderNames();
        while (headers.hasMoreElements()) {
            String header = headers.nextElement();
            log.trace(""HTTP Header: "" + header + "": ["" + req.getHeader(header) + ""]"");
        }
        log.trace(""Method: ["" + req.getMethod() + ""]"");
        log.trace(""Path Info: ["" + req.getPathInfo() + ""]"");
        log.trace(""Path Translated: ["" + req.getPathTranslated() + ""]"");
        log.trace(""Query String: ["" + req.getQueryString() + ""]"");
        log.trace(""Remote User: ["" + req.getRemoteUser() + ""]"");
        log.trace(""Requested Session ID: ["" + req.getRequestedSessionId() + ""]"");
        log.trace(""Requested Session ID From Cookie: ["" +
                req.isRequestedSessionIdFromCookie() + ""]"");
        log.trace(""Requested Session ID From URL: ["" + req.isRequestedSessionIdFromURL() + ""]"");
        log.trace(""Requested Session ID Valid: ["" + req.isRequestedSessionIdValid() + ""]"");
        log.trace(""Request URI: ["" + req.getRequestURI() + ""]"");
        log.trace(""Servlet Path: ["" + req.getServletPath() + ""]"");
        log.trace(""User Principal: ["" + req.getUserPrincipal() + ""]"");

        // Process the current session (if there is one)
        HttpSession session = req.getSession(false);
        if (session != null) {

            // Document the session properties
            log.trace(""HttpSession Properties"");
            log.trace(""ID: ["" + session.getId() + ""]"");
            log.trace(""Creation Time: ["" + new Date(session.getCreationTime()) + ""]"");
            log.trace(""Last Accessed Time: ["" + new Date(session.getLastAccessedTime()) + ""]"");
            log.trace(""Max Inactive Interval: ["" + session.getMaxInactiveInterval() + ""]"");

            // Document the session attributes
            attrs = session.getAttributeNames();
            while (attrs.hasMoreElements()) {
                String attr = attrs.nextElement();
                log.trace(""Session Attribute: "" + attr + "": ["" + session.getAttribute(attr) + ""]"");
            }
        }

        // Document the servlet configuration properties
        log.trace(""ServletConfig Properties"");
        log.trace(""Servlet Name: ["" + getServletConfig().getServletName() + ""]"");

        // Document the servlet configuration initialization parameters
        params = getServletConfig().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletConfig().getInitParameter(param);
            log.trace(""Servlet Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context properties
        log.trace(""ServletContext Properties"");
        log.trace(""Major Version: ["" + getServletContext().getMajorVersion() + ""]"");
        log.trace(""Minor Version: ["" + getServletContext().getMinorVersion() + ""]"");
        
---------------Reference log start----------------
log.trace(""Real Path for '/': ["" + getServletContext().getRealPath(""/"") + ""]"")
---------------Reference log end----------------
        log.trace(""Server Info: ["" + getServletContext().getServerInfo() + ""]"");

        // Document the servlet context initialization parameters
        log.trace(""ServletContext Initialization Parameters"");
        params = getServletContext().getInitParameterNames();
        while (params.hasMoreElements()) {
            String param = params.nextElement();
            String value = getServletContext().getInitParameter(param);
            log.trace(""Servlet Context Init Param: "" + param + "": ["" + value + ""]"");
        }

        // Document the servlet context attributes
        log.trace(""ServletContext Attributes"");
        attrs = getServletContext().getAttributeNames();
        while (attrs.hasMoreElements()) {
            String attr = attrs.nextElement();
            log.trace(""Servlet Context Attribute: "" + attr +
                    "": ["" + getServletContext().getAttribute(attr) + ""]"");
        }
    }",,
tomcat,15535,"log.debug(sm.getString(""jaasRealm.accountExpired"", username))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/JAASRealm.java/#L443,"protected Principal authenticate(String username,
            CallbackHandler callbackHandler) {

        // Establish a LoginContext to use for authentication
        try {
            LoginContext loginContext = null;
            if( appName==null ) {
                appName=""Tomcat"";
            }

            if( log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.beginLogin"", username, appName));
            }

            // What if the LoginModule is in the container class loader ?
            ClassLoader ocl = null;

            if (!isUseContextClassLoader()) {
                ocl = Thread.currentThread().getContextClassLoader();
                Thread.currentThread().setContextClassLoader(
                        this.getClass().getClassLoader());
            }

            try {
                Configuration config = getConfig();
                loginContext = new LoginContext(
                        appName, null, callbackHandler, config);
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                log.error(sm.getString(""jaasRealm.unexpectedError""), e);
                // There is configuration issue with JAAS so mark the realm as
                // unavailable
                invocationSuccess = false;
                return null;
            } finally {
                if(!isUseContextClassLoader()) {
                    Thread.currentThread().setContextClassLoader(ocl);
                }
            }

            if( log.isDebugEnabled()) {
                log.debug(""Login context created "" + username);
            }

            // Negotiate a login via this LoginContext
            Subject subject = null;
            try {
                loginContext.login();
                subject = loginContext.getSubject();
                // We were able to perform login successfully so mark JAAS realm as
                // available as it could have been set to false in prior attempts.
                // Change invocationSuccess variable only when we know the outcome
                // of the JAAS operation to keep variable consistent.
                invocationSuccess = true;
                if (subject == null) {
                    if( log.isDebugEnabled()) {
                        log.debug(sm.getString(""jaasRealm.failedLogin"", username));
                    }
                    return null;
                }
            } catch (AccountExpiredException e) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""jaasRealm.accountExpired"", username))
---------------Reference log end----------------
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (CredentialExpiredException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.credentialExpired"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (FailedLoginException e) {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""jaasRealm.failedLogin"", username));
                }
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (LoginException e) {
                log.warn(sm.getString(""jaasRealm.loginException"", username), e);
                // JAAS checked LoginExceptions are successful authentication
                // invocations so mark JAAS realm as available
                invocationSuccess = true;
                return null;
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                log.error(sm.getString(""jaasRealm.unexpectedError""), e);
                // JAAS throws exception different than LoginException so mark the
                // realm as unavailable
                invocationSuccess = false;
                return null;
            }

            if( log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.loginContextCreated"", username));
            }

            // Return the appropriate Principal for this authenticated Subject
            Principal principal = createPrincipal(username, subject, loginContext);
            if (principal == null) {
                log.debug(sm.getString(""jaasRealm.authenticateFailure"", username));
                return null;
            }
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""jaasRealm.authenticateSuccess"", username, principal));
            }

            return principal;
        } catch( Throwable t) {
            log.error( ""error "", t);
            //JAAS throws exception different than LoginException so mark the realm as unavailable
            invocationSuccess = false;
            return null;
        }
    }",,
tomcat,16328,"log.info(sm.getString(""deltaManager.noMembers"", getName()))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/session/DeltaManager.java/#L740,"public synchronized void getAllClusterSessions() {
        if (cluster != null && cluster.getMembers().length > 0) {
            long beforeSendTime = System.currentTimeMillis();
            Member mbr = findSessionMasterMember();
            if(mbr == null) { // No domain member found
                 return;
            }
            SessionMessage msg = new SessionMessageImpl(this.getName(),
                    SessionMessage.EVT_GET_ALL_SESSIONS, null, ""GET-ALL"", ""GET-ALL-"" + getName());
            msg.setTimestamp(beforeSendTime);
            // set reference time
            stateTransferCreateSendTime = beforeSendTime ;
            // request session state
            counterSend_EVT_GET_ALL_SESSIONS++;
            stateTransferred = false ;
            // FIXME This send call block the deploy thread, when sender waitForAck is enabled
            try {
                synchronized(receivedMessageQueue) {
                     receiverQueue = true ;
                }
                cluster.send(msg, mbr, Channel.SEND_OPTIONS_ASYNCHRONOUS);
                if (log.isInfoEnabled()) {
                    log.info(sm.getString(""deltaManager.waitForSessionState"",
                            getName(), mbr, Integer.valueOf(getStateTransferTimeout())));
                }
                // FIXME At sender ack mode this method check only the state
                //       transfer and resend is a problem!
                waitForSendAllSessions(beforeSendTime);
            } finally {
                synchronized(receivedMessageQueue) {
                    for (SessionMessage smsg : receivedMessageQueue) {
                        if (!stateTimestampDrop) {
                            messageReceived(smsg, smsg.getAddress());
                        } else {
                            if (smsg.getEventType() != SessionMessage.EVT_GET_ALL_SESSIONS &&
                                    smsg.getTimestamp() >= stateTransferCreateSendTime) {
                                // FIXME handle EVT_GET_ALL_SESSIONS later
                                messageReceived(smsg, smsg.getAddress());
                            } else {
                                if (log.isWarnEnabled()) {
                                    log.warn(sm.getString(""deltaManager.dropMessage"",
                                            getName(),
                                            smsg.getEventTypeString(),
                                            new Date(stateTransferCreateSendTime),
                                            new Date(smsg.getTimestamp())));
                                }
                            }
                        }
                    }
                    receivedMessageQueue.clear();
                    receiverQueue = false ;
                }
           }
        } else {
            if (log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(sm.getString(""deltaManager.noMembers"", getName()))
---------------Reference log end----------------
            }
        }
    }",,
tomcat,16721,"log.warn(sm.getString(""standardServer.accept.readError""), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardServer.java/#L643,"@Override
    public void await() {
        // Negative values - don't wait on port - tomcat is embedded or we just don't like ports
        if (getPortWithOffset() == -2) {
            // undocumented yet - for embedding apps that are around, alive.
            return;
        }
        if (getPortWithOffset() == -1) {
            try {
                awaitThread = Thread.currentThread();
                while(!stopAwait) {
                    try {
                        Thread.sleep( 10000 );
                    } catch( InterruptedException ex ) {
                        // continue and check the flag
                    }
                }
            } finally {
                awaitThread = null;
            }
            return;
        }

        // Set up a server socket to wait on
        try {
            awaitSocket = new ServerSocket(getPortWithOffset(), 1,
                    InetAddress.getByName(address));
        } catch (IOException e) {
            log.error(sm.getString(""standardServer.awaitSocket.fail"", address,
                    String.valueOf(getPortWithOffset()), String.valueOf(getPort()),
                    String.valueOf(getPortOffset())), e);
            return;
        }

        try {
            awaitThread = Thread.currentThread();

            // Loop waiting for a connection and a valid command
            while (!stopAwait) {
                ServerSocket serverSocket = awaitSocket;
                if (serverSocket == null) {
                    break;
                }

                // Wait for the next connection
                Socket socket = null;
                StringBuilder command = new StringBuilder();
                try {
                    InputStream stream;
                    long acceptStartTime = System.currentTimeMillis();
                    try {
                        socket = serverSocket.accept();
                        socket.setSoTimeout(10 * 1000);  // Ten seconds
                        stream = socket.getInputStream();
                    } catch (SocketTimeoutException ste) {
                        // This should never happen but bug 56684 suggests that
                        // it does.
                        log.warn(sm.getString(""standardServer.accept.timeout"",
                                Long.valueOf(System.currentTimeMillis() - acceptStartTime)), ste);
                        continue;
                    } catch (AccessControlException ace) {
                        log.warn(sm.getString(""standardServer.accept.security""), ace);
                        continue;
                    } catch (IOException e) {
                        if (stopAwait) {
                            // Wait was aborted with socket.close()
                            break;
                        }
                        log.error(sm.getString(""standardServer.accept.error""), e);
                        break;
                    }

                    // Read a set of characters from the socket
                    int expected = 1024; // Cut off to avoid DoS attack
                    while (expected < shutdown.length()) {
                        if (random == null) {
                            random = new Random();
                        }
                        expected += (random.nextInt() % 1024);
                    }
                    while (expected > 0) {
                        int ch = -1;
                        try {
                            ch = stream.read();
                        } catch (IOException e) {
                            
---------------Reference log start----------------
log.warn(sm.getString(""standardServer.accept.readError""), e)
---------------Reference log end----------------
                            ch = -1;
                        }
                        // Control character or EOF (-1) terminates loop
                        if (ch < 32 || ch == 127) {
                            break;
                        }
                        command.append((char) ch);
                        expected--;
                    }
                } finally {
                    // Close the socket now that we are done with it
                    try {
                        if (socket != null) {
                            socket.close();
                        }
                    } catch (IOException e) {
                        // Ignore
                    }
                }

                // Match against our command string
                boolean match = command.toString().equals(shutdown);
                if (match) {
                    log.info(sm.getString(""standardServer.shutdownViaPort""));
                    break;
                } else {
                    log.warn(sm.getString(""standardServer.invalidShutdownCommand"", command.toString()));
                }
            }
        } finally {
            ServerSocket serverSocket = awaitSocket;
            awaitThread = null;
            awaitSocket = null;

            // Close the server socket and return
            if (serverSocket != null) {
                try {
                    serverSocket.close();
                } catch (IOException e) {
                    // Ignore
                }
            }
        }
    }",,
tomcat,15473,"log.debug(sm.getString(""expiresFilter.useMatchingConfiguration"", configuration, contentTypeWithoutCharset, contentType, result))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/filters/ExpiresFilter.java/#L1306,"protected Date getExpirationDate(HttpServletRequest request, XHttpServletResponse response) {
        String contentType = response.getContentType();
        if (contentType == null && request != null &&
                request.getHttpServletMapping().getMappingMatch() == MappingMatch.DEFAULT &&
                response.getStatus() == HttpServletResponse.SC_NOT_MODIFIED) {
            // Default servlet normally sets the content type but does not for
            // 304 responses. Look it up.
            String servletPath = request.getServletPath();
            if (servletPath != null) {
                int lastSlash = servletPath.lastIndexOf('/');
                if (lastSlash > -1) {
                    String fileName = servletPath.substring(lastSlash + 1);
                    contentType = request.getServletContext().getMimeType(fileName);
                }
            }
        }
        if (contentType != null) {
            contentType = contentType.toLowerCase(Locale.ENGLISH);
        }

        // lookup exact content-type match (e.g.
        // ""text/html; charset=iso-8859-1"")
        ExpiresConfiguration configuration = expiresConfigurationByContentType.get(contentType);
        if (configuration != null) {
            Date result = getExpirationDate(configuration, response);
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(
                        ""expiresFilter.useMatchingConfiguration"",
                        configuration, contentType, contentType, result));
            }
            return result;
        }

        if (contains(contentType, "";"")) {
            // lookup content-type without charset match (e.g. ""text/html"")
            String contentTypeWithoutCharset = substringBefore(contentType, "";"").trim();
            configuration = expiresConfigurationByContentType.get(contentTypeWithoutCharset);

            if (configuration != null) {
                Date result = getExpirationDate(configuration, response);
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""expiresFilter.useMatchingConfiguration"", configuration, contentTypeWithoutCharset, contentType, result))
---------------Reference log end----------------
                }
                return result;
            }
        }

        if (contains(contentType, ""/"")) {
            // lookup major type match (e.g. ""text"")
            String majorType = substringBefore(contentType, ""/"");
            configuration = expiresConfigurationByContentType.get(majorType);
            if (configuration != null) {
                Date result = getExpirationDate(configuration, response);
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(
                            ""expiresFilter.useMatchingConfiguration"",
                            configuration, majorType, contentType, result));
                }
                return result;
            }
        }

        if (defaultExpiresConfiguration != null) {
            Date result = getExpirationDate(defaultExpiresConfiguration,
                    response);
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""expiresFilter.useDefaultConfiguration"",
                        defaultExpiresConfiguration, contentType, result));
            }
            return result;
        }

        if (log.isDebugEnabled()) {
            log.debug(sm.getString(
                    ""expiresFilter.noExpirationConfiguredForContentType"",
                    contentType));
        }
        return null;
    }",,
tomcat,16411,"log.error(sm.getString(""farmWarDeployer.deleteFail"", war))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/deploy/FarmWarDeployer.java/#L535,"protected void remove(String contextName) throws Exception {
        // TODO Handle remove also work dir content !
        // Stop the context first to be nicer
        Context context = (Context) host.findChild(contextName);
        if (context != null) {
            if(log.isDebugEnabled()) {
                log.debug(sm.getString(""farmWarDeployer.undeployLocal"",
                        contextName));
            }
            context.stop();
            String baseName = context.getBaseName();
            File war = new File(host.getAppBaseFile(), baseName + "".war"");
            File dir = new File(host.getAppBaseFile(), baseName);
            File xml = new File(configBase, baseName + "".xml"");
            if (war.exists()) {
                if (!war.delete()) {
                    
---------------Reference log start----------------
log.error(sm.getString(""farmWarDeployer.deleteFail"", war))
---------------Reference log end----------------
                }
            } else if (dir.exists()) {
                undeployDir(dir);
            } else {
                if (!xml.delete()) {
                    log.error(sm.getString(""farmWarDeployer.deleteFail"", xml));
                }
            }
        }
    }",,
tomcat,17186,"log.debug(sm.getString(""opensslconf.applyCommand"", name, value))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/net/openssl/OpenSSLConf.java/#L101,"public boolean apply(long cctx, long ctx) throws Exception {
        boolean result = true;
        SSLConf.assign(cctx, ctx);
        OpenSSLConfCmd cmd;
        String name;
        String value;
        int rc;
        for (OpenSSLConfCmd command : commands) {
            cmd = command;
            name = cmd.getName();
            value = cmd.getValue();
            if (name == null) {
                log.error(sm.getString(""opensslconf.noCommandName"", value));
                result = false;
                continue;
            }
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""opensslconf.applyCommand"", name, value))
---------------Reference log end----------------
            }
            try {
                rc = SSLConf.apply(cctx, name, value);
            } catch (Exception e) {
                log.error(sm.getString(""opensslconf.applyFailed""));
                return false;
            }
            if (rc <= 0) {
                log.error(sm.getString(""opensslconf.failedCommand"", name, value,
                        Integer.toString(rc)));
                result = false;
            } else if (log.isDebugEnabled()) {
                log.debug(sm.getString(""opensslconf.resultCommand"", name, value,
                        Integer.toString(rc)));
            }
        }
        rc = SSLConf.finish(cctx);
        if (rc <= 0) {
            log.error(sm.getString(""opensslconf.finishFailed"", Integer.toString(rc)));
            result = false;
        }
        if (!result) {
            log.error(sm.getString(""opensslconf.applyFailed""));
        }
        return result;
    }",,
tomcat,17667,"log.warn(""testAllIdle failed, it will be retried."", e)",warn,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/ConnectionPool.java/#L1211,"public void testAllIdle(boolean checkMaxAgeOnly) {
        try {
            if (idle.isEmpty()) {
              return;
            }
            Iterator<PooledConnection> unlocked = idle.iterator();
            while (unlocked.hasNext()) {
                PooledConnection con = unlocked.next();
                try {
                    con.lock();
                    //the con been taken out, we can't clean it up
                    if (busy.contains(con)) {
                      continue;
                    }

                    boolean release;
                    if (checkMaxAgeOnly) {
                        release = !reconnectIfExpired(con);
                    } else {
                        release = !reconnectIfExpired(con) || !con.validate(PooledConnection.VALIDATE_IDLE);
                    }
                    if (release) {
                        idle.remove(con);
                        release(con);
                    }
                } finally {
                    con.unlock();
                }
            } //while
        } catch (ConcurrentModificationException e) {
            log.debug(""testAllIdle failed."" ,e);
        } catch (Exception e) {
            
---------------Reference log start----------------
log.warn(""testAllIdle failed, it will be retried."", e)
---------------Reference log end----------------
        }

    }",,
tomcat,17700,"log.warn(SlowQueryReport.class.getName() + ""- No JMX support, composite type was not found."")",warn,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/interceptor/SlowQueryReportJmx.java/#L289,"protected void registerJmx() {
        try {
            //only if we notify the pool itself
            if (isNotifyPool()) {

            } else if (getCompositeType()!=null) {
                ObjectName oname = getObjectName(getClass(),poolName);
                if (mbeans.putIfAbsent(poolName, this)==null) {
                    JmxUtil.registerJmx(oname, null, this);
                }
            } else {
                
---------------Reference log start----------------
log.warn(SlowQueryReport.class.getName() + ""- No JMX support, composite type was not found."")
---------------Reference log end----------------
            }
        } catch (MalformedObjectNameException e) {
            log.error(""Jmx registration failed, no JMX data will be exposed for the query stats."",e);
        } catch (RuntimeOperationsException e) {
            log.error(""Jmx registration failed, no JMX data will be exposed for the query stats."",e);
        }
    }",,
tomcat,16579,"log.error(sm.getString(""naming.bindFailed"", e))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/NamingContextListener.java/#L591,"private void createNamingContext()
        throws NamingException {

        // Creating the comp subcontext
        if (container instanceof Server) {
            compCtx = namingContext;
            envCtx = namingContext;
        } else {
            compCtx = namingContext.createSubcontext(""comp"");
            envCtx = compCtx.createSubcontext(""env"");
        }

        int i;

        if (log.isDebugEnabled()) {
            log.debug(""Creating JNDI naming context"");
        }

        if (namingResources == null) {
            namingResources = new NamingResourcesImpl();
            namingResources.setContainer(container);
        }

        // Resource links
        ContextResourceLink[] resourceLinks =
            namingResources.findResourceLinks();
        for (i = 0; i < resourceLinks.length; i++) {
            addResourceLink(resourceLinks[i]);
        }

        // Resources
        ContextResource[] resources = namingResources.findResources();
        for (i = 0; i < resources.length; i++) {
            addResource(resources[i]);
        }

        // Resources Env
        ContextResourceEnvRef[] resourceEnvRefs = namingResources.findResourceEnvRefs();
        for (i = 0; i < resourceEnvRefs.length; i++) {
            addResourceEnvRef(resourceEnvRefs[i]);
        }

        // Environment entries
        ContextEnvironment[] contextEnvironments =
            namingResources.findEnvironments();
        for (i = 0; i < contextEnvironments.length; i++) {
            addEnvironment(contextEnvironments[i]);
        }

        // EJB references
        ContextEjb[] ejbs = namingResources.findEjbs();
        for (i = 0; i < ejbs.length; i++) {
            addEjb(ejbs[i]);
        }

        // Message Destination References
        MessageDestinationRef[] mdrs = namingResources.findMessageDestinationRefs();
        for (i = 0; i < mdrs.length; i++) {
            addMessageDestinationRef(mdrs[i]);
        }

        // WebServices references
        ContextService[] services = namingResources.findServices();
        for (i = 0; i < services.length; i++) {
            addService(services[i]);
        }

        // Binding a User Transaction reference
        if (container instanceof Context) {
            try {
                Reference ref = new TransactionRef();
                compCtx.bind(""UserTransaction"", ref);
                ContextTransaction transaction = namingResources.getTransaction();
                if (transaction != null) {
                    Iterator<String> params = transaction.listProperties();
                    while (params.hasNext()) {
                        String paramName = params.next();
                        String paramValue = (String) transaction.getProperty(paramName);
                        StringRefAddr refAddr = new StringRefAddr(paramName, paramValue);
                        ref.add(refAddr);
                    }
                }
            } catch (NameAlreadyBoundException e) {
                // Ignore because UserTransaction was obviously
                // added via ResourceLink
            } catch (NamingException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""naming.bindFailed"", e))
---------------Reference log end----------------
            }
        }

        // Binding the resources directory context
        if (container instanceof Context) {
            try {
                compCtx.bind(""Resources"",
                             ((Context) container).getResources());
            } catch (NamingException e) {
                log.error(sm.getString(""naming.bindFailed"", e));
            }
        }

    }",,
tomcat,16368,"log.error(sm.getString(""tcpSender.readError""))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/backend/TcpSender.java/#L172,"@Override
    public int send(String mess) throws Exception {
        if (connections == null) {
            log.error(sm.getString(""tcpSender.notInitialized""));
            return -1;
        }
        String requestLine = ""POST "" + config.getProxyURL() + "" HTTP/1.0"";

        for (int i = 0; i < connections.length; i++) {
            if (connections[i] == null) {
                try {
                    if (config.getHost() != null) {
                        connections[i] = new Socket();
                        InetAddress addr =  InetAddress.getByName(config.getHost());
                        InetSocketAddress addrs = new InetSocketAddress(addr, 0);
                        connections[i].setReuseAddress(true);
                        connections[i].bind(addrs);
                        addrs = new InetSocketAddress(proxies[i].address, proxies[i].port);
                        connections[i].connect(addrs);
                    } else {
                        connections[i] = new Socket(proxies[i].address, proxies[i].port);
                    }
                    connectionReaders[i] = new BufferedReader(new InputStreamReader(connections[i].getInputStream()));
                    connectionWriters[i] = new BufferedWriter(new OutputStreamWriter(connections[i].getOutputStream()));
                } catch (Exception ex) {
                    log.error(sm.getString(""tcpSender.connectionFailed""), ex);
                    close(i);
                }
            }
            if (connections[i] == null)
             {
                continue; // try next proxy in the list
            }
            BufferedWriter writer = connectionWriters[i];
            try {
                writer.write(requestLine);
                writer.write(""\r\n"");
                writer.write(""Content-Length: "" + mess.length() + ""\r\n"");
                writer.write(""User-Agent: HeartbeatListener/1.0\r\n"");
                writer.write(""Connection: Keep-Alive\r\n"");
                writer.write(""\r\n"");
                writer.write(mess);
                writer.write(""\r\n"");
                writer.flush();
            } catch (Exception ex) {
                log.error(sm.getString(""tcpSender.sendFailed""), ex);
                close(i);
            }
            if (connections[i] == null)
             {
                continue; // try next proxy in the list
            }

            /* Read httpd answer */
            String responseStatus = connectionReaders[i].readLine();
            if (responseStatus == null) {
                log.error(sm.getString(""tcpSender.responseError""));
                close(i);
                continue;
            } else {
                responseStatus = responseStatus.substring(responseStatus.indexOf(' ') + 1, responseStatus.indexOf(' ', responseStatus.indexOf(' ') + 1));
                int status = Integer.parseInt(responseStatus);
                if (status != 200) {
                    log.error(sm.getString(""tcpSender.responseErrorCode"", Integer.valueOf(status)));
                    close(i);
                    continue;
                }

                // read all the headers.
                String header = connectionReaders[i].readLine();
                int contentLength = 0;
                while (header != null && !header.isEmpty()) {
                    int colon = header.indexOf(':');
                    String headerName = header.substring(0, colon).trim();
                    String headerValue = header.substring(colon + 1).trim();
                    if (""content-length"".equalsIgnoreCase(headerName)) {
                        contentLength = Integer.parseInt(headerValue);
                    }
                    header = connectionReaders[i].readLine();
                }
                if (contentLength > 0) {
                    char[] buf = new char[512];
                    while (contentLength > 0) {
                        int thisTime = (contentLength > buf.length) ? buf.length : contentLength;
                        int n = connectionReaders[i].read(buf, 0, thisTime);
                        if (n <= 0) {
                            
---------------Reference log start----------------
log.error(sm.getString(""tcpSender.readError""))
---------------Reference log end----------------
                            close(i);
                            break;
                        } else {
                            contentLength -= n;
                        }
                   }
                }
            }

        }

        return 0;
    }",,
tomcat,16080,"log.warn(sm.getString(""connector.noSetExecutor"", con))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/ConnectorCreateRule.java/#L102,"private static void setExecutor(Connector con, Executor ex) throws Exception {
        Method m = IntrospectionUtils.findMethod(con.getProtocolHandler().getClass(),""setExecutor"",new Class[] {java.util.concurrent.Executor.class});
        if (m!=null) {
            m.invoke(con.getProtocolHandler(), new Object[] {ex});
        }else {
            
---------------Reference log start----------------
log.warn(sm.getString(""connector.noSetExecutor"", con))
---------------Reference log end----------------
        }
    }",,
tomcat,15490,"log.debug(sm.getString(""remoteIpFilter.invalidRemoteAddress"", remoteIp), e)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/filters/RemoteIpFilter.java/#L849,"public void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException {

        boolean isInternal = internalProxies != null &&
                internalProxies.matcher(request.getRemoteAddr()).matches();

        if (isInternal || (trustedProxies != null &&
                trustedProxies.matcher(request.getRemoteAddr()).matches())) {
            String remoteIp = null;
            // In java 6, proxiesHeaderValue should be declared as a java.util.Deque
            LinkedList<String> proxiesHeaderValue = new LinkedList<>();
            StringBuilder concatRemoteIpHeaderValue = new StringBuilder();

            for (Enumeration<String> e = request.getHeaders(remoteIpHeader); e.hasMoreElements();) {
                if (concatRemoteIpHeaderValue.length() > 0) {
                    concatRemoteIpHeaderValue.append("", "");
                }

                concatRemoteIpHeaderValue.append(e.nextElement());
            }

            String[] remoteIpHeaderValue = commaDelimitedListToStringArray(concatRemoteIpHeaderValue.toString());
            int idx;
            if (!isInternal) {
                proxiesHeaderValue.addFirst(request.getRemoteAddr());
            }
            // loop on remoteIpHeaderValue to find the first trusted remote ip and to build the proxies chain
            for (idx = remoteIpHeaderValue.length - 1; idx >= 0; idx--) {
                String currentRemoteIp = remoteIpHeaderValue[idx];
                remoteIp = currentRemoteIp;
                if (internalProxies !=null && internalProxies.matcher(currentRemoteIp).matches()) {
                    // do nothing, internalProxies IPs are not appended to the
                } else if (trustedProxies != null &&
                        trustedProxies.matcher(currentRemoteIp).matches()) {
                    proxiesHeaderValue.addFirst(currentRemoteIp);
                } else {
                    idx--; // decrement idx because break statement doesn't do it
                    break;
                }
            }
            // continue to loop on remoteIpHeaderValue to build the new value of the remoteIpHeader
            LinkedList<String> newRemoteIpHeaderValue = new LinkedList<>();
            for (; idx >= 0; idx--) {
                String currentRemoteIp = remoteIpHeaderValue[idx];
                newRemoteIpHeaderValue.addFirst(currentRemoteIp);
            }

            XForwardedRequest xRequest = new XForwardedRequest(request);
            if (remoteIp != null) {

                xRequest.setRemoteAddr(remoteIp);
                if (getEnableLookups()) {
                    // This isn't a lazy lookup but that would be a little more
                    // invasive - mainly in XForwardedRequest - and if
                    // enableLookups is true is seems reasonable that the
                    // hostname will be required so look it up here.
                    try {
                        InetAddress inetAddress = InetAddress.getByName(remoteIp);
                        // We know we need a DNS look up so use getCanonicalHostName()
                        xRequest.setRemoteHost(inetAddress.getCanonicalHostName());
                    } catch (UnknownHostException e) {
                        
---------------Reference log start----------------
log.debug(sm.getString(""remoteIpFilter.invalidRemoteAddress"", remoteIp), e)
---------------Reference log end----------------
                        xRequest.setRemoteHost(remoteIp);
                    }
                } else {
                    xRequest.setRemoteHost(remoteIp);
                }

                if (proxiesHeaderValue.size() == 0) {
                    xRequest.removeHeader(proxiesHeader);
                } else {
                    String commaDelimitedListOfProxies = listToCommaDelimitedString(proxiesHeaderValue);
                    xRequest.setHeader(proxiesHeader, commaDelimitedListOfProxies);
                }
                if (newRemoteIpHeaderValue.size() == 0) {
                    xRequest.removeHeader(remoteIpHeader);
                } else {
                    String commaDelimitedRemoteIpHeaderValue = listToCommaDelimitedString(newRemoteIpHeaderValue);
                    xRequest.setHeader(remoteIpHeader, commaDelimitedRemoteIpHeaderValue);
                }
            }

            if (protocolHeader != null) {
                String protocolHeaderValue = request.getHeader(protocolHeader);
                if (protocolHeaderValue == null) {
                    // Don't modify the secure, scheme and serverPort attributes
                    // of the request
                } else if (isForwardedProtoHeaderValueSecure(protocolHeaderValue)) {
                    xRequest.setSecure(true);
                    xRequest.setScheme(""https"");
                    setPorts(xRequest, httpsServerPort);
                } else {
                    xRequest.setSecure(false);
                    xRequest.setScheme(""http"");
                    setPorts(xRequest, httpServerPort);
                }
            }

            if (hostHeader != null) {
                String hostHeaderValue = request.getHeader(hostHeader);
                if (hostHeaderValue != null) {
                    try {
                        int portIndex = Host.parse(hostHeaderValue);
                        if (portIndex > -1) {
                            log.debug(sm.getString(""remoteIpFilter.invalidHostWithPort"", hostHeaderValue, hostHeader));
                            hostHeaderValue = hostHeaderValue.substring(0, portIndex);
                        }

                        xRequest.setServerName(hostHeaderValue);
                        if (isChangeLocalName()) {
                            xRequest.setLocalName(hostHeaderValue);
                        }

                    } catch (IllegalArgumentException iae) {
                        log.debug(sm.getString(""remoteIpFilter.invalidHostHeader"", hostHeaderValue, hostHeader));
                    }
                }
            }
            request.setAttribute(Globals.REQUEST_FORWARDED_ATTRIBUTE, Boolean.TRUE);

            if (log.isDebugEnabled()) {
                log.debug(""Incoming request "" + request.getRequestURI() + "" with originalRemoteAddr ["" + request.getRemoteAddr() +
                        ""], originalRemoteHost=["" + request.getRemoteHost() + ""], originalSecure=["" + request.isSecure() +
                        ""], originalScheme=["" + request.getScheme() + ""], originalServerName=["" + request.getServerName() +
                        ""], originalServerPort=["" + request.getServerPort() +
                        ""] will be seen as newRemoteAddr=["" + xRequest.getRemoteAddr() +
                        ""], newRemoteHost=["" + xRequest.getRemoteHost() + ""], newSecure=["" + xRequest.isSecure() +
                        ""], newScheme=["" + xRequest.getScheme() + ""], newServerName=["" + xRequest.getServerName() +
                        ""], newServerPort=["" + xRequest.getServerPort() + ""]"");
            }
            if (requestAttributesEnabled) {
                request.setAttribute(AccessLog.REMOTE_ADDR_ATTRIBUTE,
                        xRequest.getRemoteAddr());
                request.setAttribute(Globals.REMOTE_ADDR_ATTRIBUTE,
                        xRequest.getRemoteAddr());
                request.setAttribute(AccessLog.REMOTE_HOST_ATTRIBUTE,
                        xRequest.getRemoteHost());
                request.setAttribute(AccessLog.PROTOCOL_ATTRIBUTE,
                        xRequest.getProtocol());
                request.setAttribute(AccessLog.SERVER_NAME_ATTRIBUTE,
                        xRequest.getServerName());
                request.setAttribute(AccessLog.SERVER_PORT_ATTRIBUTE,
                        Integer.valueOf(xRequest.getServerPort()));
            }
            chain.doFilter(xRequest, response);
        } else {
            if (log.isDebugEnabled()) {
                log.debug(""Skip RemoteIpFilter for request "" + request.getRequestURI() + "" with originalRemoteAddr '""
                        + request.getRemoteAddr() + ""'"");
            }
            chain.doFilter(request, response);
        }

    }",,
tomcat,15481,"log.debug(sm.getString(""expiresFilter.setExpirationDate"", request.getRequestURI(), Integer.valueOf(response.getStatus()), response.getContentType(), expirationDate))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/filters/ExpiresFilter.java/#L1513,"public void onBeforeWriteResponseBody(HttpServletRequest request,
            XHttpServletResponse response) {

        if (!isEligibleToExpirationHeaderGeneration(request, response)) {
            return;
        }

        Date expirationDate = getExpirationDate(request, response);
        if (expirationDate == null) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""expiresFilter.noExpirationConfigured"",
                        request.getRequestURI(),
                        Integer.valueOf(response.getStatus()),
                        response.getContentType()));
            }
        } else {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""expiresFilter.setExpirationDate"", request.getRequestURI(), Integer.valueOf(response.getStatus()), response.getContentType(), expirationDate))
---------------Reference log end----------------
            }

            String maxAgeDirective = ""max-age="" +
                    ((expirationDate.getTime() - System.currentTimeMillis()) / 1000);

            String cacheControlHeader = response.getCacheControlHeader();
            String newCacheControlHeader = (cacheControlHeader == null) ? maxAgeDirective
                    : cacheControlHeader + "", "" + maxAgeDirective;
            response.setHeader(HEADER_CACHE_CONTROL, newCacheControlHeader);
            response.setDateHeader(HEADER_EXPIRES, expirationDate.getTime());
        }

    }",,
tomcat,16130,"log.debug(""Calling startup class "" + method)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/startup/Bootstrap.java/#L303,"private void load(String[] arguments) throws Exception {

        // Call the load() method
        String methodName = ""load"";
        Object param[];
        Class<?> paramTypes[];
        if (arguments==null || arguments.length==0) {
            paramTypes = null;
            param = null;
        } else {
            paramTypes = new Class[1];
            paramTypes[0] = arguments.getClass();
            param = new Object[1];
            param[0] = arguments;
        }
        Method method =
            catalinaDaemon.getClass().getMethod(methodName, paramTypes);
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Calling startup class "" + method)
---------------Reference log end----------------
        }
        method.invoke(catalinaDaemon, param);
    }",,
tomcat,17332,"log.warn(sm.getString(""webXml.version.unknown"", version))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/descriptor/web/WebXml.java/#L190,"public void setVersion(String version) {
        if (version == null) {
            return;
        }
        switch (version) {
            case ""2.4"":
                majorVersion = 2;
                minorVersion = 4;
                break;
            case ""2.5"":
                majorVersion = 2;
                minorVersion = 5;
                break;
            case ""3.0"":
                majorVersion = 3;
                minorVersion = 0;
                break;
            case ""3.1"":
                majorVersion = 3;
                minorVersion = 1;
                break;
            case ""4.0"":
                majorVersion = 4;
                minorVersion = 0;
                break;
            case ""5.0"":
                majorVersion = 5;
                minorVersion = 0;
                break;
            default:
                
---------------Reference log start----------------
log.warn(sm.getString(""webXml.version.unknown"", version))
---------------Reference log end----------------
        }
    }",,
tomcat,15831,"log.warn(sm.getString(""tcpPingInterceptor.ping.failed""), x)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/group/interceptors/TcpPingInterceptor.java/#L167,"protected void sendPingMessage(Member[] members) {
        if ( members == null || members.length == 0 ) {
            return;
        }
        ChannelData data = new ChannelData(true);//generates a unique Id
        data.setAddress(getLocalMember(false));
        data.setTimestamp(System.currentTimeMillis());
        data.setOptions(getOptionFlag());
        data.setMessage(new XByteBuffer(TCP_PING_DATA, false));
        try {
            super.sendMessage(members, data, null);
        }catch (ChannelException x) {
            
---------------Reference log start----------------
log.warn(sm.getString(""tcpPingInterceptor.ping.failed""), x)
---------------Reference log end----------------
        }
    }",,
tomcat,17461,"log.debug(""IntrospectionUtils: Unable to resolve host name:"" + value)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/IntrospectionUtils.java/#L134,"@SuppressWarnings(""null"") // setPropertyMethodVoid is not null when used
    public static boolean setProperty(Object o, String name, String value,
            boolean invokeSetProperty, StringBuilder actualMethod) {
        if (log.isDebugEnabled()) {
            log.debug(""IntrospectionUtils: setProperty("" +
                    o.getClass() + "" "" + name + ""="" + value + "")"");
        }

        if (actualMethod == null && XReflectionIntrospectionUtils.isEnabled()) {
            return XReflectionIntrospectionUtils.setPropertyInternal(o, name, value, invokeSetProperty);
        }

        String setter = ""set"" + capitalize(name);

        try {
            Method methods[] = findMethods(o.getClass());
            Method setPropertyMethodVoid = null;
            Method setPropertyMethodBool = null;

            // First, the ideal case - a setFoo( String ) method
            for (Method item : methods) {
                Class<?> paramT[] = item.getParameterTypes();
                if (setter.equals(item.getName()) && paramT.length == 1
                        && ""java.lang.String"".equals(paramT[0].getName())) {
                    item.invoke(o, new Object[]{value});
                    if (actualMethod != null) {
                        actualMethod.append(item.getName()).append(""(\"""").append(escape(value)).append(""\"")"");
                    }
                    return true;
                }
            }

            // Try a setFoo ( int ) or ( boolean )
            for (Method method : methods) {
                boolean ok = true;
                if (setter.equals(method.getName())
                        && method.getParameterTypes().length == 1) {

                    // match - find the type and invoke it
                    Class<?> paramType = method.getParameterTypes()[0];
                    Object params[] = new Object[1];

                    // Try a setFoo ( int )
                    if (""java.lang.Integer"".equals(paramType.getName())
                            || ""int"".equals(paramType.getName())) {
                        try {
                            params[0] = Integer.valueOf(value);
                        } catch (NumberFormatException ex) {
                            ok = false;
                        }
                        if (actualMethod != null) {
                            actualMethod.append(method.getName()).append(""(Integer.valueOf(\"""").append(value).append(""\""))"");
                        }
                        // Try a setFoo ( long )
                    } else if (""java.lang.Long"".equals(paramType.getName())
                            || ""long"".equals(paramType.getName())) {
                        try {
                            params[0] = Long.valueOf(value);
                        } catch (NumberFormatException ex) {
                            ok = false;
                        }
                        if (actualMethod != null) {
                            actualMethod.append(method.getName()).append(""(Long.valueOf(\"""").append(value).append(""\""))"");
                        }
                        // Try a setFoo ( boolean )
                    } else if (""java.lang.Boolean"".equals(paramType.getName())
                            || ""boolean"".equals(paramType.getName())) {
                        params[0] = Boolean.valueOf(value);
                        if (actualMethod != null) {
                            actualMethod.append(method.getName()).append(""(Boolean.valueOf(\"""").append(value).append(""\""))"");
                        }
                        // Try a setFoo ( InetAddress )
                    } else if (""java.net.InetAddress"".equals(paramType
                            .getName())) {
                        try {
                            params[0] = InetAddress.getByName(value);
                        } catch (UnknownHostException exc) {
                            if (log.isDebugEnabled()) {
                                
---------------Reference log start----------------
log.debug(""IntrospectionUtils: Unable to resolve host name:"" + value)
---------------Reference log end----------------
                            }
                            ok = false;
                        }
                        if (actualMethod != null) {
                            actualMethod.append(method.getName()).append(""(InetAddress.getByName(\"""").append(value).append(""\""))"");
                        }
                        // Unknown type
                    } else {
                        if (log.isDebugEnabled()) {
                            log.debug(""IntrospectionUtils: Unknown type "" +
                                    paramType.getName());
                        }
                    }

                    if (ok) {
                        method.invoke(o, params);
                        return true;
                    }
                }

                // save ""setProperty"" for later
                if (""setProperty"".equals(method.getName())) {
                    if (method.getReturnType() == Boolean.TYPE) {
                        setPropertyMethodBool = method;
                    } else {
                        setPropertyMethodVoid = method;
                    }

                }
            }

            // Ok, no setXXX found, try a setProperty(""name"", ""value"")
            if (invokeSetProperty && (setPropertyMethodBool != null ||
                    setPropertyMethodVoid != null)) {
                if (actualMethod != null) {
                    actualMethod.append(""setProperty(\"""").append(name).append(""\"", \"""").append(escape(value)).append(""\"")"");
                }
                Object params[] = new Object[2];
                params[0] = name;
                params[1] = value;
                if (setPropertyMethodBool != null) {
                    try {
                        return ((Boolean) setPropertyMethodBool.invoke(o,
                                params)).booleanValue();
                    }catch (IllegalArgumentException biae) {
                        //the boolean method had the wrong
                        //parameter types. lets try the other
                        if (setPropertyMethodVoid!=null) {
                            setPropertyMethodVoid.invoke(o, params);
                            return true;
                        }else {
                            throw biae;
                        }
                    }
                } else {
                    setPropertyMethodVoid.invoke(o, params);
                    return true;
                }
            }

        } catch (IllegalArgumentException | SecurityException | IllegalAccessException e) {
            log.warn(sm.getString(""introspectionUtils.setPropertyError"", name, value, o.getClass()), e);
        } catch (InvocationTargetException e) {
            ExceptionUtils.handleThrowable(e.getCause());
            log.warn(sm.getString(""introspectionUtils.setPropertyError"", name, value, o.getClass()), e);
        }
        return false;
    }",,
tomcat,16395,"log.debug(sm.getString(""farmWarDeployer.deployEnd"", contextName))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/deploy/FarmWarDeployer.java/#L248,"@Override
    public void messageReceived(ClusterMessage msg) {
        try {
            if (msg instanceof FileMessage) {
                FileMessage fmsg = (FileMessage) msg;
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""farmWarDeployer.msgRxDeploy"",
                            fmsg.getContextName(), fmsg.getFileName()));
                }
                FileMessageFactory factory = getFactory(fmsg);
                // TODO correct second try after app is in service!
                if (factory.writeMessage(fmsg)) {
                    //last message received war file is completed
                    String name = factory.getFile().getName();
                    if (!name.endsWith("".war"")) {
                        name = name + "".war"";
                    }
                    File deployable = new File(getDeployDirFile(), name);
                    try {
                        String contextName = fmsg.getContextName();
                        if (tryAddServiced(contextName)) {
                            try {
                                remove(contextName);
                                if (!factory.getFile().renameTo(deployable)) {
                                    log.error(sm.getString(
                                            ""farmWarDeployer.renameFail"",
                                            factory.getFile(), deployable));
                                }
                            } finally {
                                removeServiced(contextName);
                            }
                            check(contextName);
                            if (log.isDebugEnabled()) {
                                
---------------Reference log start----------------
log.debug(sm.getString(""farmWarDeployer.deployEnd"", contextName))
---------------Reference log end----------------
                            }
                        } else {
                            log.error(sm.getString(
                                    ""farmWarDeployer.servicingDeploy"",
                                    contextName, name));
                        }
                    } catch (Exception ex) {
                        log.error(sm.getString(""farmWarDeployer.fileMessageError""), ex);
                    } finally {
                        removeFactory(fmsg);
                    }
                }
            } else if (msg instanceof UndeployMessage) {
                try {
                    UndeployMessage umsg = (UndeployMessage) msg;
                    String contextName = umsg.getContextName();
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""farmWarDeployer.msgRxUndeploy"",
                                contextName));
                    }
                    if (tryAddServiced(contextName)) {
                        try {
                            remove(contextName);
                        } finally {
                            removeServiced(contextName);
                        }
                        if (log.isDebugEnabled()) {
                            log.debug(sm.getString(
                                    ""farmWarDeployer.undeployEnd"",
                                    contextName));
                        }
                    } else {
                        log.error(sm.getString(
                                ""farmWarDeployer.servicingUndeploy"",
                                contextName));
                    }
                } catch (Exception ex) {
                    log.error(sm.getString(""farmWarDeployer.undeployMessageError""), ex);
                }
            }
        } catch (java.io.IOException x) {
            log.error(sm.getString(""farmWarDeployer.msgIoe""), x);
        }
    }",,
tomcat,15944,"containerLog.warn(sm.getString(""singleSignOn.sessionExpire.hostNotFound"", key))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/SingleSignOn.java/#L442,"private void expire(SingleSignOnSessionKey key) {
        if (engine == null) {
            containerLog.warn(sm.getString(""singleSignOn.sessionExpire.engineNull"", key));
            return;
        }
        Container host = engine.findChild(key.getHostName());
        if (host == null) {
            
---------------Reference log start----------------
containerLog.warn(sm.getString(""singleSignOn.sessionExpire.hostNotFound"", key))
---------------Reference log end----------------
            return;
        }
        Context context = (Context) host.findChild(key.getContextName());
        if (context == null) {
            containerLog.warn(sm.getString(""singleSignOn.sessionExpire.contextNotFound"", key));
            return;
        }
        Manager manager = context.getManager();
        if (manager == null) {
            containerLog.warn(sm.getString(""singleSignOn.sessionExpire.managerNotFound"", key));
            return;
        }
        Session session = null;
        try {
            session = manager.findSession(key.getSessionId());
        } catch (IOException e) {
            containerLog.warn(sm.getString(""singleSignOn.sessionExpire.managerError"", key), e);
            return;
        }
        if (session == null) {
            containerLog.warn(sm.getString(""singleSignOn.sessionExpire.sessionNotFound"", key));
            return;
        }
        session.expire();
    }",,
tomcat,16315,"log.debug(""Backup manager, Setting map name to:"" + name)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/ha/session/BackupManager.java/#L167,"public String getMapName() {
        String name = cluster.getManagerName(getName(),this)+""-""+""map"";
        if ( log.isDebugEnabled() ) {
            
---------------Reference log start----------------
log.debug(""Backup manager, Setting map name to:"" + name)
---------------Reference log end----------------
        }
        return name;
    }",,
tomcat,15899,"log.error(sm.getString(""nioReceiver.stop.fail""), x)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/transport/nio/NioReceiver.java/#L382,"protected void stopListening() {
        setListen(false);
        Selector selector = this.selector.get();
        if (selector != null) {
            try {
                // Unlock the thread if is is blocked waiting for input
                selector.wakeup();
                // Wait for the receiver thread to finish
                int count = 0;
                while (running && count < 50) {
                    Thread.sleep(100);
                    count ++;
                }
                if (running) {
                    log.warn(sm.getString(""nioReceiver.stop.threadRunning""));
                }
                closeSelector();
            } catch (Exception x) {
                
---------------Reference log start----------------
log.error(sm.getString(""nioReceiver.stop.fail""), x)
---------------Reference log end----------------
            } finally {
                this.selector.set(null);
            }
        }
    }",,
tomcat,16662,"log.error(sm.getString(""standardContext.servletFail""))",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardContext.java/#L5214,"@Override
    protected synchronized void startInternal() throws LifecycleException {

        if(log.isDebugEnabled()) {
            log.debug(""Starting "" + getBaseName());
        }

        // Send j2ee.state.starting notification
        if (this.getObjectName() != null) {
            Notification notification = new Notification(""j2ee.state.starting"",
                    this.getObjectName(), sequenceNumber.getAndIncrement());
            broadcaster.sendNotification(notification);
        }

        setConfigured(false);
        boolean ok = true;

        // Currently this is effectively a NO-OP but needs to be called to
        // ensure the NamingResources follows the correct lifecycle
        if (namingResources != null) {
            namingResources.start();
        }

        // Post work directory
        postWorkDirectory();

        // Add missing components as necessary
        if (getResources() == null) {   // (1) Required by Loader
            if (log.isDebugEnabled()) {
                log.debug(""Configuring default Resources"");
            }

            try {
                setResources(new StandardRoot(this));
            } catch (IllegalArgumentException e) {
                log.error(sm.getString(""standardContext.resourcesInit""), e);
                ok = false;
            }
        }
        if (ok) {
            resourcesStart();
        }

        if (getLoader() == null) {
            WebappLoader webappLoader = new WebappLoader();
            webappLoader.setDelegate(getDelegate());
            setLoader(webappLoader);
        }

        // An explicit cookie processor hasn't been specified; use the default
        if (cookieProcessor == null) {
            cookieProcessor = new Rfc6265CookieProcessor();
        }

        // Initialize character set mapper
        getCharsetMapper();

        // Validate required extensions
        boolean dependencyCheck = true;
        try {
            dependencyCheck = ExtensionValidator.validateApplication
                (getResources(), this);
        } catch (IOException ioe) {
            log.error(sm.getString(""standardContext.extensionValidationError""), ioe);
            dependencyCheck = false;
        }

        if (!dependencyCheck) {
            // do not make application available if dependency check fails
            ok = false;
        }

        // Reading the ""catalina.useNaming"" environment variable
        String useNamingProperty = System.getProperty(""catalina.useNaming"");
        if ((useNamingProperty != null)
            && (useNamingProperty.equals(""false""))) {
            useNaming = false;
        }

        if (ok && isUseNaming()) {
            if (getNamingContextListener() == null) {
                NamingContextListener ncl = new NamingContextListener();
                ncl.setName(getNamingContextName());
                ncl.setExceptionOnFailedWrite(getJndiExceptionOnFailedWrite());
                addLifecycleListener(ncl);
                setNamingContextListener(ncl);
            }
        }

        // Standard container startup
        if (log.isDebugEnabled()) {
            log.debug(""Processing standard container startup"");
        }


        // Binding thread
        ClassLoader oldCCL = bindThread();

        try {
            if (ok) {
                // Start our subordinate components, if any
                Loader loader = getLoader();
                if (loader instanceof Lifecycle) {
                    ((Lifecycle) loader).start();
                }

                // since the loader just started, the webapp classloader is now
                // created.
                if (loader.getClassLoader() instanceof WebappClassLoaderBase) {
                    WebappClassLoaderBase cl = (WebappClassLoaderBase) loader.getClassLoader();
                    cl.setClearReferencesRmiTargets(getClearReferencesRmiTargets());
                    cl.setClearReferencesStopThreads(getClearReferencesStopThreads());
                    cl.setClearReferencesStopTimerThreads(getClearReferencesStopTimerThreads());
                    cl.setClearReferencesHttpClientKeepAliveThread(getClearReferencesHttpClientKeepAliveThread());
                    cl.setClearReferencesObjectStreamClassCaches(getClearReferencesObjectStreamClassCaches());
                    cl.setClearReferencesThreadLocals(getClearReferencesThreadLocals());
                }

                // By calling unbindThread and bindThread in a row, we setup the
                // current Thread CCL to be the webapp classloader
                unbindThread(oldCCL);
                oldCCL = bindThread();

                // Initialize logger again. Other components might have used it
                // too early, so it should be reset.
                logger = null;
                getLogger();

                Realm realm = getRealmInternal();
                if(null != realm) {
                    if (realm instanceof Lifecycle) {
                        ((Lifecycle) realm).start();
                    }

                    // Place the CredentialHandler into the ServletContext so
                    // applications can have access to it. Wrap it in a ""safe""
                    // handler so application's can't modify it.
                    CredentialHandler safeHandler = new CredentialHandler() {
                        @Override
                        public boolean matches(String inputCredentials, String storedCredentials) {
                            return getRealmInternal().getCredentialHandler().matches(inputCredentials, storedCredentials);
                        }

                        @Override
                        public String mutate(String inputCredentials) {
                            return getRealmInternal().getCredentialHandler().mutate(inputCredentials);
                        }
                    };
                    context.setAttribute(Globals.CREDENTIAL_HANDLER, safeHandler);
                }

                // Notify our interested LifecycleListeners
                fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null);

                // Start our child containers, if not already started
                for (Container child : findChildren()) {
                    if (!child.getState().isAvailable()) {
                        child.start();
                    }
                }

                // Start the Valves in our pipeline (including the basic),
                // if any
                if (pipeline instanceof Lifecycle) {
                    ((Lifecycle) pipeline).start();
                }

                // Acquire clustered manager
                Manager contextManager = null;
                Manager manager = getManager();
                if (manager == null) {
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""standardContext.cluster.noManager"",
                                Boolean.valueOf((getCluster() != null)),
                                Boolean.valueOf(distributable)));
                    }
                    if ((getCluster() != null) && distributable) {
                        try {
                            contextManager = getCluster().createManager(getName());
                        } catch (Exception ex) {
                            log.error(sm.getString(""standardContext.cluster.managerError""), ex);
                            ok = false;
                        }
                    } else {
                        contextManager = new StandardManager();
                    }
                }

                // Configure default manager if none was specified
                if (contextManager != null) {
                    if (log.isDebugEnabled()) {
                        log.debug(sm.getString(""standardContext.manager"",
                                contextManager.getClass().getName()));
                    }
                    setManager(contextManager);
                }

                if (manager!=null && (getCluster() != null) && distributable) {
                    //let the cluster know that there is a context that is distributable
                    //and that it has its own manager
                    getCluster().registerManager(manager);
                }
            }

            if (!getConfigured()) {
                log.error(sm.getString(""standardContext.configurationFail""));
                ok = false;
            }

            // We put the resources into the servlet context
            if (ok) {
                getServletContext().setAttribute
                    (Globals.RESOURCES_ATTR, getResources());

                if (getInstanceManager() == null) {
                    setInstanceManager(createInstanceManager());
                }
                getServletContext().setAttribute(
                        InstanceManager.class.getName(), getInstanceManager());
                InstanceManagerBindings.bind(getLoader().getClassLoader(), getInstanceManager());

                // Create context attributes that will be required
                getServletContext().setAttribute(
                        JarScanner.class.getName(), getJarScanner());

                // Make the version info available
                getServletContext().setAttribute(Globals.WEBAPP_VERSION, getWebappVersion());
            }

            // Set up the context init params
            mergeParameters();

            // Call ServletContainerInitializers
            for (Map.Entry<ServletContainerInitializer, Set<Class<?>>> entry :
                initializers.entrySet()) {
                try {
                    entry.getKey().onStartup(entry.getValue(),
                            getServletContext());
                } catch (ServletException e) {
                    log.error(sm.getString(""standardContext.sciFail""), e);
                    ok = false;
                    break;
                }
            }

            // Configure and call application event listeners
            if (ok) {
                if (!listenerStart()) {
                    log.error(sm.getString(""standardContext.listenerFail""));
                    ok = false;
                }
            }

            // Check constraints for uncovered HTTP methods
            // Needs to be after SCIs and listeners as they may programmatically
            // change constraints
            if (ok) {
                checkConstraintsForUncoveredMethods(findConstraints());
            }

            try {
                // Start manager
                Manager manager = getManager();
                if (manager instanceof Lifecycle) {
                    ((Lifecycle) manager).start();
                }
            } catch(Exception e) {
                log.error(sm.getString(""standardContext.managerFail""), e);
                ok = false;
            }

            // Configure and call application filters
            if (ok) {
                if (!filterStart()) {
                    log.error(sm.getString(""standardContext.filterFail""));
                    ok = false;
                }
            }

            // Load and initialize all ""load on startup"" servlets
            if (ok) {
                if (!loadOnStartup(findChildren())){
                    
---------------Reference log start----------------
log.error(sm.getString(""standardContext.servletFail""))
---------------Reference log end----------------
                    ok = false;
                }
            }

            // Start ContainerBackgroundProcessor thread
            super.threadStart();
        } finally {
            // Unbinding thread
            unbindThread(oldCCL);
        }

        // Set available status depending upon startup success
        if (ok) {
            if (log.isDebugEnabled()) {
                log.debug(""Starting completed"");
            }
        } else {
            log.error(sm.getString(""standardContext.startFailed"", getName()));
        }

        startTime=System.currentTimeMillis();

        // Send j2ee.state.running notification
        if (ok && (this.getObjectName() != null)) {
            Notification notification =
                new Notification(""j2ee.state.running"", this.getObjectName(),
                                 sequenceNumber.getAndIncrement());
            broadcaster.sendNotification(notification);
        }

        // The WebResources implementation caches references to JAR files. On
        // some platforms these references may lock the JAR files. Since web
        // application start is likely to have read from lots of JARs, trigger
        // a clean-up now.
        getResources().gc();

        // Reinitializing if something went wrong
        if (!ok) {
            setState(LifecycleState.FAILED);
            // Send j2ee.object.failed notification
            if (this.getObjectName() != null) {
                Notification notification = new Notification(""j2ee.object.failed"",
                        this.getObjectName(), sequenceNumber.getAndIncrement());
                broadcaster.sendNotification(notification);
            }
        } else {
            setState(LifecycleState.STARTING);
        }
    }",,
tomcat,16032,"log.error(sm.getString(""config.storeServerError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/storeconfig/StoreConfig.java/#L234,"@Override
    public synchronized boolean store(Server aServer) {
        StoreFileMover mover = new StoreFileMover(Bootstrap.getCatalinaBase(),
                getServerFilename(), getRegistry().getEncoding());
        // Open an output writer for the new configuration file
        try {
            try (PrintWriter writer = mover.getWriter()) {
                store(writer, -2, aServer);
            }
            mover.move();
            return true;
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(sm.getString(""config.storeServerError""), e)
---------------Reference log end----------------
        }
        return false;
    }",,
tomcat,17635,"log.error(""Unable to parse connection properties."", x)",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/DataSourceProxy.java/#L576,"@Override
    public void setConnectionProperties(String properties) {
        try {
            java.util.Properties prop = DataSourceFactory
                    .getProperties(properties);
            Iterator<?> i = prop.keySet().iterator();
            while (i.hasNext()) {
                String key = (String) i.next();
                String value = prop.getProperty(key);
                getPoolProperties().getDbProperties().setProperty(key, value);
            }

        } catch (Exception x) {
            
---------------Reference log start----------------
log.error(""Unable to parse connection properties."", x)
---------------Reference log end----------------
            throw new RuntimeException(x);
        }
    }",,
tomcat,15505,"log.debug(sm.getString(""combinedRealm.authFail"", username, realm.getClass().getName()))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/CombinedRealm.java/#L122,"@Override
    public Principal authenticate(String username, String clientDigest,
            String nonce, String nc, String cnonce, String qop,
            String realmName, String md5a2) {
        Principal authenticatedUser = null;

        for (Realm realm : realms) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""combinedRealm.authStart"", username,
                        realm.getClass().getName()));
            }

            authenticatedUser = realm.authenticate(username, clientDigest, nonce,
                    nc, cnonce, qop, realmName, md5a2);

            if (authenticatedUser == null) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(sm.getString(""combinedRealm.authFail"", username, realm.getClass().getName()))
---------------Reference log end----------------
                }
            } else {
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""combinedRealm.authSuccess"",
                            username, realm.getClass().getName()));
                }
                break;
            }
        }
        return authenticatedUser;
    }",,
tomcat,15845,"log.debug(""Received a failure detector packet:"" + msg)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/group/interceptors/TcpFailureDetector.java/#L120,"@Override
    public void messageReceived(ChannelMessage msg) {
        //catch incoming
        boolean process = true;
        if ( okToProcess(msg.getOptions()) ) {
            //check to see if it is a testMessage, if so, process = false
            process = ( (msg.getMessage().getLength() != TCP_FAIL_DETECT.length) ||
                        (!Arrays.equals(TCP_FAIL_DETECT,msg.getMessage().getBytes()) ) );
        }//end if

        //ignore the message, it doesnt have the flag set
        if ( process ) {
            super.messageReceived(msg);
        } else if ( log.isDebugEnabled() ) {
            
---------------Reference log start----------------
log.debug(""Received a failure detector packet:"" + msg)
---------------Reference log end----------------
        }
    }",,
tomcat,16683,"container.getLogger().error(sm.getString(""standardWrapper.allocateException"", wrapper.getName()), e)",getLogger,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardWrapperValve.java/#L136,"@Override
    public final void invoke(Request request, Response response)
        throws IOException, ServletException {

        // Initialize local variables we may need
        boolean unavailable = false;
        Throwable throwable = null;
        // This should be a Request attribute...
        long t1=System.currentTimeMillis();
        requestCount.incrementAndGet();
        StandardWrapper wrapper = (StandardWrapper) getContainer();
        Servlet servlet = null;
        Context context = (Context) wrapper.getParent();

        // Check for the application being marked unavailable
        if (!context.getState().isAvailable()) {
            response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE,
                           sm.getString(""standardContext.isUnavailable""));
            unavailable = true;
        }

        // Check for the servlet being marked unavailable
        if (!unavailable && wrapper.isUnavailable()) {
            container.getLogger().info(sm.getString(""standardWrapper.isUnavailable"",
                    wrapper.getName()));
            long available = wrapper.getAvailable();
            if ((available > 0L) && (available < Long.MAX_VALUE)) {
                response.setDateHeader(""Retry-After"", available);
                response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE,
                        sm.getString(""standardWrapper.isUnavailable"",
                                wrapper.getName()));
            } else if (available == Long.MAX_VALUE) {
                response.sendError(HttpServletResponse.SC_NOT_FOUND,
                        sm.getString(""standardWrapper.notFound"",
                                wrapper.getName()));
            }
            unavailable = true;
        }

        // Allocate a servlet instance to process this request
        try {
            if (!unavailable) {
                servlet = wrapper.allocate();
            }
        } catch (UnavailableException e) {
            
---------------Reference log start----------------
container.getLogger().error(sm.getString(""standardWrapper.allocateException"", wrapper.getName()), e)
---------------Reference log end----------------
            long available = wrapper.getAvailable();
            if ((available > 0L) && (available < Long.MAX_VALUE)) {
                response.setDateHeader(""Retry-After"", available);
                response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE,
                           sm.getString(""standardWrapper.isUnavailable"",
                                        wrapper.getName()));
            } else if (available == Long.MAX_VALUE) {
                response.sendError(HttpServletResponse.SC_NOT_FOUND,
                           sm.getString(""standardWrapper.notFound"",
                                        wrapper.getName()));
            }
        } catch (ServletException e) {
            container.getLogger().error(sm.getString(""standardWrapper.allocateException"",
                             wrapper.getName()), StandardWrapper.getRootCause(e));
            throwable = e;
            exception(request, response, e);
        } catch (Throwable e) {
            ExceptionUtils.handleThrowable(e);
            container.getLogger().error(sm.getString(""standardWrapper.allocateException"",
                             wrapper.getName()), e);
            throwable = e;
            exception(request, response, e);
            servlet = null;
        }

        MessageBytes requestPathMB = request.getRequestPathMB();
        DispatcherType dispatcherType = DispatcherType.REQUEST;
        if (request.getDispatcherType()==DispatcherType.ASYNC) {
            dispatcherType = DispatcherType.ASYNC;
        }
        request.setAttribute(Globals.DISPATCHER_TYPE_ATTR,dispatcherType);
        request.setAttribute(Globals.DISPATCHER_REQUEST_PATH_ATTR,
                requestPathMB);
        // Create the filter chain for this request
        ApplicationFilterChain filterChain =
                ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);

        // Call the filter chain for this request
        // NOTE: This also calls the servlet's service() method
        Container container = this.container;
        try {
            if ((servlet != null) && (filterChain != null)) {
                // Swallow output if needed
                if (context.getSwallowOutput()) {
                    try {
                        SystemLogHandler.startCapture();
                        if (request.isAsyncDispatching()) {
                            request.getAsyncContextInternal().doInternalDispatch();
                        } else {
                            filterChain.doFilter(request.getRequest(),
                                    response.getResponse());
                        }
                    } finally {
                        String log = SystemLogHandler.stopCapture();
                        if (log != null && log.length() > 0) {
                            context.getLogger().info(log);
                        }
                    }
                } else {
                    if (request.isAsyncDispatching()) {
                        request.getAsyncContextInternal().doInternalDispatch();
                    } else {
                        filterChain.doFilter
                            (request.getRequest(), response.getResponse());
                    }
                }

            }
        } catch (ClientAbortException | CloseNowException e) {
            if (container.getLogger().isDebugEnabled()) {
                container.getLogger().debug(sm.getString(
                        ""standardWrapper.serviceException"", wrapper.getName(),
                        context.getName()), e);
            }
            throwable = e;
            exception(request, response, e);
        } catch (IOException e) {
            container.getLogger().error(sm.getString(
                    ""standardWrapper.serviceException"", wrapper.getName(),
                    context.getName()), e);
            throwable = e;
            exception(request, response, e);
        } catch (UnavailableException e) {
            container.getLogger().error(sm.getString(
                    ""standardWrapper.serviceException"", wrapper.getName(),
                    context.getName()), e);
            //            throwable = e;
            //            exception(request, response, e);
            wrapper.unavailable(e);
            long available = wrapper.getAvailable();
            if ((available > 0L) && (available < Long.MAX_VALUE)) {
                response.setDateHeader(""Retry-After"", available);
                response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE,
                           sm.getString(""standardWrapper.isUnavailable"",
                                        wrapper.getName()));
            } else if (available == Long.MAX_VALUE) {
                response.sendError(HttpServletResponse.SC_NOT_FOUND,
                            sm.getString(""standardWrapper.notFound"",
                                        wrapper.getName()));
            }
            // Do not save exception in 'throwable', because we
            // do not want to do exception(request, response, e) processing
        } catch (ServletException e) {
            Throwable rootCause = StandardWrapper.getRootCause(e);
            if (!(rootCause instanceof ClientAbortException)) {
                container.getLogger().error(sm.getString(
                        ""standardWrapper.serviceExceptionRoot"",
                        wrapper.getName(), context.getName(), e.getMessage()),
                        rootCause);
            }
            throwable = e;
            exception(request, response, e);
        } catch (Throwable e) {
            ExceptionUtils.handleThrowable(e);
            container.getLogger().error(sm.getString(
                    ""standardWrapper.serviceException"", wrapper.getName(),
                    context.getName()), e);
            throwable = e;
            exception(request, response, e);
        } finally {
            // Release the filter chain (if any) for this request
            if (filterChain != null) {
                filterChain.release();
            }

            // Deallocate the allocated servlet instance
            try {
                if (servlet != null) {
                    wrapper.deallocate(servlet);
                }
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                container.getLogger().error(sm.getString(""standardWrapper.deallocateException"",
                                 wrapper.getName()), e);
                if (throwable == null) {
                    throwable = e;
                    exception(request, response, e);
                }
            }

            // If this servlet has been marked permanently unavailable,
            // unload it and release this instance
            try {
                if ((servlet != null) &&
                    (wrapper.getAvailable() == Long.MAX_VALUE)) {
                    wrapper.unload();
                }
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                container.getLogger().error(sm.getString(""standardWrapper.unloadException"",
                                 wrapper.getName()), e);
                if (throwable == null) {
                    exception(request, response, e);
                }
            }
            long t2=System.currentTimeMillis();

            long time=t2-t1;
            processingTime += time;
            if( time > maxTime) {
                maxTime=time;
            }
            if( time < minTime) {
                minTime=time;
            }
        }
    }",,
tomcat,16965,"log.warn(sm.getString(""upgrade.sis.onErrorFail""), t2)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/coyote/http11/upgrade/UpgradeServletInputStream.java/#L251,"private final void onError(Throwable t) {
        if (listener == null) {
            return;
        }
        ClassLoader oldCL = processor.getUpgradeToken().getContextBind().bind(false, null);
        try {
            listener.onError(t);
        } catch (Throwable t2) {
            ExceptionUtils.handleThrowable(t2);
            
---------------Reference log start----------------
log.warn(sm.getString(""upgrade.sis.onErrorFail""), t2)
---------------Reference log end----------------
        } finally {
            processor.getUpgradeToken().getContextBind().unbind(false, oldCL);
        }
        try {
            close();
        } catch (IOException ioe) {
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""upgrade.sis.errorCloseFail""), ioe);
            }
        }
        ready = Boolean.FALSE;
    }",,
tomcat,17017,"log.debug(sm.getString(""wsWebSocketContainer.connect.entry"", clientEndpointHolder.getClassName(), path))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/websocket/WsWebSocketContainer.java/#L195,"private Session connectToServerRecursive(ClientEndpointHolder clientEndpointHolder,
            ClientEndpointConfig clientEndpointConfiguration, URI path, Set<URI> redirectSet)
            throws DeploymentException {

        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(sm.getString(""wsWebSocketContainer.connect.entry"", clientEndpointHolder.getClassName(), path))
---------------Reference log end----------------
        }

        boolean secure = false;
        ByteBuffer proxyConnect = null;
        URI proxyPath;

        // Validate scheme (and build proxyPath)
        String scheme = path.getScheme();
        if (""ws"".equalsIgnoreCase(scheme)) {
            proxyPath = URI.create(""http"" + path.toString().substring(2));
        } else if (""wss"".equalsIgnoreCase(scheme)) {
            proxyPath = URI.create(""https"" + path.toString().substring(3));
            secure = true;
        } else {
            throw new DeploymentException(sm.getString(
                    ""wsWebSocketContainer.pathWrongScheme"", scheme));
        }

        // Validate host
        String host = path.getHost();
        if (host == null) {
            throw new DeploymentException(
                    sm.getString(""wsWebSocketContainer.pathNoHost""));
        }
        int port = path.getPort();

        SocketAddress sa = null;

        // Check to see if a proxy is configured. Javadoc indicates return value
        // will never be null
        List<Proxy> proxies = ProxySelector.getDefault().select(proxyPath);
        Proxy selectedProxy = null;
        for (Proxy proxy : proxies) {
            if (proxy.type().equals(Proxy.Type.HTTP)) {
                sa = proxy.address();
                if (sa instanceof InetSocketAddress) {
                    InetSocketAddress inet = (InetSocketAddress) sa;
                    if (inet.isUnresolved()) {
                        sa = new InetSocketAddress(inet.getHostName(), inet.getPort());
                    }
                }
                selectedProxy = proxy;
                break;
            }
        }

        // If the port is not explicitly specified, compute it based on the
        // scheme
        if (port == -1) {
            if (""ws"".equalsIgnoreCase(scheme)) {
                port = 80;
            } else {
                // Must be wss due to scheme validation above
                port = 443;
            }
        }

        // If sa is null, no proxy is configured so need to create sa
        if (sa == null) {
            sa = new InetSocketAddress(host, port);
        } else {
            proxyConnect = createProxyRequest(host, port);
        }

        // Create the initial HTTP request to open the WebSocket connection
        Map<String, List<String>> reqHeaders = createRequestHeaders(host, port, secure,
                clientEndpointConfiguration);
        clientEndpointConfiguration.getConfigurator().beforeRequest(reqHeaders);
        if (Constants.DEFAULT_ORIGIN_HEADER_VALUE != null
                && !reqHeaders.containsKey(Constants.ORIGIN_HEADER_NAME)) {
            List<String> originValues = new ArrayList<>(1);
            originValues.add(Constants.DEFAULT_ORIGIN_HEADER_VALUE);
            reqHeaders.put(Constants.ORIGIN_HEADER_NAME, originValues);
        }
        ByteBuffer request = createRequest(path, reqHeaders);

        AsynchronousSocketChannel socketChannel;
        try {
            socketChannel = AsynchronousSocketChannel.open(getAsynchronousChannelGroup());
        } catch (IOException ioe) {
            throw new DeploymentException(sm.getString(
                    ""wsWebSocketContainer.asynchronousSocketChannelFail""), ioe);
        }

        Map<String,Object> userProperties = clientEndpointConfiguration.getUserProperties();

        // Get the connection timeout
        long timeout = Constants.IO_TIMEOUT_MS_DEFAULT;
        String timeoutValue = (String) userProperties.get(Constants.IO_TIMEOUT_MS_PROPERTY);
        if (timeoutValue != null) {
            timeout = Long.valueOf(timeoutValue).intValue();
        }

        // Set-up
        // Same size as the WsFrame input buffer
        ByteBuffer response = ByteBuffer.allocate(getDefaultMaxBinaryMessageBufferSize());
        String subProtocol;
        boolean success = false;
        List<Extension> extensionsAgreed = new ArrayList<>();
        Transformation transformation = null;
        AsyncChannelWrapper channel = null;

        try {
            // Open the connection
            Future<Void> fConnect = socketChannel.connect(sa);

            if (proxyConnect != null) {
                fConnect.get(timeout, TimeUnit.MILLISECONDS);
                // Proxy CONNECT is clear text
                channel = new AsyncChannelWrapperNonSecure(socketChannel);
                writeRequest(channel, proxyConnect, timeout);
                HttpResponse httpResponse = processResponse(response, channel, timeout);
                if (httpResponse.getStatus() != 200) {
                    throw new DeploymentException(sm.getString(
                            ""wsWebSocketContainer.proxyConnectFail"", selectedProxy,
                            Integer.toString(httpResponse.getStatus())));
                }
            }

            if (secure) {
                // Regardless of whether a non-secure wrapper was created for a
                // proxy CONNECT, need to use TLS from this point on so wrap the
                // original AsynchronousSocketChannel
                SSLEngine sslEngine = createSSLEngine(userProperties, host, port);
                channel = new AsyncChannelWrapperSecure(socketChannel, sslEngine);
            } else if (channel == null) {
                // Only need to wrap as this point if it wasn't wrapped to process a
                // proxy CONNECT
                channel = new AsyncChannelWrapperNonSecure(socketChannel);
            }

            fConnect.get(timeout, TimeUnit.MILLISECONDS);

            Future<Void> fHandshake = channel.handshake();
            fHandshake.get(timeout, TimeUnit.MILLISECONDS);

            if (log.isDebugEnabled()) {
                SocketAddress localAddress = null;
                try {
                    localAddress = channel.getLocalAddress();
                } catch (IOException ioe) {
                    // Ignore
                }
                log.debug(sm.getString(""wsWebSocketContainer.connect.write"",
                        Integer.valueOf(request.position()), Integer.valueOf(request.limit()), localAddress));
            }
            writeRequest(channel, request, timeout);

            HttpResponse httpResponse = processResponse(response, channel, timeout);

            // Check maximum permitted redirects
            int maxRedirects = Constants.MAX_REDIRECTIONS_DEFAULT;
            String maxRedirectsValue =
                    (String) userProperties.get(Constants.MAX_REDIRECTIONS_PROPERTY);
            if (maxRedirectsValue != null) {
                maxRedirects = Integer.parseInt(maxRedirectsValue);
            }

            if (httpResponse.status != 101) {
                if(isRedirectStatus(httpResponse.status)){
                    List<String> locationHeader =
                            httpResponse.getHandshakeResponse().getHeaders().get(
                                    Constants.LOCATION_HEADER_NAME);

                    if (locationHeader == null || locationHeader.isEmpty() ||
                            locationHeader.get(0) == null || locationHeader.get(0).isEmpty()) {
                        throw new DeploymentException(sm.getString(
                                ""wsWebSocketContainer.missingLocationHeader"",
                                Integer.toString(httpResponse.status)));
                    }

                    URI redirectLocation = URI.create(locationHeader.get(0)).normalize();

                    if (!redirectLocation.isAbsolute()) {
                        redirectLocation = path.resolve(redirectLocation);
                    }

                    String redirectScheme = redirectLocation.getScheme().toLowerCase();

                    if (redirectScheme.startsWith(""http"")) {
                        redirectLocation = new URI(redirectScheme.replace(""http"", ""ws""),
                                redirectLocation.getUserInfo(), redirectLocation.getHost(),
                                redirectLocation.getPort(), redirectLocation.getPath(),
                                redirectLocation.getQuery(), redirectLocation.getFragment());
                    }

                    if (!redirectSet.add(redirectLocation) || redirectSet.size() > maxRedirects) {
                        throw new DeploymentException(sm.getString(
                                ""wsWebSocketContainer.redirectThreshold"", redirectLocation,
                                Integer.toString(redirectSet.size()),
                                Integer.toString(maxRedirects)));
                    }

                    return connectToServerRecursive(
                            clientEndpointHolder, clientEndpointConfiguration, redirectLocation, redirectSet);

                }

                else if (httpResponse.status == 401) {

                    if (userProperties.get(Constants.AUTHORIZATION_HEADER_NAME) != null) {
                        throw new DeploymentException(sm.getString(
                                ""wsWebSocketContainer.failedAuthentication"",
                                Integer.valueOf(httpResponse.status)));
                    }

                    List<String> wwwAuthenticateHeaders = httpResponse.getHandshakeResponse()
                            .getHeaders().get(Constants.WWW_AUTHENTICATE_HEADER_NAME);

                    if (wwwAuthenticateHeaders == null || wwwAuthenticateHeaders.isEmpty() ||
                            wwwAuthenticateHeaders.get(0) == null || wwwAuthenticateHeaders.get(0).isEmpty()) {
                        throw new DeploymentException(sm.getString(
                                ""wsWebSocketContainer.missingWWWAuthenticateHeader"",
                                Integer.toString(httpResponse.status)));
                    }

                    String authScheme = wwwAuthenticateHeaders.get(0).split(""\\s+"", 2)[0];
                    String requestUri = new String(request.array(), StandardCharsets.ISO_8859_1)
                            .split(""\\s"", 3)[1];

                    Authenticator auth = AuthenticatorFactory.getAuthenticator(authScheme);

                    if (auth == null) {
                        throw new DeploymentException(
                                sm.getString(""wsWebSocketContainer.unsupportedAuthScheme"",
                                        Integer.valueOf(httpResponse.status), authScheme));
                    }

                    userProperties.put(Constants.AUTHORIZATION_HEADER_NAME, auth.getAuthorization(
                            requestUri, wwwAuthenticateHeaders.get(0), userProperties));

                    return connectToServerRecursive(
                            clientEndpointHolder, clientEndpointConfiguration, path, redirectSet);

                } else {
                    throw new DeploymentException(sm.getString(""wsWebSocketContainer.invalidStatus"",
                            Integer.toString(httpResponse.status)));
                }
            }
            HandshakeResponse handshakeResponse = httpResponse.getHandshakeResponse();
            clientEndpointConfiguration.getConfigurator().afterResponse(handshakeResponse);

            // Sub-protocol
            List<String> protocolHeaders = handshakeResponse.getHeaders().get(
                    Constants.WS_PROTOCOL_HEADER_NAME);
            if (protocolHeaders == null || protocolHeaders.size() == 0) {
                subProtocol = null;
            } else if (protocolHeaders.size() == 1) {
                subProtocol = protocolHeaders.get(0);
            } else {
                throw new DeploymentException(
                        sm.getString(""wsWebSocketContainer.invalidSubProtocol""));
            }

            // Extensions
            // Should normally only be one header but handle the case of
            // multiple headers
            List<String> extHeaders = handshakeResponse.getHeaders().get(
                    Constants.WS_EXTENSIONS_HEADER_NAME);
            if (extHeaders != null) {
                for (String extHeader : extHeaders) {
                    Util.parseExtensionHeader(extensionsAgreed, extHeader);
                }
            }

            // Build the transformations
            TransformationFactory factory = TransformationFactory.getInstance();
            for (Extension extension : extensionsAgreed) {
                List<List<Extension.Parameter>> wrapper = new ArrayList<>(1);
                wrapper.add(extension.getParameters());
                Transformation t = factory.create(extension.getName(), wrapper, false);
                if (t == null) {
                    throw new DeploymentException(sm.getString(
                            ""wsWebSocketContainer.invalidExtensionParameters""));
                }
                if (transformation == null) {
                    transformation = t;
                } else {
                    transformation.setNext(t);
                }
            }

            success = true;
        } catch (ExecutionException | InterruptedException | SSLException |
                EOFException | TimeoutException | URISyntaxException | AuthenticationException e) {
            throw new DeploymentException(sm.getString(""wsWebSocketContainer.httpRequestFailed"", path), e);
        } finally {
            if (!success) {
                if (channel != null) {
                    channel.close();
                } else {
                    try {
                        socketChannel.close();
                    } catch (IOException ioe) {
                        // Ignore
                    }
                }
            }
        }

        // Switch to WebSocket
        WsRemoteEndpointImplClient wsRemoteEndpointClient = new WsRemoteEndpointImplClient(channel);

        WsSession wsSession = new WsSession(clientEndpointHolder, wsRemoteEndpointClient, this, extensionsAgreed,
                subProtocol, Collections.<String,String>emptyMap(), secure, clientEndpointConfiguration);

        WsFrameClient wsFrameClient = new WsFrameClient(response, channel,
                wsSession, transformation);
        // WsFrame adds the necessary final transformations. Copy the
        // completed transformation chain to the remote end point.
        wsRemoteEndpointClient.setTransformation(wsFrameClient.getTransformation());

        wsSession.getLocal().onOpen(wsSession, clientEndpointConfiguration);
        registerSession(wsSession.getLocal(), wsSession);

        /* It is possible that the server sent one or more messages as soon as
         * the WebSocket connection was established. Depending on the exact
         * timing of when those messages were sent they could be sat in the
         * input buffer waiting to be read and will not trigger a ""data
         * available to read"" event. Therefore, it is necessary to process the
         * input buffer here. Note that this happens on the current thread which
         * means that this thread will be used for any onMessage notifications.
         * This is a special case. Subsequent ""data available to read"" events
         * will be handled by threads from the AsyncChannelGroup's executor.
         */
        wsFrameClient.startInputProcessing();

        return wsSession;
    }",,
tomcat,16004,"containerLog.debug(""  No certificates included with this request"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/authenticator/SSLAuthenticator.java/#L73,"@Override
    protected boolean doAuthenticate(Request request, HttpServletResponse response)
            throws IOException {

        // NOTE: We don't try to reauthenticate using any existing SSO session,
        // because that will only work if the original authentication was
        // BASIC or FORM, which are less secure than the CLIENT-CERT auth-type
        // specified for this webapp
        //
        // Change to true below to allow previous FORM or BASIC authentications
        // to authenticate users for this webapp
        // TODO make this a configurable attribute (in SingleSignOn??)
        if (checkForCachedAuthentication(request, response, false)) {
            return true;
        }

        // Retrieve the certificate chain for this client
        if (containerLog.isDebugEnabled()) {
            containerLog.debug("" Looking up certificates"");
        }

        X509Certificate certs[] = getRequestCertificates(request);

        if ((certs == null) || (certs.length < 1)) {
            if (containerLog.isDebugEnabled()) {
                
---------------Reference log start----------------
containerLog.debug(""  No certificates included with this request"")
---------------Reference log end----------------
            }
            response.sendError(HttpServletResponse.SC_UNAUTHORIZED,
                    sm.getString(""authenticator.certificates""));
            return false;
        }

        // Authenticate the specified certificate chain
        Principal principal = context.getRealm().authenticate(certs);
        if (principal == null) {
            if (containerLog.isDebugEnabled()) {
                containerLog.debug(""  Realm.authenticate() returned false"");
            }
            response.sendError(HttpServletResponse.SC_UNAUTHORIZED,
                               sm.getString(""authenticator.unauthorized""));
            return false;
        }

        // Cache the principal (if requested) and record this authentication
        register(request, response, principal,
                HttpServletRequest.CLIENT_CERT_AUTH, null, null);
        return true;

    }",,
tomcat,17682,"log.error(""isValid() returned false."")",error,https://github.com/apache/tomcat/blob/main/modules/jdbc-pool/src/main/java/org/apache/tomcat/jdbc/pool/PooledConnection.java/#L555,"public boolean validate(int validateAction,String sql) {
        if (this.isDiscarded()) {
            return false;
        }

        if (!doValidate(validateAction)) {
            //no validation required, no init sql and props not set
            return true;
        }

        //Don't bother validating if already have recently enough
        long now = System.currentTimeMillis();
        if (validateAction!=VALIDATE_INIT &&
            poolProperties.getValidationInterval() > 0 &&
            (now - this.lastValidated) <
            poolProperties.getValidationInterval()) {
            return true;
        }

        if (poolProperties.getValidator() != null) {
            if (poolProperties.getValidator().validate(connection, validateAction)) {
                this.lastValidated = now;
                return true;
            } else {
                if (getPoolProperties().getLogValidationErrors()) {
                    log.error(""Custom validation through ""+poolProperties.getValidator()+"" failed."");
                }
                return false;
            }
        }

        String query = sql;

        if (validateAction == VALIDATE_INIT && poolProperties.getInitSQL() != null) {
            query = poolProperties.getInitSQL();
        }

        if (query == null) {
            query = poolProperties.getValidationQuery();
        }

        if (query == null) {
            boolean transactionCommitted = false;
            int validationQueryTimeout = poolProperties.getValidationQueryTimeout();
            if (validationQueryTimeout < 0) {
              validationQueryTimeout = 0;
            }
            try {
                if (connection.isValid(validationQueryTimeout)) {
                    this.lastValidated = now;
                    transactionCommitted = silentlyCommitTransactionIfNeeded();
                    return true;
                } else {
                    if (getPoolProperties().getLogValidationErrors()) {
                        
---------------Reference log start----------------
log.error(""isValid() returned false."")
---------------Reference log end----------------
                    }
                    return false;
                }
            } catch (SQLException e) {
                if (getPoolProperties().getLogValidationErrors()) {
                    log.error(""isValid() failed."", e);
                } else if (log.isDebugEnabled()) {
                    log.debug(""isValid() failed."", e);
                }
                return false;
            } finally {
                if (!transactionCommitted) {
                    silentlyRollbackTransactionIfNeeded();
                }
            }
        }

        boolean transactionCommitted = false;
        Statement stmt = null;
        try {
            stmt = connection.createStatement();

            int validationQueryTimeout = poolProperties.getValidationQueryTimeout();
            if (validationQueryTimeout > 0) {
                stmt.setQueryTimeout(validationQueryTimeout);
            }

            stmt.execute(query);
            stmt.close();
            this.lastValidated = now;
            transactionCommitted = silentlyCommitTransactionIfNeeded();
            return true;
        } catch (Exception ex) {
            if (getPoolProperties().getLogValidationErrors()) {
                log.error(""SQL Validation error"", ex);
            } else if (log.isDebugEnabled()) {
                log.debug(""Unable to validate object:"",ex);
            }
            if (stmt!=null) {
              try { stmt.close();} catch (Exception ignore2){/*NOOP*/}
            }

        } finally {
            if (!transactionCommitted) {
                silentlyRollbackTransactionIfNeeded();
            }
        }
        return false;
    }",,
tomcat,16800,"log.debug(""Creating UserDatabase MBeans for resource "" + name)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/mbeans/GlobalResourcesLifecycleListener.java/#L162,"protected void createMBeans(String name, UserDatabase database) throws Exception {

        // Create the MBean for the UserDatabase itself
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Creating UserDatabase MBeans for resource "" + name)
---------------Reference log end----------------
            log.debug(""Database="" + database);
        }
        try {
            MBeanUtils.createMBean(database);
        } catch(Exception e) {
            throw new IllegalArgumentException(sm.getString(""globalResources.createError.userDatabase"", name), e);
        }

        // Create the MBeans for each defined Role
        Iterator<Role> roles = database.getRoles();
        while (roles.hasNext()) {
            Role role = roles.next();
            if (log.isDebugEnabled()) {
                log.debug(""  Creating Role MBean for role "" + role);
            }
            try {
                MBeanUtils.createMBean(role);
            } catch (Exception e) {
                throw new IllegalArgumentException(sm.getString(""globalResources.createError.userDatabase.role"", role), e);
            }
        }

        // Create the MBeans for each defined Group
        Iterator<Group> groups = database.getGroups();
        while (groups.hasNext()) {
            Group group = groups.next();
            if (log.isDebugEnabled()) {
                log.debug(""  Creating Group MBean for group "" + group);
            }
            try {
                MBeanUtils.createMBean(group);
            } catch (Exception e) {
                throw new IllegalArgumentException(sm.getString(""globalResources.createError.userDatabase.group"", group), e);
            }
        }

        // Create the MBeans for each defined User
        Iterator<User> users = database.getUsers();
        while (users.hasNext()) {
            User user = users.next();
            if (log.isDebugEnabled()) {
                log.debug(""  Creating User MBean for user "" + user);
            }
            try {
                MBeanUtils.createMBean(user);
            } catch (Exception e) {
                throw new IllegalArgumentException(sm.getString(""globalResources.createError.userDatabase.user"", user), e);
            }
        }
    }",,
tomcat,15610,"log.debug(""  No applicable constraint located"")",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/RealmBase.java/#L780,"@Override
    public SecurityConstraint [] findSecurityConstraints(Request request,
                                                         Context context) {

        ArrayList<SecurityConstraint> results = null;
        // Are there any defined security constraints?
        SecurityConstraint constraints[] = context.findConstraints();
        if ((constraints == null) || (constraints.length == 0)) {
            if (log.isDebugEnabled()) {
                log.debug(""  No applicable constraints defined"");
            }
            return null;
        }

        // Check each defined security constraint
        String uri = request.getRequestPathMB().toString();
        // Bug47080 - in rare cases this may be null or """"
        // Mapper treats as '/' do the same to prevent NPE
        if (uri == null || uri.length() == 0) {
            uri = ""/"";
        }

        String method = request.getMethod();
        int i;
        boolean found = false;
        for (i = 0; i < constraints.length; i++) {
            SecurityCollection[] collections = constraints[i].findCollections();

            // If collection is null, continue to avoid an NPE
            // See Bugzilla 30624
            if (collections == null) {
                continue;
            }

            if (log.isDebugEnabled()) {
                log.debug(""  Checking constraint '"" + constraints[i] +
                    ""' against "" + method + "" "" + uri + "" --> "" +
                    constraints[i].included(uri, method));
            }

            for (SecurityCollection securityCollection : collections) {
                String[] patterns = securityCollection.findPatterns();

                // If patterns is null, continue to avoid an NPE
                // See Bugzilla 30624
                if (patterns == null) {
                    continue;
                }

                for (String pattern : patterns) {
                    // Exact match including special case for the context root.
                    if (uri.equals(pattern) || pattern.length() == 0 && uri.equals(""/"")) {
                        found = true;
                        if (securityCollection.findMethod(method)) {
                            if (results == null) {
                                results = new ArrayList<>();
                            }
                            results.add(constraints[i]);
                        }
                    }
                }
            }
        }

        if(found) {
            return resultsToArray(results);
        }

        int longest = -1;

        for (i = 0; i < constraints.length; i++) {
            SecurityCollection [] collection = constraints[i].findCollections();

            // If collection is null, continue to avoid an NPE
            // See Bugzilla 30624
            if ( collection == null) {
                continue;
            }

            if (log.isDebugEnabled()) {
                log.debug(""  Checking constraint '"" + constraints[i] +
                    ""' against "" + method + "" "" + uri + "" --> "" +
                    constraints[i].included(uri, method));
            }

            for (SecurityCollection securityCollection : collection) {
                String[] patterns = securityCollection.findPatterns();

                // If patterns is null, continue to avoid an NPE
                // See Bugzilla 30624
                if (patterns == null) {
                    continue;
                }

                boolean matched = false;
                int length = -1;
                for (String pattern : patterns) {
                    if (pattern.startsWith(""/"") && pattern.endsWith(""/*"") &&
                            pattern.length() >= longest) {

                        if (pattern.length() == 2) {
                            matched = true;
                            length = pattern.length();
                        } else if (pattern.regionMatches(0, uri, 0, pattern.length() - 1) ||
                                (pattern.length() - 2 == uri.length() &&
                                        pattern.regionMatches(0, uri, 0, pattern.length() - 2))) {
                            matched = true;
                            length = pattern.length();
                        }
                    }
                }
                if (matched) {
                    if (length > longest) {
                        found = false;
                        if (results != null) {
                            results.clear();
                        }
                        longest = length;
                    }
                    if (securityCollection.findMethod(method)) {
                        found = true;
                        if (results == null) {
                            results = new ArrayList<>();
                        }
                        results.add(constraints[i]);
                    }
                }
            }
        }

        if(found) {
            return  resultsToArray(results);
        }

        for (i = 0; i < constraints.length; i++) {
            SecurityCollection [] collection = constraints[i].findCollections();

            // If collection is null, continue to avoid an NPE
            // See Bugzilla 30624
            if ( collection == null) {
                continue;
            }

            if (log.isDebugEnabled()) {
                log.debug(""  Checking constraint '"" + constraints[i] +
                    ""' against "" + method + "" "" + uri + "" --> "" +
                    constraints[i].included(uri, method));
            }

            boolean matched = false;
            int pos = -1;
            for(int j=0; j < collection.length; j++){
                String [] patterns = collection[j].findPatterns();

                // If patterns is null, continue to avoid an NPE
                // See Bugzilla 30624
                if ( patterns == null) {
                    continue;
                }

                for(int k=0; k < patterns.length && !matched; k++) {
                    String pattern = patterns[k];
                    if(pattern.startsWith(""*."")){
                        int slash = uri.lastIndexOf('/');
                        int dot = uri.lastIndexOf('.');
                        if(slash >= 0 && dot > slash &&
                           dot != uri.length()-1 &&
                           uri.length()-dot == pattern.length()-1) {
                            if(pattern.regionMatches(1,uri,dot,uri.length()-dot)) {
                                matched = true;
                                pos = j;
                            }
                        }
                    }
                }
            }
            if(matched) {
                found = true;
                if(collection[pos].findMethod(method)) {
                    if(results == null) {
                        results = new ArrayList<>();
                    }
                    results.add(constraints[i]);
                }
            }
        }

        if(found) {
            return resultsToArray(results);
        }

        for (i = 0; i < constraints.length; i++) {
            SecurityCollection [] collection = constraints[i].findCollections();

            // If collection is null, continue to avoid an NPE
            // See Bugzilla 30624
            if ( collection == null) {
                continue;
            }

            if (log.isDebugEnabled()) {
                log.debug(""  Checking constraint '"" + constraints[i] +
                    ""' against "" + method + "" "" + uri + "" --> "" +
                    constraints[i].included(uri, method));
            }

            for (SecurityCollection securityCollection : collection) {
                String[] patterns = securityCollection.findPatterns();

                // If patterns is null, continue to avoid an NPE
                // See Bugzilla 30624
                if (patterns == null) {
                    continue;
                }

                boolean matched = false;
                for (String pattern : patterns) {
                    if (pattern.equals(""/"")) {
                        matched = true;
                        break;
                    }
                }
                if (matched) {
                    if (results == null) {
                        results = new ArrayList<>();
                    }
                    results.add(constraints[i]);
                }
            }
        }

        if(results == null) {
            // No applicable security constraint was found
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""  No applicable constraint located"")
---------------Reference log end----------------
            }
        }
        return resultsToArray(results);
    }",,
tomcat,16036,"log.warn(sm.getString(""storeFactory.noDescriptor"", aElement.getClass(), ""WatchedResource""))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/storeconfig/WatchedResourceSF.java/#L51,"@Override
    public void store(PrintWriter aWriter, int indent, Object aElement)
            throws Exception {
        if (aElement instanceof StandardContext) {
            StoreDescription elementDesc = getRegistry().findDescription(
                    aElement.getClass().getName() + "".[WatchedResource]"");
            String[] resources = ((StandardContext) aElement)
                    .findWatchedResources();
            if (elementDesc != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""store "" + elementDesc.getTag() + ""( "" + aElement
                            + "" )"");
                }
                getStoreAppender().printTagArray(aWriter, ""WatchedResource"",
                        indent, resources);
            }
        } else {
            
---------------Reference log start----------------
log.warn(sm.getString(""storeFactory.noDescriptor"", aElement.getClass(), ""WatchedResource""))
---------------Reference log end----------------
        }
    }",,
tomcat,17331,"log.warn(sm.getString(""xmlErrorHandler.error"", e.getMessage(), source))",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/descriptor/XmlErrorHandler.java/#L71,"public void logFindings(Log log, String source) {
        for (SAXParseException e : getWarnings()) {
            log.warn(sm.getString(
                    ""xmlErrorHandler.warning"", e.getMessage(), source));
        }
        for (SAXParseException e : getErrors()) {
            
---------------Reference log start----------------
log.warn(sm.getString(""xmlErrorHandler.error"", e.getMessage(), source))
---------------Reference log end----------------
        }
    }",,
tomcat,17405,"log.warn(sm.getString(""digester.encodingInvalid"", enc), e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/util/digester/Digester.java/#L1194,"@Override
    public void startDocument() throws SAXException {

        if (saxLog.isDebugEnabled()) {
            saxLog.debug(""startDocument()"");
        }

        if (locator instanceof Locator2) {
            if (root instanceof DocumentProperties.Charset) {
                String enc = ((Locator2) locator).getEncoding();
                if (enc != null) {
                    try {
                        ((DocumentProperties.Charset) root).setCharset(B2CConverter.getCharset(enc));
                    } catch (UnsupportedEncodingException e) {
                        
---------------Reference log start----------------
log.warn(sm.getString(""digester.encodingInvalid"", enc), e)
---------------Reference log end----------------
                    }
                }
            }
        }

        // ensure that the digester is properly configured, as
        // the digester could be used as a SAX ContentHandler
        // rather than via the parse() methods.
        configure();
    }",,
tomcat,17476,"log.debug(""Failed to convert ["" + m.group(2) + ""] to Short"", e)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/jasper/optimizations/ELInterpreterTagSetters.java/#L166,"@Override
    public String interpreterCall(JspCompilationContext context,
            boolean isTagFile, String expression,
            Class<?> expectedType, String fnmapvar) {

        String result = null;

        // Boolean
        if (Boolean.TYPE == expectedType) {
            Matcher m = PATTERN_BOOLEAN.matcher(expression);
            if (m.matches()) {
                result = m.group(2);
            }
        } else if (Boolean.class == expectedType) {
            Matcher m = PATTERN_BOOLEAN.matcher(expression);
            if (m.matches()) {
                if (""true"".equals(m.group(2))) {
                    result = ""Boolean.TRUE"";
                } else {
                    result = ""Boolean.FALSE"";
                }
            }
        // Character
        } else if (Character.TYPE == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                return ""\'"" + m.group(2).charAt(0) + ""\'"";
            }
        } else if (Character.class == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                return ""Character.valueOf(\'"" + m.group(2).charAt(0) + ""\')"";
            }
        // Numeric - BigDecimal
        } else if (BigDecimal.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    BigDecimal unused = new BigDecimal(m.group(2));
                    result = ""new java.math.BigDecimal(\"""" + m.group(2) + ""\"")"";
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to BigDecimal"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - long/Long
        } else if (Long.TYPE == expectedType || Long.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Long unused = Long.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // Long requires explicit declaration as a long literal
                        result = m.group(2) + ""L"";
                    } else {
                        result = ""Long.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Long"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - int/Integer
        } else if (Integer.TYPE == expectedType || Integer.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Integer unused = Integer.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        result = m.group(2);
                    } else {
                        result = ""Integer.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Integer"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - short/Short
        } else if (Short.TYPE == expectedType || Short.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Short unused = Short.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // short requires a downcast
                        result = ""(short) "" + m.group(2);
                    } else {
                        result = ""Short.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    
---------------Reference log start----------------
log.debug(""Failed to convert ["" + m.group(2) + ""] to Short"", e)
---------------Reference log end----------------
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - byte/Byte
        } else if (Byte.TYPE == expectedType || Byte.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Byte unused = Byte.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // byte requires a downcast
                        result = ""(byte) "" + m.group(2);
                    } else {
                        result = ""Byte.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Byte"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - double/Double
        } else if (Double.TYPE == expectedType || Double.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Double unused = Double.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        result = m.group(2);
                    } else {
                        result = ""Double.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Double"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - float/Float
        } else if (Float.TYPE == expectedType || Float.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    Float unused = Float.valueOf(m.group(2));
                    if (expectedType.isPrimitive()) {
                        // Float requires explicit declaration as a float literal
                        result = m.group(2) + ""f"";
                    } else {
                        result = ""Float.valueOf(\"""" + m.group(2) + ""\"")"";
                    }
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Float"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Numeric - BigInteger
        } else if (BigInteger.class == expectedType) {
            Matcher m = PATTERN_NUMERIC.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings(""unused"")
                    BigInteger unused = new BigInteger(m.group(2));
                    result = ""new java.math.BigInteger(\"""" + m.group(2) + ""\"")"";
                } catch (NumberFormatException e) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to BigInteger"", e);
                    // Continue and resolve the value at runtime
                }
            }
        // Enum
        } else if (expectedType.isEnum()){
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                try {
                    @SuppressWarnings({ ""unchecked"", ""rawtypes"" })
                    Enum<?> enumValue = Enum.valueOf((Class<? extends Enum>) expectedType, m.group(2));
                    result = expectedType.getName() + ""."" + enumValue.name();
                } catch (IllegalArgumentException iae) {
                    log.debug(""Failed to convert ["" + m.group(2) + ""] to Enum type ["" + expectedType.getName() + ""]"", iae);
                    // Continue and resolve the value at runtime
                }
            }
        // String
        } else if (String.class == expectedType) {
            Matcher m = PATTERN_STRING_CONSTANT.matcher(expression);
            if (m.matches()) {
                result = ""\"""" + m.group(2) + ""\"""";
            }
        }

        if (result == null) {
            result = JspUtil.interpreterCall(isTagFile, expression, expectedType,
                    fnmapvar);
        }

        if (log.isDebugEnabled()) {
            log.debug(""Expression ["" + expression + ""], type ["" + expectedType.getName() + ""], returns ["" + result + ""]"");
        }

        return result;
    }",,
tomcat,15152,"log.info(""Putting AsyncThread to sleep"")",info,https://github.com/apache/tomcat/blob/main/webapps/examples/WEB-INF/classes/async/Async1.java/#L46,"@Override
            public void run() {
                try {
                    String path = ""/jsp/async/async1.jsp"";
                    Thread.currentThread().setName(""Async1-Thread"");
                    
---------------Reference log start----------------
log.info(""Putting AsyncThread to sleep"")
---------------Reference log end----------------
                    Thread.sleep(2*1000);
                    log.info(""Dispatching to ""+path);
                    actx.dispatch(path);
                }catch (InterruptedException x) {
                    log.error(""Async1"",x);
                }catch (IllegalStateException x) {
                    log.error(""Async1"",x);
                }
            }",,
tomcat,16688,"container.getLogger().error(sm.getString(""standardWrapper.serviceException"", wrapper.getName(), context.getName()), e)",getLogger,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardWrapperValve.java/#L222,"@Override
    public final void invoke(Request request, Response response)
        throws IOException, ServletException {

        // Initialize local variables we may need
        boolean unavailable = false;
        Throwable throwable = null;
        // This should be a Request attribute...
        long t1=System.currentTimeMillis();
        requestCount.incrementAndGet();
        StandardWrapper wrapper = (StandardWrapper) getContainer();
        Servlet servlet = null;
        Context context = (Context) wrapper.getParent();

        // Check for the application being marked unavailable
        if (!context.getState().isAvailable()) {
            response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE,
                           sm.getString(""standardContext.isUnavailable""));
            unavailable = true;
        }

        // Check for the servlet being marked unavailable
        if (!unavailable && wrapper.isUnavailable()) {
            container.getLogger().info(sm.getString(""standardWrapper.isUnavailable"",
                    wrapper.getName()));
            long available = wrapper.getAvailable();
            if ((available > 0L) && (available < Long.MAX_VALUE)) {
                response.setDateHeader(""Retry-After"", available);
                response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE,
                        sm.getString(""standardWrapper.isUnavailable"",
                                wrapper.getName()));
            } else if (available == Long.MAX_VALUE) {
                response.sendError(HttpServletResponse.SC_NOT_FOUND,
                        sm.getString(""standardWrapper.notFound"",
                                wrapper.getName()));
            }
            unavailable = true;
        }

        // Allocate a servlet instance to process this request
        try {
            if (!unavailable) {
                servlet = wrapper.allocate();
            }
        } catch (UnavailableException e) {
            container.getLogger().error(
                    sm.getString(""standardWrapper.allocateException"",
                            wrapper.getName()), e);
            long available = wrapper.getAvailable();
            if ((available > 0L) && (available < Long.MAX_VALUE)) {
                response.setDateHeader(""Retry-After"", available);
                response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE,
                           sm.getString(""standardWrapper.isUnavailable"",
                                        wrapper.getName()));
            } else if (available == Long.MAX_VALUE) {
                response.sendError(HttpServletResponse.SC_NOT_FOUND,
                           sm.getString(""standardWrapper.notFound"",
                                        wrapper.getName()));
            }
        } catch (ServletException e) {
            container.getLogger().error(sm.getString(""standardWrapper.allocateException"",
                             wrapper.getName()), StandardWrapper.getRootCause(e));
            throwable = e;
            exception(request, response, e);
        } catch (Throwable e) {
            ExceptionUtils.handleThrowable(e);
            container.getLogger().error(sm.getString(""standardWrapper.allocateException"",
                             wrapper.getName()), e);
            throwable = e;
            exception(request, response, e);
            servlet = null;
        }

        MessageBytes requestPathMB = request.getRequestPathMB();
        DispatcherType dispatcherType = DispatcherType.REQUEST;
        if (request.getDispatcherType()==DispatcherType.ASYNC) {
            dispatcherType = DispatcherType.ASYNC;
        }
        request.setAttribute(Globals.DISPATCHER_TYPE_ATTR,dispatcherType);
        request.setAttribute(Globals.DISPATCHER_REQUEST_PATH_ATTR,
                requestPathMB);
        // Create the filter chain for this request
        ApplicationFilterChain filterChain =
                ApplicationFilterFactory.createFilterChain(request, wrapper, servlet);

        // Call the filter chain for this request
        // NOTE: This also calls the servlet's service() method
        Container container = this.container;
        try {
            if ((servlet != null) && (filterChain != null)) {
                // Swallow output if needed
                if (context.getSwallowOutput()) {
                    try {
                        SystemLogHandler.startCapture();
                        if (request.isAsyncDispatching()) {
                            request.getAsyncContextInternal().doInternalDispatch();
                        } else {
                            filterChain.doFilter(request.getRequest(),
                                    response.getResponse());
                        }
                    } finally {
                        String log = SystemLogHandler.stopCapture();
                        if (log != null && log.length() > 0) {
                            context.getLogger().info(log);
                        }
                    }
                } else {
                    if (request.isAsyncDispatching()) {
                        request.getAsyncContextInternal().doInternalDispatch();
                    } else {
                        filterChain.doFilter
                            (request.getRequest(), response.getResponse());
                    }
                }

            }
        } catch (ClientAbortException | CloseNowException e) {
            if (container.getLogger().isDebugEnabled()) {
                container.getLogger().debug(sm.getString(
                        ""standardWrapper.serviceException"", wrapper.getName(),
                        context.getName()), e);
            }
            throwable = e;
            exception(request, response, e);
        } catch (IOException e) {
            container.getLogger().error(sm.getString(
                    ""standardWrapper.serviceException"", wrapper.getName(),
                    context.getName()), e);
            throwable = e;
            exception(request, response, e);
        } catch (UnavailableException e) {
            
---------------Reference log start----------------
container.getLogger().error(sm.getString(""standardWrapper.serviceException"", wrapper.getName(), context.getName()), e)
---------------Reference log end----------------
            //            throwable = e;
            //            exception(request, response, e);
            wrapper.unavailable(e);
            long available = wrapper.getAvailable();
            if ((available > 0L) && (available < Long.MAX_VALUE)) {
                response.setDateHeader(""Retry-After"", available);
                response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE,
                           sm.getString(""standardWrapper.isUnavailable"",
                                        wrapper.getName()));
            } else if (available == Long.MAX_VALUE) {
                response.sendError(HttpServletResponse.SC_NOT_FOUND,
                            sm.getString(""standardWrapper.notFound"",
                                        wrapper.getName()));
            }
            // Do not save exception in 'throwable', because we
            // do not want to do exception(request, response, e) processing
        } catch (ServletException e) {
            Throwable rootCause = StandardWrapper.getRootCause(e);
            if (!(rootCause instanceof ClientAbortException)) {
                container.getLogger().error(sm.getString(
                        ""standardWrapper.serviceExceptionRoot"",
                        wrapper.getName(), context.getName(), e.getMessage()),
                        rootCause);
            }
            throwable = e;
            exception(request, response, e);
        } catch (Throwable e) {
            ExceptionUtils.handleThrowable(e);
            container.getLogger().error(sm.getString(
                    ""standardWrapper.serviceException"", wrapper.getName(),
                    context.getName()), e);
            throwable = e;
            exception(request, response, e);
        } finally {
            // Release the filter chain (if any) for this request
            if (filterChain != null) {
                filterChain.release();
            }

            // Deallocate the allocated servlet instance
            try {
                if (servlet != null) {
                    wrapper.deallocate(servlet);
                }
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                container.getLogger().error(sm.getString(""standardWrapper.deallocateException"",
                                 wrapper.getName()), e);
                if (throwable == null) {
                    throwable = e;
                    exception(request, response, e);
                }
            }

            // If this servlet has been marked permanently unavailable,
            // unload it and release this instance
            try {
                if ((servlet != null) &&
                    (wrapper.getAvailable() == Long.MAX_VALUE)) {
                    wrapper.unload();
                }
            } catch (Throwable e) {
                ExceptionUtils.handleThrowable(e);
                container.getLogger().error(sm.getString(""standardWrapper.unloadException"",
                                 wrapper.getName()), e);
                if (throwable == null) {
                    exception(request, response, e);
                }
            }
            long t2=System.currentTimeMillis();

            long time=t2-t1;
            processingTime += time;
            if( time > maxTime) {
                maxTime=time;
            }
            if( time < minTime) {
                minTime=time;
            }
        }
    }",,
tomcat,15759,"log.info(sm.getString(""replicatedMap.relocate.complete"", Long.toString(complete)))",info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/tipis/ReplicatedMap.java/#L252,"@Override
    public void memberDisappeared(Member member) {
        boolean removed = false;
        Log log = getLog();
        synchronized (mapMembers) {
            removed = (mapMembers.remove(member) != null );
            if (!removed) {
                if (log.isDebugEnabled()) {
                    log.debug(""Member[""+member+""] disappeared, but was not present in the map."");
                }
                return; //the member was not part of our map.
            }
        }
        if (log.isInfoEnabled()) {
            log.info(sm.getString(""replicatedMap.member.disappeared"", member));
        }
        long start = System.currentTimeMillis();
        for (Entry<K, MapEntry<K, V>> e : innerMap.entrySet()) {
            MapEntry<K,V> entry = innerMap.get(e.getKey());
            if (entry==null) {
                continue;
            }
            if (entry.isPrimary()) {
                try {
                    Member[] backup = getMapMembers();
                    if (backup.length > 0) {
                        MapMessage msg = new MapMessage(getMapContextName(), MapMessage.MSG_NOTIFY_MAPMEMBER,false,
                                (Serializable)entry.getKey(),null,null,channel.getLocalMember(false),backup);
                        getChannel().send(backup, msg, getChannelSendOptions());
                    }
                    entry.setBackupNodes(backup);
                    entry.setPrimary(channel.getLocalMember(false));
                } catch (ChannelException x) {
                    log.error(sm.getString(""replicatedMap.unable.relocate"", entry.getKey()), x);
                }
            } else if (member.equals(entry.getPrimary())) {
                entry.setPrimary(null);
            }

            if ( entry.getPrimary() == null &&
                        entry.isCopy() &&
                        entry.getBackupNodes()!=null &&
                        entry.getBackupNodes().length > 0 &&
                        entry.getBackupNodes()[0].equals(channel.getLocalMember(false)) ) {
                try {
                    entry.setPrimary(channel.getLocalMember(false));
                    entry.setBackup(false);
                    entry.setProxy(false);
                    entry.setCopy(false);
                    Member[] backup = getMapMembers();
                    if (backup.length > 0) {
                        MapMessage msg = new MapMessage(getMapContextName(), MapMessage.MSG_NOTIFY_MAPMEMBER,false,
                                (Serializable)entry.getKey(),null,null,channel.getLocalMember(false),backup);
                        getChannel().send(backup, msg, getChannelSendOptions());
                    }
                    entry.setBackupNodes(backup);
                    if ( mapOwner!=null ) {
                        mapOwner.objectMadePrimary(entry.getKey(),entry.getValue());
                    }

                } catch (ChannelException x) {
                    log.error(sm.getString(""replicatedMap.unable.relocate"", entry.getKey()), x);
                }
            }

        } //while
        long complete = System.currentTimeMillis() - start;
        if (log.isInfoEnabled()) {
            
---------------Reference log start----------------
log.info(sm.getString(""replicatedMap.relocate.complete"", Long.toString(complete)))
---------------Reference log end----------------
        }
    }",,
tomcat,16019,"log.error(sm.getString(""standardContextSF.canonicalPathError""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/storeconfig/StandardContextSF.java/#L309,"protected File configBase(Context context) {

        File file = new File(System.getProperty(""catalina.base""), ""conf"");
        Container host = context.getParent();

        if (host instanceof Host) {
            Container engine = host.getParent();
            if (engine instanceof Engine) {
                file = new File(file, engine.getName());
            }
            file = new File(file, host.getName());
            try {
                file = file.getCanonicalFile();
            } catch (IOException e) {
                
---------------Reference log start----------------
log.error(sm.getString(""standardContextSF.canonicalPathError""), e)
---------------Reference log end----------------
            }
        }
        return file;

    }",,
tomcat,16554,log.info(msg),info,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/AprLifecycleListener.java/#L125,"@Override
    public void lifecycleEvent(LifecycleEvent event) {

        if (Lifecycle.BEFORE_INIT_EVENT.equals(event.getType())) {
            synchronized (lock) {
                init();
                for (String msg : initInfoLogMessages) {
                    
---------------Reference log start----------------
log.info(msg)
---------------Reference log end----------------
                }
                initInfoLogMessages.clear();
                if (AprStatus.isAprAvailable()) {
                    try {
                        initializeSSL();
                    } catch (Throwable t) {
                        t = ExceptionUtils.unwrapInvocationTargetException(t);
                        ExceptionUtils.handleThrowable(t);
                        log.error(sm.getString(""aprListener.sslInit""), t);
                    }
                }
                // Failure to initialize FIPS mode is fatal
                if (!(null == FIPSMode || ""off"".equalsIgnoreCase(FIPSMode)) && !isFIPSModeActive()) {
                    String errorMessage = sm.getString(""aprListener.initializeFIPSFailed"");
                    Error e = new Error(errorMessage);
                    // Log here, because thrown error might be not logged
                    log.fatal(errorMessage, e);
                    throw e;
                }
            }
        } else if (Lifecycle.AFTER_DESTROY_EVENT.equals(event.getType())) {
            synchronized (lock) {
                if (!AprStatus.isAprAvailable()) {
                    return;
                }
                try {
                    terminateAPR();
                } catch (Throwable t) {
                    t = ExceptionUtils.unwrapInvocationTargetException(t);
                    ExceptionUtils.handleThrowable(t);
                    log.info(sm.getString(""aprListener.aprDestroy""));
                }
            }
        }

    }",,
tomcat,17038,"log.warn(""Failed to complete JMX unregistration for "" + objectName, e)",warn,https://github.com/apache/tomcat/blob/main/java/org/apache/tomcat/dbcp/dbcp2/ObjectNameWrapper.java/#L95,"public void unregisterMBean() {
        if (MBEAN_SERVER == null || objectName == null) {
            return;
        }
        if (MBEAN_SERVER.isRegistered(objectName)) {
            try {
                MBEAN_SERVER.unregisterMBean(objectName);
            } catch (final LinkageError | Exception e) {
                
---------------Reference log start----------------
log.warn(""Failed to complete JMX unregistration for "" + objectName, e)
---------------Reference log end----------------
            }
        }
    }",,
tomcat,16524,log.trace(cgiEnvLine),trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L626,"@Override
    protected void doGet(HttpServletRequest req, HttpServletResponse res)
            throws ServletException, IOException {

        CGIEnvironment cgiEnv = new CGIEnvironment(req, getServletContext());

        if (cgiEnv.isValid()) {
            CGIRunner cgi = new CGIRunner(cgiEnv.getCommand(),
                                          cgiEnv.getEnvironment(),
                                          cgiEnv.getWorkingDirectory(),
                                          cgiEnv.getParameters());

            if (""POST"".equals(req.getMethod())) {
                cgi.setInput(req.getInputStream());
            }
            cgi.setResponse(res);
            cgi.run();
        } else {
            res.sendError(404);
        }

        if (log.isTraceEnabled()) {
            String[] cgiEnvLines = cgiEnv.toString().split(System.lineSeparator());
            for (String cgiEnvLine : cgiEnvLines) {
                
---------------Reference log start----------------
log.trace(cgiEnvLine)
---------------Reference log end----------------
            }

            printServletEnvironment(req);
        }
    }",,
tomcat,15612,"log.debug(""No role found:  "" + role)",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/realm/RealmBase.java/#L877,"@Override
    public boolean hasResourcePermission(Request request,
                                         Response response,
                                         SecurityConstraint []constraints,
                                         Context context)
        throws IOException {

        if (constraints == null || constraints.length == 0) {
            return true;
        }

        // Which user principal have we already authenticated?
        Principal principal = request.getPrincipal();
        boolean status = false;
        boolean denyfromall = false;
        for (SecurityConstraint constraint : constraints) {
            String roles[];
            if (constraint.getAllRoles()) {
                // * means all roles defined in web.xml
                roles = request.getContext().findSecurityRoles();
            } else {
                roles = constraint.findAuthRoles();
            }

            if (roles == null) {
                roles = new String[0];
            }

            if (log.isDebugEnabled()) {
                log.debug(""  Checking roles "" + principal);
            }

            if (constraint.getAuthenticatedUsers() && principal != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""Passing all authenticated users"");
                }
                status = true;
            }
            else if (roles.length == 0 && !constraint.getAllRoles() &&
                    !constraint.getAuthenticatedUsers()) {
                if (constraint.getAuthConstraint()) {
                    if (log.isDebugEnabled()) {
                        log.debug(""No roles"");
                    }
                    status = false; // No listed roles means no access at all
                    denyfromall = true;
                    break;
                }

                if (log.isDebugEnabled()) {
                    log.debug(""Passing all access"");
                }
                status = true;
            } else if (principal == null) {
                if (log.isDebugEnabled()) {
                    log.debug(""  No user authenticated, cannot grant access"");
                }
            } else {
                for (String role : roles) {
                    if (hasRole(request.getWrapper(), principal, role)) {
                        status = true;
                        if (log.isDebugEnabled()) {
                            log.debug(""Role found:  "" + role);
                        }
                    } else if (log.isDebugEnabled()) {
                        
---------------Reference log start----------------
log.debug(""No role found:  "" + role)
---------------Reference log end----------------
                    }
                }
            }
        }

        if (!denyfromall && allRolesMode != AllRolesMode.STRICT_MODE &&
                !status && principal != null) {
            if (log.isDebugEnabled()) {
                log.debug(""Checking for all roles mode: "" + allRolesMode);
            }
            // Check for an all roles(role-name=""*"")
            for (SecurityConstraint constraint : constraints) {
                String roles[];
                // If the all roles mode exists, sets
                if (constraint.getAllRoles()) {
                    if (allRolesMode == AllRolesMode.AUTH_ONLY_MODE) {
                        if (log.isDebugEnabled()) {
                            log.debug(""Granting access for role-name=*, auth-only"");
                        }
                        status = true;
                        break;
                    }

                    // For AllRolesMode.STRICT_AUTH_ONLY_MODE there must be zero roles
                    roles = request.getContext().findSecurityRoles();
                    if (roles.length == 0 && allRolesMode == AllRolesMode.STRICT_AUTH_ONLY_MODE) {
                        if (log.isDebugEnabled()) {
                            log.debug(""Granting access for role-name=*, strict auth-only"");
                        }
                        status = true;
                        break;
                    }
                }
            }
        }

        // Return a ""Forbidden"" message denying access to this resource
        if(!status) {
            response.sendError
                (HttpServletResponse.SC_FORBIDDEN,
                 sm.getString(""realmBase.forbidden""));
        }
        return status;

    }",,
tomcat,16527,"log.debug(sm.getString(""cgiServlet.find.path"", pathInfo, webAppRootDir))",debug,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/servlets/CGIServlet.java/#L924,"protected String[] findCGI(String pathInfo, String webAppRootDir,
                                   String contextPath, String servletPath,
                                   String cgiPathPrefix) {
            String path = null;
            String name = null;
            String scriptname = null;

            if (webAppRootDir != null &&
                    webAppRootDir.lastIndexOf(File.separator) == (webAppRootDir.length() - 1)) {
                //strip the trailing ""/"" from the webAppRootDir
                webAppRootDir = webAppRootDir.substring(0, (webAppRootDir.length() - 1));
            }

            if (cgiPathPrefix != null) {
                webAppRootDir = webAppRootDir + File.separator + cgiPathPrefix;
            }

            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(sm.getString(""cgiServlet.find.path"", pathInfo, webAppRootDir))
---------------Reference log end----------------
            }

            File currentLocation = new File(webAppRootDir);
            StringTokenizer dirWalker = new StringTokenizer(pathInfo, ""/"");
            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""cgiServlet.find.location"",
                        currentLocation.getAbsolutePath()));
            }
            StringBuilder cginameBuilder = new StringBuilder();
            while (!currentLocation.isFile() && dirWalker.hasMoreElements()) {
                String nextElement = (String) dirWalker.nextElement();
                currentLocation = new File(currentLocation, nextElement);
                cginameBuilder.append('/').append(nextElement);
                if (log.isDebugEnabled()) {
                    log.debug(sm.getString(""cgiServlet.find.location"",
                            currentLocation.getAbsolutePath()));
                }
            }
            String cginame = cginameBuilder.toString();
            if (!currentLocation.isFile()) {
                return new String[] { null, null, null, null };
            }

            path = currentLocation.getAbsolutePath();
            name = currentLocation.getName();

            if (servletPath.startsWith(cginame)) {
                scriptname = contextPath + cginame;
            } else {
                scriptname = contextPath + servletPath + cginame;
            }

            if (log.isDebugEnabled()) {
                log.debug(sm.getString(""cgiServlet.find.found"", name, path, scriptname, cginame));
            }
            return new String[] { path, scriptname, cginame, name };
        }",,
tomcat,16607,"log.error(sm.getString(""standardPipeline.basic.stop""), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/StandardPipeline.java/#L269,"@Override
    public void setBasic(Valve valve) {

        // Change components if necessary
        Valve oldBasic = this.basic;
        if (oldBasic == valve) {
            return;
        }

        // Stop the old component if necessary
        if (oldBasic != null) {
            if (getState().isAvailable() && (oldBasic instanceof Lifecycle)) {
                try {
                    ((Lifecycle) oldBasic).stop();
                } catch (LifecycleException e) {
                    
---------------Reference log start----------------
log.error(sm.getString(""standardPipeline.basic.stop""), e)
---------------Reference log end----------------
                }
            }
            if (oldBasic instanceof Contained) {
                try {
                    ((Contained) oldBasic).setContainer(null);
                } catch (Throwable t) {
                    ExceptionUtils.handleThrowable(t);
                }
            }
        }

        // Start the new component if necessary
        if (valve == null) {
            return;
        }
        if (valve instanceof Contained) {
            ((Contained) valve).setContainer(this.container);
        }
        if (getState().isAvailable() && valve instanceof Lifecycle) {
            try {
                ((Lifecycle) valve).start();
            } catch (LifecycleException e) {
                log.error(sm.getString(""standardPipeline.basic.start""), e);
                return;
            }
        }

        // Update the pipeline
        Valve current = first;
        while (current != null) {
            if (current.getNext() == oldBasic) {
                current.setNext(valve);
                break;
            }
            current = current.getNext();
        }

        this.basic = valve;

    }",,
tomcat,15812,"Logs.MESSAGES.trace(""GroupChannel - Sent msg:"" + new UniqueId(data.getUniqueId()) + "" at "" + new java.sql.Timestamp(System.currentTimeMillis()) + "" to "" + Arrays.toNameString(destination))",trace,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/group/GroupChannel.java/#L282,"@Override
    public UniqueId send(Member[] destination, Serializable msg, int options, ErrorHandler handler)
            throws ChannelException {
        if ( msg == null ) {
            throw new ChannelException(sm.getString(""groupChannel.nullMessage""));
        }
        XByteBuffer buffer = null;
        try {
            if (destination == null || destination.length == 0) {
                throw new ChannelException(sm.getString(""groupChannel.noDestination""));
            }
            ChannelData data = new ChannelData(true);//generates a unique Id
            data.setAddress(getLocalMember(false));
            data.setTimestamp(System.currentTimeMillis());
            byte[] b = null;
            if ( msg instanceof ByteMessage ){
                b = ((ByteMessage)msg).getMessage();
                options = options | SEND_OPTIONS_BYTE_MESSAGE;
            } else {
                b = XByteBuffer.serialize(msg);
                options = options & (~SEND_OPTIONS_BYTE_MESSAGE);
            }
            data.setOptions(options);
            //XByteBuffer buffer = new XByteBuffer(b.length+128,false);
            buffer = BufferPool.getBufferPool().getBuffer(b.length+128, false);
            buffer.append(b,0,b.length);
            data.setMessage(buffer);
            InterceptorPayload payload = null;
            if ( handler != null ) {
                payload = new InterceptorPayload();
                payload.setErrorHandler(handler);
            }
            getFirstInterceptor().sendMessage(destination, data, payload);
            if ( Logs.MESSAGES.isTraceEnabled() ) {
                
---------------Reference log start----------------
Logs.MESSAGES.trace(""GroupChannel - Sent msg:"" + new UniqueId(data.getUniqueId()) + "" at "" + new java.sql.Timestamp(System.currentTimeMillis()) + "" to "" + Arrays.toNameString(destination))
---------------Reference log end----------------
                Logs.MESSAGES.trace(""GroupChannel - Send Message:"" +
                        new UniqueId(data.getUniqueId()) + "" is "" + msg);
            }

            return new UniqueId(data.getUniqueId());
        } catch (RuntimeException | IOException e) {
            throw new ChannelException(e);
        } finally {
            if ( buffer != null ) {
                BufferPool.getBufferPool().returnBuffer(buffer);
            }
        }
    }",,
tomcat,15743,"log.error(sm.getString(""jmxRegistry.objectName.failed"", sb.toString()), e)",error,https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/tribes/jmx/JmxRegistry.java/#L103,"private static ObjectName createBaseObjectName(String domain, String prefix, String name) {
        if (domain == null) {
            log.warn(sm.getString(""jmxRegistry.no.domain""));
            return null;
        }
        ObjectName on = null;
        StringBuilder sb = new StringBuilder(domain);
        sb.append(':');
        sb.append(prefix);
        sb.append(""type=Channel,channel="");
        sb.append(name);
        try {
            on = new ObjectName(sb.toString());
        } catch (MalformedObjectNameException e) {
            
---------------Reference log start----------------
log.error(sm.getString(""jmxRegistry.objectName.failed"", sb.toString()), e)
---------------Reference log end----------------
        }
        return on;
    }",,
hadoop,3853,"LOG.info(""Storing info for app: "" + appId + "" at: "" + nodeCreatePath)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/FileSystemRMStateStore.java/#L434,"@Override
  public synchronized void storeApplicationStateInternal(ApplicationId appId,
      ApplicationStateData appStateDataPB) throws Exception {
    Path appDirPath = getAppDir(rmAppRoot, appId);
    mkdirsWithRetries(appDirPath);
    Path nodeCreatePath = getNodePath(appDirPath, appId.toString());

    
---------------Reference log start----------------
LOG.info(""Storing info for app: "" + appId + "" at: "" + nodeCreatePath)
---------------Reference log end----------------
    byte[] appStateData = appStateDataPB.getProto().toByteArray();
    try {
      // currently throw all exceptions. May need to respond differently for HA
      // based on whether we have lost the right to write to FS
      writeFileWithRetries(nodeCreatePath, appStateData, true);
    } catch (Exception e) {
      LOG.info(""Error storing info for app: "" + appId, e);
      throw e;
    }
  }",,
hadoop,4283,"LOG.info(""Adding protocol "" + pbProtocol.getCanonicalName() + "" to the server"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/factories/impl/pb/RpcServerFactoryPBImpl.java/#L174,"private Server createServer(Class<?> pbProtocol, InetSocketAddress addr, Configuration conf, 
      SecretManager<? extends TokenIdentifier> secretManager, int numHandlers, 
      BlockingService blockingService, String portRangeConfig) throws IOException {
    RPC.setProtocolEngine(conf, pbProtocol, ProtobufRpcEngine2.class);
    RPC.Server server = new RPC.Builder(conf).setProtocol(pbProtocol)
        .setInstance(blockingService).setBindAddress(addr.getHostName())
        .setPort(addr.getPort()).setNumHandlers(numHandlers).setVerbose(false)
        .setSecretManager(secretManager).setPortRangeConfig(portRangeConfig)
        .build();
    
---------------Reference log start----------------
LOG.info(""Adding protocol "" + pbProtocol.getCanonicalName() + "" to the server"")
---------------Reference log end----------------
    server.addProtocol(RPC.RpcKind.RPC_PROTOCOL_BUFFER, pbProtocol, blockingService);
    return server;
  }",,
hadoop,2827,LOG.info(message),info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceTrackerService.java/#L680,"@SuppressWarnings(""unchecked"")
  @Override
  public NodeHeartbeatResponse nodeHeartbeat(NodeHeartbeatRequest request)
      throws YarnException, IOException {

    NodeStatus remoteNodeStatus = request.getNodeStatus();
    /**
     * Here is the node heartbeat sequence...
     * 1. Check if it's a valid (i.e. not excluded) node
     * 2. Check if it's a registered node
     * 3. Check if it's a 'fresh' heartbeat i.e. not duplicate heartbeat
     * 4. Send healthStatus to RMNode
     * 5. Update node's labels if distributed Node Labels configuration is enabled
     */
    NodeId nodeId = remoteNodeStatus.getNodeId();

    // 1. Check if it's a valid (i.e. not excluded) node, if not, see if it is
    // in decommissioning.
    if (!this.nodesListManager.isValidNode(nodeId.getHost())
        && !isNodeInDecommissioning(nodeId)) {
      String message =
          ""Disallowed NodeManager nodeId: "" + nodeId + "" hostname: ""
              + nodeId.getHost();
      LOG.info(message);
      return YarnServerBuilderUtils.newNodeHeartbeatResponse(
          NodeAction.SHUTDOWN, message);
    }

    // 2. Check if it's a registered node
    RMNode rmNode = this.rmContext.getRMNodes().get(nodeId);
    if (rmNode == null) {
      /* node does not exist */
      String message = ""Node not found resyncing "" + remoteNodeStatus.getNodeId();
      LOG.info(message);
      return YarnServerBuilderUtils.newNodeHeartbeatResponse(NodeAction.RESYNC,
          message);
    }

    // Send ping
    this.nmLivelinessMonitor.receivedPing(nodeId);
    this.decommissioningWatcher.update(rmNode, remoteNodeStatus);

    // 3. Check if it's a 'fresh' heartbeat i.e. not duplicate heartbeat
    NodeHeartbeatResponse lastNodeHeartbeatResponse = rmNode.getLastNodeHeartBeatResponse();
    if (getNextResponseId(
        remoteNodeStatus.getResponseId()) == lastNodeHeartbeatResponse
            .getResponseId()) {
      LOG.info(""Received duplicate heartbeat from node ""
          + rmNode.getNodeAddress()+ "" responseId="" + remoteNodeStatus.getResponseId());
      return lastNodeHeartbeatResponse;
    } else if (remoteNodeStatus.getResponseId() != lastNodeHeartbeatResponse
        .getResponseId()) {
      String message =
          ""Too far behind rm response id:""
              + lastNodeHeartbeatResponse.getResponseId() + "" nm response id:""
              + remoteNodeStatus.getResponseId();
      
---------------Reference log start----------------
LOG.info(message)
---------------Reference log end----------------
      // TODO: Just sending reboot is not enough. Think more.
      this.rmContext.getDispatcher().getEventHandler().handle(
          new RMNodeEvent(nodeId, RMNodeEventType.REBOOTING));
      return YarnServerBuilderUtils.newNodeHeartbeatResponse(NodeAction.RESYNC,
          message);
    }

    // Evaluate whether a DECOMMISSIONING node is ready to be DECOMMISSIONED.
    if (rmNode.getState() == NodeState.DECOMMISSIONING &&
        decommissioningWatcher.checkReadyToBeDecommissioned(
            rmNode.getNodeID())) {
      String message = ""DECOMMISSIONING "" + nodeId +
          "" is ready to be decommissioned"";
      LOG.info(message);
      this.rmContext.getDispatcher().getEventHandler().handle(
          new RMNodeEvent(nodeId, RMNodeEventType.DECOMMISSION));
      this.nmLivelinessMonitor.unregister(nodeId);
      return YarnServerBuilderUtils.newNodeHeartbeatResponse(
          NodeAction.SHUTDOWN, message);
    }

    if (timelineServiceV2Enabled) {
      // Check & update collectors info from request.
      updateAppCollectorsMap(request);
    }

    // Heartbeat response
    long newInterval = nextHeartBeatInterval;
    if (heartBeatIntervalScalingEnable) {
      newInterval = rmNode.calculateHeartBeatInterval(
          nextHeartBeatInterval, heartBeatIntervalMin,
          heartBeatIntervalMax, heartBeatIntervalSpeedupFactor,
          heartBeatIntervalSlowdownFactor);
    }
    NodeHeartbeatResponse nodeHeartBeatResponse =
        YarnServerBuilderUtils.newNodeHeartbeatResponse(
            getNextResponseId(lastNodeHeartbeatResponse.getResponseId()),
            NodeAction.NORMAL, null, null, null, null, newInterval);
    rmNode.setAndUpdateNodeHeartbeatResponse(nodeHeartBeatResponse);

    populateKeys(request, nodeHeartBeatResponse);

    populateTokenSequenceNo(request, nodeHeartBeatResponse);

    if (timelineServiceV2Enabled) {
      // Return collectors' map that NM needs to know
      setAppCollectorsMapToResponse(rmNode.getRunningApps(),
          nodeHeartBeatResponse);
    }

    // 4. Send status to RMNode, saving the latest response.
    RMNodeStatusEvent nodeStatusEvent =
        new RMNodeStatusEvent(nodeId, remoteNodeStatus);
    if (request.getLogAggregationReportsForApps() != null
        && !request.getLogAggregationReportsForApps().isEmpty()) {
      nodeStatusEvent.setLogAggregationReportsForApps(request
        .getLogAggregationReportsForApps());
    }
    this.rmContext.getDispatcher().getEventHandler().handle(nodeStatusEvent);

    // 5. Update node's labels to RM's NodeLabelManager.
    if (isDistributedNodeLabelsConf && request.getNodeLabels() != null) {
      try {
        updateNodeLabelsFromNMReport(
            NodeLabelsUtils.convertToStringSet(request.getNodeLabels()),
            nodeId);
        nodeHeartBeatResponse.setAreNodeLabelsAcceptedByRM(true);
      } catch (IOException ex) {
        //ensure the error message is captured and sent across in response
        nodeHeartBeatResponse.setDiagnosticsMessage(ex.getMessage());
        nodeHeartBeatResponse.setAreNodeLabelsAcceptedByRM(false);
      }
    }

    // 6. check if node's capacity is load from dynamic-resources.xml
    // if so, send updated resource back to NM.
    String nid = nodeId.toString();
    Resource capability = loadNodeResourceFromDRConfiguration(nid);
    // sync back with new resource if not null.
    if (capability != null) {
      nodeHeartBeatResponse.setResource(capability);
    }
    // Check if we got an event (AdminService) that updated the resources
    if (rmNode.isUpdatedCapability()) {
      nodeHeartBeatResponse.setResource(rmNode.getTotalCapability());
      rmNode.resetUpdatedCapability();
    }

    // 7. Send Container Queuing Limits back to the Node. This will be used by
    // the node to truncate the number of Containers queued for execution.
    if (this.rmContext.getNodeManagerQueueLimitCalculator() != null) {
      nodeHeartBeatResponse.setContainerQueuingLimit(
          this.rmContext.getNodeManagerQueueLimitCalculator()
              .createContainerQueuingLimit());
    }

    // 8. Get node's attributes and update node-to-attributes mapping
    // in RMNodeAttributeManager.
    if (request.getNodeAttributes() != null) {
      try {
        // update node attributes if necessary then update heartbeat response
        updateNodeAttributesIfNecessary(nodeId, request.getNodeAttributes());
        nodeHeartBeatResponse.setAreNodeAttributesAcceptedByRM(true);
      } catch (IOException ex) {
        //ensure the error message is captured and sent across in response
        String errorMsg =
            nodeHeartBeatResponse.getDiagnosticsMessage() == null ?
                ex.getMessage() :
                nodeHeartBeatResponse.getDiagnosticsMessage() + ""\n"" + ex
                    .getMessage();
        nodeHeartBeatResponse.setDiagnosticsMessage(errorMsg);
        nodeHeartBeatResponse.setAreNodeAttributesAcceptedByRM(false);
      }
    }

    return nodeHeartBeatResponse;
  }",,
hadoop,11971,"LOG.debug(""add to "" + mapName + ""map:"" + nameId[0] + "" id:"" + nameId[1])",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/ShellBasedIdMapping.java/#L234,"@VisibleForTesting
  public static boolean updateMapInternal(BiMap<Integer, String> map,
      String mapName, String command, String regex,
      Map<Integer, Integer> staticMapping) throws IOException  {
    boolean updated = false;
    BufferedReader br = null;
    try {
      Process process = Runtime.getRuntime().exec(
          new String[] { ""bash"", ""-c"", command });
      br = new BufferedReader(
          new InputStreamReader(process.getInputStream(),
                                Charset.defaultCharset()));
      String line = null;
      while ((line = br.readLine()) != null) {
        String[] nameId = line.split(regex);
        if ((nameId == null) || (nameId.length != 2)) {
          throw new IOException(""Can't parse "" + mapName + "" list entry:"" + line);
        }
        
---------------Reference log start----------------
LOG.debug(""add to "" + mapName + ""map:"" + nameId[0] + "" id:"" + nameId[1])
---------------Reference log end----------------
        // HDFS can't differentiate duplicate names with simple authentication
        final Integer key = staticMapping.get(parseId(nameId[1]));
        final String value = nameId[0];
        if (map.containsKey(key)) {
          final String prevValue = map.get(key);
          if (value.equals(prevValue)) {
            // silently ignore equivalent entries
            continue;
          }
          reportDuplicateEntry(
              ""Got multiple names associated with the same id: "",
              key, value, key, prevValue);           
          continue;
        }
        if (map.containsValue(value)) {
          final Integer prevKey = map.inverse().get(value);
          reportDuplicateEntry(
              ""Got multiple ids associated with the same name: "",
              key, value, prevKey, value);
          continue;
        }
        map.put(key, value);
        updated = true;
      }
      LOG.debug(""Updated "" + mapName + "" map size: "" + map.size());
      
    } catch (IOException e) {
      LOG.error(""Can't update "" + mapName + "" map"");
      throw e;
    } finally {
      if (br != null) {
        try {
          br.close();
        } catch (IOException e1) {
          LOG.error(""Can't close BufferedReader of command result"", e1);
        }
      }
    }
    return updated;
  }",,
hadoop,2279,"LOG.info(""Initializing user {}"", user)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DefaultContainerExecutor.java/#L849,"void createUserCacheDirs(List<String> localDirs, String user)
      throws IOException {
    
---------------Reference log start----------------
LOG.info(""Initializing user {}"", user)
---------------Reference log end----------------

    boolean appcacheDirStatus = false;
    boolean distributedCacheDirStatus = false;
    FsPermission appCachePerms = new FsPermission(APPCACHE_PERM);
    FsPermission fileperms = new FsPermission(FILECACHE_PERM);

    for (String localDir : localDirs) {
      // create $local.dir/usercache/$user/appcache
      Path localDirPath = new Path(localDir);
      final Path appDir = getAppcacheDir(localDirPath, user);
      try {
        createDir(appDir, appCachePerms, true, user);
        appcacheDirStatus = true;
      } catch (IOException e) {
        LOG.warn(""Unable to create app cache directory : {}"", appDir, e);
      }
      // create $local.dir/usercache/$user/filecache
      final Path distDir = getFileCacheDir(localDirPath, user);
      try {
        createDir(distDir, fileperms, true, user);
        distributedCacheDirStatus = true;
      } catch (IOException e) {
        LOG.warn(""Unable to create file cache directory : {}"", distDir, e);
      }
    }
    if (!appcacheDirStatus) {
      throw new IOException(""Not able to initialize app-cache directories ""
          + ""in any of the configured local directories for user "" + user);
    }
    if (!distributedCacheDirStatus) {
      throw new IOException(
          ""Not able to initialize distributed-cache directories ""
              + ""in any of the configured local directories for user ""
              + user);
    }
  }",,
hadoop,12868,"LOG.debug(""Illegal progress value found, progress is "" + ""Float.NEGATIVE_INFINITY. Progress will be changed to 0"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/Progress.java/#L170,"public synchronized void set(float progress) {
    if (Float.isNaN(progress)) {
      progress = 0;
      LOG.debug(""Illegal progress value found, progress is Float.NaN. "" +
        ""Progress will be changed to 0"");
    }
    else if (progress == Float.NEGATIVE_INFINITY) {
      progress = 0;
      
---------------Reference log start----------------
LOG.debug(""Illegal progress value found, progress is "" + ""Float.NEGATIVE_INFINITY. Progress will be changed to 0"")
---------------Reference log end----------------
    }
    else if (progress < 0) {
      progress = 0;
      LOG.debug(""Illegal progress value found, progress is less than 0."" +
        "" Progress will be changed to 0"");
    }
    else if (progress > 1) {
      progress = 1;
      LOG.debug(""Illegal progress value found, progress is larger than 1."" +
        "" Progress will be changed to 1"");
    }
    else if (progress == Float.POSITIVE_INFINITY) {
      progress = 1;
      LOG.debug(""Illegal progress value found, progress is "" +
        ""Float.POSITIVE_INFINITY. Progress will be changed to 1"");
    }
    this.progress = progress;
  }",,
hadoop,4274,"LOG.warn(""Interrupted Exception while stopping"", ie)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/event/AsyncDispatcher.java/#L237,"@Override
  protected void serviceStop() throws Exception {
    if (drainEventsOnStop) {
      blockNewEvents = true;
      LOG.info(""AsyncDispatcher is draining to stop, ignoring any new events."");
      long endTime = System.currentTimeMillis() + getConfig()
          .getLong(YarnConfiguration.DISPATCHER_DRAIN_EVENTS_TIMEOUT,
              YarnConfiguration.DEFAULT_DISPATCHER_DRAIN_EVENTS_TIMEOUT);

      synchronized (waitForDrained) {
        while (!isDrained() && eventHandlingThread != null
            && eventHandlingThread.isAlive()
            && System.currentTimeMillis() < endTime) {
          waitForDrained.wait(100);
          LOG.info(""Waiting for AsyncDispatcher to drain. Thread state is :"" +
              eventHandlingThread.getState());
        }
      }
    }
    stopped = true;
    if (eventHandlingThread != null) {
      eventHandlingThread.interrupt();
      try {
        eventHandlingThread.join();
      } catch (InterruptedException ie) {
        
---------------Reference log start----------------
LOG.warn(""Interrupted Exception while stopping"", ie)
---------------Reference log end----------------
      }
    }
    printEventDetailsExecutor.shutdownNow();

    // stop all the components
    super.serviceStop();
  }",,
hadoop,10483,"LOG.warn(DistCpOptionSwitch.FILE_LIMIT.getSwitch() + "" is a deprecated"" + "" option. Ignoring."")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/OptionsParser.java/#L205,"public static DistCpOptions parse(String[] args)
      throws IllegalArgumentException {

    CommandLineParser parser = new CustomParser();

    CommandLine command;
    try {
      command = parser.parse(cliOptions, args, true);
    } catch (ParseException e) {
      throw new IllegalArgumentException(""Unable to parse arguments. "" +
        Arrays.toString(args), e);
    }

    DistCpOptions.Builder builder = parseSourceAndTargetPaths(command);
    builder
        .withAtomicCommit(
            command.hasOption(DistCpOptionSwitch.ATOMIC_COMMIT.getSwitch()))
        .withSyncFolder(
            command.hasOption(DistCpOptionSwitch.SYNC_FOLDERS.getSwitch()))
        .withDeleteMissing(
            command.hasOption(DistCpOptionSwitch.DELETE_MISSING.getSwitch()))
        .withIgnoreFailures(
            command.hasOption(DistCpOptionSwitch.IGNORE_FAILURES.getSwitch()))
        .withOverwrite(
            command.hasOption(DistCpOptionSwitch.OVERWRITE.getSwitch()))
        .withAppend(
            command.hasOption(DistCpOptionSwitch.APPEND.getSwitch()))
        .withCRC(
            command.hasOption(DistCpOptionSwitch.SKIP_CRC.getSwitch()))
        .withBlocking(
            !command.hasOption(DistCpOptionSwitch.BLOCKING.getSwitch()))
        .withVerboseLog(
            command.hasOption(DistCpOptionSwitch.VERBOSE_LOG.getSwitch()))
        .withDirectWrite(
            command.hasOption(DistCpOptionSwitch.DIRECT_WRITE.getSwitch()))
        .withUseIterator(
            command.hasOption(DistCpOptionSwitch.USE_ITERATOR.getSwitch()));

    if (command.hasOption(DistCpOptionSwitch.DIFF.getSwitch())) {
      String[] snapshots = getVals(command,
          DistCpOptionSwitch.DIFF.getSwitch());
      checkSnapshotsArgs(snapshots);
      builder.withUseDiff(snapshots[0], snapshots[1]);
    }
    if (command.hasOption(DistCpOptionSwitch.RDIFF.getSwitch())) {
      String[] snapshots = getVals(command,
          DistCpOptionSwitch.RDIFF.getSwitch());
      checkSnapshotsArgs(snapshots);
      builder.withUseRdiff(snapshots[0], snapshots[1]);
    }

    if (command.hasOption(DistCpOptionSwitch.FILTERS.getSwitch())) {
      builder.withFiltersFile(
          getVal(command, DistCpOptionSwitch.FILTERS.getSwitch()));
    }

    if (command.hasOption(DistCpOptionSwitch.LOG_PATH.getSwitch())) {
      builder.withLogPath(
          new Path(getVal(command, DistCpOptionSwitch.LOG_PATH.getSwitch())));
    }

    if (command.hasOption(DistCpOptionSwitch.WORK_PATH.getSwitch())) {
      final String workPath = getVal(command,
          DistCpOptionSwitch.WORK_PATH.getSwitch());
      if (workPath != null && !workPath.isEmpty()) {
        builder.withAtomicWorkPath(new Path(workPath));
      }
    }
    if (command.hasOption(DistCpOptionSwitch.TRACK_MISSING.getSwitch())) {
      builder.withTrackMissing(
          new Path(getVal(
              command,
              DistCpOptionSwitch.TRACK_MISSING.getSwitch())));
    }

    if (command.hasOption(DistCpOptionSwitch.BANDWIDTH.getSwitch())) {
      try {
        final Float mapBandwidth = Float.parseFloat(
            getVal(command, DistCpOptionSwitch.BANDWIDTH.getSwitch()));
        builder.withMapBandwidth(mapBandwidth);
      } catch (NumberFormatException e) {
        throw new IllegalArgumentException(""Bandwidth specified is invalid: "" +
            getVal(command, DistCpOptionSwitch.BANDWIDTH.getSwitch()), e);
      }
    }

    if (command.hasOption(
        DistCpOptionSwitch.NUM_LISTSTATUS_THREADS.getSwitch())) {
      try {
        final Integer numThreads = Integer.parseInt(getVal(command,
            DistCpOptionSwitch.NUM_LISTSTATUS_THREADS.getSwitch()));
        builder.withNumListstatusThreads(numThreads);
      } catch (NumberFormatException e) {
        throw new IllegalArgumentException(
            ""Number of liststatus threads is invalid: "" + getVal(command,
                DistCpOptionSwitch.NUM_LISTSTATUS_THREADS.getSwitch()), e);
      }
    }

    if (command.hasOption(DistCpOptionSwitch.MAX_MAPS.getSwitch())) {
      try {
        final Integer maps = Integer.parseInt(
            getVal(command, DistCpOptionSwitch.MAX_MAPS.getSwitch()));
        builder.maxMaps(maps);
      } catch (NumberFormatException e) {
        throw new IllegalArgumentException(""Number of maps is invalid: "" +
            getVal(command, DistCpOptionSwitch.MAX_MAPS.getSwitch()), e);
      }
    }

    if (command.hasOption(DistCpOptionSwitch.COPY_STRATEGY.getSwitch())) {
      builder.withCopyStrategy(
            getVal(command, DistCpOptionSwitch.COPY_STRATEGY.getSwitch()));
    }

    if (command.hasOption(DistCpOptionSwitch.PRESERVE_STATUS.getSwitch())) {
      builder.preserve(
          getVal(command, DistCpOptionSwitch.PRESERVE_STATUS.getSwitch()));
    }

    if (command.hasOption(DistCpOptionSwitch.FILE_LIMIT.getSwitch())) {
      
---------------Reference log start----------------
LOG.warn(DistCpOptionSwitch.FILE_LIMIT.getSwitch() + "" is a deprecated"" + "" option. Ignoring."")
---------------Reference log end----------------
    }

    if (command.hasOption(DistCpOptionSwitch.SIZE_LIMIT.getSwitch())) {
      LOG.warn(DistCpOptionSwitch.SIZE_LIMIT.getSwitch() + "" is a deprecated"" +
          "" option. Ignoring."");
    }

    if (command.hasOption(DistCpOptionSwitch.BLOCKS_PER_CHUNK.getSwitch())) {
      final String chunkSizeStr = getVal(command,
          DistCpOptionSwitch.BLOCKS_PER_CHUNK.getSwitch().trim());
      try {
        int csize = Integer.parseInt(chunkSizeStr);
        csize = csize > 0 ? csize : 0;
        LOG.info(""Set distcp blocksPerChunk to "" + csize);
        builder.withBlocksPerChunk(csize);
      } catch (NumberFormatException e) {
        throw new IllegalArgumentException(""blocksPerChunk is invalid: ""
            + chunkSizeStr, e);
      }
    }

    if (command.hasOption(DistCpOptionSwitch.COPY_BUFFER_SIZE.getSwitch())) {
      final String copyBufferSizeStr = getVal(command,
          DistCpOptionSwitch.COPY_BUFFER_SIZE.getSwitch().trim());
      try {
        int copyBufferSize = Integer.parseInt(copyBufferSizeStr);
        builder.withCopyBufferSize(copyBufferSize);
      } catch (NumberFormatException e) {
        throw new IllegalArgumentException(""copyBufferSize is invalid: ""
            + copyBufferSizeStr, e);
      }
    }

    return builder.build();
  }",,
hadoop,11383,"LOG.debug(""Cancelling futures"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSBlockOutputStream.java/#L218,"private List<PartETag> waitForAllPartUploads() throws IOException {
    LOG.debug(""Waiting for {} uploads to complete"", partETagsFutures.size());
    try {
      return Futures.allAsList(partETagsFutures).get();
    } catch (InterruptedException ie) {
      LOG.warn(""Interrupted partUpload"", ie);
      Thread.currentThread().interrupt();
      return null;
    } catch (ExecutionException ee) {
      //there is no way of recovering so abort
      //cancel all partUploads
      LOG.debug(""While waiting for upload completion"", ee);
      
---------------Reference log start----------------
LOG.debug(""Cancelling futures"")
---------------Reference log end----------------
      for (ListenableFuture<PartETag> future : partETagsFutures) {
        future.cancel(true);
      }
      //abort multipartupload
      store.abortMultipartUpload(key, uploadId);
      throw new IOException(""Multi-part upload with id '"" + uploadId
        + ""' to "" + key, ee);
    }
  }",,
hadoop,2483,"LOG.debug(""getEntityTimeline type={} id={}"", entityType, entityId)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/EntityGroupFSTimelineStore.java/#L1117,"@Override
  public TimelineEvents getEntityTimelines(String entityType,
      SortedSet<String> entityIds, Long limit, Long windowStart,
      Long windowEnd, Set<String> eventTypes) throws IOException {
    LOG.debug(""getEntityTimelines type={} ids={}"", entityType, entityIds);
    TimelineEvents returnEvents = new TimelineEvents();
    List<EntityCacheItem> relatedCacheItems = new ArrayList<>();

    if (entityIds == null || entityIds.isEmpty()) {
      return returnEvents;
    }

    for (String entityId : entityIds) {
      
---------------Reference log start----------------
LOG.debug(""getEntityTimeline type={} id={}"", entityType, entityId)
---------------Reference log end----------------
      List<TimelineStore> stores
          = getTimelineStoresForRead(entityId, entityType, relatedCacheItems);
      for (TimelineStore store : stores) {
        LOG.debug(""Try timeline store {}:{} for the request"", store.getName(),
            store.toString());
        SortedSet<String> entityIdSet = new TreeSet<>();
        entityIdSet.add(entityId);
        TimelineEvents events =
            store.getEntityTimelines(entityType, entityIdSet, limit,
                windowStart, windowEnd, eventTypes);
        if (events != null) {
          returnEvents.addEvents(events.getAllEvents());
        }
      }
    }
    return returnEvents;
  }",,
hadoop,12951,"LOG.debug(""beforeExecute in thread: "" + Thread.currentThread().getName() + "", runnable type: "" + r.getClass().getName())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/concurrent/HadoopScheduledThreadPoolExecutor.java/#L61,"@Override
  protected void beforeExecute(Thread t, Runnable r) {
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""beforeExecute in thread: "" + Thread.currentThread().getName() + "", runnable type: "" + r.getClass().getName())
---------------Reference log end----------------
    }
  }",,
hadoop,758,"LOG.debug(""proxy address is: {}"", add.getHostAddress())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/main/java/org/apache/hadoop/yarn/server/webproxy/amfilter/AmIpFilter.java/#L112,"protected Set<String> getProxyAddresses() throws ServletException {
    long now = Time.monotonicNow();
    synchronized(this) {
      if (proxyAddresses == null || (lastUpdate + updateInterval) <= now) {
        proxyAddresses = new HashSet<>();
        for (String proxyHost : proxyHosts) {
          try {
            for (InetAddress add : InetAddress.getAllByName(proxyHost)) {
              
---------------Reference log start----------------
LOG.debug(""proxy address is: {}"", add.getHostAddress())
---------------Reference log end----------------
              proxyAddresses.add(add.getHostAddress());
            }
            lastUpdate = now;
          } catch (UnknownHostException e) {
            LOG.warn(""Could not locate {} - skipping"", proxyHost, e);
          }
        }
        if (proxyAddresses.isEmpty()) {
          throw new ServletException(""Could not locate any of the proxy hosts"");
        }
      }
      return proxyAddresses;
    }
  }",,
hadoop,9273,"LOG.info(""From option {} get {}"", OBSConstants.OBS_SECURITY_PROVIDER, securityProviderClass)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-huaweicloud/src/main/java/org/apache/hadoop/fs/obs/DefaultOBSClientFactory.java/#L297,"private static ObsClient createObsClientWithoutCredentialsProvider(
      final Configuration conf, final ObsConfiguration obsConf,
      final URI name) throws IOException {
    ObsClient obsClient;
    OBSLoginHelper.Login creds = OBSCommonUtils.getOBSAccessKeys(name,
        conf);

    String ak = creds.getUser();
    String sk = creds.getPassword();
    String token = creds.getToken();

    String endPoint = conf.getTrimmed(OBSConstants.ENDPOINT, """");
    obsConf.setEndPoint(endPoint);

    if (!StringUtils.isEmpty(ak) || !StringUtils.isEmpty(sk)) {
      obsClient = new ObsClient(ak, sk, token, obsConf);
      return obsClient;
    }

    Class<?> securityProviderClass;
    try {
      securityProviderClass = conf.getClass(
          OBSConstants.OBS_SECURITY_PROVIDER, null);
      
---------------Reference log start----------------
LOG.info(""From option {} get {}"", OBSConstants.OBS_SECURITY_PROVIDER, securityProviderClass)
---------------Reference log end----------------
    } catch (RuntimeException e) {
      Throwable c = e.getCause() != null ? e.getCause() : e;
      throw new IOException(
          ""From option "" + OBSConstants.OBS_SECURITY_PROVIDER + ' ' + c,
          c);
    }

    if (securityProviderClass == null) {
      obsClient = new ObsClient(ak, sk, token, obsConf);
      return obsClient;
    }

    IObsCredentialsProvider securityProvider;
    try {
      Optional<Constructor> cons = tryGetConstructor(
          securityProviderClass,
          new Class[] {URI.class, Configuration.class});

      if (cons.isPresent()) {
        securityProvider = (IObsCredentialsProvider) cons.get()
            .newInstance(name, conf);
      } else {
        securityProvider
            = (IObsCredentialsProvider) securityProviderClass
            .getDeclaredConstructor().newInstance();
      }

    } catch (NoSuchMethodException
        | IllegalAccessException
        | InstantiationException
        | InvocationTargetException
        | RuntimeException e) {
      Throwable c = e.getCause() != null ? e.getCause() : e;
      throw new IOException(
          ""From option "" + OBSConstants.OBS_SECURITY_PROVIDER + ' ' + c,
          c);
    }
    obsClient = new ObsClient(securityProvider, obsConf);

    return obsClient;
  }",,
hadoop,7116,"LOG.error(""FSImageSaver cancel checkpoint threw an exception:"", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImage.java/#L1058,"@Override
    public void run() {
      // Deletes checkpoint file in every storage directory when shutdown.
      Runnable cancelCheckpointFinalizer = () -> {
        try {
          deleteCancelledCheckpoint(context.getTxId());
          LOG.info(""FSImageSaver clean checkpoint: txid={} when meet "" +
              ""shutdown."", context.getTxId());
        } catch (IOException e) {
          
---------------Reference log start----------------
LOG.error(""FSImageSaver cancel checkpoint threw an exception:"", e)
---------------Reference log end----------------
        }
      };
      ShutdownHookManager.get().addShutdownHook(cancelCheckpointFinalizer,
          SHUTDOWN_HOOK_PRIORITY);
      try {
        saveFSImage(context, sd, nnf);
      } catch (SaveNamespaceCancelledException snce) {
        LOG.info(""Cancelled image saving for "" + sd.getRoot() +
            "": "" + snce.getMessage());
        // don't report an error on the storage dir!
      } catch (Throwable t) {
        LOG.error(""Unable to save image for "" + sd.getRoot(), t);
        context.reportErrorOnStorageDirectory(sd);
        try {
          deleteCancelledCheckpoint(context.getTxId());
          LOG.info(""FSImageSaver clean checkpoint: txid={} when meet "" +
              ""Throwable."", context.getTxId());
        } catch (IOException e) {
          LOG.error(""FSImageSaver cancel checkpoint threw an exception:"", e);
        }
      }
    }",,
hadoop,8602,"LOG.debug(""Received handleLifeline from nodeReg = "" + nodeReg)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java/#L1901,"public void handleLifeline(DatanodeRegistration nodeReg,
      StorageReport[] reports, long cacheCapacity,
      long cacheUsed, int xceiverCount, int failedVolumes,
      VolumeFailureSummary volumeFailureSummary) throws IOException {
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""Received handleLifeline from nodeReg = "" + nodeReg)
---------------Reference log end----------------
    }
    DatanodeDescriptor nodeinfo = getDatanode(nodeReg);
    if (nodeinfo == null || !nodeinfo.isRegistered()) {
      // This can happen if the lifeline message comes when DataNode is either
      // not registered at all or its marked dead at NameNode and expectes
      // re-registration. Ignore lifeline messages without registration.
      // Lifeline message handling can't send commands back to the DataNode to
      // tell it to register, so simply exit.
      return;
    }
    if (nodeinfo.isDisallowed()) {
      // This is highly unlikely, because heartbeat handling is much more
      // frequent and likely would have already sent the disallowed error.
      // Lifeline messages are not intended to send any kind of control response
      // back to the DataNode, so simply exit.
      return;
    }
    heartbeatManager.updateLifeline(nodeinfo, reports, cacheCapacity, cacheUsed,
        xceiverCount, failedVolumes, volumeFailureSummary);
  }",,
hadoop,8119,"LOG.debug(""syncBlock replicaInfo: block="" + block + "", from datanode "" + r.id + "", receivedState="" + rState.name() + "", receivedLength="" + r.rInfo.getNumBytes() + "", bestState=FINALIZED, finalizedLength="" + finalizedLength)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.java/#L253,"void syncBlock(List<BlockRecord> syncList) throws IOException {
      DatanodeProtocolClientSideTranslatorPB nn =
          getActiveNamenodeForBP(block.getBlockPoolId());

      boolean isTruncateRecovery = rBlock.getNewBlock() != null;
      long blockId = (isTruncateRecovery) ?
          rBlock.getNewBlock().getBlockId() : block.getBlockId();

      LOG.info(""BlockRecoveryWorker: block={} (length={}),""
              + "" isTruncateRecovery={}, syncList={}"", block,
          block.getNumBytes(), isTruncateRecovery, syncList);

      // syncList.isEmpty() means that all data-nodes do not have the block
      // or their replicas have 0 length.
      // The block can be deleted.
      if (syncList.isEmpty()) {
        if (LOG.isDebugEnabled()) {
          LOG.debug(""syncBlock for block "" + block + "", all datanodes don't "" +
              ""have the block or their replicas have 0 length. The block can "" +
              ""be deleted."");
        }
        nn.commitBlockSynchronization(block, recoveryId, 0,
            true, true, DatanodeID.EMPTY_ARRAY, null);
        return;
      }

      // Calculate the best available replica state.
      ReplicaState bestState = ReplicaState.RWR;
      long finalizedLength = -1;
      for (BlockRecord r : syncList) {
        assert r.rInfo.getNumBytes() > 0 : ""zero length replica"";
        ReplicaState rState = r.rInfo.getOriginalReplicaState();
        if (rState.getValue() < bestState.getValue()) {
          bestState = rState;
        }
        if(rState == ReplicaState.FINALIZED) {
          if (finalizedLength > 0 && finalizedLength != r.rInfo.getNumBytes()) {
            throw new IOException(""Inconsistent size of finalized replicas. "" +
                ""Replica "" + r.rInfo + "" expected size: "" + finalizedLength);
          }
          finalizedLength = r.rInfo.getNumBytes();
        }
      }

      // Calculate list of nodes that will participate in the recovery
      // and the new block size
      List<BlockRecord> participatingList = new ArrayList<>();
      final ExtendedBlock newBlock = new ExtendedBlock(bpid, blockId,
          -1, recoveryId);
      switch(bestState) {
      case FINALIZED:
        assert finalizedLength > 0 : ""finalizedLength is not positive"";
        for(BlockRecord r : syncList) {
          ReplicaState rState = r.rInfo.getOriginalReplicaState();
          if (rState == ReplicaState.FINALIZED ||
              rState == ReplicaState.RBW &&
                  r.rInfo.getNumBytes() == finalizedLength) {
            participatingList.add(r);
          }
          if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""syncBlock replicaInfo: block="" + block + "", from datanode "" + r.id + "", receivedState="" + rState.name() + "", receivedLength="" + r.rInfo.getNumBytes() + "", bestState=FINALIZED, finalizedLength="" + finalizedLength)
---------------Reference log end----------------
          }
        }
        newBlock.setNumBytes(finalizedLength);
        break;
      case RBW:
      case RWR:
        long minLength = Long.MAX_VALUE;
        for(BlockRecord r : syncList) {
          ReplicaState rState = r.rInfo.getOriginalReplicaState();
          if(rState == bestState) {
            minLength = Math.min(minLength, r.rInfo.getNumBytes());
            participatingList.add(r);
          }
          if (LOG.isDebugEnabled()) {
            LOG.debug(""syncBlock replicaInfo: block="" + block +
                "", from datanode "" + r.id + "", receivedState="" + rState.name() +
                "", receivedLength="" + r.rInfo.getNumBytes() + "", bestState="" +
                bestState.name());
          }
        }
        // recover() guarantees syncList will have at least one replica with RWR
        // or better state.
        if (minLength == Long.MAX_VALUE) {
          throw new IOException(""Incorrect block size"");
        }
        newBlock.setNumBytes(minLength);
        break;
      case RUR:
      case TEMPORARY:
        assert false : ""bad replica state: "" + bestState;
      default:
        break; // we have 'case' all enum values
      }
      if (isTruncateRecovery) {
        newBlock.setNumBytes(rBlock.getNewBlock().getNumBytes());
      }

      LOG.info(""BlockRecoveryWorker: block={} (length={}), bestState={},""
              + "" newBlock={} (length={}), participatingList={}"",
          block, block.getNumBytes(), bestState.name(), newBlock,
          newBlock.getNumBytes(), participatingList);

      List<DatanodeID> failedList = new ArrayList<>();
      final List<BlockRecord> successList = new ArrayList<>();
      for (BlockRecord r : participatingList) {
        try {
          r.updateReplicaUnderRecovery(bpid, recoveryId, blockId,
              newBlock.getNumBytes());
          successList.add(r);
        } catch (IOException e) {
          InterDatanodeProtocol.LOG.warn(""Failed to updateBlock (newblock=""
              + newBlock + "", datanode="" + r.id + "")"", e);
          failedList.add(r.id);
        }
      }

      // Abort if all failed.
      if (successList.isEmpty()) {
        throw new IOException(""Cannot recover "" + block
            + "", the following datanodes failed: "" + failedList);
      }

      // Notify the name-node about successfully recovered replicas.
      final DatanodeID[] datanodes = new DatanodeID[successList.size()];
      final String[] storages = new String[datanodes.length];
      for (int i = 0; i < datanodes.length; i++) {
        final BlockRecord r = successList.get(i);
        datanodes[i] = r.id;
        storages[i] = r.storageID;
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug(""Datanode triggering commitBlockSynchronization, block="" +
            block + "", newGs="" + newBlock.getGenerationStamp() +
            "", newLength="" + newBlock.getNumBytes());
      }

      nn.commitBlockSynchronization(block,
          newBlock.getGenerationStamp(), newBlock.getNumBytes(), true, false,
          datanodes, storages);
    }",,
hadoop,10561,"LOG.info(""SLSRunner takes {} ms to launch all nodes."", System.currentTimeMillis() - startTimeMS)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java/#L430,"private void waitForNodesRunning() throws InterruptedException {
    long startTimeMS = System.currentTimeMillis();
    while (true) {
      int numRunningNodes = 0;
      for (RMNode node : rm.getRMContext().getRMNodes().values()) {
        if (node.getState() == NodeState.RUNNING) {
          numRunningNodes++;
        }
      }
      if (numRunningNodes == numNMs) {
        break;
      }
      LOG.info(""SLSRunner is waiting for all nodes RUNNING.""
          + "" {} of {} NMs initialized."", numRunningNodes, numNMs);
      Thread.sleep(1000);
    }
    
---------------Reference log start----------------
LOG.info(""SLSRunner takes {} ms to launch all nodes."", System.currentTimeMillis() - startTimeMS)
---------------Reference log end----------------
  }
  }",,
hadoop,3922,"LOG.info(""Successfully updated reservation: {} in plan."", reservation.getReservationId())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/InMemoryPlan.java/#L410,"@Override
  public boolean updateReservation(ReservationAllocation reservation)
      throws PlanningException {
    writeLock.lock();
    boolean result = false;
    try {
      ReservationId resId = reservation.getReservationId();
      ReservationAllocation currReservation = getReservationById(resId);
      if (currReservation == null) {
        String errMsg = ""The specified Reservation with ID "" + resId
            + "" does not exist in the plan"";
        LOG.error(errMsg);
        throw new IllegalArgumentException(errMsg);
      }
      // validate if we can accept this reservation, throws exception if
      // validation fails
      policy.validate(this, reservation);
      if (!removeReservation(currReservation)) {
        LOG.error(""Unable to replace reservation: {} from plan."",
            reservation.getReservationId());
        return result;
      }
      try {
        result = addReservation(reservation, false);
      } catch (PlanningException e) {
        LOG.error(""Unable to update reservation: {} from plan due to {}."",
            reservation.getReservationId(), e.getMessage());
      }
      if (result) {
        
---------------Reference log start----------------
LOG.info(""Successfully updated reservation: {} in plan."", reservation.getReservationId())
---------------Reference log end----------------
        return result;
      } else {
        // rollback delete
        addReservation(currReservation, false);
        LOG.info(""Rollbacked update reservation: {} from plan."",
            reservation.getReservationId());
        return result;
      }
    } finally {
      writeLock.unlock();
    }
  }",,
hadoop,3991,"LOG.info(""Found a renamed directory that was left undeleted at "" + path.toString() + "". Deleting."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/src/main/java/org/apache/hadoop/yarn/server/sharedcachemanager/CleanerTask.java/#L205,"void processSingleResource(FileStatus resource) {
    Path path = resource.getPath();
    // indicates the processing status of the resource
    ResourceStatus resourceStatus = ResourceStatus.INIT;

    // first, if the path ends with the renamed suffix, it indicates the
    // directory was moved (as stale) but somehow not deleted (probably due to
    // SCM failure); delete the directory
    if (path.toString().endsWith(RENAMED_SUFFIX)) {
      
---------------Reference log start----------------
LOG.info(""Found a renamed directory that was left undeleted at "" + path.toString() + "". Deleting."")
---------------Reference log end----------------
      try {
        if (fs.delete(path, true)) {
          resourceStatus = ResourceStatus.DELETED;
        }
      } catch (IOException e) {
        LOG.error(""Error while processing a shared cache resource: "" + path, e);
      }
    } else {
      // this is the path to the cache resource directory
      // the directory name is the resource key (i.e. a unique identifier)
      String key = path.getName();

      try {
        store.cleanResourceReferences(key);
      } catch (YarnException e) {
        LOG.error(""Exception thrown while removing dead appIds."", e);
      }

      if (store.isResourceEvictable(key, resource)) {
        try {
          /*
           * TODO See YARN-2663: There is a race condition between
           * store.removeResource(key) and
           * removeResourceFromCacheFileSystem(path) operations because they do
           * not happen atomically and resources can be uploaded with different
           * file names by the node managers.
           */
          // remove the resource from scm (checks for appIds as well)
          if (store.removeResource(key)) {
            // remove the resource from the file system
            boolean deleted = removeResourceFromCacheFileSystem(path);
            if (deleted) {
              resourceStatus = ResourceStatus.DELETED;
            } else {
              LOG.error(""Failed to remove path from the file system.""
                  + "" Skipping this resource: "" + path);
              resourceStatus = ResourceStatus.ERROR;
            }
          } else {
            // we did not delete the resource because it contained application
            // ids
            resourceStatus = ResourceStatus.PROCESSED;
          }
        } catch (IOException e) {
          LOG.error(
              ""Failed to remove path from the file system. Skipping this resource: ""
                  + path, e);
          resourceStatus = ResourceStatus.ERROR;
        }
      } else {
        resourceStatus = ResourceStatus.PROCESSED;
      }
    }

    // record the processing
    switch (resourceStatus) {
    case DELETED:
      metrics.reportAFileDelete();
      break;
    case PROCESSED:
      metrics.reportAFileProcess();
      break;
    case ERROR:
      metrics.reportAFileError();
      break;
    default:
      LOG.error(""Cleaner encountered an invalid status ("" + resourceStatus
          + "") while processing resource: "" + path.getName());
    }
  }",,
hadoop,1755,"LOG.info(""Resource "" + rsrc.getLocalPath() + "" is missing, localizing it again"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/LocalResourcesTrackerImpl.java/#L144,"@Override
  public synchronized void handle(ResourceEvent event) {
    LocalResourceRequest req = event.getLocalResourceRequest();
    LocalizedResource rsrc = localrsrc.get(req);
    switch (event.getType()) {
    case LOCALIZED:
      if (useLocalCacheDirectoryManager) {
        inProgressLocalResourcesMap.remove(req);
      }
      break;
    case REQUEST:
      if (rsrc != null && (!isResourcePresent(rsrc))) {
        
---------------Reference log start----------------
LOG.info(""Resource "" + rsrc.getLocalPath() + "" is missing, localizing it again"")
---------------Reference log end----------------
        removeResource(req);
        rsrc = null;
      }
      if (null == rsrc) {
        rsrc = new LocalizedResource(req, dispatcher);
        localrsrc.put(req, rsrc);
      }
      break;
    case RELEASE:
      if (null == rsrc) {
        // The container sent a release event on a resource which 
        // 1) Failed
        // 2) Removed for some reason (ex. disk is no longer accessible)
        ResourceReleaseEvent relEvent = (ResourceReleaseEvent) event;
        LOG.info(""Container "" + relEvent.getContainer()
            + "" sent RELEASE event on a resource request "" + req
            + "" not present in cache."");
        return;
      }
      break;
    case LOCALIZATION_FAILED:
      /*
       * If resource localization fails then Localized resource will be
       * removed from local cache.
       */
      removeResource(req);
      break;
    case RECOVERED:
      if (rsrc != null) {
        LOG.warn(""Ignoring attempt to recover existing resource "" + rsrc);
        return;
      }
      rsrc = recoverResource(req, (ResourceRecoveredEvent) event);
      localrsrc.put(req, rsrc);
      break;
    }

    if (rsrc == null) {
      LOG.warn(""Received "" + event.getType() + "" event for request "" + req
          + "" but localized resource is missing"");
      return;
    }
    rsrc.handle(event);

    // Remove the resource if its downloading and its reference count has
    // become 0 after RELEASE. This maybe because a container was killed while
    // localizing and no other container is referring to the resource.
    // NOTE: This should NOT be done for public resources since the
    //       download is not associated with a container-specific localizer.
    if (event.getType() == ResourceEventType.RELEASE) {
      if (rsrc.getState() == ResourceState.DOWNLOADING &&
          rsrc.getRefCount() <= 0 &&
          rsrc.getRequest().getVisibility() != LocalResourceVisibility.PUBLIC) {
        removeResource(req);
      }
    }

    if (event.getType() == ResourceEventType.LOCALIZED) {
      if (rsrc.getLocalPath() != null) {
        try {
          stateStore.finishResourceLocalization(user, appId,
              buildLocalizedResourceProto(rsrc));
        } catch (IOException ioe) {
          LOG.error(""Error storing resource state for "" + rsrc, ioe);
        }
      } else {
        LOG.warn(""Resource "" + rsrc + "" localized without a location"");
      }
    }
  }",,
hadoop,12866,"LOG.debug(""Illegal progress value found, progress is larger than 1."" + "" Progress will be changed to 1"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/Progress.java/#L180,"public synchronized void set(float progress) {
    if (Float.isNaN(progress)) {
      progress = 0;
      LOG.debug(""Illegal progress value found, progress is Float.NaN. "" +
        ""Progress will be changed to 0"");
    }
    else if (progress == Float.NEGATIVE_INFINITY) {
      progress = 0;
      LOG.debug(""Illegal progress value found, progress is "" +
        ""Float.NEGATIVE_INFINITY. Progress will be changed to 0"");
    }
    else if (progress < 0) {
      progress = 0;
      LOG.debug(""Illegal progress value found, progress is less than 0."" +
        "" Progress will be changed to 0"");
    }
    else if (progress > 1) {
      progress = 1;
      
---------------Reference log start----------------
LOG.debug(""Illegal progress value found, progress is larger than 1."" + "" Progress will be changed to 1"")
---------------Reference log end----------------
    }
    else if (progress == Float.POSITIVE_INFINITY) {
      progress = 1;
      LOG.debug(""Illegal progress value found, progress is "" +
        ""Float.POSITIVE_INFINITY. Progress will be changed to 1"");
    }
    this.progress = progress;
  }",,
hadoop,4985,"LOG.info(""Finished spill "" + numSpills)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java/#L1700,"private void sortAndSpill() throws IOException, ClassNotFoundException,
                                       InterruptedException {
      //approximate the length of the output file to be the length of the
      //buffer + header lengths for the partitions
      final long size = distanceTo(bufstart, bufend, bufvoid) +
                  partitions * APPROX_HEADER_LENGTH;
      FSDataOutputStream out = null;
      FSDataOutputStream partitionOut = null;
      try {
        // create spill file
        final SpillRecord spillRec = new SpillRecord(partitions);
        final Path filename =
            mapOutputFile.getSpillFileForWrite(numSpills, size);
        out = rfs.create(filename);

        final int mstart = kvend / NMETA;
        final int mend = 1 + // kvend is a valid record
          (kvstart >= kvend
          ? kvstart
          : kvmeta.capacity() + kvstart) / NMETA;
        sorter.sort(MapOutputBuffer.this, mstart, mend, reporter);
        int spindex = mstart;
        final IndexRecord rec = new IndexRecord();
        final InMemValBytes value = new InMemValBytes();
        for (int i = 0; i < partitions; ++i) {
          IFile.Writer<K, V> writer = null;
          try {
            long segmentStart = out.getPos();
            partitionOut =
                IntermediateEncryptedStream.wrapIfNecessary(job, out, false,
                    filename);
            writer = new Writer<K, V>(job, partitionOut, keyClass, valClass, codec,
                                      spilledRecordsCounter);
            if (combinerRunner == null) {
              // spill directly
              DataInputBuffer key = new DataInputBuffer();
              while (spindex < mend &&
                  kvmeta.get(offsetFor(spindex % maxRec) + PARTITION) == i) {
                final int kvoff = offsetFor(spindex % maxRec);
                int keystart = kvmeta.get(kvoff + KEYSTART);
                int valstart = kvmeta.get(kvoff + VALSTART);
                key.reset(kvbuffer, keystart, valstart - keystart);
                getVBytesForOffset(kvoff, value);
                writer.append(key, value);
                ++spindex;
              }
            } else {
              int spstart = spindex;
              while (spindex < mend &&
                  kvmeta.get(offsetFor(spindex % maxRec)
                            + PARTITION) == i) {
                ++spindex;
              }
              // Note: we would like to avoid the combiner if we've fewer
              // than some threshold of records for a partition
              if (spstart != spindex) {
                combineCollector.setWriter(writer);
                RawKeyValueIterator kvIter =
                  new MRResultIterator(spstart, spindex);
                combinerRunner.combine(kvIter, combineCollector);
              }
            }

            // close the writer
            writer.close();
            if (partitionOut != out) {
              partitionOut.close();
              partitionOut = null;
            }

            // record offsets
            rec.startOffset = segmentStart;
            rec.rawLength = writer.getRawLength() + CryptoUtils.cryptoPadding(job);
            rec.partLength = writer.getCompressedLength() + CryptoUtils.cryptoPadding(job);
            spillRec.putIndex(rec, i);

            writer = null;
          } finally {
            if (null != writer) writer.close();
          }
        }

        if (totalIndexCacheMemory >= indexCacheMemoryLimit) {
          // create spill index file
          Path indexFilename =
              mapOutputFile.getSpillIndexFileForWrite(numSpills, partitions
                  * MAP_OUTPUT_INDEX_RECORD_LENGTH);
          IntermediateEncryptedStream.addSpillIndexFile(indexFilename, job);
          spillRec.writeToFile(indexFilename, job);
        } else {
          indexCacheList.add(spillRec);
          totalIndexCacheMemory +=
            spillRec.size() * MAP_OUTPUT_INDEX_RECORD_LENGTH;
        }
        
---------------Reference log start----------------
LOG.info(""Finished spill "" + numSpills)
---------------Reference log end----------------
        ++numSpills;
      } finally {
        if (out != null) out.close();
        if (partitionOut != null) {
          partitionOut.close();
        }
      }
    }",,
hadoop,5687,"LOG.debug(""NFS SYMLINK, target: {} link: {} namenodeId: {} client: {}"", symData, linkIdPath, namenodeId, remoteAddress)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java/#L1461,"@VisibleForTesting
  SYMLINK3Response symlink(XDR xdr, SecurityHandler securityHandler,
      SocketAddress remoteAddress) {
    SYMLINK3Response response = new SYMLINK3Response(Nfs3Status.NFS3_OK);

    if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_WRITE)) {
      response.setStatus(Nfs3Status.NFS3ERR_ACCES);
      return response;
    }

    SYMLINK3Request request;
    try {
      request = SYMLINK3Request.deserialize(xdr);
    } catch (IOException e) {
      LOG.error(""Invalid SYMLINK request"");
      response.setStatus(Nfs3Status.NFS3ERR_INVAL);
      return response;
    }

    FileHandle dirHandle = request.getHandle();
    String name = request.getName();
    String symData = request.getSymData();
    String linkDirIdPath = Nfs3Utils.getFileIdPath(dirHandle);
    int namenodeId = dirHandle.getNamenodeId();

    // Don't do any name check to source path, just leave it to HDFS
    String linkIdPath = linkDirIdPath + ""/"" + name;
    
---------------Reference log start----------------
LOG.debug(""NFS SYMLINK, target: {} link: {} namenodeId: {} client: {}"", symData, linkIdPath, namenodeId, remoteAddress)
---------------Reference log end----------------

    DFSClient dfsClient =
        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);
    if (dfsClient == null) {
      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);
      return response;
    }

    try {
      WccData dirWcc = response.getDirWcc();
      WccAttr preOpAttr = Nfs3Utils.getWccAttr(dfsClient, linkDirIdPath);
      dirWcc.setPreOpAttr(preOpAttr);

      dfsClient.createSymlink(symData, linkIdPath, false);
      // Set symlink attr is considered as to change the attr of the target
      // file. So no need to set symlink attr here after it's created.

      HdfsFileStatus linkstat = dfsClient.getFileLinkInfo(linkIdPath);
      Nfs3FileAttributes objAttr = Nfs3Utils.getNfs3FileAttrFromFileStatus(
          linkstat, iug);
      dirWcc
          .setPostOpAttr(Nfs3Utils.getFileAttr(dfsClient, linkDirIdPath, iug));

      return new SYMLINK3Response(Nfs3Status.NFS3_OK, new FileHandle(
          objAttr.getFileId(), namenodeId), objAttr, dirWcc);

    } catch (IOException e) {
      LOG.warn(""Exception"", e);
      int status = mapErrorStatus(e);
      response.setStatus(status);
      return response;
    }
  }",,
hadoop,9679,"LOG.warn(""Got unexpected exception trying to get lease on {} . {}"", pathToKey(parent), e.getMessage())",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/NativeAzureFileSystem.java/#L1742,"@Override
  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,
      boolean overwrite, int bufferSize, short replication, long blockSize,
      Progressable progress) throws IOException {

    Path parent = f.getParent();

    // Get exclusive access to folder if this is a directory designated
    // for atomic rename. The primary use case of for HBase write-ahead
    // log file management.
    SelfRenewingLease lease = null;
    if (store.isAtomicRenameKey(pathToKey(f))) {
      try {
        lease = acquireLease(parent);
      } catch (AzureException e) {

        String errorCode = """";
        try {
          StorageException e2 = (StorageException) e.getCause();
          errorCode = e2.getErrorCode();
        } catch (Exception e3) {
          // do nothing if cast fails
        }
        if (errorCode.equals(""BlobNotFound"")) {
          throw new FileNotFoundException(""Cannot create file "" +
              f.getName() + "" because parent folder does not exist."");
        }

        
---------------Reference log start----------------
LOG.warn(""Got unexpected exception trying to get lease on {} . {}"", pathToKey(parent), e.getMessage())
---------------Reference log end----------------
        throw e;
      }
    }

    // See if the parent folder exists. If not, throw error.
    // The exists() check will push any pending rename operation forward,
    // if there is one, and return false.
    //
    // At this point, we have exclusive access to the source folder
    // via the lease, so we will not conflict with an active folder
    // rename operation.
    //
    // In the secure case, the call to exists will happen in the context
    // of the user that initiated the operation. In this case, we should
    // do the auth-check against ranger for the path.
    if (!exists(parent)) {
      try {

        // This'll let the keep-alive thread exit as soon as it wakes up.
        lease.free();
      } catch (Exception e) {
        LOG.warn(""Unable to free lease because: {}"", e.getMessage());
      }
      throw new FileNotFoundException(""Cannot create file "" +
          f.getName() + "" because parent folder does not exist."");
    }

    // Create file inside folder.
    FSDataOutputStream out = null;
    try {
      out = create(f, permission, overwrite, false,
          bufferSize, replication, blockSize, progress, lease);
    } finally {
      // Release exclusive access to folder.
      try {
        if (lease != null) {
          lease.free();
        }
      } catch (Exception e) {
        NativeAzureFileSystemHelper.cleanup(LOG, out);
        String msg = ""Unable to free lease on "" + parent.toUri();
        LOG.error(msg);
        throw new IOException(msg, e);
      }
    }
    return out;
  }",,
hadoop,11622,"LOG.debug(""ls {}"", fullpath)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-registry/src/main/java/org/apache/hadoop/registry/client/impl/zk/CuratorService.java/#L741,"public List<String> zkList(String path) throws IOException {
    checkServiceLive();
    String fullpath = createFullPath(path);
    try {
      if (LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
LOG.debug(""ls {}"", fullpath)
---------------Reference log end----------------
      }
      GetChildrenBuilder builder = curator.getChildren();
      List<String> children = builder.forPath(fullpath);
      return children;
    } catch (Exception e) {
      throw operationFailure(path, ""ls()"", e);
    }
  }",,
hadoop,7808,"LOG.info(""Starting IBR Task Handler."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java/#L1134,"@Override
    public void run() {
      
---------------Reference log start----------------
LOG.info(""Starting IBR Task Handler."")
---------------Reference log end----------------
      while (shouldRun()) {
        try {
          final long startTime = scheduler.monotonicNow();
          final boolean sendHeartbeat = scheduler.isHeartbeatDue(startTime);
          if (!dn.areIBRDisabledForTests() &&
              (ibrManager.sendImmediately() || sendHeartbeat)) {
            synchronized (sendIBRLock) {
              ibrManager.sendIBRs(bpNamenode, bpRegistration,
                  bpos.getBlockPoolId(), getRpcMetricSuffix());
            }
          }
          // There is no work to do; sleep until heartbeat timer elapses,
          // or work arrives, and then iterate again.
          ibrManager.waitTillNextIBR(scheduler.getHeartbeatWaitTime());
        } catch (Throwable t) {
          LOG.error(""Exception in IBRTaskHandler."", t);
          sleepAndLogInterrupts(5000, ""offering IBR service"");
        }
      }
    }",,
hadoop,5341,"LOG.error(""Error while starting the Secret Manager threads"", io)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java/#L98,"@Override
    protected void serviceStart() throws Exception {
      boolean recoveryEnabled = getConfig().getBoolean(
          JHAdminConfig.MR_HS_RECOVERY_ENABLE,
          JHAdminConfig.DEFAULT_MR_HS_RECOVERY_ENABLE);
      if (recoveryEnabled) {
        assert stateStore.isInState(STATE.STARTED);
        HistoryServerState state = stateStore.loadState();
        jhsDTSecretManager.recover(state);
      }

      try {
        jhsDTSecretManager.startThreads();
      } catch(IOException io) {
        
---------------Reference log start----------------
LOG.error(""Error while starting the Secret Manager threads"", io)
---------------Reference log end----------------
        throw io;
      }

      super.serviceStart();
    }",,
hadoop,1623,"LOG.info(""couldn't find application "" + appID + "" while processing"" + "" FINISH_APPS event. The ResourceManager allocated resources"" + "" for this application to the NodeManager but no active"" + "" containers were found to process."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/ContainerManagerImpl.java/#L1674,"@SuppressWarnings(""unchecked"")
  @Override
  public void handle(ContainerManagerEvent event) {
    switch (event.getType()) {
    case FINISH_APPS:
      CMgrCompletedAppsEvent appsFinishedEvent =
          (CMgrCompletedAppsEvent) event;
      for (ApplicationId appID : appsFinishedEvent.getAppsToCleanup()) {
        Application app = this.context.getApplications().get(appID);
        if (app == null) {
          
---------------Reference log start----------------
LOG.info(""couldn't find application "" + appID + "" while processing"" + "" FINISH_APPS event. The ResourceManager allocated resources"" + "" for this application to the NodeManager but no active"" + "" containers were found to process."")
---------------Reference log end----------------
          continue;
        }

        boolean shouldDropEvent = false;
        for (Container container : app.getContainers().values()) {
          if (container.isRecovering()) {
            LOG.info(""drop FINISH_APPS event to "" + appID + "" because ""
                + ""container "" + container.getContainerId()
                + "" is recovering"");
            shouldDropEvent = true;
            break;
          }
        }
        if (shouldDropEvent) {
          continue;
        }

        String diagnostic = """";
        if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.ON_SHUTDOWN) {
          diagnostic = ""Application killed on shutdown"";
        } else if (appsFinishedEvent.getReason() == CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER) {
          diagnostic = ""Application killed by ResourceManager"";
        }
        this.dispatcher.getEventHandler().handle(
            new ApplicationFinishEvent(appID,
                diagnostic));
      }
      break;
    case FINISH_CONTAINERS:
      CMgrCompletedContainersEvent containersFinishedEvent =
          (CMgrCompletedContainersEvent) event;
      for (ContainerId containerId : containersFinishedEvent
          .getContainersToCleanup()) {
        ApplicationId appId =
            containerId.getApplicationAttemptId().getApplicationId();
        Application app = this.context.getApplications().get(appId);
        if (app == null) {
          LOG.warn(""couldn't find app "" + appId + "" while processing""
              + "" FINISH_CONTAINERS event"");
          continue;
        }

        Container container = app.getContainers().get(containerId);
        if (container == null) {
          LOG.warn(""couldn't find container "" + containerId
              + "" while processing FINISH_CONTAINERS event"");
          continue;
        }

        if (container.isRecovering()) {
          LOG.info(""drop FINISH_CONTAINERS event to "" + containerId
              + "" because container is recovering"");
          continue;
        }

        this.dispatcher.getEventHandler().handle(
              new ContainerKillEvent(containerId,
                  ContainerExitStatus.KILLED_BY_RESOURCEMANAGER,
                  ""Container Killed by ResourceManager""));
      }
      break;
    case UPDATE_CONTAINERS:
      CMgrUpdateContainersEvent containersDecreasedEvent =
          (CMgrUpdateContainersEvent) event;
      for (org.apache.hadoop.yarn.api.records.Container container
          : containersDecreasedEvent.getContainersToUpdate()) {
        try {
          ContainerTokenIdentifier containerTokenIdentifier =
              BuilderUtils.newContainerTokenIdentifier(
                  container.getContainerToken());
          updateContainerInternal(container.getId(),
              containerTokenIdentifier);
        } catch (YarnException e) {
          LOG.error(""Unable to decrease container resource"", e);
        } catch (IOException e) {
          LOG.error(""Unable to update container resource in store"", e);
        }
      }
      break;
    case SIGNAL_CONTAINERS:
      CMgrSignalContainersEvent containersSignalEvent =
          (CMgrSignalContainersEvent) event;
      for (SignalContainerRequest request : containersSignalEvent
          .getContainersToSignal()) {
        internalSignalToContainer(request, ""ResourceManager"");
      }
      break;
    default:
        throw new YarnRuntimeException(
            ""Got an unknown ContainerManagerEvent type: "" + event.getType());
    }
  }",,
hadoop,1806,"LOG.warn(""Process tree for container: {} has processes older than 1 "" + ""iteration running over the configured limit. "" + ""Limit={}, current usage = {}"", containerId, memLimit, curMemUsageOfAgedProcesses)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/ContainersMonitorImpl.java/#L470,"private boolean isProcessTreeOverLimit(String containerId,
                                  long currentMemUsage,
                                  long curMemUsageOfAgedProcesses,
                                  long memLimit) {
    boolean isOverLimit = false;

    if (currentMemUsage > (2 * memLimit)) {
      LOG.warn(""Process tree for container: {} running over twice ""
          + ""the configured limit. Limit={}, current usage = {}"",
          containerId, memLimit, currentMemUsage);
      isOverLimit = true;
    } else if (curMemUsageOfAgedProcesses > memLimit) {
      
---------------Reference log start----------------
LOG.warn(""Process tree for container: {} has processes older than 1 "" + ""iteration running over the configured limit. "" + ""Limit={}, current usage = {}"", containerId, memLimit, curMemUsageOfAgedProcesses)
---------------Reference log end----------------
      isOverLimit = true;
    }

    return isOverLimit;
  }",,
hadoop,3270,"LOG.debug(""Requested Node Label Expression : "" + labelExp)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerUtils.java/#L237,"private static void normalizeNodeLabelExpressionInRequest(
      ResourceRequest resReq, QueueInfo queueInfo) {

    String labelExp = resReq.getNodeLabelExpression();
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""Requested Node Label Expression : "" + labelExp)
---------------Reference log end----------------
      LOG.debug(""Queue Info : "" + queueInfo);
    }

    // if queue has default label expression, and RR doesn't have, use the
    // default label expression of queue
    if (labelExp == null && queueInfo != null && ResourceRequest.ANY
        .equals(resReq.getResourceName())) {
      LOG.debug(""Setting default node label expression : {}"", queueInfo
          .getDefaultNodeLabelExpression());
      labelExp = queueInfo.getDefaultNodeLabelExpression();
    }

    // If labelExp still equals to null, it could either be a dynamic queue
    // or the label is not configured
    // set it to be NO_LABEL in case of a pre-configured queue. Dynamic
    // queues are handled in RMAppAttemptImp.ScheduledTransition
    if (labelExp == null && queueInfo != null) {
      labelExp = RMNodeLabelsManager.NO_LABEL;
    }

    if (labelExp != null) {
      resReq.setNodeLabelExpression(labelExp);
    }
  }",,
hadoop,12370,"LOG.info(""Stopping server on "" + port)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java/#L3496,"public synchronized void stop() {
    
---------------Reference log start----------------
LOG.info(""Stopping server on "" + port)
---------------Reference log end----------------
    running = false;
    if (handlers != null) {
      for (int i = 0; i < handlerCount; i++) {
        if (handlers[i] != null) {
          handlers[i].interrupt();
        }
      }
    }
    listener.interrupt();
    listener.doStop();
    if (auxiliaryListenerMap != null && auxiliaryListenerMap.size() > 0) {
      for (Listener newListener : auxiliaryListenerMap.values()) {
        newListener.interrupt();
        newListener.doStop();
      }
    }
    responder.interrupt();
    notifyAll();
    this.rpcMetrics.shutdown();
    this.rpcDetailedMetrics.shutdown();
  }",,
hadoop,10657,"LOG.debug(""Region for endpoint {}, URI {} is determined as {}"", endpoint, epr, region)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/DefaultS3ClientFactory.java/#L270,"@VisibleForTesting
  public static AwsClientBuilder.EndpointConfiguration
      createEndpointConfiguration(
      final String endpoint, final ClientConfiguration awsConf,
      String awsRegion) {
    LOG.debug(""Creating endpoint configuration for \""{}\"""", endpoint);
    if (endpoint == null || endpoint.isEmpty()) {
      // the default endpoint...we should be using null at this point.
      LOG.debug(""Using default endpoint -no need to generate a configuration"");
      return null;
    }

    final URI epr = RuntimeHttpUtils.toUri(endpoint, awsConf);
    LOG.debug(""Endpoint URI = {}"", epr);
    String region = awsRegion;
    if (StringUtils.isBlank(region)) {
      if (!ServiceUtils.isS3USStandardEndpoint(endpoint)) {
        LOG.debug(""Endpoint {} is not the default; parsing"", epr);
        region = AwsHostNameUtils.parseRegion(
            epr.getHost(),
            S3_SERVICE_NAME);
      } else {
        // US-east, set region == null.
        LOG.debug(""Endpoint {} is the standard one; declare region as null"",
            epr);
        region = null;
      }
    }
    
---------------Reference log start----------------
LOG.debug(""Region for endpoint {}, URI {} is determined as {}"", endpoint, epr, region)
---------------Reference log end----------------
    return new AwsClientBuilder.EndpointConfiguration(endpoint, region);
  }",,
hadoop,2285,"LOG.debug(""Scheduling DeletionTask (delay {}) : {}"", debugDelay, deletionTask)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DeletionService.java/#L88,"public void delete(DeletionTask deletionTask) {
    if (debugDelay != -1) {
      
---------------Reference log start----------------
LOG.debug(""Scheduling DeletionTask (delay {}) : {}"", debugDelay, deletionTask)
---------------Reference log end----------------
      recordDeletionTaskInStateStore(deletionTask);
      sched.schedule(deletionTask, debugDelay, TimeUnit.SECONDS);
    }
  }",,
hadoop,8343,"FsDatasetImpl.LOG.info(""Time taken to scan block pool "" + bpid + "" on "" + v + "": "" + timeTaken + ""ms"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java/#L483,"public void run() {
          try (FsVolumeReference ref = v.obtainReference()) {
            FsDatasetImpl.LOG.info(""Scanning block pool "" + bpid +
                "" on volume "" + v + ""..."");
            long startTime = Time.monotonicNow();
            v.addBlockPool(bpid, conf);
            long timeTaken = Time.monotonicNow() - startTime;
            
---------------Reference log start----------------
FsDatasetImpl.LOG.info(""Time taken to scan block pool "" + bpid + "" on "" + v + "": "" + timeTaken + ""ms"")
---------------Reference log end----------------
          } catch (IOException ioe) {
            FsDatasetImpl.LOG.info(""Caught exception while scanning "" + v +
                "". Will throw later."", ioe);
            unhealthyDataDirs.put(v, ioe);
          }
        }",,
hadoop,10531,"LOG.debug(""concat "" + targetFile + "" allChunkSize+ "" + allChunkPaths.size())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyCommitter.java/#L620,"private void concatFileChunks(Configuration conf, Path sourceFile,
                                Path targetFile, LinkedList<Path> allChunkPaths,
                                CopyListingFileStatus srcFileStatus)
      throws IOException {
    if (allChunkPaths.size() == 1) {
      return;
    }
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""concat "" + targetFile + "" allChunkSize+ "" + allChunkPaths.size())
---------------Reference log end----------------
    }
    FileSystem dstfs = targetFile.getFileSystem(conf);
    FileSystem srcfs = sourceFile.getFileSystem(conf);

    Path firstChunkFile = allChunkPaths.removeFirst();
    Path[] restChunkFiles = new Path[allChunkPaths.size()];
    allChunkPaths.toArray(restChunkFiles);
    if (LOG.isDebugEnabled()) {
      LOG.debug(""concat: firstchunk: "" + dstfs.getFileStatus(firstChunkFile));
      int i = 0;
      for (Path f : restChunkFiles) {
        LOG.debug(""concat: other chunk: "" + i + "": "" + dstfs.getFileStatus(f));
        ++i;
      }
    }
    dstfs.concat(firstChunkFile, restChunkFiles);
    if (LOG.isDebugEnabled()) {
      LOG.debug(""concat: result: "" + dstfs.getFileStatus(firstChunkFile));
    }
    rename(dstfs, firstChunkFile, targetFile);
    DistCpUtils.compareFileLengthsAndChecksums(srcFileStatus.getLen(),
        srcfs, sourceFile, null, dstfs,
            targetFile, skipCrc, srcFileStatus.getLen());
  }",,
hadoop,12195,"LOG.debug(String.format(""KeyStore loaded successfully from '%s' since '%s'"" + ""was corrupted !!"", backupPath, path))",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/JavaKeyStoreProvider.java/#L207,"private FsPermission tryLoadFromPath(Path path, Path backupPath)
      throws NoSuchAlgorithmException, CertificateException,
      IOException {
    FsPermission perm = null;
    try {
      perm = loadFromPath(path, password);
      // Remove _OLD if exists
      fs.delete(backupPath, true);
      LOG.debug(""KeyStore loaded successfully !!"");
    } catch (IOException ioe) {
      // If file is corrupted for some reason other than
      // wrong password try the _OLD file if exits
      if (!isBadorWrongPassword(ioe)) {
        perm = loadFromPath(backupPath, password);
        // Rename CURRENT to CORRUPTED
        renameOrFail(path, new Path(path.toString() + ""_CORRUPTED_""
            + System.currentTimeMillis()));
        renameOrFail(backupPath, path);
        if (LOG.isDebugEnabled()) {
          
---------------Reference log start----------------
LOG.debug(String.format(""KeyStore loaded successfully from '%s' since '%s'"" + ""was corrupted !!"", backupPath, path))
---------------Reference log end----------------
        }
      } else {
        throw ioe;
      }
    }
    return perm;
  }",,
hadoop,8246,"LOG.debug(""Writing out partial crc for data len "" + len + "", skip="" + skip)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java/#L790,"private int receivePacket() throws IOException {
    // read the next packet
    packetReceiver.receiveNextPacket(in);

    PacketHeader header = packetReceiver.getHeader();
    long seqno = header.getSeqno();
    LOG.debug(""Receiving one packet for block {} seqno:{} header:{} "", block,
        seqno, header);

    // Sanity check the header
    if (header.getOffsetInBlock() > replicaInfo.getNumBytes()) {
      throw new IOException(""Received an out-of-sequence packet for "" + block + 
          ""from "" + inAddr + "" at offset "" + header.getOffsetInBlock() +
          "". Expecting packet starting at "" + replicaInfo.getNumBytes());
    }
    if (header.getDataLen() < 0) {
      throw new IOException(""Got wrong length during writeBlock("" + block + 
                            "") from "" + inAddr + "" at offset "" + 
                            header.getOffsetInBlock() + "": "" +
                            header.getDataLen()); 
    }

    long offsetInBlock = header.getOffsetInBlock();
    boolean lastPacketInBlock = header.isLastPacketInBlock();
    final int len = header.getDataLen();
    boolean syncBlock = header.getSyncBlock();

    // avoid double sync'ing on close
    if (syncBlock && lastPacketInBlock) {
      this.syncOnClose = false;
      // sync directory for finalize irrespective of syncOnClose config since
      // sync is requested.
      this.dirSyncOnFinalize = true;
    }

    // update received bytes
    final long firstByteInBlock = offsetInBlock;
    offsetInBlock += len;
    if (replicaInfo.getNumBytes() < offsetInBlock) {
      replicaInfo.setNumBytes(offsetInBlock);
    }
    
    // put in queue for pending acks, unless sync was requested
    if (responder != null && !syncBlock && !shouldVerifyChecksum()) {
      ((PacketResponder) responder.getRunnable()).enqueue(seqno,
          lastPacketInBlock, offsetInBlock, Status.SUCCESS);
    }

    // Drop heartbeat for testing.
    if (seqno < 0 && len == 0 &&
        DataNodeFaultInjector.get().dropHeartbeatPacket()) {
      return 0;
    }

    datanode.metrics.incrPacketsReceived();
    //First write the packet to the mirror:
    if (mirrorOut != null && !mirrorError) {
      try {
        long begin = Time.monotonicNow();
        // For testing. Normally no-op.
        DataNodeFaultInjector.get().stopSendingPacketDownstream(mirrorAddr);
        packetReceiver.mirrorPacketTo(mirrorOut);
        mirrorOut.flush();
        long now = Time.monotonicNow();
        this.lastSentTime.set(now);
        long duration = now - begin;
        DataNodeFaultInjector.get().logDelaySendingPacketDownstream(
            mirrorAddr,
            duration);
        trackSendPacketToLastNodeInPipeline(duration);
        if (duration > datanodeSlowLogThresholdMs) {
          datanode.metrics.incrPacketsSlowWriteToMirror();
          if (LOG.isWarnEnabled()) {
            LOG.warn(""Slow BlockReceiver write packet to mirror took {}ms "" +
                ""(threshold={}ms), downstream DNs={}, blockId={}, seqno={}"",
                duration, datanodeSlowLogThresholdMs,
                Arrays.toString(downstreamDNs), replicaInfo.getBlockId(),
                seqno);
          }
        }
      } catch (IOException e) {
        handleMirrorOutError(e);
      }
    }
    
    ByteBuffer dataBuf = packetReceiver.getDataSlice();
    ByteBuffer checksumBuf = packetReceiver.getChecksumSlice();
    
    if (lastPacketInBlock || len == 0) {
      if(LOG.isDebugEnabled()) {
        LOG.debug(""Receiving an empty packet or the end of the block "" + block);
      }
      // sync block if requested
      if (syncBlock) {
        flushOrSync(true, seqno);
      }
    } else {
      final int checksumLen = diskChecksum.getChecksumSize(len);
      final int checksumReceivedLen = checksumBuf.capacity();

      if (checksumReceivedLen > 0 && checksumReceivedLen != checksumLen) {
        throw new IOException(""Invalid checksum length: received length is ""
            + checksumReceivedLen + "" but expected length is "" + checksumLen);
      }

      if (checksumReceivedLen > 0 && shouldVerifyChecksum()) {
        try {
          verifyChunks(dataBuf, checksumBuf);
        } catch (IOException ioe) {
          // checksum error detected locally. there is no reason to continue.
          if (responder != null) {
            try {
              ((PacketResponder) responder.getRunnable()).enqueue(seqno,
                  lastPacketInBlock, offsetInBlock,
                  Status.ERROR_CHECKSUM);
              // Wait until the responder sends back the response
              // and interrupt this thread.
              Thread.sleep(3000);
            } catch (InterruptedException e) { }
          }
          throw new IOException(""Terminating due to a checksum error."" + ioe);
        }
 
        if (needsChecksumTranslation) {
          // overwrite the checksums in the packet buffer with the
          // appropriate polynomial for the disk storage.
          translateChunks(dataBuf, checksumBuf);
        }
      }

      if (checksumReceivedLen == 0 && !streams.isTransientStorage()) {
        // checksum is missing, need to calculate it
        checksumBuf = ByteBuffer.allocate(checksumLen);
        diskChecksum.calculateChunkedSums(dataBuf, checksumBuf);
      }
      
      // by this point, the data in the buffer uses the disk checksum

      final boolean shouldNotWriteChecksum = checksumReceivedLen == 0
          && streams.isTransientStorage();
      try {
        long onDiskLen = replicaInfo.getBytesOnDisk();
        if (onDiskLen<offsetInBlock) {
          // Normally the beginning of an incoming packet is aligned with the
          // existing data on disk. If the beginning packet data offset is not
          // checksum chunk aligned, the end of packet will not go beyond the
          // next chunk boundary.
          // When a failure-recovery is involved, the client state and the
          // the datanode state may not exactly agree. I.e. the client may
          // resend part of data that is already on disk. Correct number of
          // bytes should be skipped when writing the data and checksum
          // buffers out to disk.
          long partialChunkSizeOnDisk = onDiskLen % bytesPerChecksum;
          long lastChunkBoundary = onDiskLen - partialChunkSizeOnDisk;
          boolean alignedOnDisk = partialChunkSizeOnDisk == 0;
          boolean alignedInPacket = firstByteInBlock % bytesPerChecksum == 0;

          // If the end of the on-disk data is not chunk-aligned, the last
          // checksum needs to be overwritten.
          boolean overwriteLastCrc = !alignedOnDisk && !shouldNotWriteChecksum;
          // If the starting offset of the packat data is at the last chunk
          // boundary of the data on disk, the partial checksum recalculation
          // can be skipped and the checksum supplied by the client can be used
          // instead. This reduces disk reads and cpu load.
          boolean doCrcRecalc = overwriteLastCrc &&
              (lastChunkBoundary != firstByteInBlock);

          // If this is a partial chunk, then verify that this is the only
          // chunk in the packet. If the starting offset is not chunk
          // aligned, the packet should terminate at or before the next
          // chunk boundary.
          if (!alignedInPacket && len > bytesPerChecksum) {
            throw new IOException(""Unexpected packet data length for ""
                +  block + "" from "" + inAddr + "": a partial chunk must be ""
                + "" sent in an individual packet (data length = "" + len
                +  "" > bytesPerChecksum = "" + bytesPerChecksum + "")"");
          }

          // If the last portion of the block file is not a full chunk,
          // then read in pre-existing partial data chunk and recalculate
          // the checksum so that the checksum calculation can continue
          // from the right state. If the client provided the checksum for
          // the whole chunk, this is not necessary.
          Checksum partialCrc = null;
          if (doCrcRecalc) {
            if (LOG.isDebugEnabled()) {
              LOG.debug(""receivePacket for "" + block 
                  + "": previous write did not end at the chunk boundary.""
                  + "" onDiskLen="" + onDiskLen);
            }
            long offsetInChecksum = BlockMetadataHeader.getHeaderSize() +
                onDiskLen / bytesPerChecksum * checksumSize;
            partialCrc = computePartialChunkCrc(onDiskLen, offsetInChecksum);
          }

          // The data buffer position where write will begin. If the packet
          // data and on-disk data have no overlap, this will not be at the
          // beginning of the buffer.
          int startByteToDisk = (int)(onDiskLen-firstByteInBlock) 
              + dataBuf.arrayOffset() + dataBuf.position();

          // Actual number of data bytes to write.
          int numBytesToDisk = (int)(offsetInBlock-onDiskLen);
          
          // Write data to disk.
          long begin = Time.monotonicNow();
          streams.writeDataToDisk(dataBuf.array(),
              startByteToDisk, numBytesToDisk);
          // no-op in prod
          DataNodeFaultInjector.get().delayWriteToDisk();
          long duration = Time.monotonicNow() - begin;
          if (duration > datanodeSlowLogThresholdMs) {
            datanode.metrics.incrPacketsSlowWriteToDisk();
            if (LOG.isWarnEnabled()) {
              LOG.warn(""Slow BlockReceiver write data to disk cost: {}ms "" +
                      ""(threshold={}ms), volume={}, blockId={}, seqno={}"",
                  duration, datanodeSlowLogThresholdMs, getVolumeBaseUri(),
                  replicaInfo.getBlockId(), seqno);
            }
          }

          if (duration > maxWriteToDiskMs) {
            maxWriteToDiskMs = duration;
          }

          final byte[] lastCrc;
          if (shouldNotWriteChecksum) {
            lastCrc = null;
          } else {
            int skip = 0;
            byte[] crcBytes = null;

            // First, prepare to overwrite the partial crc at the end.
            if (overwriteLastCrc) { // not chunk-aligned on disk
              // prepare to overwrite last checksum
              adjustCrcFilePosition();
            }

            // The CRC was recalculated for the last partial chunk. Update the
            // CRC by reading the rest of the chunk, then write it out.
            if (doCrcRecalc) {
              // Calculate new crc for this chunk.
              int bytesToReadForRecalc =
                  (int)(bytesPerChecksum - partialChunkSizeOnDisk);
              if (numBytesToDisk < bytesToReadForRecalc) {
                bytesToReadForRecalc = numBytesToDisk;
              }

              partialCrc.update(dataBuf.array(), startByteToDisk,
                  bytesToReadForRecalc);
              byte[] buf = FSOutputSummer.convertToByteStream(partialCrc,
                  checksumSize);
              crcBytes = copyLastChunkChecksum(buf, checksumSize, buf.length);
              checksumOut.write(buf);
              if(LOG.isDebugEnabled()) {
                
---------------Reference log start----------------
LOG.debug(""Writing out partial crc for data len "" + len + "", skip="" + skip)
---------------Reference log end----------------
              }
              skip++; //  For the partial chunk that was just read.
            }

            // Determine how many checksums need to be skipped up to the last
            // boundary. The checksum after the boundary was already counted
            // above. Only count the number of checksums skipped up to the
            // boundary here.
            long skippedDataBytes = lastChunkBoundary - firstByteInBlock;

            if (skippedDataBytes > 0) {
              skip += (int)(skippedDataBytes / bytesPerChecksum) +
                  ((skippedDataBytes % bytesPerChecksum == 0) ? 0 : 1);
            }
            skip *= checksumSize; // Convert to number of bytes

            // write the rest of checksum
            final int offset = checksumBuf.arrayOffset() +
                checksumBuf.position() + skip;
            final int end = offset + checksumLen - skip;
            // If offset >= end, there is no more checksum to write.
            // I.e. a partial chunk checksum rewrite happened and there is no
            // more to write after that.
            if (offset >= end && doCrcRecalc) {
              lastCrc = crcBytes;
            } else {
              final int remainingBytes = checksumLen - skip;
              lastCrc = copyLastChunkChecksum(checksumBuf.array(),
                  checksumSize, end);
              checksumOut.write(checksumBuf.array(), offset, remainingBytes);
            }
          }

          /// flush entire packet, sync if requested
          flushOrSync(syncBlock, seqno);
          
          replicaInfo.setLastChecksumAndDataLen(offsetInBlock, lastCrc);

          datanode.metrics.incrBytesWritten(len);
          datanode.metrics.incrTotalWriteTime(duration);

          manageWriterOsCache(offsetInBlock, seqno);
        }
      } catch (IOException iex) {
        // Volume error check moved to FileIoProvider
        throw iex;
      }
    }

    // if sync was requested, put in queue for pending acks here
    // (after the fsync finished)
    if (responder != null && (syncBlock || shouldVerifyChecksum())) {
      ((PacketResponder) responder.getRunnable()).enqueue(seqno,
          lastPacketInBlock, offsetInBlock, Status.SUCCESS);
    }

    /*
     * Send in-progress responses for the replaceBlock() calls back to caller to
     * avoid timeouts due to balancer throttling. HDFS-6247
     */
    if (isReplaceBlock
        && (Time.monotonicNow() - lastResponseTime > responseInterval)) {
      BlockOpResponseProto.Builder response = BlockOpResponseProto.newBuilder()
          .setStatus(Status.IN_PROGRESS);
      response.build().writeDelimitedTo(replyOut);
      replyOut.flush();

      lastResponseTime = Time.monotonicNow();
    }

    if (throttler != null) { // throttle I/O
      throttler.throttle(len);
    }
    
    return lastPacketInBlock?-1:len;
  }",,
hadoop,6708,"LOG.trace(""Added block {} to CACHED list."", cachedBlock)",trace,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java/#L1037,"private void processCacheReportImpl(final DatanodeDescriptor datanode,
      final List<Long> blockIds) {
    CachedBlocksList cached = datanode.getCached();
    cached.clear();
    CachedBlocksList cachedList = datanode.getCached();
    CachedBlocksList pendingCachedList = datanode.getPendingCached();
    for (Iterator<Long> iter = blockIds.iterator(); iter.hasNext(); ) {
      long blockId = iter.next();
      LOG.trace(""Cache report from datanode {} has block {}"", datanode,
          blockId);
      CachedBlock cachedBlock =
          new CachedBlock(blockId, (short)0, false);
      CachedBlock prevCachedBlock = cachedBlocks.get(cachedBlock);
      // Add the block ID from the cache report to the cachedBlocks map
      // if it's not already there.
      if (prevCachedBlock != null) {
        cachedBlock = prevCachedBlock;
      } else {
        cachedBlocks.put(cachedBlock);
        LOG.trace(""Added block {}  to cachedBlocks"", cachedBlock);
      }
      // Add the block to the datanode's implicit cached block list
      // if it's not already there.  Similarly, remove it from the pending
      // cached block list if it exists there.
      if (!cachedBlock.isPresent(cachedList)) {
        cachedList.add(cachedBlock);
        
---------------Reference log start----------------
LOG.trace(""Added block {} to CACHED list."", cachedBlock)
---------------Reference log end----------------
      }
      if (cachedBlock.isPresent(pendingCachedList)) {
        pendingCachedList.remove(cachedBlock);
        LOG.trace(""Removed block {} from PENDING_CACHED list."", cachedBlock);
      }
    }
  }",,
hadoop,7704,"LOG.info(""Starting plan for Node : {}:{}"", node.getDataNodeName(), node.getDataNodePort())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/planner/GreedyPlanner.java/#L70,"@Override
  public NodePlan plan(DiskBalancerDataNode node) throws Exception {
    final long startTime = Time.monotonicNow();
    NodePlan plan = new NodePlan(node.getDataNodeName(),
        node.getDataNodePort());
    
---------------Reference log start----------------
LOG.info(""Starting plan for Node : {}:{}"", node.getDataNodeName(), node.getDataNodePort())
---------------Reference log end----------------
    while (node.isBalancingNeeded(this.threshold)) {
      for (DiskBalancerVolumeSet vSet : node.getVolumeSets().values()) {
        balanceVolumeSet(node, vSet, plan);
      }
    }

    final long endTime = Time.monotonicNow();
    LOG.info(""Compute Plan for Node : {}:{} took {} ms"",
        node.getDataNodeName(), node.getDataNodePort(), endTime - startTime);

    return plan;
  }",,
hadoop,8827,"LOG.error(""RedundancyMonitor thread received Runtime exception. "", t)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java/#L4941,"@Override
    public void run() {
      while (namesystem.isRunning()) {
        try {
          // Process recovery work only when active NN is out of safe mode.
          if (isPopulatingReplQueues()) {
            computeDatanodeWork();
            processPendingReconstructions();
            rescanPostponedMisreplicatedBlocks();
            lastRedundancyCycleTS.set(Time.monotonicNow());
          }
          TimeUnit.MILLISECONDS.sleep(redundancyRecheckIntervalMs);
        } catch (Throwable t) {
          if (!namesystem.isRunning()) {
            LOG.info(""Stopping RedundancyMonitor."");
            if (!(t instanceof InterruptedException)) {
              LOG.info(""RedundancyMonitor received an exception""
                  + "" while shutting down."", t);
            }
            break;
          } else if (!checkNSRunning && t instanceof InterruptedException) {
            LOG.info(""Stopping RedundancyMonitor for testing."");
            break;
          }
          
---------------Reference log start----------------
LOG.error(""RedundancyMonitor thread received Runtime exception. "", t)
---------------Reference log end----------------
          terminate(1, t);
        }
      }
    }",,
hadoop,7627,"LOG.warn(""Failed to move block:{} from src:{} to destin:{} to satisfy "" + ""storageType:{}"", blkMovingInfo.getBlock(), blkMovingInfo.getSource(), blkMovingInfo.getTarget(), blkMovingInfo.getTargetStorageType(), e)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/sps/BlockDispatcher.java/#L154,"public BlockMovementStatus moveBlock(BlockMovingInfo blkMovingInfo,
      SaslDataTransferClient saslClient, ExtendedBlock eb, Socket sock,
      DataEncryptionKeyFactory km, Token<BlockTokenIdentifier> accessToken) {
    LOG.info(""Start moving block:{} from src:{} to destin:{} to satisfy ""
        + ""storageType, sourceStoragetype:{} and destinStoragetype:{}"",
        blkMovingInfo.getBlock(), blkMovingInfo.getSource(),
        blkMovingInfo.getTarget(), blkMovingInfo.getSourceStorageType(),
        blkMovingInfo.getTargetStorageType());
    DataOutputStream out = null;
    DataInputStream in = null;
    try {
      NetUtils.connect(sock,
          NetUtils.createSocketAddr(
              blkMovingInfo.getTarget().getXferAddr(connectToDnViaHostname)),
          socketTimeout);
      // Set read timeout so that it doesn't hang forever against
      // unresponsive nodes. Datanode normally sends IN_PROGRESS response
      // twice within the client read timeout period (every 30 seconds by
      // default). Here, we make it give up after ""socketTimeout * 5"" period
      // of no response.
      sock.setSoTimeout(socketTimeout * 5);
      sock.setKeepAlive(true);
      OutputStream unbufOut = sock.getOutputStream();
      InputStream unbufIn = sock.getInputStream();
      LOG.debug(""Connecting to datanode {}"", blkMovingInfo.getTarget());

      IOStreamPair saslStreams = saslClient.socketSend(sock, unbufOut,
          unbufIn, km, accessToken, blkMovingInfo.getTarget());
      unbufOut = saslStreams.out;
      unbufIn = saslStreams.in;
      out = new DataOutputStream(
          new BufferedOutputStream(unbufOut, ioFileBufferSize));
      in = new DataInputStream(
          new BufferedInputStream(unbufIn, ioFileBufferSize));
      sendRequest(out, eb, accessToken, blkMovingInfo.getSource(),
          blkMovingInfo.getTargetStorageType());
      receiveResponse(in);

      LOG.info(
          ""Successfully moved block:{} from src:{} to destin:{} for""
              + "" satisfying storageType:{}"",
          blkMovingInfo.getBlock(), blkMovingInfo.getSource(),
          blkMovingInfo.getTarget(), blkMovingInfo.getTargetStorageType());
      return BlockMovementStatus.DN_BLK_STORAGE_MOVEMENT_SUCCESS;
    } catch (BlockPinningException e) {
      // Pinned block won't be able to move to a different node. So, its not
      // required to do retries, just marked as SUCCESS.
      LOG.debug(""Pinned block can't be moved, so skipping block:{}"",
          blkMovingInfo.getBlock(), e);
      return BlockMovementStatus.DN_BLK_STORAGE_MOVEMENT_SUCCESS;
    } catch (IOException e) {
      // TODO: handle failure retries
      
---------------Reference log start----------------
LOG.warn(""Failed to move block:{} from src:{} to destin:{} to satisfy "" + ""storageType:{}"", blkMovingInfo.getBlock(), blkMovingInfo.getSource(), blkMovingInfo.getTarget(), blkMovingInfo.getTargetStorageType(), e)
---------------Reference log end----------------
      return BlockMovementStatus.DN_BLK_STORAGE_MOVEMENT_FAILURE;
    } finally {
      IOUtils.closeStream(out);
      IOUtils.closeStream(in);
      IOUtils.closeSocket(sock);
    }
  }",,
hadoop,12359,"LOG.debug(Thread.currentThread().getName() + "": "" + call + "" for RpcKind "" + call.rpcKind)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java/#L3035,"@Override
    public void run() {
      LOG.debug(Thread.currentThread().getName() + "": starting"");
      SERVER.set(Server.this);
      while (running) {
        TraceScope traceScope = null;
        Call call = null;
        long startTimeNanos = 0;
        // True iff the connection for this call has been dropped.
        // Set to true by default and update to false later if the connection
        // can be succesfully read.
        boolean connDropped = true;

        try {
          call = callQueue.take(); // pop the queue; maybe blocked here
          startTimeNanos = Time.monotonicNowNanos();
          if (alignmentContext != null && call.isCallCoordinated() &&
              call.getClientStateId() > alignmentContext.getLastSeenStateId()) {
            /*
             * The call processing should be postponed until the client call's
             * state id is aligned (<=) with the server state id.

             * NOTE:
             * Inserting the call back to the queue can change the order of call
             * execution comparing to their original placement into the queue.
             * This is not a problem, because Hadoop RPC does not have any
             * constraints on ordering the incoming rpc requests.
             * In case of Observer, it handles only reads, which are
             * commutative.
             */
            // Re-queue the call and continue
            requeueCall(call);
            call = null;
            continue;
          }
          if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(Thread.currentThread().getName() + "": "" + call + "" for RpcKind "" + call.rpcKind)
---------------Reference log end----------------
          }
          CurCall.set(call);
          if (call.span != null) {
            traceScope = tracer.activateSpan(call.span);
            call.span.addTimelineAnnotation(""called"");
          }
          // always update the current call context
          CallerContext.setCurrent(call.callerContext);
          UserGroupInformation remoteUser = call.getRemoteUser();
          connDropped = !call.isOpen();
          if (remoteUser != null) {
            remoteUser.doAs(call);
          } else {
            call.run();
          }
        } catch (InterruptedException e) {
          if (running) {                          // unexpected -- log it
            LOG.info(Thread.currentThread().getName() + "" unexpectedly interrupted"", e);
            if (traceScope != null) {
              traceScope.addTimelineAnnotation(""unexpectedly interrupted: "" +
                  StringUtils.stringifyException(e));
            }
          }
        } catch (Exception e) {
          LOG.info(Thread.currentThread().getName() + "" caught an exception"", e);
          if (traceScope != null) {
            traceScope.addTimelineAnnotation(""Exception: "" +
                StringUtils.stringifyException(e));
          }
        } finally {
          CurCall.set(null);
          IOUtils.cleanupWithLogger(LOG, traceScope);
          if (call != null) {
            updateMetrics(call, startTimeNanos, connDropped);
            ProcessingDetails.LOG.debug(
                ""Served: [{}]{} name={} user={} details={}"",
                call, (call.isResponseDeferred() ? "", deferred"" : """"),
                call.getDetailedMetricsName(), call.getRemoteUser(),
                call.getProcessingDetails());
          }
        }
      }
      LOG.debug(Thread.currentThread().getName() + "": exiting"");
    }",,
hadoop,216,LOG.info(message),info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServer.java/#L661,"private Response flexService(Service service, UserGroupInformation ugi)
      throws IOException, InterruptedException {
    String appName = service.getName();
    Response response = Response.status(Status.BAD_REQUEST).build();
    Map<String, String> componentCountStrings = new HashMap<String, String>();
    for (Component c : service.getComponents()) {
      componentCountStrings.put(c.getName(),
          c.getNumberOfContainers().toString());
    }
    Integer result = ugi.doAs(new PrivilegedExceptionAction<Integer>() {

      @Override
      public Integer run() throws YarnException, IOException {
        int result = 0;
        ServiceClient sc = new ServiceClient();
        try {
          sc.init(YARN_CONFIG);
          sc.start();
          result = sc
              .actionFlex(appName, componentCountStrings);
          return Integer.valueOf(result);
        } finally {
          sc.close();
        }
      }
    });
    if (result == EXIT_SUCCESS) {
      String message = ""Service "" + appName + "" is successfully flexed."";
      
---------------Reference log start----------------
LOG.info(message)
---------------Reference log end----------------
      ServiceStatus status = new ServiceStatus();
      status.setDiagnostics(message);
      status.setState(ServiceState.ACCEPTED);
      response = formatResponse(Status.ACCEPTED, status);
    }
    return response;
  }",,
hadoop,3533,"LOG.info(""Submit reservation request failed"", ue)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/RMWebServices.java/#L2182,"@POST
  @Path(RMWSConsts.RESERVATION_SUBMIT)
  @Produces({ MediaType.APPLICATION_JSON + ""; "" + JettyUtils.UTF_8,
      MediaType.APPLICATION_XML + ""; "" + JettyUtils.UTF_8 })
  @Consumes({ MediaType.APPLICATION_JSON, MediaType.APPLICATION_XML })
  @Override
  public Response submitReservation(ReservationSubmissionRequestInfo resContext,
      @Context HttpServletRequest hsr)
      throws AuthorizationException, IOException, InterruptedException {

    UserGroupInformation callerUGI = getCallerUserGroupInformation(hsr, true);
    initForWritableEndpoints(callerUGI, false);

    final ReservationSubmissionRequest reservation =
        createReservationSubmissionRequest(resContext);

    try {
      callerUGI
          .doAs(new PrivilegedExceptionAction<ReservationSubmissionResponse>() {
            @Override
            public ReservationSubmissionResponse run()
                throws IOException, YarnException {
              return rm.getClientRMService().submitReservation(reservation);
            }
          });
    } catch (UndeclaredThrowableException ue) {
      if (ue.getCause() instanceof YarnException) {
        throw new BadRequestException(ue.getCause().getMessage());
      }
      
---------------Reference log start----------------
LOG.info(""Submit reservation request failed"", ue)
---------------Reference log end----------------
      throw ue;
    }

    return Response.status(Status.ACCEPTED).build();
  }",,
hadoop,2577,"LOG.debug(""Removing delegation token for appId="" + applicationId + ""; token="" + dttr.token.getService())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/DelegationTokenRenewer.java/#L866,"private void removeApplicationFromRenewal(ApplicationId applicationId) {
    rmContext.getSystemCredentialsForApps().remove(applicationId);
    Set<DelegationTokenToRenew> tokens = appTokens.remove(applicationId);

    if (tokens != null && !tokens.isEmpty()) {
      synchronized (tokens) {
        Iterator<DelegationTokenToRenew> it = tokens.iterator();
        while (it.hasNext()) {
          DelegationTokenToRenew dttr = it.next();
          if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""Removing delegation token for appId="" + applicationId + ""; token="" + dttr.token.getService())
---------------Reference log end----------------
          }

          // continue if the app list isn't empty
          synchronized(dttr.referringAppIds) {
            dttr.referringAppIds.remove(applicationId);
            if (!dttr.referringAppIds.isEmpty()) {
              continue;
            }
          }
          // cancel the timer
          dttr.cancelTimer();

          // cancel the token
          cancelToken(dttr);

          allTokens.remove(dttr.token);
        }
      }
    }
  }",,
hadoop,167,LOG.warn(e.getCause().getMessage()),warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/SystemServiceManagerImpl.java/#L176,"void launchUserService(Map<String, Set<Service>> userServices) {
    for (Map.Entry<String, Set<Service>> entry : userServices.entrySet()) {
      String user = entry.getKey();
      Set<Service> services = entry.getValue();
      if (services.isEmpty()) {
        continue;
      }
      ServiceClient serviceClient = null;
      try {
        UserGroupInformation userUgi = getProxyUser(user);
        serviceClient = createServiceClient(userUgi);
        for (Service service : services) {
          LOG.info(""POST: createService = {} user = {}"", service, userUgi);
          try {
            launchServices(userUgi, serviceClient, service);
          } catch (IOException | UndeclaredThrowableException e) {
            if (e.getCause() != null) {
              
---------------Reference log start----------------
LOG.warn(e.getCause().getMessage())
---------------Reference log end----------------
            } else {
              String message =
                  ""Failed to create service "" + service.getName() + "" : "";
              LOG.error(message, e);
            }
          }
        }
      } catch (InterruptedException e) {
        LOG.warn(""System service launcher thread interrupted"", e);
        break;
      } catch (Exception e) {
        LOG.error(""Error while submitting services for user "" + user, e);
      } finally {
        if (serviceClient != null) {
          try {
            serviceClient.close();
          } catch (IOException e) {
            LOG.warn(""Error while closing serviceClient for user {}"", user);
          }
        }
      }
    }
  }",,
hadoop,1199,"LOG.info(""UAM id {} is unregistered"", uamId)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/uam/UnmanagedAMPoolManager.java/#L369,"public FinishApplicationMasterResponse finishApplicationMaster(String uamId,
      FinishApplicationMasterRequest request)
      throws YarnException, IOException {
    if (!this.unmanagedAppMasterMap.containsKey(uamId)) {
      throw new YarnException(""UAM "" + uamId + "" does not exist"");
    }
    LOG.info(""Finishing UAM id {} for application {}"", uamId,
        this.appIdMap.get(uamId));
    FinishApplicationMasterResponse response =
        this.unmanagedAppMasterMap.get(uamId).finishApplicationMaster(request);

    if (response.getIsUnregistered()) {
      // Only remove the UAM when the unregister finished
      this.unmanagedAppMasterMap.remove(uamId);
      this.appIdMap.remove(uamId);
      
---------------Reference log start----------------
LOG.info(""UAM id {} is unregistered"", uamId)
---------------Reference log end----------------
    }
    return response;
  }",,
hadoop,6198,"LOG.warn(""Error Recovery for "" + block + "" in pipeline "" + Arrays.toString(nodes) + "": datanode "" + badNodeIndex + ""("" + nodes[badNodeIndex] + "") is "" + reason)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java/#L1622,"boolean handleBadDatanode() {
    final int badNodeIndex = errorState.getBadNodeIndex();
    if (badNodeIndex >= 0) {
      if (nodes.length <= 1) {
        lastException.set(new IOException(""All datanodes ""
            + Arrays.toString(nodes) + "" are bad. Aborting...""));
        streamerClosed = true;
        return false;
      }

      String reason = ""bad."";
      if (errorState.getRestartingNodeIndex() == badNodeIndex) {
        reason = ""restarting."";
        restartingNodes.add(nodes[badNodeIndex]);
      }
      
---------------Reference log start----------------
LOG.warn(""Error Recovery for "" + block + "" in pipeline "" + Arrays.toString(nodes) + "": datanode "" + badNodeIndex + ""("" + nodes[badNodeIndex] + "") is "" + reason)
---------------Reference log end----------------
      failed.add(nodes[badNodeIndex]);

      DatanodeInfo[] newnodes = new DatanodeInfo[nodes.length-1];
      arraycopy(nodes, newnodes, badNodeIndex);

      final StorageType[] newStorageTypes = new StorageType[newnodes.length];
      arraycopy(storageTypes, newStorageTypes, badNodeIndex);

      final String[] newStorageIDs = new String[newnodes.length];
      arraycopy(storageIDs, newStorageIDs, badNodeIndex);

      setPipeline(newnodes, newStorageTypes, newStorageIDs);

      errorState.adjustState4RestartingNode();
      lastException.clear();
    }
    return true;
  }",,
hadoop,4367,LOG.error(e.toString()),error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/ProcfsBasedProcessTree.java/#L805,"private static void constructProcessSMAPInfo(ProcessTreeSmapMemInfo pInfo,
      String procfsDir) {
    BufferedReader in = null;
    InputStreamReader fReader = null;
    try {
      File pidDir = new File(procfsDir, pInfo.getPid());
      File file = new File(pidDir, SMAPS);
      if (!file.exists()) {
        return;
      }
      fReader = new InputStreamReader(
          new FileInputStream(file), Charset.forName(""UTF-8""));
      in = new BufferedReader(fReader);
      ProcessSmapMemoryInfo memoryMappingInfo = null;
      List<String> lines = IOUtils.readLines(in);
      for (String line : lines) {
        line = line.trim();
        try {
          Matcher address = ADDRESS_PATTERN.matcher(line);
          if (address.find()) {
            memoryMappingInfo = new ProcessSmapMemoryInfo(line);
            memoryMappingInfo.setPermission(address.group(4));
            pInfo.getMemoryInfoList().add(memoryMappingInfo);
            continue;
          }
          Matcher memInfo = MEM_INFO_PATTERN.matcher(line);
          if (memInfo.find()) {
            String key = memInfo.group(1).trim();
            String value = memInfo.group(2).replace(KB, """").trim();
            LOG.debug(""MemInfo : {} : Value  : {}"", key, value);

            if (memoryMappingInfo != null) {
              memoryMappingInfo.setMemInfo(key, value);
            }
          }
        } catch (Throwable t) {
          LOG
            .warn(""Error parsing smaps line : "" + line + ""; "" + t.getMessage());
        }
      }
    } catch (FileNotFoundException f) {
      LOG.error(f.toString());
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.error(e.toString())
---------------Reference log end----------------
    } catch (Throwable t) {
      LOG.error(t.toString());
    } finally {
      org.apache.hadoop.io.IOUtils.closeStream(in);
    }
  }",,
hadoop,10104,"LOG.error(""A task status you don't know about is \"""" + status + ""\""."", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java/#L1021,"private void processTaskLine(ParsedLine line) {
    if (jobBeingTraced != null) {
      // these fields are in both the start and finish record
      String taskID = line.get(""TASKID"");
      String taskType = line.get(""TASK_TYPE"");

      // this field is only in the start record
      String startTime = line.get(""START_TIME"");

      // these fields only exist or are only relevant in the finish record
      String status = line.get(""TASK_STATUS"");
      String finishTime = line.get(""FINISH_TIME"");

      String splits = line.get(""SPLITS"");

      LoggedTask task = tasksInCurrentJob.get(taskID);

      boolean taskAlreadyLogged = task != null;

      if (task == null) {
        task = new LoggedTask();
      }

      if (splits != null) {
        ArrayList<LoggedLocation> locations = null;

        StringTokenizer tok = new StringTokenizer(splits, "","", false);

        if (tok.countTokens() <= MAXIMUM_PREFERRED_LOCATIONS) {
          locations = new ArrayList<LoggedLocation>();
        }

        while (tok.hasMoreTokens()) {
          String nextSplit = tok.nextToken();

          ParsedHost node = getAndRecordParsedHost(nextSplit);

          if (locations != null && node != null) {
            locations.add(node.makeLoggedLocation());
          }
        }

        task.setPreferredLocations(locations);
      }

      task.setTaskID(taskID);

      if (startTime != null) {
        task.setStartTime(Long.parseLong(startTime));
      }

      if (finishTime != null) {
        task.setFinishTime(Long.parseLong(finishTime));
      }

      Pre21JobHistoryConstants.Values typ;
      Pre21JobHistoryConstants.Values stat;

      try {
        stat =
            status == null ? null : Pre21JobHistoryConstants.Values
                .valueOf(status);
      } catch (IllegalArgumentException e) {
        
---------------Reference log start----------------
LOG.error(""A task status you don't know about is \"""" + status + ""\""."", e)
---------------Reference log end----------------
        stat = null;
      }

      task.setTaskStatus(stat);

      try {
        typ =
            taskType == null ? null : Pre21JobHistoryConstants.Values
                .valueOf(taskType);
      } catch (IllegalArgumentException e) {
        LOG.error(""A task type you don't know about is \"""" + taskType + ""\""."",
            e);
        typ = null;
      }

      if (typ == null) {
        return;
      }

      task.setTaskType(typ);

      List<LoggedTask> vec =
          typ == Pre21JobHistoryConstants.Values.MAP ? jobBeingTraced
              .getMapTasks() : typ == Pre21JobHistoryConstants.Values.REDUCE
              ? jobBeingTraced.getReduceTasks() : jobBeingTraced
                  .getOtherTasks();

      if (!taskAlreadyLogged) {
        vec.add(task);

        tasksInCurrentJob.put(taskID, task);
      }
    }
  }",,
hadoop,3952,"LOG.warn(""Gave up waiting for the app check task to shutdown."")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/src/main/java/org/apache/hadoop/yarn/server/sharedcachemanager/store/InMemorySCMStore.java/#L154,"@Override
  protected void serviceStop() throws Exception {
    LOG.info(""Stopping the "" + InMemorySCMStore.class.getSimpleName()
        + "" service."");
    if (scheduler != null) {
      LOG.info(""Shutting down the background thread."");
      scheduler.shutdownNow();
      try {
        if (!scheduler.awaitTermination(10, TimeUnit.SECONDS)) {
          
---------------Reference log start----------------
LOG.warn(""Gave up waiting for the app check task to shutdown."")
---------------Reference log end----------------
        }
      } catch (InterruptedException e) {
        LOG.warn(
            ""The InMemorySCMStore was interrupted while shutting down the ""
                + ""app check task."", e);
      }
      LOG.info(""The background thread stopped."");
    }
    super.serviceStop();
  }",,
hadoop,3916,"LOG.error(""Unable to add reservation: {} to plan."", inMemReservation.getReservationId())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/InMemoryPlan.java/#L365,"@Override
  public boolean addReservation(ReservationAllocation reservation,
      boolean isRecovering) throws PlanningException {
    // Verify the allocation is memory based otherwise it is not supported
    InMemoryReservationAllocation inMemReservation =
        (InMemoryReservationAllocation) reservation;
    if (inMemReservation.getUser() == null) {
      String errMsg = ""The specified Reservation with ID ""
          + inMemReservation.getReservationId() + "" is not mapped to any user"";
      LOG.error(errMsg);
      throw new IllegalArgumentException(errMsg);
    }
    writeLock.lock();
    try {
      if (reservationTable.containsKey(inMemReservation.getReservationId())) {
        String errMsg = ""The specified Reservation with ID ""
            + inMemReservation.getReservationId() + "" already exists"";
        LOG.error(errMsg);
        throw new IllegalArgumentException(errMsg);
      }
      // Validate if we can accept this reservation, throws exception if
      // validation fails
      if (!isRecovering) {
        policy.validate(this, inMemReservation);
        // we record here the time in which the allocation has been accepted
        reservation.setAcceptanceTimestamp(clock.getTime());
        if (rmStateStore != null) {
          rmStateStore.storeNewReservation(
              ReservationSystemUtil.buildStateProto(inMemReservation),
              getQueueName(), inMemReservation.getReservationId().toString());
        }
      }
      ReservationInterval searchInterval = new ReservationInterval(
          inMemReservation.getStartTime(), inMemReservation.getEndTime());
      Set<InMemoryReservationAllocation> reservations =
          currentReservations.get(searchInterval);
      if (reservations == null) {
        reservations = new HashSet<InMemoryReservationAllocation>();
      }
      if (!reservations.add(inMemReservation)) {
        
---------------Reference log start----------------
LOG.error(""Unable to add reservation: {} to plan."", inMemReservation.getReservationId())
---------------Reference log end----------------
        return false;
      }
      currentReservations.put(searchInterval, reservations);
      reservationTable.put(inMemReservation.getReservationId(),
          inMemReservation);
      incrementAllocation(inMemReservation);
      LOG.info(""Successfully added reservation: {} to plan."",
          inMemReservation.getReservationId());
      return true;
    } finally {
      writeLock.unlock();
    }
  }",,
hadoop,2815,LOG.info(message),info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceTrackerService.java/#L431,"@SuppressWarnings(""unchecked"")
  @Override
  public RegisterNodeManagerResponse registerNodeManager(
      RegisterNodeManagerRequest request) throws YarnException,
      IOException {
    NodeId nodeId = request.getNodeId();
    String host = nodeId.getHost();
    int cmPort = nodeId.getPort();
    int httpPort = request.getHttpPort();
    Resource capability = request.getResource();
    String nodeManagerVersion = request.getNMVersion();
    Resource physicalResource = request.getPhysicalResource();
    NodeStatus nodeStatus = request.getNodeStatus();

    RegisterNodeManagerResponse response = recordFactory
        .newRecordInstance(RegisterNodeManagerResponse.class);

    if (!minimumNodeManagerVersion.equals(""NONE"")) {
      if (minimumNodeManagerVersion.equals(""EqualToRM"")) {
        minimumNodeManagerVersion = YarnVersionInfo.getVersion();
      }

      if ((nodeManagerVersion == null) ||
          (VersionUtil.compareVersions(nodeManagerVersion,minimumNodeManagerVersion)) < 0) {
        String message =
            ""Disallowed NodeManager Version "" + nodeManagerVersion
                + "", is less than the minimum version ""
                + minimumNodeManagerVersion + "" sending SHUTDOWN signal to ""
                + ""NodeManager."";
        
---------------Reference log start----------------
LOG.info(message)
---------------Reference log end----------------
        response.setDiagnosticsMessage(message);
        response.setNodeAction(NodeAction.SHUTDOWN);
        return response;
      }
    }

    if (checkIpHostnameInRegistration) {
      InetSocketAddress nmAddress =
          NetUtils.createSocketAddrForHost(host, cmPort);
      InetAddress inetAddress = Server.getRemoteIp();
      if (inetAddress != null && nmAddress.isUnresolved()) {
        // Reject registration of unresolved nm to prevent resourcemanager
        // getting stuck at allocations.
        final String message =
            ""hostname cannot be resolved (ip="" + inetAddress.getHostAddress()
                + "", hostname="" + host + "")"";
        LOG.warn(""Unresolved nodemanager registration: "" + message);
        response.setDiagnosticsMessage(message);
        response.setNodeAction(NodeAction.SHUTDOWN);
        return response;
      }
    }

    // Check if this node is a 'valid' node
    if (!this.nodesListManager.isValidNode(host) &&
        !isNodeInDecommissioning(nodeId)) {
      String message =
          ""Disallowed NodeManager from  "" + host
              + "", Sending SHUTDOWN signal to the NodeManager."";
      LOG.info(message);
      response.setDiagnosticsMessage(message);
      response.setNodeAction(NodeAction.SHUTDOWN);
      return response;
    }

    // check if node's capacity is load from dynamic-resources.xml
    String nid = nodeId.toString();

    Resource dynamicLoadCapability = loadNodeResourceFromDRConfiguration(nid);
    if (dynamicLoadCapability != null) {
      LOG.debug(""Resource for node: {} is adjusted from: {} to: {} due to""
          + "" settings in dynamic-resources.xml."", nid, capability,
          dynamicLoadCapability);
      capability = dynamicLoadCapability;
      // sync back with new resource.
      response.setResource(capability);
    }

    // Check if this node has minimum allocations
    if (capability.getMemorySize() < minAllocMb
        || capability.getVirtualCores() < minAllocVcores) {
      String message = ""NodeManager from  "" + host
          + "" doesn't satisfy minimum allocations, Sending SHUTDOWN""
          + "" signal to the NodeManager. Node capabilities are "" + capability
          + ""; minimums are "" + minAllocMb + ""mb and "" + minAllocVcores
          + "" vcores"";
      LOG.info(message);
      response.setDiagnosticsMessage(message);
      response.setNodeAction(NodeAction.SHUTDOWN);
      return response;
    }

    response.setContainerTokenMasterKey(containerTokenSecretManager
        .getCurrentKey());
    response.setNMTokenMasterKey(nmTokenSecretManager
        .getCurrentKey());

    RMNode rmNode = new RMNodeImpl(nodeId, rmContext, host, cmPort, httpPort,
        resolve(host), capability, nodeManagerVersion, physicalResource);

    RMNode oldNode = this.rmContext.getRMNodes().putIfAbsent(nodeId, rmNode);
    if (oldNode == null) {
      RMNodeStartedEvent startEvent = new RMNodeStartedEvent(nodeId,
          request.getNMContainerStatuses(),
          request.getRunningApplications(), nodeStatus);
      if (request.getLogAggregationReportsForApps() != null
          && !request.getLogAggregationReportsForApps().isEmpty()) {
        if (LOG.isDebugEnabled()) {
          LOG.debug(""Found the number of previous cached log aggregation ""
              + ""status from nodemanager:"" + nodeId + "" is :""
              + request.getLogAggregationReportsForApps().size());
        }
        startEvent.setLogAggregationReportsForApps(request
            .getLogAggregationReportsForApps());
      }
      this.rmContext.getDispatcher().getEventHandler().handle(
          startEvent);
    } else {
      LOG.info(""Reconnect from the node at: "" + host);
      this.nmLivelinessMonitor.unregister(nodeId);

      if (CollectionUtils.isEmpty(request.getRunningApplications())
          && rmNode.getState() != NodeState.DECOMMISSIONING
          && rmNode.getHttpPort() != oldNode.getHttpPort()) {
        // Reconnected node differs, so replace old node and start new node
        switch (rmNode.getState()) {
        case RUNNING:
          ClusterMetrics.getMetrics().decrNumActiveNodes();
          break;
        case UNHEALTHY:
          ClusterMetrics.getMetrics().decrNumUnhealthyNMs();
          break;
        default:
          LOG.debug(""Unexpected Rmnode state"");
        }
        this.rmContext.getDispatcher().getEventHandler()
            .handle(new NodeRemovedSchedulerEvent(rmNode));

        this.rmContext.getRMNodes().put(nodeId, rmNode);
        this.rmContext.getDispatcher().getEventHandler()
            .handle(new RMNodeStartedEvent(nodeId, null, null, nodeStatus));
      } else {
        // Reset heartbeat ID since node just restarted.
        oldNode.resetLastNodeHeartBeatResponse();

        this.rmContext.getDispatcher().getEventHandler()
            .handle(new RMNodeReconnectEvent(nodeId, rmNode,
                request.getRunningApplications(),
                request.getNMContainerStatuses()));
      }
    }
    // On every node manager register we will be clearing NMToken keys if
    // present for any running application.
    this.nmTokenSecretManager.removeNodeKey(nodeId);
    this.nmLivelinessMonitor.register(nodeId);
    
    // Handle received container status, this should be processed after new
    // RMNode inserted
    if (!rmContext.isWorkPreservingRecoveryEnabled()) {
      if (!request.getNMContainerStatuses().isEmpty()) {
        LOG.info(""received container statuses on node manager register :""
            + request.getNMContainerStatuses());
        for (NMContainerStatus status : request.getNMContainerStatuses()) {
          handleNMContainerStatus(status, nodeId);
        }
      }
    }

    // Update node's labels to RM's NodeLabelManager.
    Set<String> nodeLabels = NodeLabelsUtils.convertToStringSet(
        request.getNodeLabels());
    if (isDistributedNodeLabelsConf && nodeLabels != null) {
      try {
        updateNodeLabelsFromNMReport(nodeLabels, nodeId);
        response.setAreNodeLabelsAcceptedByRM(true);
      } catch (IOException ex) {
        // Ensure the exception is captured in the response
        response.setDiagnosticsMessage(ex.getMessage());
        response.setAreNodeLabelsAcceptedByRM(false);
      }
    } else if (isDelegatedCentralizedNodeLabelsConf) {
      this.rmContext.getRMDelegatedNodeLabelsUpdater().updateNodeLabels(nodeId);
    }

    // Update node's attributes to RM's NodeAttributesManager.
    if (request.getNodeAttributes() != null) {
      try {
        // update node attributes if necessary then update heartbeat response
        updateNodeAttributesIfNecessary(nodeId, request.getNodeAttributes());
        response.setAreNodeAttributesAcceptedByRM(true);
      } catch (IOException ex) {
        //ensure the error message is captured and sent across in response
        String errorMsg = response.getDiagnosticsMessage() == null ?
            ex.getMessage() :
            response.getDiagnosticsMessage() + ""\n"" + ex.getMessage();
        response.setDiagnosticsMessage(errorMsg);
        response.setAreNodeAttributesAcceptedByRM(false);
      }
    }

    StringBuilder message = new StringBuilder();
    message.append(""NodeManager from node "").append(host).append(""(cmPort: "")
        .append(cmPort).append("" httpPort: "");
    message.append(httpPort).append("") "")
        .append(""registered with capability: "").append(capability);
    message.append("", assigned nodeId "").append(nodeId);
    if (response.getAreNodeLabelsAcceptedByRM()) {
      message.append("", node labels { "").append(
          StringUtils.join("","", nodeLabels) + "" } "");
    }
    if (response.getAreNodeAttributesAcceptedByRM()) {
      message.append("", node attributes { "")
          .append(request.getNodeAttributes() + "" } "");
    }

    LOG.info(message.toString());
    response.setNodeAction(NodeAction.NORMAL);
    response.setRMIdentifier(ResourceManager.getClusterTimeStamp());
    response.setRMVersion(YarnVersionInfo.getVersion());
    return response;
  }",,
hadoop,11463,"LOG.info(JOB_DIR_LABEL + ""="" + jobdir)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/DistCh.java/#L435,"private boolean setup(List<FileOperation> ops, Path log) 
  throws IOException {
    final String randomId = getRandomId();
    JobClient jClient = new JobClient(jobconf);
    Path stagingArea;
    try {
      stagingArea = JobSubmissionFiles.getStagingDir(
                       jClient.getClusterHandle(), jobconf);
    } catch (InterruptedException ie){
      throw new IOException(ie);
    }
    Path jobdir = new Path(stagingArea + NAME + ""_"" + randomId);
    FsPermission mapredSysPerms = 
      new FsPermission(JobSubmissionFiles.JOB_DIR_PERMISSION);
    FileSystem.mkdirs(jClient.getFs(), jobdir, mapredSysPerms);
    
---------------Reference log start----------------
LOG.info(JOB_DIR_LABEL + ""="" + jobdir)
---------------Reference log end----------------

    if (log == null) {
      log = new Path(jobdir, ""_logs"");
    }
    FileOutputFormat.setOutputPath(jobconf, log);
    LOG.info(""log="" + log);

    //create operation list
    FileSystem fs = jobdir.getFileSystem(jobconf);
    Path opList = new Path(jobdir, ""_"" + OP_LIST_LABEL);
    jobconf.set(OP_LIST_LABEL, opList.toString());
    int opCount = 0, synCount = 0;
    try (SequenceFile.Writer opWriter = SequenceFile.createWriter(fs, jobconf, opList, Text.class,
            FileOperation.class, SequenceFile.CompressionType.NONE)) {
      for(FileOperation op : ops) {
        FileStatus srcstat = fs.getFileStatus(op.src); 
        if (srcstat.isDirectory() && op.isDifferent(srcstat)) {
          ++opCount;
          opWriter.append(new Text(op.src.toString()), op);
        }

        Stack<Path> pathstack = new Stack<Path>();
        for(pathstack.push(op.src); !pathstack.empty(); ) {
          for(FileStatus stat : fs.listStatus(pathstack.pop())) {
            if (stat.isDirectory()) {
              pathstack.push(stat.getPath());
            }

            if (op.isDifferent(stat)) {              
              ++opCount;
              if (++synCount > SYNC_FILE_MAX) {
                opWriter.sync();
                synCount = 0;
              }
              Path f = stat.getPath();
              opWriter.append(new Text(f.toString()), new FileOperation(f, op));
            }
          }
        }
      }
    }

    checkDuplication(fs, opList, new Path(jobdir, ""_sorted""), jobconf);
    jobconf.setInt(OP_COUNT_LABEL, opCount);
    LOG.info(OP_COUNT_LABEL + ""="" + opCount);
    jobconf.setNumMapTasks(getMapCount(opCount,
        new JobClient(jobconf).getClusterStatus().getTaskTrackers()));
    return opCount != 0;    
  }",,
hadoop,1375,"LOG.warn(""{} exception trying to delete pid file {}. Ignoring."", containerId, pidFilePath, ioe)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerCleanup.java/#L169,"@Override
  public void run() {
    ContainerId containerId = container.getContainerId();
    String containerIdStr = containerId.toString();
    LOG.info(""Cleaning up container "" + containerIdStr);

    try {
      context.getNMStateStore().storeContainerKilled(containerId);
    } catch (IOException e) {
      LOG.error(""Unable to mark container "" + containerId
          + "" killed in store"", e);
    }

    // launch flag will be set to true if process already launched,
    // in process of launching, or failed to launch.
    boolean alreadyLaunched = !launch.markLaunched() ||
        launch.isLaunchCompleted();
    if (!alreadyLaunched) {
      LOG.info(""Container "" + containerIdStr + "" not launched.""
          + "" No cleanup needed to be done"");
      return;
    }
    LOG.debug(""Marking container {} as inactive"", containerIdStr);
    // this should ensure that if the container process has not launched
    // by this time, it will never be launched
    exec.deactivateContainer(containerId);
    Path pidFilePath = launch.getPidFilePath();
    LOG.debug(""Getting pid for container {} to kill""
        + "" from pid file {}"", containerIdStr, pidFilePath != null ?
        pidFilePath : ""null"");
    // however the container process may have already started
    try {

      // get process id from pid file if available
      // else if shell is still active, get it from the shell
      String processId = launch.getContainerPid();

      // kill process
      String user = container.getUser();
      if (processId != null) {
        signalProcess(processId, user, containerIdStr);
      } else {
        // Normally this means that the process was notified about
        // deactivateContainer above and did not start.
        // Since we already set the state to RUNNING or REINITIALIZING
        // we have to send a killed event to continue.
        if (!launch.isLaunchCompleted()) {
          LOG.warn(""Container clean up before pid file created ""
              + containerIdStr);
          dispatcher.getEventHandler().handle(
              new ContainerExitEvent(container.getContainerId(),
                  ContainerEventType.CONTAINER_KILLED_ON_REQUEST,
                  Shell.WINDOWS ?
                      ContainerExecutor.ExitCode.FORCE_KILLED.getExitCode() :
                      ContainerExecutor.ExitCode.TERMINATED.getExitCode(),
                  ""Container terminated before pid file created.""));
          // There is a possibility that the launch grabbed the file name before
          // the deactivateContainer above but it was slow enough to avoid
          // getContainerPid.
          // Increasing YarnConfiguration.NM_PROCESS_KILL_WAIT_MS
          // reduces the likelihood of this race condition and process leak.
        }
      }

      // rm container in docker
      if (DockerLinuxContainerRuntime.isDockerContainerRequested(conf,
          container.getLaunchContext().getEnvironment())) {
        rmDockerContainerDelayed();
      }
    } catch (Exception e) {
      String message =
          ""Exception when trying to cleanup container "" + containerIdStr
              + "": "" + StringUtils.stringifyException(e);
      LOG.warn(message);
      dispatcher.getEventHandler().handle(
          new ContainerDiagnosticsUpdateEvent(containerId, message));
    } finally {
      // cleanup pid file if present
      if (pidFilePath != null) {
        try {
          FileContext lfs = FileContext.getLocalFSFileContext();
          lfs.delete(pidFilePath, false);
          lfs.delete(pidFilePath.suffix(EXIT_CODE_FILE_SUFFIX), false);
        } catch (IOException ioe) {
          
---------------Reference log start----------------
LOG.warn(""{} exception trying to delete pid file {}. Ignoring."", containerId, pidFilePath, ioe)
---------------Reference log end----------------
        }
      }
    }

    try {
      // Reap the container
      launch.reapContainer();
    } catch (IOException ioe) {
      LOG.warn(""{} exception trying to reap container. Ignoring."", containerId,
          ioe);
    }
  }",,
hadoop,1645,"LOG.info(""Un-publish volume {}, request {}"", volume.getVolumeId().toString(), unpublishRequest.toString())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/volume/csi/ContainerVolumePublisher.java/#L203,"private void unpublishVolume(VolumeMetaData volume)
      throws YarnException, IOException {
    CsiAdaptorProtocol csiClient =
        runtime.getCsiClients().get(volume.getDriverName());
    if (csiClient == null) {
      throw new YarnException(
          ""No csi-adaptor is found that can talk""
              + "" to csi-driver "" + volume.getDriverName());
    }

    // When container is launched, the container work dir is memorized,
    // and that is also the dir we mount the volume to.
    File localMount = getLocalVolumeMountPath(container.getCsiVolumesRootDir(),
        volume.getVolumeId().toString());
    if (!localMount.exists()) {
      LOG.info(""Local mount {} no longer exist, skipping cleaning""
          + "" up the volume"", localMount.getAbsolutePath());
      return;
    }
    NodeUnpublishVolumeRequest unpublishRequest =
        NodeUnpublishVolumeRequest.newInstance(
            volume.getVolumeId().getId(), // volume id
            localMount.getAbsolutePath());  // target path

    // un-publish volume from node
    
---------------Reference log start----------------
LOG.info(""Un-publish volume {}, request {}"", volume.getVolumeId().toString(), unpublishRequest.toString())
---------------Reference log end----------------
    csiClient.nodeUnpublishVolume(unpublishRequest);
  }",,
hadoop,3826,"LOG.warn(""Couldn't find Proxy CA data"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/LeveldbRMStateStore.java/#L529,"private void loadProxyCAManagerState(RMState rmState) throws Exception {
    byte[] caCertData;
    byte[] caPrivateKeyData;

    String caCertKey = getProxyCACertNodeKey();
    String caPrivateKeyKey = getProxyCAPrivateKeyNodeKey();

    try {
      caCertData = db.get(bytes(caCertKey));
    } catch (DBException e) {
      throw new IOException(e);
    }

    try {
      caPrivateKeyData = db.get(bytes(caPrivateKeyKey));
    } catch (DBException e) {
      throw new IOException(e);
    }

    if (caCertData == null || caPrivateKeyData == null) {
      
---------------Reference log start----------------
LOG.warn(""Couldn't find Proxy CA data"")
---------------Reference log end----------------
      return;
    }

    rmState.proxyCAState.setCaCert(caCertData);
    rmState.proxyCAState.setCaPrivateKey(caPrivateKeyData);
  }",,
hadoop,8700,"LOG.info(""Checked {} blocks and {} nodes this tick. {} nodes are now "" + ""in maintenance or transitioning state. {} nodes pending."", numBlocksChecked, numNodesChecked, outOfServiceNodeBlocks.size(), pendingNodes.size())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java/#L164,"@Override
  public void run() {
    LOG.debug(""DatanodeAdminMonitor is running."");
    if (!namesystem.isRunning()) {
      LOG.info(""Namesystem is not running, skipping "" +
          ""decommissioning/maintenance checks."");
      return;
    }
    // Reset the checked count at beginning of each iteration
    numBlocksChecked = 0;
    numBlocksCheckedPerLock = 0;
    numNodesChecked = 0;
    // Check decommission or maintenance progress.
    namesystem.writeLock();
    try {
      processPendingNodes();
      check();
    } catch (Exception e) {
      LOG.warn(""DatanodeAdminMonitor caught exception when processing node."",
          e);
    } finally {
      namesystem.writeUnlock();
    }
    if (numBlocksChecked + numNodesChecked > 0) {
      
---------------Reference log start----------------
LOG.info(""Checked {} blocks and {} nodes this tick. {} nodes are now "" + ""in maintenance or transitioning state. {} nodes pending."", numBlocksChecked, numNodesChecked, outOfServiceNodeBlocks.size(), pendingNodes.size())
---------------Reference log end----------------
    }
  }",,
hadoop,11402,"LOG.error(""Failed to purge "" + prefix)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSFileSystemStore.java/#L494,"public void purge(String prefix) throws IOException {
    String key;
    try {
      ObjectListing objects = listObjects(prefix, maxKeys, null, true);
      for (OSSObjectSummary object : objects.getObjectSummaries()) {
        key = object.getKey();
        ossClient.deleteObject(bucketName, key);
        statistics.incrementWriteOps(1);
      }

      for (String dir: objects.getCommonPrefixes()) {
        deleteDirs(dir);
      }
    } catch (OSSException | ClientException e) {
      
---------------Reference log start----------------
LOG.error(""Failed to purge "" + prefix)
---------------Reference log end----------------
    }
  }",,
hadoop,10428,"LOG.error(""Duplicate files in input path: "", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCp.java/#L160,"@Override
  public int run(String[] argv) {
    if (argv.length < 1) {
      OptionsParser.usage();
      return DistCpConstants.INVALID_ARGUMENT;
    }
    
    try {
      context = new DistCpContext(OptionsParser.parse(argv));
      checkSplitLargeFile();
      setTargetPathExists();
      LOG.info(""Input Options: "" + context);
    } catch (Throwable e) {
      LOG.error(""Invalid arguments: "", e);
      System.err.println(""Invalid arguments: "" + e.getMessage());
      OptionsParser.usage();      
      return DistCpConstants.INVALID_ARGUMENT;
    }

    Job job = null;
    try {
      job = execute();
    } catch (InvalidInputException e) {
      LOG.error(""Invalid input: "", e);
      return DistCpConstants.INVALID_ARGUMENT;
    } catch (DuplicateFileException e) {
      
---------------Reference log start----------------
LOG.error(""Duplicate files in input path: "", e)
---------------Reference log end----------------
      return DistCpConstants.DUPLICATE_INPUT;
    } catch (AclsNotSupportedException e) {
      LOG.error(""ACLs not supported on at least one file system: "", e);
      return DistCpConstants.ACLS_NOT_SUPPORTED;
    } catch (XAttrsNotSupportedException e) {
      LOG.error(""XAttrs not supported on at least one file system: "", e);
      return DistCpConstants.XATTRS_NOT_SUPPORTED;
    } catch (Exception e) {
      LOG.error(""Exception encountered "", e);
      return DistCpConstants.UNKNOWN_ERROR;
    } finally {
      //Blocking distcp so close the job after its done
      if (job != null && context.shouldBlock()) {
        try {
          job.close();
        } catch (IOException e) {
          LOG.error(""Exception encountered while closing distcp job"", e);
        }
      }
    }
    return DistCpConstants.SUCCESS;
  }",,
hadoop,10396,"LOG.info(""No eligible applications to process"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-archive-logs/src/main/java/org/apache/hadoop/tools/HadoopArchiveLogs.java/#L184,"@Override
  public int run(String[] args) throws Exception {
    int exitCode = 1;

    handleOpts(args);

    FileSystem fs = null;

    LogAggregationFileControllerFactory factory =
        new LogAggregationFileControllerFactory(conf);
    List<LogAggregationFileController> fileControllers = factory
        .getConfiguredLogAggregationFileControllerList();
    if (fileControllers == null || fileControllers.isEmpty()) {
      LOG.info(""Can not find any valid fileControllers."");
      if (verbose) {
        LOG.info(""The configurated fileControllers:""
            + YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS);
      }
      return 0;
    }
    try {
      fs = FileSystem.get(conf);
      // find eligibleApplications for all the fileControllers
      int previousTotal = 0;
      for (LogAggregationFileController fileController : fileControllers) {
        Path remoteRootLogDir = fileController.getRemoteRootLogDir();
        String suffix = fileController.getRemoteRootLogDirSuffix();
        Path workingDir = new Path(remoteRootLogDir, ""archive-logs-work"");
        if (verbose) {
          LOG.info(""LogAggregationFileController:"" + fileController
              .getClass().getName());
          LOG.info(""Remote Log Dir Root: "" + remoteRootLogDir);
          LOG.info(""Log Suffix: "" + suffix);
          LOG.info(""Working Dir: "" + workingDir);
        }
        checkFilesAndSeedApps(fs, remoteRootLogDir, suffix, workingDir);

        filterAppsByAggregatedStatus();

        if (eligibleApplications.size() > previousTotal) {
          workingDirs.add(workingDir);
          previousTotal = eligibleApplications.size();
        }
      }
      checkMaxEligible();
      if (workingDirs.isEmpty() || eligibleApplications.isEmpty()) {
        
---------------Reference log start----------------
LOG.info(""No eligible applications to process"")
---------------Reference log end----------------
        return 0;
      }
      for (Path workingDir : workingDirs) {
        if (!prepareWorkingDir(fs, workingDir)) {
          LOG.error(""Failed to create the workingDir:""
              + workingDir.toString());
          return 1;
        }
      }
      StringBuilder sb =
          new StringBuilder(""Will process the following applications:"");
      for (AppInfo app : eligibleApplications) {
        sb.append(""\n\t"").append(app.getAppId());
      }
      LOG.info(sb.toString());
      File localScript = File.createTempFile(""hadoop-archive-logs-"", "".sh"");
      generateScript(localScript);

      exitCode = runDistributedShell(localScript) ? 0 : 1;
    } finally {
      if (fs != null) {
        // Cleanup working directory
        for (Path workingDir : workingDirs) {
          fs.delete(workingDir, true);
        }
        fs.close();
      }
    }
    return exitCode;
  }",,
hadoop,10305,"LOG.error(""Failed to start DataNode Container "" + containerId)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/ApplicationMaster.java/#L640,"@Override
    public void onStartContainerError(ContainerId containerId, Throwable t) {
      if (isNameNode(containerId)) {
        LOG.error(""Failed to start namenode container ID "" + containerId, t);
        namenodeContainer = null;
        markCompleted();
      } else if (isDataNode(containerId)) {
        
---------------Reference log start----------------
LOG.error(""Failed to start DataNode Container "" + containerId)
---------------Reference log end----------------
        datanodeContainers.remove(containerId);
        numCompletedDataNodeContainers.incrementAndGet();
        numFailedDataNodeContainers.incrementAndGet();
      } else {
        LOG.error(""onStartContainerError received unknown container ID: ""
            + containerId);
      }
    }",,
hadoop,13141,"logger.trace(""Basic auth starting"")",trace,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/server/LdapAuthenticationHandler.java/#L184,"@Override
  public AuthenticationToken authenticate(HttpServletRequest request,
      HttpServletResponse response)
          throws IOException, AuthenticationException {
    AuthenticationToken token = null;
    String authorization =
        request.getHeader(HttpConstants.AUTHORIZATION_HEADER);

    if (authorization == null
        || !AuthenticationHandlerUtil.matchAuthScheme(HttpConstants.BASIC,
            authorization)) {
      response.setHeader(WWW_AUTHENTICATE, HttpConstants.BASIC);
      response.setStatus(HttpServletResponse.SC_UNAUTHORIZED);
      if (authorization == null) {
        
---------------Reference log start----------------
logger.trace(""Basic auth starting"")
---------------Reference log end----------------
      } else {
        logger.warn(""'"" + HttpConstants.AUTHORIZATION_HEADER
            + ""' does not start with '"" + HttpConstants.BASIC + ""' :  {}"",
            authorization);
      }
    } else {
      authorization =
          authorization.substring(HttpConstants.BASIC.length()).trim();
      final Base64 base64 = new Base64(0);
      // As per RFC7617, UTF-8 charset should be used for decoding.
      String[] credentials = new String(base64.decode(authorization),
          StandardCharsets.UTF_8).split("":"", 2);
      if (credentials.length == 2) {
        token = authenticateUser(credentials[0], credentials[1]);
        response.setStatus(HttpServletResponse.SC_OK);
      }
    }
    return token;
  }",,
hadoop,9360,"LOG.debug(""Requesting buffer of size {}"", limit)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-huaweicloud/src/main/java/org/apache/hadoop/fs/obs/OBSDataBlocks.java/#L513,"public static ByteBuffer requestBuffer(final int limit) {
      
---------------Reference log start----------------
LOG.debug(""Requesting buffer of size {}"", limit)
---------------Reference log end----------------
      BUFFERS_OUTSTANDING.incrementAndGet();
      return BUFFER_POOL.getBuffer(limit);
    }",,
hadoop,7922,"LOG.trace(""{} exiting because of InterruptedException."", this)",trace,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java/#L668,"@Override
  public void run() {
    // Record the minute on which the scanner started.
    this.startMinute =
        TimeUnit.MINUTES.convert(Time.monotonicNow(), TimeUnit.MILLISECONDS);
    this.curMinute = startMinute;
    try {
      LOG.trace(""{}: thread starting."", this);
      resultHandler.setup(this);
      try {
        long timeout = 0;
        while (true) {
          ExtendedBlock suspectBlock = null;
          // Take the lock to check if we should stop, and access the
          // suspect block list.
          synchronized (this) {
            if (stopping) {
              break;
            }
            if (timeout > 0) {
              LOG.debug(""{}: wait for {} milliseconds"", this, timeout);
              wait(timeout);
              if (stopping) {
                break;
              }
            }
            suspectBlock = popNextSuspectBlock();
          }
          timeout = runLoop(suspectBlock);
        }
      } catch (InterruptedException e) {
        // We are exiting because of an InterruptedException,
        // probably sent by VolumeScanner#shutdown.
        
---------------Reference log start----------------
LOG.trace(""{} exiting because of InterruptedException."", this)
---------------Reference log end----------------
      } catch (Throwable e) {
        LOG.error(""{} exiting because of exception "", this, e);
      }
      LOG.info(""{} exiting."", this);
      VolumeScannerCBInjector.get().preSavingBlockIteratorTask(this);
      // Save the current position of all block iterators and close them.
      for (BlockIterator iter : blockIters) {
        saveBlockIterator(iter);
        IOUtils.cleanupWithLogger(null, iter);
      }
    } finally {
      VolumeScannerCBInjector.get().terminationCallBack(this);
      // When the VolumeScanner exits, release the reference we were holding
      // on the volume.  This will allow the volume to be removed later.
      IOUtils.cleanupWithLogger(null, ref);
    }
  }",,
hadoop,6662,"NameNode.stateChangeLog.info(""DIR* completeFile: "" + ""request from "" + holder + "" to complete inode "" + fileId + ""("" + src + "") which is already closed. But, it appears to be "" + ""an RPC retry. Returning success"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirWriteFileOp.java/#L716,"private static boolean completeFileInternal(
      FSNamesystem fsn, INodesInPath iip,
      String holder, Block last, long fileId)
      throws IOException {
    assert fsn.hasWriteLock();
    final String src = iip.getPath();
    final INodeFile pendingFile;
    INode inode = null;
    try {
      inode = iip.getLastINode();
      pendingFile = fsn.checkLease(iip, holder, fileId);
    } catch (LeaseExpiredException lee) {
      if (inode != null && inode.isFile() &&
          !inode.asFile().isUnderConstruction()) {
        // This could be a retry RPC - i.e the client tried to close
        // the file, but missed the RPC response. Thus, it is trying
        // again to close the file. If the file still exists and
        // the client's view of the last block matches the actual
        // last block, then we'll treat it as a successful close.
        // See HDFS-3031.
        final Block realLastBlock = inode.asFile().getLastBlock();
        if (Block.matchingIdAndGenStamp(last, realLastBlock)) {
          
---------------Reference log start----------------
NameNode.stateChangeLog.info(""DIR* completeFile: "" + ""request from "" + holder + "" to complete inode "" + fileId + ""("" + src + "") which is already closed. But, it appears to be "" + ""an RPC retry. Returning success"")
---------------Reference log end----------------
          return true;
        }
      }
      throw lee;
    }
    // Check the state of the penultimate block. It should be completed
    // before attempting to complete the last one.
    if (!fsn.checkFileProgress(src, pendingFile, false)) {
      return false;
    }

    // commit the last block and complete it if it has minimum replicas
    fsn.commitOrCompleteLastBlock(pendingFile, iip, last);

    if (!fsn.checkFileProgress(src, pendingFile, true)) {
      return false;
    }

    fsn.addCommittedBlocksToPending(pendingFile);

    fsn.finalizeINodeFileUnderConstruction(src, pendingFile,
        Snapshot.CURRENT_STATE_ID, true);
    return true;
  }",,
hadoop,3673,"LOG.warn(""Name {} is converted to {} when it is used as a queue name."", name, converted)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/placement/FairQueuePlacementUtils.java/#L57,"protected static String cleanName(String name) {
    name = FairSchedulerUtilities.trimQueueName(name);
    if (name.contains(DOT)) {
      String converted = name.replaceAll(""\\."", DOT_REPLACEMENT);
      
---------------Reference log start----------------
LOG.warn(""Name {} is converted to {} when it is used as a queue name."", name, converted)
---------------Reference log end----------------
      return converted;
    } else {
      return name;
    }
  }",,
hadoop,8958,"LOG.error(""Unhandled exception updating NN registration for {}"", getNamenodeDesc(), ex)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/NamenodeHeartbeatService.java/#L243,"private void updateState() {
    NamenodeStatusReport report = getNamenodeStatusReport();
    if (!report.registrationValid()) {
      // Not operational
      LOG.error(""Namenode is not operational: {}"", getNamenodeDesc());
    } else if (report.haStateValid()) {
      // block and HA status available
      LOG.debug(""Received service state: {} from HA namenode: {}"",
          report.getState(), getNamenodeDesc());
    } else if (localTarget == null) {
      // block info available, HA status not expected
      LOG.debug(
          ""Reporting non-HA namenode as operational: "" + getNamenodeDesc());
    } else {
      // block info available, HA status should be available, but was not
      // fetched do nothing and let the current state stand
      return;
    }
    try {
      if (!resolver.registerNamenode(report)) {
        LOG.warn(""Cannot register namenode {}"", report);
      }
    } catch (IOException e) {
      LOG.info(""Cannot register namenode in the State Store"");
    } catch (Exception ex) {
      
---------------Reference log start----------------
LOG.error(""Unhandled exception updating NN registration for {}"", getNamenodeDesc(), ex)
---------------Reference log end----------------
    }
  }",,
hadoop,8598,"LOG.info(""Skipped stale nodes for recovery : "" + (storages.length - recoveryLocations.size()))",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java/#L1694,"private BlockRecoveryCommand getBlockRecoveryCommand(String blockPoolId,
      DatanodeDescriptor nodeinfo) throws IOException {
    BlockInfo[] blocks = nodeinfo.getLeaseRecoveryCommand(Integer.MAX_VALUE);
    if (blocks == null) {
      return null;
    }
    BlockRecoveryCommand brCommand = new BlockRecoveryCommand(blocks.length);
    for (BlockInfo b : blocks) {
      BlockUnderConstructionFeature uc = b.getUnderConstructionFeature();
      if(uc == null) {
        throw new IOException(""Recovery block "" + b +
            "" where it is not under construction."");
      }
      final DatanodeStorageInfo[] storages = uc.getExpectedStorageLocations();
      // Skip stale nodes during recovery
      final List<DatanodeStorageInfo> recoveryLocations =
          new ArrayList<>(storages.length);
      for (DatanodeStorageInfo storage : storages) {
        if (!storage.getDatanodeDescriptor().isStale(staleInterval)) {
          recoveryLocations.add(storage);
        }
      }
      // If we are performing a truncate recovery than set recovery fields
      // to old block.
      boolean truncateRecovery = uc.getTruncateBlock() != null;
      boolean copyOnTruncateRecovery = truncateRecovery &&
          uc.getTruncateBlock().getBlockId() != b.getBlockId();
      ExtendedBlock primaryBlock = (copyOnTruncateRecovery) ?
          new ExtendedBlock(blockPoolId, uc.getTruncateBlock()) :
          new ExtendedBlock(blockPoolId, b);
      // If we only get 1 replica after eliminating stale nodes, choose all
      // replicas for recovery and let the primary data node handle failures.
      DatanodeInfo[] recoveryInfos;
      if (recoveryLocations.size() > 1) {
        if (recoveryLocations.size() != storages.length) {
          
---------------Reference log start----------------
LOG.info(""Skipped stale nodes for recovery : "" + (storages.length - recoveryLocations.size()))
---------------Reference log end----------------
        }
        recoveryInfos = DatanodeStorageInfo.toDatanodeInfos(recoveryLocations);
      } else {
        // If too many replicas are stale, then choose all replicas to
        // participate in block recovery.
        recoveryInfos = DatanodeStorageInfo.toDatanodeInfos(storages);
      }
      RecoveringBlock rBlock;
      if (truncateRecovery) {
        Block recoveryBlock = (copyOnTruncateRecovery) ? b : uc.getTruncateBlock();
        rBlock = new RecoveringBlock(primaryBlock, recoveryInfos, recoveryBlock);
      } else {
        rBlock = new RecoveringBlock(primaryBlock, recoveryInfos,
            uc.getBlockRecoveryId());
        if (b.isStriped()) {
          rBlock = new RecoveringStripedBlock(rBlock, uc.getBlockIndices(),
              ((BlockInfoStriped) b).getErasureCodingPolicy());
        }
      }
      brCommand.add(rBlock);
    }
    return brCommand;
  }",,
hadoop,12547,"LOG.warn(""Can not read a null symLink"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java/#L206,"public static String readLink(File f) {
    /* NB: Use readSymbolicLink in java.nio.file.Path once available. Could
     * use getCanonicalPath in File to get the target of the symlink but that
     * does not indicate if the given path refers to a symlink.
     */

    if (f == null) {
      
---------------Reference log start----------------
LOG.warn(""Can not read a null symLink"")
---------------Reference log end----------------
      return """";
    }

    try {
      return Shell.execCommand(
          Shell.getReadlinkCommand(f.toString())).trim();
    } catch (IOException x) {
      return """";
    }
  }",,
hadoop,5433,"LOG.info(""Recovering "" + getClass().getSimpleName())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JHSDelegationTokenSecretManager.java/#L139,"public void recover(HistoryServerState state) throws IOException {
    
---------------Reference log start----------------
LOG.info(""Recovering "" + getClass().getSimpleName())
---------------Reference log end----------------
    for (DelegationKey key : state.tokenMasterKeyState) {
      addKey(key);
    }
    for (Entry<MRDelegationTokenIdentifier, Long> entry :
        state.tokenState.entrySet()) {
      addPersistedDelegationToken(entry.getKey(), entry.getValue());
    }
  }",,
hadoop,2486,"LOG.warn(""Error closing timeline store"", e)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/EntityCacheItem.java/#L138,"public synchronized void forceRelease() {
    try {
      if (store != null) {
        store.close();
      }
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.warn(""Error closing timeline store"", e)
---------------Reference log end----------------
    }
    store = null;
    // reset offsets so next time logs are re-parsed
    for (LogInfo log : appLogs.getDetailLogs()) {
      if (log.getFilename().contains(groupId.toString())) {
        log.setOffset(0);
      }
    }
    LOG.debug(""Cache for group {} released. "", groupId);
  }",,
hadoop,5078,"LOG.debug(""Sent abort command"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/BinaryProtocol.java/#L343,"public void abort() throws IOException {
    WritableUtils.writeVInt(stream, MessageType.ABORT.code);
    
---------------Reference log start----------------
LOG.debug(""Sent abort command"")
---------------Reference log end----------------
  }
  }",,
hadoop,6842,"LOG.info(""Stopping StoragePolicySatisfier."", t)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/StoragePolicySatisfier.java/#L333,"@Override
  public void run() {
    while (isRunning) {
      // Check if dependent service is running
      if (!ctxt.isRunning()) {
        if (LOG.isDebugEnabled()) {
          LOG.debug(""Upstream service is down, skipping the sps work."");
        }
        continue;
      }
      ItemInfo itemInfo = null;
      try {
        boolean retryItem = false;
        if (!ctxt.isInSafeMode()) {
          itemInfo = storageMovementNeeded.get();
          if (itemInfo != null) {
            if(itemInfo.getRetryCount() >= blockMovementMaxRetry){
              LOG.info(""Failed to satisfy the policy after ""
                  + blockMovementMaxRetry + "" retries. Removing inode ""
                  + itemInfo.getFile() + "" from the queue"");
              storageMovementNeeded.removeItemTrackInfo(itemInfo, false);
              continue;
            }
            long trackId = itemInfo.getFile();
            BlocksMovingAnalysis status = null;
            BlockStoragePolicy existingStoragePolicy;
            // TODO: presently, context internally acquire the lock
            // and returns the result. Need to discuss to move the lock outside?
            HdfsFileStatus fileStatus = ctxt.getFileInfo(trackId);
            // Check path existence.
            if (fileStatus == null || fileStatus.isDir()) {
              // File doesn't exists (maybe got deleted) or its a directory,
              // just remove trackId from the queue
              storageMovementNeeded.removeItemTrackInfo(itemInfo, true);
            } else {
              byte existingStoragePolicyID = fileStatus.getStoragePolicy();
              existingStoragePolicy = ctxt
                  .getStoragePolicy(existingStoragePolicyID);

              HdfsLocatedFileStatus file = (HdfsLocatedFileStatus) fileStatus;
              status = analyseBlocksStorageMovementsAndAssignToDN(file,
                  existingStoragePolicy);
              switch (status.status) {
              // Just add to monitor, so it will be retried after timeout
              case ANALYSIS_SKIPPED_FOR_RETRY:
                // Just add to monitor, so it will be tracked for report and
                // be removed on storage movement attempt finished report.
              case BLOCKS_TARGETS_PAIRED:
                if (LOG.isDebugEnabled()) {
                  LOG.debug(""Block analysis status:{} for the file id:{}.""
                      + "" Adding to attempt monitor queue for the storage ""
                      + ""movement attempt finished report"",
                      status.status, fileStatus.getFileId());
                }
                this.storageMovementsMonitor.add(itemInfo.getStartPath(),
                    itemInfo.getFile(), monotonicNow(), status.assignedBlocks,
                    itemInfo.getRetryCount());
                break;
              case NO_BLOCKS_TARGETS_PAIRED:
                if (LOG.isDebugEnabled()) {
                  LOG.debug(""Adding trackID:{} for the file id:{} back to""
                      + "" retry queue as none of the blocks found its eligible""
                      + "" targets."", trackId, fileStatus.getFileId());
                }
                retryItem = true;
                break;
              case FEW_LOW_REDUNDANCY_BLOCKS:
                if (LOG.isDebugEnabled()) {
                  LOG.debug(""Adding trackID:{} for the file id:{} back to ""
                      + ""retry queue as some of the blocks are low redundant."",
                      trackId, fileStatus.getFileId());
                }
                retryItem = true;
                break;
              case BLOCKS_FAILED_TO_MOVE:
                if (LOG.isDebugEnabled()) {
                  LOG.debug(""Adding trackID:{} for the file id:{} back to ""
                      + ""retry queue as some of the blocks movement failed."",
                      trackId, fileStatus.getFileId());
                }
                retryItem = true;
                break;
              // Just clean Xattrs
              case BLOCKS_TARGET_PAIRING_SKIPPED:
              case BLOCKS_ALREADY_SATISFIED:
              default:
                LOG.info(""Block analysis status:{} for the file id:{}.""
                    + "" So, Cleaning up the Xattrs."", status.status,
                    fileStatus.getFileId());
                storageMovementNeeded.removeItemTrackInfo(itemInfo, true);
                break;
              }
            }
          }
        } else {
          LOG.info(""Namenode is in safemode. It will retry again."");
          Thread.sleep(3000);
        }
        int numLiveDn = ctxt.getNumLiveDataNodes();
        if (storageMovementNeeded.size() == 0
            || blockCount > (numLiveDn * spsWorkMultiplier)) {
          Thread.sleep(3000);
          blockCount = 0L;
        }
        if (retryItem) {
          this.storageMovementNeeded.add(itemInfo);
        }
      } catch (IOException e) {
        LOG.error(""Exception during StoragePolicySatisfier execution - ""
            + ""will continue next cycle"", e);
        // Since it could not finish this item in previous iteration due to IOE,
        // just try again.
        this.storageMovementNeeded.add(itemInfo);
      } catch (Throwable t) {
        synchronized (this) {
          if (isRunning) {
            isRunning = false;
            if (t instanceof InterruptedException) {
              
---------------Reference log start----------------
LOG.info(""Stopping StoragePolicySatisfier."", t)
---------------Reference log end----------------
            } else {
              LOG.error(""StoragePolicySatisfier thread received ""
                  + ""runtime exception."", t);
            }
            // Stopping monitor thread and clearing queues as well
            this.clearQueues();
            this.storageMovementsMonitor.stopGracefully();
          }
        }
      }
    }
  }",,
hadoop,12383,LOG.error(e.toString()),error,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/ganglia/AbstractGangliaSink.java/#L158,"@Override
  public void init(SubsetConfiguration conf) {
    LOG.debug(""Initializing the GangliaSink for Ganglia metrics."");

    this.conf = conf;

    // Take the hostname from the DNS class.
    if (conf.getString(""slave.host.name"") != null) {
      hostName = conf.getString(""slave.host.name"");
    } else {
      try {
        hostName = DNS.getDefaultHost(
            conf.getString(""dfs.datanode.dns.interface"", ""default""),
            conf.getString(""dfs.datanode.dns.nameserver"", ""default""));
      } catch (UnknownHostException uhe) {
        LOG.error(uhe.toString());
        hostName = ""UNKNOWN.example.com"";
      }
    }

    // load the gannglia servers from properties
    metricsServers = Servers.parse(conf.getString(SERVERS_PROPERTY),
        DEFAULT_PORT);
    multicastEnabled = conf.getBoolean(MULTICAST_ENABLED_PROPERTY,
            DEFAULT_MULTICAST_ENABLED);
    multicastTtl = conf.getInt(MULTICAST_TTL_PROPERTY, DEFAULT_MULTICAST_TTL);

    // extract the Ganglia conf per metrics
    gangliaConfMap = new HashMap<String, GangliaConf>();
    loadGangliaConf(GangliaConfType.units);
    loadGangliaConf(GangliaConfType.tmax);
    loadGangliaConf(GangliaConfType.dmax);
    loadGangliaConf(GangliaConfType.slope);

    try {
      if (multicastEnabled) {
        LOG.info(""Enabling multicast for Ganglia with TTL "" + multicastTtl);
        datagramSocket = new MulticastSocket();
        ((MulticastSocket) datagramSocket).setTimeToLive(multicastTtl);
      } else {
        datagramSocket = new DatagramSocket();
      }
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.error(e.toString())
---------------Reference log end----------------
    }

    // see if sparseMetrics is supported. Default is false
    supportSparseMetrics = conf.getBoolean(SUPPORT_SPARSE_METRICS_PROPERTY,
        SUPPORT_SPARSE_METRICS_DEFAULT);
  }",,
hadoop,10152,"LOG.info(""Number of HDFS based distributed cache files to be generated is "" + fileCount + "". Total size of HDFS based distributed cache files "" + ""to be generated is "" + byteCount)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java/#L463,"private int writeDistCacheFilesList()
      throws IOException {
    // Sort the distributed cache files in the decreasing order of file sizes.
    List dcFiles = new ArrayList(distCacheFiles.entrySet());
    Collections.sort(dcFiles, new Comparator() {
      public int compare(Object dc1, Object dc2) {
        return ((Comparable) ((Map.Entry) (dc2)).getValue())
            .compareTo(((Map.Entry) (dc1)).getValue());
      }
    });

    // write the sorted distributed cache files to the sequence file
    FileSystem fs = FileSystem.get(conf);
    Path distCacheFilesList = new Path(distCachePath, ""_distCacheFiles.txt"");
    conf.set(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_LIST,
        distCacheFilesList.toString());
    SequenceFile.Writer src_writer = SequenceFile.createWriter(fs, conf,
        distCacheFilesList, LongWritable.class, BytesWritable.class,
        SequenceFile.CompressionType.NONE);

    // Total number of unique distributed cache files
    int fileCount = dcFiles.size();
    long byteCount = 0;// Total size of all distributed cache files
    long bytesSync = 0;// Bytes after previous sync;used to add sync marker

    for (Iterator it = dcFiles.iterator(); it.hasNext();) {
      Map.Entry entry = (Map.Entry)it.next();
      LongWritable fileSize =
          new LongWritable(Long.parseLong(entry.getValue().toString()));
      BytesWritable filePath =
          new BytesWritable(
          entry.getKey().toString().getBytes(charsetUTF8));

      byteCount += fileSize.get();
      bytesSync += fileSize.get();
      if (bytesSync > AVG_BYTES_PER_MAP) {
        src_writer.sync();
        bytesSync = fileSize.get();
      }
      src_writer.append(fileSize, filePath);
    }
    if (src_writer != null) {
      src_writer.close();
    }
    // Set delete on exit for 'dist cache files list' as it is not needed later.
    fs.deleteOnExit(distCacheFilesList);

    conf.setInt(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_COUNT, fileCount);
    conf.setLong(GenerateDistCacheData.GRIDMIX_DISTCACHE_BYTE_COUNT, byteCount);
    
---------------Reference log start----------------
LOG.info(""Number of HDFS based distributed cache files to be generated is "" + fileCount + "". Total size of HDFS based distributed cache files "" + ""to be generated is "" + byteCount)
---------------Reference log end----------------

    if (!shouldGenerateDistCacheData() && fileCount > 0) {
      LOG.error(""Missing "" + fileCount + "" distributed cache files under the ""
          + "" directory\n"" + distCachePath + ""\nthat are needed for gridmix""
          + "" to emulate distributed cache load. Either use -generate\noption""
          + "" to generate distributed cache data along with input data OR ""
          + ""disable\ndistributed cache emulation by configuring '""
          + DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE
          + ""' to false."");
      return Gridmix.MISSING_DIST_CACHE_FILES_ERROR;
    }
    return 0;
  }",,
hadoop,8698,"LOG.info(""Namesystem is not running, skipping "" + ""decommissioning/maintenance checks."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java/#L144,"@Override
  public void run() {
    LOG.debug(""DatanodeAdminMonitor is running."");
    if (!namesystem.isRunning()) {
      
---------------Reference log start----------------
LOG.info(""Namesystem is not running, skipping "" + ""decommissioning/maintenance checks."")
---------------Reference log end----------------
      return;
    }
    // Reset the checked count at beginning of each iteration
    numBlocksChecked = 0;
    numBlocksCheckedPerLock = 0;
    numNodesChecked = 0;
    // Check decommission or maintenance progress.
    namesystem.writeLock();
    try {
      processPendingNodes();
      check();
    } catch (Exception e) {
      LOG.warn(""DatanodeAdminMonitor caught exception when processing node."",
          e);
    } finally {
      namesystem.writeUnlock();
    }
    if (numBlocksChecked + numNodesChecked > 0) {
      LOG.info(""Checked {} blocks and {} nodes this tick. {} nodes are now "" +
              ""in maintenance or transitioning state. {} nodes pending."",
          numBlocksChecked, numNodesChecked, outOfServiceNodeBlocks.size(),
          pendingNodes.size());
    }
  }",,
hadoop,5888,"LOG.warn(ShortCircuitCache.this + "": failed to release "" + ""short-circuit shared memory slot "" + slot + "" by sending "" + ""ReleaseShortCircuitAccessRequestProto to "" + path + "".  Closing shared memory segment. "" + ""DataNode may have been stopped or restarted"", e)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java/#L232,"@Override
    public void run() {
      if (slot == null) {
        return;
      }
      LOG.trace(""{}: about to release {}"", ShortCircuitCache.this, slot);
      final DfsClientShm shm = (DfsClientShm)slot.getShm();
      final DomainSocket shmSock = shm.getPeer().getDomainSocket();
      final String path = shmSock.getPath();
      DataOutputStream out = null;
      boolean success = false;
      int retries = 2;
      try {
        while (retries > 0) {
          try {
            if (domainSocket == null || !domainSocket.isOpen()) {
              // we are running in single thread mode, no protection needed for
              // domainSocket
              domainSocket = DomainSocket.connect(path);
            }

            out = new DataOutputStream(
                new BufferedOutputStream(domainSocket.getOutputStream()));
            new Sender(out).releaseShortCircuitFds(slot.getSlotId());
            DataInputStream in =
                new DataInputStream(domainSocket.getInputStream());
            ReleaseShortCircuitAccessResponseProto resp =
                ReleaseShortCircuitAccessResponseProto
                    .parseFrom(PBHelperClient.vintPrefixed(in));
            if (resp.getStatus() != Status.SUCCESS) {
              String error = resp.hasError() ? resp.getError() : ""(unknown)"";
              throw new IOException(resp.getStatus().toString() + "": "" + error);
            }

            LOG.trace(""{}: released {}"", this, slot);
            success = true;
            break;

          } catch (SocketException se) {
            // the domain socket on datanode may be timed out, we retry once
            retries--;
            domainSocket.close();
            domainSocket = null;
            if (retries == 0) {
              throw new SocketException(""Create domain socket failed"");
            }
          }
        }
      } catch (IOException e) {
        
---------------Reference log start----------------
LOG.warn(ShortCircuitCache.this + "": failed to release "" + ""short-circuit shared memory slot "" + slot + "" by sending "" + ""ReleaseShortCircuitAccessRequestProto to "" + path + "".  Closing shared memory segment. "" + ""DataNode may have been stopped or restarted"", e)
---------------Reference log end----------------
      } finally {
        if (success) {
          shmManager.freeSlot(slot);
        } else {
          shm.getEndpointShmManager().shutdown(shm);
          IOUtilsClient.cleanupWithLogger(LOG, domainSocket, out);
          domainSocket = null;
        }
      }
    }",,
hadoop,7045,"LOG.info(""ImageServlet allowing administrator: "" + remoteUser)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageServlet.java/#L342,"@VisibleForTesting
  static boolean isValidRequestor(ServletContext context, String remoteUser,
      Configuration conf) throws IOException {
    if (remoteUser == null) { // This really shouldn't happen...
      LOG.warn(""Received null remoteUser while authorizing access to getImage servlet"");
      return false;
    }

    Set<String> validRequestors = new HashSet<String>();

    validRequestors.add(SecurityUtil.getServerPrincipal(conf
        .get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY),
        DFSUtilClient.getNNAddress(conf).getHostName()));
    try {
      validRequestors.add(
          SecurityUtil.getServerPrincipal(conf
              .get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY),
              SecondaryNameNode.getHttpAddress(conf).getHostName()));
    } catch (Exception e) {
      // Don't halt if SecondaryNameNode principal could not be added.
      LOG.debug(""SecondaryNameNode principal could not be added"", e);
      String msg = String.format(
        ""SecondaryNameNode principal not considered, %s = %s, %s = %s"",
        DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY,
        conf.get(DFSConfigKeys.DFS_SECONDARY_NAMENODE_KERBEROS_PRINCIPAL_KEY),
        DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,
        conf.getTrimmed(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY,
          DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_DEFAULT));
      LOG.warn(msg);
    }

    if (HAUtil.isHAEnabled(conf, DFSUtil.getNamenodeNameServiceId(conf))) {
      List<Configuration> otherNnConfs = HAUtil.getConfForOtherNodes(conf);
      for (Configuration otherNnConf : otherNnConfs) {
        validRequestors.add(SecurityUtil.getServerPrincipal(otherNnConf
                .get(DFSConfigKeys.DFS_NAMENODE_KERBEROS_PRINCIPAL_KEY),
            DFSUtilClient.getNNAddress(otherNnConf).getHostName()));
      }
    }

    for (String v : validRequestors) {
      if (v != null && v.equals(remoteUser)) {
        LOG.info(""ImageServlet allowing checkpointer: "" + remoteUser);
        return true;
      }
    }

    if (HttpServer2.userHasAdministratorAccess(context, remoteUser)) {
      
---------------Reference log start----------------
LOG.info(""ImageServlet allowing administrator: "" + remoteUser)
---------------Reference log end----------------
      return true;
    }

    LOG.info(""ImageServlet rejecting: "" + remoteUser);
    return false;
  }",,
hadoop,5255,"LOG.warn(""couldn't parse Token Cache JSON file with user secret keys"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobSubmitter.java/#L414,"@SuppressWarnings(""unchecked"")
  private void readTokensFromFiles(Configuration conf, Credentials credentials)
  throws IOException {
    // add tokens and secrets coming from a token storage file
    String binaryTokenFilename =
      conf.get(MRJobConfig.MAPREDUCE_JOB_CREDENTIALS_BINARY);
    if (binaryTokenFilename != null) {
      Credentials binary = Credentials.readTokenStorageFile(
          FileSystem.getLocal(conf).makeQualified(
              new Path(binaryTokenFilename)),
          conf);
      credentials.addAll(binary);
    }
    // add secret keys coming from a json file
    String tokensFileName = conf.get(""mapreduce.job.credentials.json"");
    if(tokensFileName != null) {
      LOG.info(""loading user's secret keys from "" + tokensFileName);
      String localFileName = new Path(tokensFileName).toUri().getPath();

      try {
        // read JSON
        Map<String, String> nm = JsonSerialization.mapReader().readValue(
            new File(localFileName));

        for(Map.Entry<String, String> ent: nm.entrySet()) {
          credentials.addSecretKey(new Text(ent.getKey()), ent.getValue()
              .getBytes(Charsets.UTF_8));
        }
      } catch (JsonMappingException | JsonParseException e) {
        
---------------Reference log start----------------
LOG.warn(""couldn't parse Token Cache JSON file with user secret keys"")
---------------Reference log end----------------
      }
    }
  }",,
hadoop,1264,"LOG.debug(String.format(""EFS:setPermission: %s %s"", p, permission))",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/WindowsSecureContainerExecutor.java/#L347,"@Override
      public void setPermission(Path p, FsPermission permission) 
          throws IOException {
        if (LOG.isDebugEnabled()) {
          
---------------Reference log start----------------
LOG.debug(String.format(""EFS:setPermission: %s %s"", p, permission))
---------------Reference log end----------------
        }
        Native.Elevated.chmod(p, permission.toShort());
      }",,
hadoop,12521,"LOG.warn(""The cluster does not contain node: "" + NodeBase.getPath(node2))",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/NetworkTopology.java/#L352,"public int getDistance(Node node1, Node node2) {
    if ((node1 != null && node1.equals(node2)) ||
        (node1 == null && node2 == null))  {
      return 0;
    }
    if (node1 == null || node2 == null) {
      LOG.warn(""One of the nodes is a null pointer"");
      return Integer.MAX_VALUE;
    }
    Node n1=node1, n2=node2;
    int dis = 0;
    netlock.readLock().lock();
    try {
      int level1=node1.getLevel(), level2=node2.getLevel();
      while(n1!=null && level1>level2) {
        n1 = n1.getParent();
        level1--;
        dis++;
      }
      while(n2!=null && level2>level1) {
        n2 = n2.getParent();
        level2--;
        dis++;
      }
      while(n1!=null && n2!=null && n1.getParent()!=n2.getParent()) {
        n1=n1.getParent();
        n2=n2.getParent();
        dis+=2;
      }
    } finally {
      netlock.readLock().unlock();
    }
    if (n1==null) {
      LOG.warn(""The cluster does not contain node: ""+NodeBase.getPath(node1));
      return Integer.MAX_VALUE;
    }
    if (n2==null) {
      
---------------Reference log start----------------
LOG.warn(""The cluster does not contain node: "" + NodeBase.getPath(node2))
---------------Reference log end----------------
      return Integer.MAX_VALUE;
    }
    return dis+2;
  }",,
hadoop,466,"LOG.error(""Invalid health monitor window {} secs for component {}. Monitor not "" + ""enabled."", window, componentSpec.getName())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/Component.java/#L307,"private void checkAndScheduleHealthThresholdMonitor() {
    // Determine health threshold percent
    int healthThresholdPercent = YarnServiceConf.getInt(
        CONTAINER_HEALTH_THRESHOLD_PERCENT,
        DEFAULT_CONTAINER_HEALTH_THRESHOLD_PERCENT,
        componentSpec.getConfiguration(), scheduler.getConfig());
    // Validations
    if (healthThresholdPercent == CONTAINER_HEALTH_THRESHOLD_PERCENT_DISABLED) {
      LOG.info(""No health threshold monitor enabled for component {}"",
          componentSpec.getName());
      return;
    }
    // If threshold is set to outside acceptable range then don't enable monitor
    if (healthThresholdPercent <= 0 || healthThresholdPercent > 100) {
      LOG.error(
          ""Invalid health threshold percent {}% for component {}. Monitor not ""
              + ""enabled."",
          healthThresholdPercent, componentSpec.getName());
      return;
    }
    // Determine the threshold properties
    long window = YarnServiceConf.getLong(CONTAINER_HEALTH_THRESHOLD_WINDOW_SEC,
        DEFAULT_CONTAINER_HEALTH_THRESHOLD_WINDOW_SEC,
        componentSpec.getConfiguration(), scheduler.getConfig());
    long initDelay = YarnServiceConf.getLong(
        CONTAINER_HEALTH_THRESHOLD_INIT_DELAY_SEC,
        DEFAULT_CONTAINER_HEALTH_THRESHOLD_INIT_DELAY_SEC,
        componentSpec.getConfiguration(), scheduler.getConfig());
    long pollFrequency = YarnServiceConf.getLong(
        CONTAINER_HEALTH_THRESHOLD_POLL_FREQUENCY_SEC,
        DEFAULT_CONTAINER_HEALTH_THRESHOLD_POLL_FREQUENCY_SEC,
        componentSpec.getConfiguration(), scheduler.getConfig());
    // Validations
    if (window <= 0) {
      
---------------Reference log start----------------
LOG.error(""Invalid health monitor window {} secs for component {}. Monitor not "" + ""enabled."", window, componentSpec.getName())
---------------Reference log end----------------
      return;
    }
    if (initDelay < 0) {
      LOG.error(""Invalid health monitor init delay {} secs for component {}. ""
          + ""Monitor not enabled."", initDelay, componentSpec.getName());
      return;
    }
    if (pollFrequency <= 0) {
      LOG.error(
          ""Invalid health monitor poll frequency {} secs for component {}. ""
              + ""Monitor not enabled."",
          pollFrequency, componentSpec.getName());
      return;
    }
    LOG.info(
        ""Scheduling the health threshold monitor for component {} with percent ""
            + ""= {}%, window = {} secs, poll freq = {} secs, init-delay = {} ""
            + ""secs"",
        componentSpec.getName(), healthThresholdPercent, window, pollFrequency,
        initDelay);
    // Add 3 extra seconds to initial delay to account for the time taken to
    // request containers before the monitor starts calculating health.
    this.scheduler.executorService.scheduleAtFixedRate(
        new ComponentHealthThresholdMonitor(this, healthThresholdPercent,
            window),
        initDelay + 3, pollFrequency, TimeUnit.SECONDS);
    setHealthThresholdMonitorEnabled(true);
  }",,
hadoop,4977,"LOG.info(""Starting flush of map output"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MapTask.java/#L1477,"public void flush() throws IOException, ClassNotFoundException,
           InterruptedException {
      
---------------Reference log start----------------
LOG.info(""Starting flush of map output"")
---------------Reference log end----------------
      if (kvbuffer == null) {
        LOG.info(""kvbuffer is null. Skipping flush."");
        return;
      }
      spillLock.lock();
      try {
        while (spillInProgress) {
          reporter.progress();
          spillDone.await();
        }
        checkSpillException();

        final int kvbend = 4 * kvend;
        if ((kvbend + METASIZE) % kvbuffer.length !=
            equator - (equator % METASIZE)) {
          // spill finished
          resetSpill();
        }
        if (kvindex != kvend) {
          kvend = (kvindex + NMETA) % kvmeta.capacity();
          bufend = bufmark;
          LOG.info(""Spilling map output"");
          LOG.info(""bufstart = "" + bufstart + ""; bufend = "" + bufmark +
                   ""; bufvoid = "" + bufvoid);
          LOG.info(""kvstart = "" + kvstart + ""("" + (kvstart * 4) +
                   ""); kvend = "" + kvend + ""("" + (kvend * 4) +
                   ""); length = "" + (distanceTo(kvend, kvstart,
                         kvmeta.capacity()) + 1) + ""/"" + maxRec);
          sortAndSpill();
        }
      } catch (InterruptedException e) {
        throw new IOException(""Interrupted while waiting for the writer"", e);
      } finally {
        spillLock.unlock();
      }
      assert !spillLock.isHeldByCurrentThread();
      // shut down spill thread and wait for it to exit. Since the preceding
      // ensures that it is finished with its work (and sortAndSpill did not
      // throw), we elect to use an interrupt instead of setting a flag.
      // Spilling simultaneously from this thread while the spill thread
      // finishes its work might be both a useful way to extend this and also
      // sufficient motivation for the latter approach.
      try {
        spillThread.interrupt();
        spillThread.join();
      } catch (InterruptedException e) {
        throw new IOException(""Spill failed"", e);
      }
      // release sort buffer before the merge
      kvbuffer = null;
      mergeParts();
      Path outputPath = mapOutputFile.getOutputFile();
      fileOutputByteCounter.increment(rfs.getFileStatus(outputPath).getLen());
      // If necessary, make outputs permissive enough for shuffling.
      if (!SHUFFLE_OUTPUT_PERM.equals(
          SHUFFLE_OUTPUT_PERM.applyUMask(FsPermission.getUMask(job)))) {
        Path indexPath = mapOutputFile.getOutputIndexFile();
        rfs.setPermission(outputPath, SHUFFLE_OUTPUT_PERM);
        rfs.setPermission(indexPath, SHUFFLE_OUTPUT_PERM);
      }
    }",,
hadoop,3454,"LOG.info(""Making reservation: node="" + node.getNodeName() + "" app_id="" + getApplicationId())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java/#L709,"private boolean reserve(Resource perAllocationResource, FSSchedulerNode node,
      Container reservedContainer, NodeType type,
      SchedulerRequestKey schedulerKey) {

    RMContainer nodeReservedContainer = node.getReservedContainer();
    boolean reservableForThisApp = nodeReservedContainer == null ||
        nodeReservedContainer.getApplicationAttemptId()
            .equals(getApplicationAttemptId());
    if (reservableForThisApp &&!reservationExceedsThreshold(node, type)) {
      
---------------Reference log start----------------
LOG.info(""Making reservation: node="" + node.getNodeName() + "" app_id="" + getApplicationId())
---------------Reference log end----------------
      if (reservedContainer == null) {
        reservedContainer =
            createContainer(node, perAllocationResource,
              schedulerKey);
        getMetrics().reserveResource(node.getPartition(), getUser(),
            reservedContainer.getResource());
        RMContainer rmContainer =
                super.reserve(node, schedulerKey, null, reservedContainer);
        node.reserveResource(this, schedulerKey, rmContainer);
        setReservation(node);
      } else {
        RMContainer rmContainer = node.getReservedContainer();
        super.reserve(node, schedulerKey, rmContainer, reservedContainer);
        node.reserveResource(this, schedulerKey, rmContainer);
        setReservation(node);
      }
      return true;
    }
    return false;
  }",,
hadoop,6086,"PerformanceAdvisory.LOG.debug(""{}: failed to get "" + ""ShortCircuitReplica. Cannot construct "" + ""BlockReaderLocal via {}"", this, pathInfo.getPath())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderFactory.java/#L491,"private BlockReader getBlockReaderLocal() throws IOException {
    LOG.trace(""{}: trying to construct a BlockReaderLocal for short-circuit ""
        + "" reads."", this);
    if (pathInfo == null) {
      pathInfo = clientContext.getDomainSocketFactory()
          .getPathInfo(inetSocketAddress, conf.getShortCircuitConf());
    }
    if (!pathInfo.getPathState().getUsableForShortCircuit()) {
      PerformanceAdvisory.LOG.debug(""{}: {} is not usable for short circuit; "" +
              ""giving up on BlockReaderLocal."", this, pathInfo);
      return null;
    }
    ShortCircuitCache cache =
        clientContext.getShortCircuitCache(block.getBlockId());
    ExtendedBlockId key = new ExtendedBlockId(block.getBlockId(),
        block.getBlockPoolId());
    ShortCircuitReplicaInfo info = cache.fetchOrCreate(key, this);
    InvalidToken exc = info.getInvalidTokenException();
    if (exc != null) {
      LOG.trace(""{}: got InvalidToken exception while trying to construct ""
          + ""BlockReaderLocal via {}"", this, pathInfo.getPath());
      throw exc;
    }
    if (info.getReplica() == null) {
      
---------------Reference log start----------------
PerformanceAdvisory.LOG.debug(""{}: failed to get "" + ""ShortCircuitReplica. Cannot construct "" + ""BlockReaderLocal via {}"", this, pathInfo.getPath())
---------------Reference log end----------------
      return null;
    }
    return new BlockReaderLocal.Builder(conf.getShortCircuitConf()).
        setFilename(fileName).
        setBlock(block).
        setStartOffset(startOffset).
        setShortCircuitReplica(info.getReplica()).
        setVerifyChecksum(verifyChecksum).
        setCachingStrategy(cachingStrategy).
        setStorageType(storageType).
        build();
  }",,
hadoop,4335,"LOG.info(""Attempt to dump logs when appender is already running"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/AdHocLogDumper.java/#L68,"public void dumpLogs(String level, int timePeriod)
      throws YarnRuntimeException, IOException {
    synchronized (lock){
      if (logFlag) {
        
---------------Reference log start----------------
LOG.info(""Attempt to dump logs when appender is already running"")
---------------Reference log end----------------
        throw new YarnRuntimeException(""Appender is already dumping logs"");
      }
      Level targetLevel = Level.toLevel(level);
      Logger logger = LogManager.getLogger(name);
      appenderLevels.clear();
      currentLogLevel = logger.getLevel();
      Level currentEffectiveLevel = logger.getEffectiveLevel();

      // make sure we can create the appender first
      Layout layout = new PatternLayout(""%d{ISO8601} %p %c: %m%n"");
      FileAppender fApp;
      File file =
          new File(System.getProperty(""yarn.log.dir""), targetFilename);
      try {
        fApp = new FileAppender(layout, file.getAbsolutePath(), false);
      } catch (IOException ie) {
        LOG.warn(""Error creating file, can't dump logs to ""
            + file.getAbsolutePath(), ie);
        throw ie;
      }
      fApp.setName(AdHocLogDumper.AD_HOC_DUMPER_APPENDER);
      fApp.setThreshold(targetLevel);

      // get current threshold of all appenders and set it to the effective
      // level
      for (Enumeration appenders = Logger.getRootLogger().getAllAppenders();
          appenders.hasMoreElements();) {
        Object obj = appenders.nextElement();
        if (obj instanceof AppenderSkeleton) {
          AppenderSkeleton appender = (AppenderSkeleton) obj;
          appenderLevels.put(appender.getName(), appender.getThreshold());
          appender.setThreshold(currentEffectiveLevel);
        }
      }

      logger.addAppender(fApp);
      LOG.info(""Dumping adhoc logs for "" + name + "" to ""
          + file.getAbsolutePath() + "" for "" + timePeriod + "" milliseconds"");
      logger.setLevel(targetLevel);
      logFlag = true;

      TimerTask restoreLogLevel = new RestoreLogLevel();
      Timer restoreLogLevelTimer = new Timer();
      restoreLogLevelTimer.schedule(restoreLogLevel, timePeriod);
    }
  }",,
hadoop,5213,"LOG.info(""Reporting fetch failure for "" + mapId + "" to MRAppMaster."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/ShuffleSchedulerImpl.java/#L349,"private void checkAndInformMRAppMaster(
      int failures, TaskAttemptID mapId, boolean readError,
      boolean connectExcpt, boolean hostFailed) {
    if (connectExcpt || (reportReadErrorImmediately && readError)
        || ((failures % maxFetchFailuresBeforeReporting) == 0) || hostFailed) {
      
---------------Reference log start----------------
LOG.info(""Reporting fetch failure for "" + mapId + "" to MRAppMaster."")
---------------Reference log end----------------
      status.addFetchFailedMap((org.apache.hadoop.mapred.TaskAttemptID) mapId);
    }
  }",,
hadoop,10215,"LOG.info(""Job submission failed notification for job "" + jobID)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/JobMonitor.java/#L100,"public void submissionFailed(JobStats job) {
    String jobID = job.getJob().getConfiguration().get(Gridmix.ORIGINAL_JOB_ID);
    
---------------Reference log start----------------
LOG.info(""Job submission failed notification for job "" + jobID)
---------------Reference log end----------------
    synchronized (statistics) {
      this.statistics.add(job);
    }
  }",,
hadoop,11188,"LOG.info(""Table {} contains no version marker ITEM but contains "" + ""compatible version marker TAG. Restoring the version marker "" + ""item from tag."", tableName)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStoreTableManager.java/#L466,"@VisibleForTesting
  protected void verifyVersionCompatibility() throws IOException {
    final Item versionMarkerItem = getVersionMarkerItem();
    Item versionMarkerFromTag = null;
    boolean canReadDdbTags = true;

    try {
      versionMarkerFromTag = getVersionMarkerFromTags(table, amazonDynamoDB);
    } catch (AccessDeniedException e) {
      LOG.debug(""Can not read tags of table."");
      canReadDdbTags = false;
    }

    LOG.debug(""versionMarkerItem: {};  versionMarkerFromTag: {}"",
        versionMarkerItem, versionMarkerFromTag);

    if (versionMarkerItem == null && versionMarkerFromTag == null) {
      if (!isEmptyTable(tableName, amazonDynamoDB)) {
        LOG.error(""Table is not empty but missing the version maker. Failing."");
        throw new IOException(E_NO_VERSION_MARKER_AND_NOT_EMPTY
            + "" Table: "" + tableName);
      }

      if (canReadDdbTags) {
        LOG.info(""Table {} contains no version marker item and tag. "" +
            ""The table is empty, so the version marker will be added "" +
            ""as TAG and ITEM."", tableName);
        putVersionMarkerItemToTable();
        tagTableWithVersionMarker();
      }

      if (!canReadDdbTags) {
        LOG.info(""Table {} contains no version marker item and the tags are not readable. "" +
            ""The table is empty, so the ITEM version marker will be added ."", tableName);
        putVersionMarkerItemToTable();
      }
    }

    if (versionMarkerItem == null && versionMarkerFromTag != null) {
      final int tagVersionMarker =
          extractVersionFromMarker(versionMarkerFromTag);
      throwExceptionOnVersionMismatch(tagVersionMarker, tableName,
          E_INCOMPATIBLE_TAG_VERSION);

      
---------------Reference log start----------------
LOG.info(""Table {} contains no version marker ITEM but contains "" + ""compatible version marker TAG. Restoring the version marker "" + ""item from tag."", tableName)
---------------Reference log end----------------

      putVersionMarkerItemToTable();
    }

    if (versionMarkerItem != null && versionMarkerFromTag == null
        && canReadDdbTags) {
      final int itemVersionMarker =
          extractVersionFromMarker(versionMarkerItem);
      throwExceptionOnVersionMismatch(itemVersionMarker, tableName,
          E_INCOMPATIBLE_ITEM_VERSION);

      LOG.info(""Table {} contains no version marker TAG but contains "" +
          ""compatible version marker ITEM. Restoring the version marker "" +
          ""item from item."", tableName);

      tagTableWithVersionMarker();
    }

    if (versionMarkerItem != null && versionMarkerFromTag != null) {
      final int tagVersionMarker =
          extractVersionFromMarker(versionMarkerFromTag);
      final int itemVersionMarker =
          extractVersionFromMarker(versionMarkerItem);

      throwExceptionOnVersionMismatch(tagVersionMarker, tableName,
          E_INCOMPATIBLE_TAG_VERSION);
      throwExceptionOnVersionMismatch(itemVersionMarker, tableName,
          E_INCOMPATIBLE_ITEM_VERSION);

      LOG.debug(""Table {} contains correct version marker TAG and ITEM."",
          tableName);
    }
  }",,
hadoop,1351,"LOG.info(""Node's resource is updated to {}"", newResource)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdaterImpl.java/#L1430,"@Override
    @SuppressWarnings(""unchecked"")
    public void run() {
      int lastHeartbeatID = 0;
      boolean missedHearbeat = false;
      while (!isStopped) {
        // Send heartbeat
        try {
          NodeHeartbeatResponse response = null;
          Set<NodeLabel> nodeLabelsForHeartbeat =
              nodeLabelsHandler.getNodeLabelsForHeartbeat();
          Set<NodeAttribute> nodeAttributesForHeartbeat =
                  nodeAttributesHandler.getNodeAttributesForHeartbeat();
          NodeStatus nodeStatus = getNodeStatus(lastHeartbeatID);
          NodeHeartbeatRequest request =
              NodeHeartbeatRequest.newInstance(nodeStatus,
                  NodeStatusUpdaterImpl.this.context
                      .getContainerTokenSecretManager().getCurrentKey(),
                  NodeStatusUpdaterImpl.this.context
                      .getNMTokenSecretManager().getCurrentKey(),
                  nodeLabelsForHeartbeat,
                  nodeAttributesForHeartbeat,
                  NodeStatusUpdaterImpl.this.context
                      .getRegisteringCollectors());

          if (logAggregationEnabled) {
            // pull log aggregation status for application running in this NM
            List<LogAggregationReport> logAggregationReports =
                getLogAggregationReportsForApps(context
                    .getLogAggregationStatusForApps());
            if (logAggregationReports != null
                && !logAggregationReports.isEmpty()) {
              request.setLogAggregationReportsForApps(logAggregationReports);
            }
          }

          request.setTokenSequenceNo(
              NodeStatusUpdaterImpl.this.tokenSequenceNo);
          response = resourceTracker.nodeHeartbeat(request);
          //get next heartbeat interval from response
          nextHeartBeatInterval = response.getNextHeartBeatInterval();
          updateMasterKeys(response);

          if (!handleShutdownOrResyncCommand(response)) {
            nodeLabelsHandler.verifyRMHeartbeatResponseForNodeLabels(
                response);
            nodeAttributesHandler
                .verifyRMHeartbeatResponseForNodeAttributes(response);

            // Explicitly put this method after checking the resync
            // response. We
            // don't want to remove the completed containers before resync
            // because these completed containers will be reported back to RM
            // when NM re-registers with RM.
            // Only remove the cleanedup containers that are acked
            removeOrTrackCompletedContainersFromContext(response
                .getContainersToBeRemovedFromNM());

            // If the last heartbeat was missed, it is possible that the
            // RM saw this one as a duplicate and did not process it.
            // If so, we can fail to notify the RM of these completed containers
            // on the next heartbeat if we clear pendingCompletedContainers.
            // If it wasn't a duplicate, the only impact is we might notify
            // the RM twice, which it can handle.
            if (!missedHearbeat) {
              pendingCompletedContainers.clear();
            } else {
              LOG.info(""skipped clearing pending completed containers due to "" +
                  ""missed heartbeat"");
              missedHearbeat = false;
            }

            logAggregationReportForAppsTempList.clear();
            lastHeartbeatID = response.getResponseId();
            List<ContainerId> containersToCleanup = response
                .getContainersToCleanup();
            if (!containersToCleanup.isEmpty()) {
              dispatcher.getEventHandler().handle(
                  new CMgrCompletedContainersEvent(containersToCleanup,
                      CMgrCompletedContainersEvent.Reason
                          .BY_RESOURCEMANAGER));
            }
            List<ApplicationId> appsToCleanup =
                response.getApplicationsToCleanup();
            //Only start tracking for keepAlive on FINISH_APP
            trackAppsForKeepAlive(appsToCleanup);
            if (!appsToCleanup.isEmpty()) {
              dispatcher.getEventHandler().handle(
                  new CMgrCompletedAppsEvent(appsToCleanup,
                      CMgrCompletedAppsEvent.Reason.BY_RESOURCEMANAGER));
            }
            Map<ApplicationId, ByteBuffer> systemCredentials =
                YarnServerBuilderUtils.convertFromProtoFormat(
                    response.getSystemCredentialsForApps());
            if (systemCredentials != null && !systemCredentials.isEmpty()) {
              ((NMContext) context).setSystemCrendentialsForApps(
                  parseCredentials(systemCredentials));
              context.getContainerManager().handleCredentialUpdate();
            }
            List<org.apache.hadoop.yarn.api.records.Container>
                containersToUpdate = response.getContainersToUpdate();
            if (!containersToUpdate.isEmpty()) {
              dispatcher.getEventHandler().handle(
                  new CMgrUpdateContainersEvent(containersToUpdate));
            }

            // SignalContainer request originally comes from end users via
            // ClientRMProtocol's SignalContainer. Forward the request to
            // ContainerManager which will dispatch the event to
            // ContainerLauncher.
            List<SignalContainerRequest> containersToSignal = response
                .getContainersToSignalList();
            if (!containersToSignal.isEmpty()) {
              dispatcher.getEventHandler().handle(
                  new CMgrSignalContainersEvent(containersToSignal));
            }

            // Update QueuingLimits if ContainerManager supports queuing
            ContainerQueuingLimit queuingLimit =
                response.getContainerQueuingLimit();
            if (queuingLimit != null) {
              context.getContainerManager().updateQueuingLimit(queuingLimit);
            }
          }
          // Handling node resource update case.
          Resource newResource = response.getResource();
          if (newResource != null) {
            updateNMResource(newResource);
            LOG.debug(""Node's resource is updated to {}"", newResource);
            if (!totalResource.equals(newResource)) {
              
---------------Reference log start----------------
LOG.info(""Node's resource is updated to {}"", newResource)
---------------Reference log end----------------
            }
          }
          if (timelineServiceV2Enabled) {
            updateTimelineCollectorData(response);
          }

          NodeStatusUpdaterImpl.this.tokenSequenceNo =
              response.getTokenSequenceNo();
        } catch (ConnectException e) {
          //catch and throw the exception if tried MAX wait time to connect RM
          dispatcher.getEventHandler().handle(
              new NodeManagerEvent(NodeManagerEventType.SHUTDOWN));
          // failed to connect to RM.
          failedToConnect = true;
          throw new YarnRuntimeException(e);
        } catch (Exception e) {

          // TODO Better error handling. Thread can die with the rest of the
          // NM still running.
          LOG.error(""Caught exception in status-updater"", e);
          missedHearbeat = true;
        } finally {
          synchronized (heartbeatMonitor) {
            nextHeartBeatInterval = nextHeartBeatInterval <= 0 ?
                YarnConfiguration.DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS :
                nextHeartBeatInterval;
            try {
              heartbeatMonitor.wait(nextHeartBeatInterval);
            } catch (InterruptedException e) {
              // Do Nothing
            }
          }
        }
      }
    }",,
hadoop,8554,"LOG.trace(""Block {}: removing from PENDING_UNCACHED for node {} "" + ""because the DataNode uncached it."", cblock.getBlockId(), datanode.getDatanodeUuid())",trace,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java/#L536,"private void rescanCachedBlockMap() {
    // Remove pendingCached blocks that will make DN out-of-capacity.
    Set<DatanodeDescriptor> datanodes =
        blockManager.getDatanodeManager().getDatanodes();
    for (DatanodeDescriptor dn : datanodes) {
      long remaining = dn.getCacheRemaining();
      for (Iterator<CachedBlock> it = dn.getPendingCached().iterator();
           it.hasNext();) {
        CachedBlock cblock = it.next();
        BlockInfo blockInfo = blockManager.
            getStoredBlock(new Block(cblock.getBlockId()));
        if (blockInfo == null) {
          // Cannot find this block on the NameNode, skip this block from
          // capacity calculation. Later logic will handle this block.
          LOG.debug(""Block {}: cannot be found in block manager and hence""
              + "" skipped from calculation for node {}."", cblock.getBlockId(),
              dn.getDatanodeUuid());
          continue;
        }
        if (blockInfo.getNumBytes() > remaining) {
          LOG.debug(""Block {}: removing from PENDING_CACHED for node {} ""
                  + ""because it cannot fit in remaining cache size {}."",
              cblock.getBlockId(), dn.getDatanodeUuid(), remaining);
          it.remove();
        } else {
          remaining -= blockInfo.getNumBytes();
        }
      }
    }
    for (Iterator<CachedBlock> cbIter = cachedBlocks.iterator();
        cbIter.hasNext(); ) {
      scannedBlocks++;
      CachedBlock cblock = cbIter.next();
      List<DatanodeDescriptor> pendingCached =
          cblock.getDatanodes(Type.PENDING_CACHED);
      List<DatanodeDescriptor> cached =
          cblock.getDatanodes(Type.CACHED);
      List<DatanodeDescriptor> pendingUncached =
          cblock.getDatanodes(Type.PENDING_UNCACHED);
      // Remove nodes from PENDING_UNCACHED if they were actually uncached.
      for (Iterator<DatanodeDescriptor> iter = pendingUncached.iterator();
          iter.hasNext(); ) {
        DatanodeDescriptor datanode = iter.next();
        if (!cblock.isInList(datanode.getCached())) {
          
---------------Reference log start----------------
LOG.trace(""Block {}: removing from PENDING_UNCACHED for node {} "" + ""because the DataNode uncached it."", cblock.getBlockId(), datanode.getDatanodeUuid())
---------------Reference log end----------------
          datanode.getPendingUncached().remove(cblock);
          iter.remove();
        }
      }
      BlockInfo blockInfo = blockManager.
            getStoredBlock(new Block(cblock.getBlockId()));
      String reason = findReasonForNotCaching(cblock, blockInfo);
      int neededCached = 0;
      if (reason != null) {
        LOG.trace(""Block {}: can't cache block because it is {}"",
            cblock.getBlockId(), reason);
      } else {
        neededCached = cblock.getReplication();
      }
      int numCached = cached.size();
      if (numCached >= neededCached) {
        // If we have enough replicas, drop all pending cached.
        for (Iterator<DatanodeDescriptor> iter = pendingCached.iterator();
            iter.hasNext(); ) {
          DatanodeDescriptor datanode = iter.next();
          datanode.getPendingCached().remove(cblock);
          iter.remove();
          LOG.trace(""Block {}: removing from PENDING_CACHED for node {} ""
                  + ""because we already have {} cached replicas and we only"" +
                  "" need {}"",
              cblock.getBlockId(), datanode.getDatanodeUuid(), numCached,
              neededCached
          );
        }
      }
      if (numCached < neededCached) {
        // If we don't have enough replicas, drop all pending uncached.
        for (Iterator<DatanodeDescriptor> iter = pendingUncached.iterator();
            iter.hasNext(); ) {
          DatanodeDescriptor datanode = iter.next();
          datanode.getPendingUncached().remove(cblock);
          iter.remove();
          LOG.trace(""Block {}: removing from PENDING_UNCACHED for node {} ""
                  + ""because we only have {} cached replicas and we need "" +
                  ""{}"", cblock.getBlockId(), datanode.getDatanodeUuid(),
              numCached, neededCached
          );
        }
      }
      int neededUncached = numCached -
          (pendingUncached.size() + neededCached);
      if (neededUncached > 0) {
        addNewPendingUncached(neededUncached, cblock, cached,
            pendingUncached);
      } else {
        int additionalCachedNeeded = neededCached -
            (numCached + pendingCached.size());
        if (additionalCachedNeeded > 0) {
          addNewPendingCached(additionalCachedNeeded, cblock, cached,
              pendingCached);
        }
      }
      if ((neededCached == 0) &&
          pendingUncached.isEmpty() &&
          pendingCached.isEmpty()) {
        // we have nothing more to do with this block.
        LOG.trace(""Block {}: removing from cachedBlocks, since neededCached ""
                + ""== 0, and pendingUncached and pendingCached are empty."",
            cblock.getBlockId()
        );
        cbIter.remove();
      }
    }
  }",,
hadoop,4929,"LOG.warn(""CleanupThread:Unable to delete path "" + context.fullPath)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/CleanupQueue.java/#L133,"public void run() {
      if (LOG.isDebugEnabled()) {
        LOG.debug(getName() + "" started."");
      }
      PathDeletionContext context = null;
      while (true) {
        try {
          context = queue.take();
          // delete the path.
          if (!deletePath(context)) {
            
---------------Reference log start----------------
LOG.warn(""CleanupThread:Unable to delete path "" + context.fullPath)
---------------Reference log end----------------
          }
          else if (LOG.isDebugEnabled()) {
            LOG.debug(""DELETED "" + context.fullPath);
          }
        } catch (InterruptedException t) {
          if (context == null) {
            LOG.warn(""Interrupted deletion of an invalid path: Path deletion ""
                + ""context is null."");
          } else {
            LOG.warn(""Interrupted deletion of "" + context.fullPath);
          }
          return;
        } catch (Exception e) {
          LOG.warn(""Error deleting path "" + context.fullPath + "": "" + e);
        } 
      }
    }",,
hadoop,6153,"LOG.warn(""src={}"" + "", datanodes[{}]={}"", getSrc(), j, datanodes[j], ie)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/FileChecksumHelper.java/#L558,"private boolean checksumBlock(LocatedBlock locatedBlock) {
      ExtendedBlock block = locatedBlock.getBlock();
      if (getRemaining() < block.getNumBytes()) {
        block.setNumBytes(getRemaining());
      }
      setRemaining(getRemaining() - block.getNumBytes());

      DatanodeInfo[] datanodes = locatedBlock.getLocations();

      int tmpTimeout = 3000 * datanodes.length +
          getClient().getConf().getSocketTimeout();
      setTimeout(tmpTimeout);

      //try each datanode location of the block
      boolean done = false;
      for (int j = 0; !done && j < datanodes.length; j++) {
        try {
          tryDatanode(locatedBlock, datanodes[j]);
          done = true;
        } catch (InvalidBlockTokenException ibte) {
          if (blockIdx > getLastRetriedIndex()) {
            LOG.debug(""Got access token error in response to OP_BLOCK_CHECKSUM ""
                    + ""for file {} for block {} from datanode {}. Will retry ""
                    + ""the block once."",
                getSrc(), block, datanodes[j]);
            setLastRetriedIndex(blockIdx);
            done = true; // actually it's not done; but we'll retry
            blockIdx--; // repeat at blockIdx-th block
            setRefetchBlocks(true);
          }
        } catch (InvalidEncryptionKeyException iee) {
          if (blockIdx > getLastRetriedIndex()) {
            LOG.debug(""Got invalid encryption key error in response to ""
                    + ""OP_BLOCK_CHECKSUM for file {} for block {} from ""
                    + ""datanode {}. Will retry "" + ""the block once."",
                  getSrc(), block, datanodes[j]);
            setLastRetriedIndex(blockIdx);
            done = true; // actually it's not done; but we'll retry
            blockIdx--; // repeat at i-th block
            getClient().clearDataEncryptionKey();
          }
        } catch (IOException ie) {
          
---------------Reference log start----------------
LOG.warn(""src={}"" + "", datanodes[{}]={}"", getSrc(), j, datanodes[j], ie)
---------------Reference log end----------------
        }
      }

      return done;
    }",,
hadoop,8585,"LOG.error(""Unresolved topology mapping. Using "" + NetworkTopology.DEFAULT_RACK + "" for host "" + node.getHostName())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java/#L989,"private String resolveNetworkLocationWithFallBackToDefaultLocation (
      DatanodeID node) {
    String networkLocation;
    try {
      networkLocation = resolveNetworkLocation(node);
    } catch (UnresolvedTopologyException e) {
      
---------------Reference log start----------------
LOG.error(""Unresolved topology mapping. Using "" + NetworkTopology.DEFAULT_RACK + "" for host "" + node.getHostName())
---------------Reference log end----------------
      networkLocation = NetworkTopology.DEFAULT_RACK;
    }
    return networkLocation;
  }",,
hadoop,7210,"NameNode.stateChangeLog.info(""STATE* Safe mode is ON.\n"" + getSafeModeTip())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java/#L5120,"void enterSafeMode(boolean resourcesLow) throws IOException {
    writeLock();
    try {
      // Stop the secret manager, since rolling the master key would
      // try to write to the edit log
      stopSecretManager();

      // Ensure that any concurrent operations have been fully synced
      // before entering safe mode. This ensures that the FSImage
      // is entirely stable on disk as soon as we're in safe mode.
      boolean isEditlogOpenForWrite = getEditLog().isOpenForWrite();
      // Before Editlog is in OpenForWrite mode, editLogStream will be null. So,
      // logSyncAll call can be called only when Edlitlog is in OpenForWrite mode
      if (isEditlogOpenForWrite) {
        getEditLog().logSyncAll();
      }
      setManualAndResourceLowSafeMode(!resourcesLow, resourcesLow);
      
---------------Reference log start----------------
NameNode.stateChangeLog.info(""STATE* Safe mode is ON.\n"" + getSafeModeTip())
---------------Reference log end----------------
    } finally {
      writeUnlock(""enterSafeMode"", getLockReportInfoSupplier(null));
    }
  }",,
hadoop,1079,"LOG.info(""Insert into the state store the policy for the queue: "" + policyConf.getQueue())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/store/impl/SQLFederationStateStore.java/#L902,"@Override
  public SetSubClusterPolicyConfigurationResponse setPolicyConfiguration(
      SetSubClusterPolicyConfigurationRequest request) throws YarnException {

    // Input validator
    FederationPolicyStoreInputValidator.validate(request);

    CallableStatement cstmt = null;

    SubClusterPolicyConfiguration policyConf = request.getPolicyConfiguration();

    try {
      cstmt = getCallableStatement(CALL_SP_SET_POLICY_CONFIGURATION);

      // Set the parameters for the stored procedure
      cstmt.setString(1, policyConf.getQueue());
      cstmt.setString(2, policyConf.getType());
      cstmt.setBytes(3, getByteArray(policyConf.getParams()));
      cstmt.registerOutParameter(4, java.sql.Types.INTEGER);

      // Execute the query
      long startTime = clock.getTime();
      cstmt.executeUpdate();
      long stopTime = clock.getTime();

      // Check the ROWCOUNT value, if it is equal to 0 it means the call
      // did not add a new policy into FederationStateStore
      if (cstmt.getInt(4) == 0) {
        String errMsg = ""The policy "" + policyConf.getQueue()
            + "" was not insert into the StateStore"";
        FederationStateStoreUtils.logAndThrowStoreException(LOG, errMsg);
      }
      // Check the ROWCOUNT value, if it is different from 1 it means the call
      // had a wrong behavior. Maybe the database is not set correctly.
      if (cstmt.getInt(4) != 1) {
        String errMsg =
            ""Wrong behavior during insert the policy "" + policyConf.getQueue();
        FederationStateStoreUtils.logAndThrowStoreException(LOG, errMsg);
      }

      
---------------Reference log start----------------
LOG.info(""Insert into the state store the policy for the queue: "" + policyConf.getQueue())
---------------Reference log end----------------
      FederationStateStoreClientMetrics
          .succeededStateStoreCall(stopTime - startTime);

    } catch (SQLException e) {
      FederationStateStoreClientMetrics.failedStateStoreCall();
      FederationStateStoreUtils.logAndThrowRetriableException(LOG,
          ""Unable to insert the newly generated policy for the queue :""
              + policyConf.getQueue(),
          e);
    } finally {
      // Return to the pool the CallableStatement
      FederationStateStoreUtils.returnToPool(LOG, cstmt);
    }
    return SetSubClusterPolicyConfigurationResponse.newInstance();
  }",,
hadoop,13069,"LOG.error(""Cannot close PowerShell script"", ioe)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/PowerShellFencer.java/#L149,"private String buildPSScript(final String processName, final String host) {
    LOG.info(
        ""Building PowerShell script to kill "" + processName + "" at "" + host);
    String ps1script = null;
    BufferedWriter writer = null;
    try {
      File file = File.createTempFile(""temp-fence-command"", "".ps1"");
      file.deleteOnExit();
      FileOutputStream fos = new FileOutputStream(file, false);
      OutputStreamWriter osw =
          new OutputStreamWriter(fos, StandardCharsets.UTF_8);
      writer = new BufferedWriter(osw);

      // Filter to identify the Namenode process
      String filter = StringUtils.join("" and "", new String[] {
          ""Name LIKE '%java.exe%'"",
          ""CommandLine LIKE '%"" + processName+ ""%'""});

      // Identify the process
      String cmd = ""Get-WmiObject Win32_Process"";
      cmd += "" -Filter \"""" + filter + ""\"""";
      // Remote location
      cmd += "" -Computer "" + host;
      // Kill it
      cmd += "" |% { $_.Terminate() }"";

      LOG.info(""PowerShell command: "" + cmd);
      writer.write(cmd);
      writer.flush();

      ps1script = file.getAbsolutePath();
    } catch (IOException ioe) {
      LOG.error(""Cannot create PowerShell script"", ioe);
    } finally {
      if (writer != null) {
        try {
          writer.close();
        } catch (IOException ioe) {
          
---------------Reference log start----------------
LOG.error(""Cannot close PowerShell script"", ioe)
---------------Reference log end----------------
        }
      }
    }
    return ps1script;
  }",,
hadoop,10494,"LOG.debug(""Creating split : "" + split + "", bytes in split: "" + currentSplitSize)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java/#L120,"private List<InputSplit> getSplits(Configuration configuration, int numSplits,
                                     long totalSizeBytes) throws IOException {
    List<InputSplit> splits = new ArrayList<InputSplit>(numSplits);
    long nBytesPerSplit = (long) Math.ceil(totalSizeBytes * 1.0 / numSplits);

    CopyListingFileStatus srcFileStatus = new CopyListingFileStatus();
    Text srcRelPath = new Text();
    long currentSplitSize = 0;
    long lastSplitStart = 0;
    long lastPosition = 0;

    final Path listingFilePath = getListingFilePath(configuration);

    if (LOG.isDebugEnabled()) {
      LOG.debug(""Average bytes per map: "" + nBytesPerSplit +
          "", Number of maps: "" + numSplits + "", total size: "" + totalSizeBytes);
    }
    SequenceFile.Reader reader=null;
    try {
      reader = getListingFileReader(configuration);
      while (reader.next(srcRelPath, srcFileStatus)) {
        // If adding the current file would cause the bytes per map to exceed
        // limit. Add the current file to new split
        if (currentSplitSize + srcFileStatus.getChunkLength() > nBytesPerSplit
            && lastPosition != 0) {
          FileSplit split = new FileSplit(listingFilePath, lastSplitStart,
              lastPosition - lastSplitStart, null);
          if (LOG.isDebugEnabled()) {
            LOG.debug (""Creating split : "" + split + "", bytes in split: "" + currentSplitSize);
          }
          splits.add(split);
          lastSplitStart = lastPosition;
          currentSplitSize = 0;
        }
        currentSplitSize += srcFileStatus.getChunkLength();
        lastPosition = reader.getPosition();
      }
      if (lastPosition > lastSplitStart) {
        FileSplit split = new FileSplit(listingFilePath, lastSplitStart,
            lastPosition - lastSplitStart, null);
        if (LOG.isDebugEnabled()) {
          
---------------Reference log start----------------
LOG.debug(""Creating split : "" + split + "", bytes in split: "" + currentSplitSize)
---------------Reference log end----------------
        }
        splits.add(split);
      }

    } finally {
      IOUtils.closeStream(reader);
    }

    return splits;
  }",,
hadoop,5160,"LOG.info(""closeInMemoryMergedFile -> size: "" + mapOutput.getSize() + "", inMemoryMergedMapOutputs.size() -> "" + inMemoryMergedMapOutputs.size())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/MergeManagerImpl.java/#L350,"public synchronized void closeInMemoryMergedFile(InMemoryMapOutput<K,V> mapOutput) {
    inMemoryMergedMapOutputs.add(mapOutput);
    
---------------Reference log start----------------
LOG.info(""closeInMemoryMergedFile -> size: "" + mapOutput.getSize() + "", inMemoryMergedMapOutputs.size() -> "" + inMemoryMergedMapOutputs.size())
---------------Reference log end----------------
  }
  }",,
hadoop,11519,"LOG.debug(""SwiftFileSystem.mkdirs: "" + path)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeFileSystem.java/#L337,"@Override
  public boolean mkdirs(Path path, FsPermission permission) throws IOException {
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""SwiftFileSystem.mkdirs: "" + path)
---------------Reference log end----------------
    }
    Path directory = makeAbsolute(path);

    //build a list of paths to create
    List<Path> paths = new ArrayList<Path>();
    while (shouldCreate(directory)) {
      //this directory needs creation, add to the list
      paths.add(0, directory);
      //now see if the parent needs to be created
      directory = directory.getParent();
    }

    //go through the list of directories to create
    for (Path p : paths) {
      if (isNotRoot(p)) {
        //perform a mkdir operation without any polling of
        //the far end first
        forceMkdir(p);
      }
    }

    //if an exception was not thrown, this operation is considered
    //a success
    return true;
  }",,
hadoop,13192,"LOG.debug(""No subject in context, logging in"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-auth/src/main/java/org/apache/hadoop/security/authentication/client/KerberosAuthenticator.java/#L305,"private void doSpnegoSequence(final AuthenticatedURL.Token token)
      throws IOException, AuthenticationException {
    try {
      AccessControlContext context = AccessController.getContext();
      Subject subject = Subject.getSubject(context);
      if (subject == null
          || (!KerberosUtil.hasKerberosKeyTab(subject)
              && !KerberosUtil.hasKerberosTicket(subject))) {
        
---------------Reference log start----------------
LOG.debug(""No subject in context, logging in"")
---------------Reference log end----------------
        subject = new Subject();
        LoginContext login = new LoginContext("""", subject,
            null, new KerberosConfiguration());
        login.login();
      }

      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using subject: "" + subject);
      }
      Subject.doAs(subject, new PrivilegedExceptionAction<Void>() {

        @Override
        public Void run() throws Exception {
          GSSContext gssContext = null;
          try {
            GSSManager gssManager = GSSManager.getInstance();
            String servicePrincipal = KerberosUtil.getServicePrincipal(""HTTP"",
                KerberosAuthenticator.this.url.getHost());
            Oid oid = KerberosUtil.NT_GSS_KRB5_PRINCIPAL_OID;
            GSSName serviceName = gssManager.createName(servicePrincipal,
                                                        oid);
            oid = KerberosUtil.GSS_KRB5_MECH_OID;
            gssContext = gssManager.createContext(serviceName, oid, null,
                                                  GSSContext.DEFAULT_LIFETIME);
            gssContext.requestCredDeleg(true);
            gssContext.requestMutualAuth(true);

            byte[] inToken = new byte[0];
            byte[] outToken;
            boolean established = false;

            // Loop while the context is still not established
            while (!established) {
              HttpURLConnection conn =
                  token.openConnection(url, connConfigurator);
              outToken = gssContext.initSecContext(inToken, 0, inToken.length);
              if (outToken != null) {
                sendToken(conn, outToken);
              }

              if (!gssContext.isEstablished()) {
                inToken = readToken(conn);
              } else {
                established = true;
              }
            }
          } finally {
            if (gssContext != null) {
              gssContext.dispose();
              gssContext = null;
            }
          }
          return null;
        }
      });
    } catch (PrivilegedActionException ex) {
      if (ex.getException() instanceof IOException) {
        throw (IOException) ex.getException();
      } else {
        throw new AuthenticationException(ex.getException());
      }
    } catch (LoginException ex) {
      throw new AuthenticationException(ex);
    }
  }",,
hadoop,6490,"LOG.info(""Purging no-longer needed file {}"", txid)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JNStorage.java/#L205,"private static void purgeMatching(File dir, List<Pattern> patterns,
      long minTxIdToKeep) throws IOException {

    for (File f : FileUtil.listFiles(dir)) {
      if (!f.isFile()) continue;
      
      for (Pattern p : patterns) {
        Matcher matcher = p.matcher(f.getName());
        if (matcher.matches()) {
          // This parsing will always succeed since the group(1) is
          // /\d+/ in the regex itself.
          long txid = Long.parseLong(matcher.group(1));
          if (txid < minTxIdToKeep) {
            
---------------Reference log start----------------
LOG.info(""Purging no-longer needed file {}"", txid)
---------------Reference log end----------------
            if (!f.delete()) {
              LOG.warn(""Unable to delete no-longer-needed data {}"", f);
            }
            break;
          }
        }
      }
    }
  }",,
hadoop,9143,"LOG.info(""Connection to the State Store driver {} is open and ready"", driverName)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/store/StateStoreService.java/#L293,"public void loadDriver() {
    synchronized (this.driver) {
      if (!isDriverReady()) {
        String driverName = this.driver.getClass().getSimpleName();
        if (this.driver.init(
            conf, getIdentifier(), getSupportedRecords(), metrics)) {
          
---------------Reference log start----------------
LOG.info(""Connection to the State Store driver {} is open and ready"", driverName)
---------------Reference log end----------------
          this.refreshCaches();
        } else {
          LOG.error(""Cannot initialize State Store driver {}"", driverName);
        }
      }
    }
  }",,
hadoop,12789,"LOG.warn(""Can't open BloomFilter: "" + ioe + "" - fallback to MapFile."")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/BloomMapFile.java/#L249,"private void initBloomFilter(Path dirName, 
                                 Configuration conf) {
      
      DataInputStream in = null;
      try {
        FileSystem fs = dirName.getFileSystem(conf);
        in = fs.open(new Path(dirName, BLOOM_FILE_NAME));
        bloomFilter = new DynamicBloomFilter();
        bloomFilter.readFields(in);
        in.close();
        in = null;
      } catch (IOException ioe) {
        
---------------Reference log start----------------
LOG.warn(""Can't open BloomFilter: "" + ioe + "" - fallback to MapFile."")
---------------Reference log end----------------
        bloomFilter = null;
      } finally {
        IOUtils.closeStream(in);
      }
    }",,
hadoop,12409,"LOG.info(prefix + "" metrics system started in standby mode"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/impl/MetricsSystemImpl.java/#L172,"@Override
  public synchronized MetricsSystem init(String prefix) {
    if (monitoring && !DefaultMetricsSystem.inMiniClusterMode()) {
      LOG.warn(this.prefix +"" metrics system already initialized!"");
      return this;
    }
    this.prefix = checkNotNull(prefix, ""prefix"");
    ++refCount;
    if (monitoring) {
      // in mini cluster mode
      LOG.info(this.prefix +"" metrics system started (again)"");
      return this;
    }
    switch (initMode()) {
      case NORMAL:
        try { start(); }
        catch (MetricsConfigException e) {
          // Configuration errors (e.g., typos) should not be fatal.
          // We can always start the metrics system later via JMX.
          LOG.warn(""Metrics system not started: ""+ e.getMessage());
          LOG.debug(""Stacktrace: "", e);
        }
        break;
      case STANDBY:
        
---------------Reference log start----------------
LOG.info(prefix + "" metrics system started in standby mode"")
---------------Reference log end----------------
    }
    initSystemMBean();
    return this;
  }",,
hadoop,3880,"LOG.info(""Recovering Reservation system"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/AbstractReservationSystem.java/#L206,"@Override
  public void recover(RMState state) throws Exception {
    
---------------Reference log start----------------
LOG.info(""Recovering Reservation system"")
---------------Reference log end----------------
    writeLock.lock();
    try {
      Map<String, Map<ReservationId, ReservationAllocationStateProto>> reservationSystemState =
          state.getReservationState();
      if (planFollower != null) {
        for (String plan : plans.keySet()) {
          // recover reservations if any from state store
          if (reservationSystemState.containsKey(plan)) {
            loadPlan(plan, reservationSystemState.get(plan));
          }
          synchronizePlan(plan, false);
        }
        startPlanFollower(conf.getLong(
            YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS,
            YarnConfiguration.DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS));
      }
    } finally {
      writeLock.unlock();
    }
  }",,
hadoop,4995,"LOG.debug(""using new api for output committer"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java/#L603,"public void initialize(JobConf job, JobID id, 
                         Reporter reporter,
                         boolean useNewApi) throws IOException, 
                                                   ClassNotFoundException,
                                                   InterruptedException {
    jobContext = new JobContextImpl(job, id, reporter);
    taskContext = new TaskAttemptContextImpl(job, taskId, reporter);
    if (getState() == TaskStatus.State.UNASSIGNED) {
      setState(TaskStatus.State.RUNNING);
    }
    if (useNewApi) {
      if (LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
LOG.debug(""using new api for output committer"")
---------------Reference log end----------------
      }
      outputFormat =
        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);
      committer = outputFormat.getOutputCommitter(taskContext);
    } else {
      committer = conf.getOutputCommitter();
    }
    Path outputPath = FileOutputFormat.getOutputPath(conf);
    if (outputPath != null) {
      if ((committer instanceof FileOutputCommitter)) {
        FileOutputFormat.setWorkOutputPath(conf, 
          ((FileOutputCommitter)committer).getTaskAttemptPath(taskContext));
      } else {
        FileOutputFormat.setWorkOutputPath(conf, outputPath);
      }
    }
    committer.setupTask(taskContext);
    Class<? extends ResourceCalculatorProcessTree> clazz =
        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PROCESS_TREE,
            null, ResourceCalculatorProcessTree.class);
    pTree = ResourceCalculatorProcessTree
            .getResourceCalculatorProcessTree(System.getenv().get(""JVM_PID""), clazz, conf);
    LOG.info("" Using ResourceCalculatorProcessTree : "" + pTree);
    if (pTree != null) {
      pTree.updateProcessTree();
      initCpuCumulativeTime = pTree.getCumulativeCpuTime();
    }
  }",,
hadoop,2376,"LOG.debug(""{} deleting {}"", container.getContainerId(), symLink.getValue())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/ContainerExecutor.java/#L804,"public void cleanupBeforeRelaunch(Container container)
      throws IOException, InterruptedException {
    if (container.getLocalizedResources() != null) {

      Map<Path, Path> symLinks = resolveSymLinks(
          container.getLocalizedResources(), container.getUser());

      for (Map.Entry<Path, Path> symLink : symLinks.entrySet()) {
        
---------------Reference log start----------------
LOG.debug(""{} deleting {}"", container.getContainerId(), symLink.getValue())
---------------Reference log end----------------
        deleteAsUser(new DeletionAsUserContext.Builder()
            .setUser(container.getUser())
            .setSubDir(symLink.getValue())
            .build());
      }
    }
  }",,
hadoop,9628,"LOGGER.warn(""Delete resource skylines for {}."", recurrenceId)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-resourceestimator/src/main/java/org/apache/hadoop/resourceestimator/skylinestore/impl/InMemoryStore.java/#L144,"@Override public final void deleteHistory(final RecurrenceId recurrenceId)
      throws SkylineStoreException {
    inputValidator.validate(recurrenceId);
    writeLock.lock();
    try {
      if (skylineStore.containsKey(recurrenceId)) {
        skylineStore.remove(recurrenceId);
        
---------------Reference log start----------------
LOGGER.warn(""Delete resource skylines for {}."", recurrenceId)
---------------Reference log end----------------
      } else {
        StringBuilder errMsg = new StringBuilder();
        errMsg.append(
            ""Trying to deleteHistory non-existing recurring pipeline  ""
                + recurrenceId + ""\'s resource skylines"");
        LOGGER.error(errMsg.toString());
        throw new RecurrenceIdNotFoundException(errMsg.toString());
      }
    } finally {
      writeLock.unlock();
    }
  }",,
hadoop,10946,"LOG.debug(""No version ID to use as a constraint"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/impl/ChangeDetectionPolicy.java/#L455,"@Override
    public void applyRevisionConstraint(GetObjectMetadataRequest request,
        String revisionId) {
      if (revisionId != null) {
        LOG.debug(""Restricting metadata request to version {}"", revisionId);
        request.withVersionId(revisionId);
      } else {
        
---------------Reference log start----------------
LOG.debug(""No version ID to use as a constraint"")
---------------Reference log end----------------
      }
    }",,
hadoop,12805,"LOG.info(""mlocking "" + identifier)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java/#L314,"public void mlock(String identifier, ByteBuffer buffer,
          long len) throws IOException {
        
---------------Reference log start----------------
LOG.info(""mlocking "" + identifier)
---------------Reference log end----------------
      }
      }",,
hadoop,11822,"LOG.debug(startupShutdownMessage(serviceName, args))",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/ServiceLauncher.java/#L289,"public void launchServiceAndExit(List<String> args) {
    StringBuilder builder = new StringBuilder();
    for (String arg : args) {
      builder.append('""').append(arg).append(""\"" "");
    }
    String argumentString = builder.toString();
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(startupShutdownMessage(serviceName, args))
---------------Reference log end----------------
      LOG.debug(argumentString);
    }
    registerFailureHandling();
    // set up the configs, using reflection to push in the -site.xml files
    loadConfigurationClasses();
    Configuration conf = createConfiguration();
    for (URL resourceUrl : confResourceUrls) {
      conf.addResource(resourceUrl);
    }
    bindCommandOptions();
    ExitUtil.ExitException exitException;
    try {
      List<String> processedArgs = extractCommandOptions(conf, args);
      exitException = launchService(conf, processedArgs, true, true);
    } catch (ExitUtil.ExitException e) {
      exitException = e;
      noteException(exitException);
    }
    if (exitException.getExitCode() == LauncherExitCodes.EXIT_USAGE) {
      // something went wrong. Print the usage and commands
      System.err.println(getUsageMessage());
      System.err.println(""Command: "" + argumentString);
    }
    System.out.flush();
    System.err.flush();
    exit(exitException);
  }",,
hadoop,3986,"LOG.warn(""Invalid file at path "" + resource.getPath().toString() + "" when a directory was expected"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-sharedcachemanager/src/main/java/org/apache/hadoop/yarn/server/sharedcachemanager/CleanerTask.java/#L165,"void process() {
    // mark the beginning of the run in the metrics
    metrics.reportCleaningStart();
    try {
      // now traverse individual directories and process them
      // the directory structure is specified by the nested level parameter
      // (e.g. 9/c/d/<checksum>)
      String pattern = SharedCacheUtil.getCacheEntryGlobPattern(nestedLevel);
      FileStatus[] resources =
          fs.globStatus(new Path(root, pattern));
      int numResources = resources == null ? 0 : resources.length;
      LOG.info(""Processing "" + numResources + "" resources in the shared cache"");
      long beginMs = System.currentTimeMillis();
      if (resources != null) {
        for (FileStatus resource : resources) {
          // check for interruption so it can abort in a timely manner in case
          // of shutdown
          if (Thread.currentThread().isInterrupted()) {
            LOG.warn(""The cleaner task was interrupted. Aborting."");
            break;
          }

          if (resource.isDirectory()) {
            processSingleResource(resource);
          } else {
            
---------------Reference log start----------------
LOG.warn(""Invalid file at path "" + resource.getPath().toString() + "" when a directory was expected"")
---------------Reference log end----------------
          }
          // add sleep time between cleaning each directory if it is non-zero
          if (sleepTime > 0) {
            Thread.sleep(sleepTime);
          }
        }
      }
      long endMs = System.currentTimeMillis();
      long durationMs = endMs - beginMs;
      LOG.info(""Processed "" + numResources + "" resource(s) in "" + durationMs +
          "" ms."");
    } catch (IOException e1) {
      LOG.error(""Unable to complete the cleaner task"", e1);
    } catch (InterruptedException e2) {
      Thread.currentThread().interrupt(); // restore the interrupt
    }
  }",,
hadoop,4445,"LOG.warn(""Ignored "" + expanded + "". It is not a directory"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/main/java/org/apache/hadoop/mapred/uploader/FrameworkUploader.java/#L164,"@VisibleForTesting
  void collectPackages() throws UploaderException {
    parseLists();
    String[] list = StringUtils.split(input, File.pathSeparatorChar);
    for (String item : list) {
      LOG.info(""Original source "" + item);
      String expanded = expandEnvironmentVariables(item, System.getenv());
      LOG.info(""Expanded source "" + expanded);
      if (expanded.endsWith(""*"")) {
        File path = new File(expanded.substring(0, expanded.length() - 1));
        if (path.isDirectory()) {
          File[] files = path.listFiles();
          if (files != null) {
            for (File jar : files) {
              if (!jar.isDirectory()) {
                addJar(jar);
              } else {
                LOG.info(""Ignored "" + jar + "" because it is a directory"");
              }
            }
          } else {
            LOG.warn(""Could not list directory "" + path);
          }
        } else {
          
---------------Reference log start----------------
LOG.warn(""Ignored "" + expanded + "". It is not a directory"")
---------------Reference log end----------------
        }
      } else if (expanded.endsWith("".jar"")) {
        File jarFile = new File(expanded);
        addJar(jarFile);
      } else if (!expanded.isEmpty()) {
        LOG.warn(""Ignored "" + expanded + "" only jars are supported"");
      }
    }
  }",,
hadoop,7681,"LOG.error(""Query plan failed. ex: {}"", ex)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java/#L87,"@Override
  public void execute(CommandLine cmd) throws Exception {
    LOG.info(""Executing \""query plan\"" command."");
    Preconditions.checkState(cmd.hasOption(DiskBalancerCLI.QUERY));
    verifyCommandOptions(DiskBalancerCLI.QUERY, cmd);
    String nodeName = cmd.getOptionValue(DiskBalancerCLI.QUERY);
    Preconditions.checkNotNull(nodeName);
    nodeName = nodeName.trim();
    String nodeAddress = nodeName;

    // if the string is not name:port format use the default port.
    if (!nodeName.matches(""[^\\:]+:[0-9]{2,5}"")) {
      int defaultIPC = NetUtils.createSocketAddr(
          getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,
              DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();
      nodeAddress = nodeName + "":"" + defaultIPC;
      LOG.debug(""Using default data node port :  {}"", nodeAddress);
    }

    ClientDatanodeProtocol dataNode = getDataNodeProxy(nodeAddress);
    try {
      DiskBalancerWorkStatus workStatus = dataNode.queryDiskBalancerPlan();
      System.out.printf(""Plan File: %s%nPlan ID: %s%nResult: %s%n"",
              workStatus.getPlanFile(),
              workStatus.getPlanID(),
              workStatus.getResult().toString());

      if (cmd.hasOption(DiskBalancerCLI.VERBOSE)) {
        System.out.printf(""%s"", workStatus.currentStateString());
      }
    } catch (DiskBalancerException ex) {
      
---------------Reference log start----------------
LOG.error(""Query plan failed. ex: {}"", ex)
---------------Reference log end----------------
      throw ex;
    }
  }",,
hadoop,6512,"LOG.debug(""Tailing edits starting from txn ID "" + fromTxnId + "" via RPC mechanism"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java/#L522,"@Override
  public void selectInputStreams(Collection<EditLogInputStream> streams,
      long fromTxnId, boolean inProgressOk,
      boolean onlyDurableTxns) throws IOException {
    // Some calls will use inProgressOK to get in-progress edits even if
    // the cache used for RPC calls is not enabled; fall back to using the
    // streaming mechanism to serve such requests
    if (inProgressOk && inProgressTailingEnabled) {
      if (LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
LOG.debug(""Tailing edits starting from txn ID "" + fromTxnId + "" via RPC mechanism"")
---------------Reference log end----------------
      }
      try {
        Collection<EditLogInputStream> rpcStreams = new ArrayList<>();
        selectRpcInputStreams(rpcStreams, fromTxnId, onlyDurableTxns);
        streams.addAll(rpcStreams);
        return;
      } catch (IOException ioe) {
        LOG.warn(""Encountered exception while tailing edits >= "" + fromTxnId +
            "" via RPC; falling back to streaming."", ioe);
      }
    }
    selectStreamingInputStreams(streams, fromTxnId, inProgressOk,
        onlyDurableTxns);
  }",,
hadoop,3707,"LOG.info(""Unknown object type passed in as config for rule {}: {}"", getName(), initArg.getClass())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/placement/FSPlacementRule.java/#L96,"@Override
  public void setConfig(Object initArg) {
    if (null == initArg) {
      LOG.debug(""Null object passed in: no config set"");
      return;
    }
    if (initArg instanceof Element) {
      LOG.debug(""Setting config from XML"");
      setConfig((Element) initArg);
    } else if (initArg instanceof Boolean) {
      LOG.debug(""Setting config from Boolean"");
      setConfig((Boolean) initArg);
    } else {
      
---------------Reference log start----------------
LOG.info(""Unknown object type passed in as config for rule {}: {}"", getName(), initArg.getClass())
---------------Reference log end----------------
    }
  }",,
hadoop,2336,"LOG.debug(""Remove collector data for done app {}"", entry.getKey())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeManager.java/#L605,"protected void reregisterCollectors() {
    Map<ApplicationId, AppCollectorData> knownCollectors
        = context.getKnownCollectors();
    if (knownCollectors == null) {
      return;
    }
    ConcurrentMap<ApplicationId, AppCollectorData> registeringCollectors
        = context.getRegisteringCollectors();
    for (Map.Entry<ApplicationId, AppCollectorData> entry
        : knownCollectors.entrySet()) {
      Application app = context.getApplications().get(entry.getKey());
      if ((app != null)
          && !ApplicationState.FINISHED.equals(app.getApplicationState())) {
        registeringCollectors.putIfAbsent(entry.getKey(), entry.getValue());
        AppCollectorData data = entry.getValue();
        LOG.debug(""{} : {}@<{}, {}>"", entry.getKey(), data.getCollectorAddr(),
            data.getRMIdentifier(), data.getVersion());
      } else {
        
---------------Reference log start----------------
LOG.debug(""Remove collector data for done app {}"", entry.getKey())
---------------Reference log end----------------
      }
    }
    knownCollectors.clear();
  }",,
hadoop,983,"LOG.debug(""NoOpTimelineReader is configured. Response to all the read "" + ""requests would be empty"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/NoOpTimelineReaderImpl.java/#L54,"@Override
  public TimelineEntity getEntity(TimelineReaderContext context,
       TimelineDataToRetrieve dataToRetrieve) throws IOException {
    
---------------Reference log start----------------
LOG.debug(""NoOpTimelineReader is configured. Response to all the read "" + ""requests would be empty"")
---------------Reference log end----------------
    return new TimelineEntity();
  }",,
hadoop,287,"log.info(""Reading config from: "" + configFile.getSrcFile() + "", writing to: "" + remoteFile)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderUtils.java/#L446,"@SuppressWarnings(""unchecked"")
  private static void resolveHadoopXmlTemplateAndSaveOnHdfs(FileSystem fs,
      Map<String, String> tokensForSubstitution, ConfigFile configFile,
      Path remoteFile, ServiceContext context) throws IOException {
    Map<String, String> conf;
    try {
      conf = (Map<String, String>) context.configCache.get(configFile);
    } catch (ExecutionException e) {
      log.info(""Failed to load config file: "" + configFile, e);
      return;
    }
    // make a copy for substitution
    org.apache.hadoop.conf.Configuration confCopy =
        new org.apache.hadoop.conf.Configuration(false);
    for (Map.Entry<String, String> entry : conf.entrySet()) {
      confCopy.set(entry.getKey(), entry.getValue());
    }
    // substitute properties
    for (Map.Entry<String, String> entry : configFile.getProperties().entrySet()) {
      confCopy.set(entry.getKey(), entry.getValue());
    }
    // substitute env variables
    for (Map.Entry<String, String> entry : confCopy) {
      String val = entry.getValue();
      if (val != null) {
        for (Map.Entry<String, String> token : tokensForSubstitution
            .entrySet()) {
          val = val.replaceAll(Pattern.quote(token.getKey()), token.getValue());
          confCopy.set(entry.getKey(), val);
        }
      }
    }
    // save on hdfs
    try (OutputStream output = fs.create(remoteFile)) {
      confCopy.writeXml(output);
      
---------------Reference log start----------------
log.info(""Reading config from: "" + configFile.getSrcFile() + "", writing to: "" + remoteFile)
---------------Reference log end----------------
    }
  }",,
hadoop,11377,"LOG.warn(""interrupted when wait copies to finish"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSFileSystem.java/#L743,"private boolean copyDirectory(Path srcPath, Path dstPath) throws IOException {
    String srcKey = AliyunOSSUtils
        .maybeAddTrailingSlash(pathToKey(srcPath));
    String dstKey = AliyunOSSUtils
        .maybeAddTrailingSlash(pathToKey(dstPath));

    if (dstKey.startsWith(srcKey)) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Cannot rename a directory to a subdirectory of self"");
      }
      return false;
    }

    store.storeEmptyFile(dstKey);
    AliyunOSSCopyFileContext copyFileContext = new AliyunOSSCopyFileContext();
    ExecutorService executorService = MoreExecutors.listeningDecorator(
        new SemaphoredDelegatingExecutor(boundedCopyThreadPool,
            maxConcurrentCopyTasksPerDir, true));
    ObjectListing objects = store.listObjects(srcKey, maxKeys, null, true);
    // Copy files from src folder to dst
    int copiesToFinish = 0;
    while (true) {
      for (OSSObjectSummary objectSummary : objects.getObjectSummaries()) {
        String newKey =
            dstKey.concat(objectSummary.getKey().substring(srcKey.length()));

        //copy operation just copies metadata, oss will support shallow copy
        executorService.execute(new AliyunOSSCopyFileTask(
            store, objectSummary.getKey(),
            objectSummary.getSize(), newKey, copyFileContext));
        copiesToFinish++;
        // No need to call lock() here.
        // It's ok to copy one more file if the rename operation failed
        // Reduce the call of lock() can also improve our performance
        if (copyFileContext.isCopyFailure()) {
          //some error occurs, break
          break;
        }
      }
      if (objects.isTruncated()) {
        String nextMarker = objects.getNextMarker();
        objects = store.listObjects(srcKey, maxKeys, nextMarker, true);
      } else {
        break;
      }
    }
    //wait operations in progress to finish
    copyFileContext.lock();
    try {
      copyFileContext.awaitAllFinish(copiesToFinish);
    } catch (InterruptedException e) {
      
---------------Reference log start----------------
LOG.warn(""interrupted when wait copies to finish"")
---------------Reference log end----------------
    } finally {
      copyFileContext.unlock();
    }
    return !copyFileContext.isCopyFailure();
  }",,
hadoop,6012,"LOG.debug(""Invocation of {} using {} was successful"", method.getName(), current.proxyInfo)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/ObserverReadProxyProvider.java/#L454,"@Override
    public Object invoke(Object proxy, final Method method, final Object[] args)
        throws Throwable {
      lastProxy = null;
      Object retVal;

      if (observerReadEnabled && shouldFindObserver() && isRead(method)) {
        if (!msynced) {
          // An msync() must first be performed to ensure that this client is
          // up-to-date with the active's state. This will only be done once.
          initializeMsync();
        } else {
          autoMsyncIfNecessary();
        }

        int failedObserverCount = 0;
        int activeCount = 0;
        int standbyCount = 0;
        int unreachableCount = 0;
        for (int i = 0; i < nameNodeProxies.size(); i++) {
          NNProxyInfo<T> current = getCurrentProxy();
          HAServiceState currState = current.getCachedState();
          if (currState != HAServiceState.OBSERVER) {
            if (currState == HAServiceState.ACTIVE) {
              activeCount++;
            } else if (currState == HAServiceState.STANDBY) {
              standbyCount++;
            } else if (currState == null) {
              unreachableCount++;
            }
            LOG.debug(""Skipping proxy {} for {} because it is in state {}"",
                current.proxyInfo, method.getName(),
                currState == null ? ""unreachable"" : currState);
            changeProxy(current);
            continue;
          }
          LOG.debug(""Attempting to service {} using proxy {}"",
              method.getName(), current.proxyInfo);
          try {
            retVal = method.invoke(current.proxy, args);
            lastProxy = current;
            
---------------Reference log start----------------
LOG.debug(""Invocation of {} using {} was successful"", method.getName(), current.proxyInfo)
---------------Reference log end----------------
            return retVal;
          } catch (InvocationTargetException ite) {
            if (!(ite.getCause() instanceof Exception)) {
              throw ite.getCause();
            }
            Exception e = (Exception) ite.getCause();
            if (e instanceof InterruptedIOException ||
                e instanceof InterruptedException) {
              // If interrupted, do not retry.
              LOG.warn(""Invocation returned interrupted exception on [{}];"",
                  current.proxyInfo, e);
              throw e;
            }
            if (e instanceof RemoteException) {
              RemoteException re = (RemoteException) e;
              Exception unwrapped = re.unwrapRemoteException(
                  ObserverRetryOnActiveException.class);
              if (unwrapped instanceof ObserverRetryOnActiveException) {
                LOG.debug(""Encountered ObserverRetryOnActiveException from {}."" +
                    "" Retry active namenode directly."", current.proxyInfo);
                break;
              }
            }
            RetryAction retryInfo = observerRetryPolicy.shouldRetry(e, 0, 0,
                method.isAnnotationPresent(Idempotent.class)
                    || method.isAnnotationPresent(AtMostOnce.class));
            if (retryInfo.action == RetryAction.RetryDecision.FAIL) {
              throw e;
            } else {
              failedObserverCount++;
              LOG.warn(
                  ""Invocation returned exception on [{}]; {} failure(s) so far"",
                  current.proxyInfo, failedObserverCount, e);
              changeProxy(current);
            }
          }
        }

        // Only log message if there are actual observer failures.
        // Getting here with failedObserverCount = 0 could
        // be that there is simply no Observer node running at all.
        if (failedObserverCount > 0) {
          // If we get here, it means all observers have failed.
          LOG.warn(""{} observers have failed for read request {}; ""
                  + ""also found {} standby, {} active, and {} unreachable. ""
                  + ""Falling back to active."", failedObserverCount,
              method.getName(), standbyCount, activeCount, unreachableCount);
          lastObserverProbeTime = 0;
        } else {
          if (LOG.isDebugEnabled()) {
            LOG.debug(""Read falling back to active without observer read ""
                + ""fail, is there no observer node running?"");
          }
          lastObserverProbeTime = Time.monotonicNow();
        }
      }

      // Either all observers have failed, observer reads are disabled,
      // or this is a write request. In any case, forward the request to
      // the active NameNode.
      LOG.debug(""Using failoverProxy to service {}"", method.getName());
      ProxyInfo<T> activeProxy = failoverProxy.getProxy();
      try {
        retVal = method.invoke(activeProxy.proxy, args);
      } catch (InvocationTargetException e) {
        // This exception will be handled by higher layers
        throw e.getCause();
      }
      // If this was reached, the request reached the active, so the
      // state is up-to-date with active and no further msync is needed.
      msynced = true;
      lastMsyncTimeMs = Time.monotonicNow();
      lastProxy = activeProxy;
      return retVal;
    }",,
hadoop,10534,"LOG.debug(""concat: result: "" + dstfs.getFileStatus(firstChunkFile))",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/CopyCommitter.java/#L639,"private void concatFileChunks(Configuration conf, Path sourceFile,
                                Path targetFile, LinkedList<Path> allChunkPaths,
                                CopyListingFileStatus srcFileStatus)
      throws IOException {
    if (allChunkPaths.size() == 1) {
      return;
    }
    if (LOG.isDebugEnabled()) {
      LOG.debug(""concat "" + targetFile + "" allChunkSize+ ""
          + allChunkPaths.size());
    }
    FileSystem dstfs = targetFile.getFileSystem(conf);
    FileSystem srcfs = sourceFile.getFileSystem(conf);

    Path firstChunkFile = allChunkPaths.removeFirst();
    Path[] restChunkFiles = new Path[allChunkPaths.size()];
    allChunkPaths.toArray(restChunkFiles);
    if (LOG.isDebugEnabled()) {
      LOG.debug(""concat: firstchunk: "" + dstfs.getFileStatus(firstChunkFile));
      int i = 0;
      for (Path f : restChunkFiles) {
        LOG.debug(""concat: other chunk: "" + i + "": "" + dstfs.getFileStatus(f));
        ++i;
      }
    }
    dstfs.concat(firstChunkFile, restChunkFiles);
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""concat: result: "" + dstfs.getFileStatus(firstChunkFile))
---------------Reference log end----------------
    }
    rename(dstfs, firstChunkFile, targetFile);
    DistCpUtils.compareFileLengthsAndChecksums(srcFileStatus.getLen(),
        srcfs, sourceFile, null, dstfs,
            targetFile, skipCrc, srcFileStatus.getLen());
  }",,
hadoop,5577,"LOG.debug(""Created ugi: {} for username: {}"", ugi, effectiveUser)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/DFSClientCache.java/#L272,"UserGroupInformation getUserGroupInformation(
          String effectiveUser,
          UserGroupInformation realUser)
          throws IOException {
    Preconditions.checkNotNull(effectiveUser);
    Preconditions.checkNotNull(realUser);
    realUser.checkTGTAndReloginFromKeytab();

    UserGroupInformation ugi =
            UserGroupInformation.createProxyUser(effectiveUser, realUser);
    
---------------Reference log start----------------
LOG.debug(""Created ugi: {} for username: {}"", ugi, effectiveUser)
---------------Reference log end----------------
    return ugi;
  }",,
hadoop,11701,"LOG.debug(""Using exact match for '"" + host + ""' and "" + privilege)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-nfs/src/main/java/org/apache/hadoop/nfs/NfsExports.java/#L402,"private static Match getMatch(String line) {
    String[] parts = line.split(""\\s+"");
    final String host;
    AccessPrivilege privilege = AccessPrivilege.READ_ONLY;
    switch (parts.length) {
    case 1:
      host = StringUtils.toLowerCase(parts[0]).trim();
      break;
    case 2:
      host = StringUtils.toLowerCase(parts[0]).trim();
      String option = parts[1].trim();
      if (""rw"".equalsIgnoreCase(option)) {
        privilege = AccessPrivilege.READ_WRITE;
      }
      break;
    default:
      throw new IllegalArgumentException(""Incorrectly formatted line '"" + line
          + ""'"");
    }
    if (host.equals(""*"")) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using match all for '"" + host + ""' and "" + privilege);
      }
      return new AnonymousMatch(privilege);
    } else if (CIDR_FORMAT_SHORT.matcher(host).matches()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using CIDR match for '"" + host + ""' and "" + privilege);
      }
      return new CIDRMatch(privilege, new SubnetUtils(host).getInfo());
    } else if (CIDR_FORMAT_LONG.matcher(host).matches()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using CIDR match for '"" + host + ""' and "" + privilege);
      }
      String[] pair = host.split(""/"");
      return new CIDRMatch(privilege,
          new SubnetUtils(pair[0], pair[1]).getInfo());
    } else if (host.contains(""*"") || host.contains(""?"") || host.contains(""["")
        || host.contains(""]"") || host.contains(""("") || host.contains("")"")) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using Regex match for '"" + host + ""' and "" + privilege);
      }
      return new RegexMatch(privilege, host);
    } else if (HOSTNAME_FORMAT.matcher(host).matches()) {
      if (LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
LOG.debug(""Using exact match for '"" + host + ""' and "" + privilege)
---------------Reference log end----------------
      }
      return new ExactMatch(privilege, host);
    } else {
      throw new IllegalArgumentException(""Invalid hostname provided '"" + host
          + ""'"");
    }
  }",,
hadoop,9873,"LOG.debug(""createFile filesystem: {} path: {} overwrite: {} permission: {} umask: {} isNamespaceEnabled: {}"", client.getFileSystem(), path, overwrite, permission, umask, isNamespaceEnabled)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java/#L501,"public OutputStream createFile(final Path path,
      final FileSystem.Statistics statistics, final boolean overwrite,
      final FsPermission permission, final FsPermission umask,
      TracingContext tracingContext) throws AzureBlobFileSystemException {
    try (AbfsPerfInfo perfInfo = startTracking(""createFile"", ""createPath"")) {
      boolean isNamespaceEnabled = getIsNamespaceEnabled(tracingContext);
      
---------------Reference log start----------------
LOG.debug(""createFile filesystem: {} path: {} overwrite: {} permission: {} umask: {} isNamespaceEnabled: {}"", client.getFileSystem(), path, overwrite, permission, umask, isNamespaceEnabled)
---------------Reference log end----------------

      String relativePath = getRelativePath(path);
      boolean isAppendBlob = false;
      if (isAppendBlobKey(path.toString())) {
        isAppendBlob = true;
      }

      // if ""fs.azure.enable.conditional.create.overwrite"" is enabled and
      // is a create request with overwrite=true, create will follow different
      // flow.
      boolean triggerConditionalCreateOverwrite = false;
      if (overwrite
          && abfsConfiguration.isConditionalCreateOverwriteEnabled()) {
        triggerConditionalCreateOverwrite = true;
      }

      AbfsRestOperation op;
      if (triggerConditionalCreateOverwrite) {
        op = conditionalCreateOverwriteFile(relativePath,
            statistics,
            isNamespaceEnabled ? getOctalNotation(permission) : null,
            isNamespaceEnabled ? getOctalNotation(umask) : null,
            isAppendBlob,
            tracingContext
        );

      } else {
        op = client.createPath(relativePath, true,
            overwrite,
            isNamespaceEnabled ? getOctalNotation(permission) : null,
            isNamespaceEnabled ? getOctalNotation(umask) : null,
            isAppendBlob,
            null,
            tracingContext);

      }
      perfInfo.registerResult(op.getResult()).registerSuccess(true);

      AbfsLease lease = maybeCreateLease(relativePath, tracingContext);

      return new AbfsOutputStream(
          client,
          statistics,
          relativePath,
          0,
          populateAbfsOutputStreamContext(isAppendBlob, lease),
          tracingContext);
    }
  }",,
hadoop,11201,"LOG.info(""Root directory {}"", p)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/AuthoritativeAuditOperation.java/#L190,"@VisibleForTesting
  Pair<Integer, Integer> executeAudit(
      final Path path,
      final boolean requireAuth,
      final boolean recursive) throws IOException {
    int dirs = 0;
    int nonauth = 0;
    final Queue<DDBPathMetadata> queue = new ArrayDeque<>();
    final boolean isRoot = path.isRoot();
    final DDBPathMetadata baseData = metastore.get(path);
    if (baseData == null) {
      throw new ExitUtil.ExitException(LauncherExitCodes.EXIT_NOT_FOUND,
          ""No S3Guard entry for path "" + path);
    }

    if (isRoot || isDirectory(baseData)) {
      // we have the root entry or an authoritative a directory
      queue.add(baseData);
    } else {
      LOG.info(""Path represents file"");
      return Pair.of(0, 0);
    }

    while (!queue.isEmpty()) {
      dirs++;
      final DDBPathMetadata dir = queue.poll();
      final Path p = dir.getFileStatus().getPath();
      LOG.debug(""Directory {}"", dir.prettyPrint());
      // log a message about the dir state, with root treated specially
      if (!p.isRoot()) {
        if (!dir.isAuthoritativeDir()) {
          LOG.warn(""Directory {} is not authoritative"", p);
          nonauth++;
          verifyAuthDir(dir, requireAuth);
        } else {
          LOG.info(""Directory {}"", p);
        }
      } else {
        // this is done to avoid the confusing message about root not being
        // authoritative
        
---------------Reference log start----------------
LOG.info(""Root directory {}"", p)
---------------Reference log end----------------
      }

      // list its children
      if (recursive) {
        final DirListingMetadata entry = metastore.listChildren(p);

        if (entry != null) {
          final Collection<PathMetadata> listing = entry.getListing();
          int files = 0, subdirs = 0;
          for (PathMetadata e : listing) {
            if (isDirectory(e)) {
              // queue for auditing
              queue.add((DDBPathMetadata) e);
              subdirs++;
            } else {
              files++;
            }
          }
          if (verbose && files > 0 || subdirs > 0) {
            LOG.info(""  files {}; directories {}"", files, subdirs);
          }
        } else {
          LOG.info(""Directory {} has been deleted"", dir);
        }
      }
    }
    // end of scan
    if (dirs == 1 && isRoot) {
      LOG.info(""The store has no directories to scan"");
    } else {
      LOG.info(""Scanned {} directories - {} were not marked as authoritative"",
          dirs, nonauth);
    }
    return Pair.of(dirs, nonauth);
  }",,
hadoop,2587,"LOG.error(""Error in removing master key with KeyID: "" + key.getKeyId())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/RMDelegationTokenSecretManager.java/#L110,"@Override
  protected void removeStoredMasterKey(DelegationKey key) {
    try {
      LOG.info(""removing master key with keyID "" + key.getKeyId());
      rm.getRMContext().getStateStore().removeRMDTMasterKey(key);
    } catch (Exception e) {
      if (!shouldIgnoreException(e)) {
        
---------------Reference log start----------------
LOG.error(""Error in removing master key with KeyID: "" + key.getKeyId())
---------------Reference log end----------------
        ExitUtil.terminate(1, e);
      }
    }
  }",,
hadoop,4571,"LOG.error(""Task: "" + taskAttemptID + "" - exited : "" + msg)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java/#L298,"@Override
  public void fatalError(TaskAttemptID taskAttemptID, String msg, boolean fastFail)
      throws IOException {
    // This happens only in Child and in the Task.
    
---------------Reference log start----------------
LOG.error(""Task: "" + taskAttemptID + "" - exited : "" + msg)
---------------Reference log end----------------
    reportDiagnosticInfo(taskAttemptID, ""Error: "" + msg);

    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID =
        TypeConverter.toYarn(taskAttemptID);

    // handling checkpoints
    preemptionPolicy.handleFailedContainer(attemptID);

    context.getEventHandler().handle(
        new TaskAttemptFailEvent(attemptID, fastFail));
  }",,
hadoop,12129,"LOG.debug(""Key with path ["" + nodeCreatePath + ""] already exists.. Updating !!"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/ZKDelegationTokenSecretManager.java/#L795,"private void addOrUpdateDelegationKey(DelegationKey key, boolean isUpdate)
      throws IOException {
    String nodeCreatePath =
        getNodePath(ZK_DTSM_MASTER_KEY_ROOT,
            DELEGATION_KEY_PREFIX + key.getKeyId());
    ByteArrayOutputStream os = new ByteArrayOutputStream();
    DataOutputStream fsOut = new DataOutputStream(os);
    if (LOG.isDebugEnabled()) {
      LOG.debug(""Storing ZKDTSMDelegationKey_"" + key.getKeyId());
    }
    key.write(fsOut);
    try {
      if (zkClient.checkExists().forPath(nodeCreatePath) != null) {
        zkClient.setData().forPath(nodeCreatePath, os.toByteArray())
            .setVersion(-1);
        if (!isUpdate) {
          
---------------Reference log start----------------
LOG.debug(""Key with path ["" + nodeCreatePath + ""] already exists.. Updating !!"")
---------------Reference log end----------------
        }
      } else {
        zkClient.create().withMode(CreateMode.PERSISTENT)
            .forPath(nodeCreatePath, os.toByteArray());
        if (isUpdate) {
          LOG.debug(""Updating non existent Key path ["" + nodeCreatePath
              + ""].. Adding new !!"");
        }
      }
    } catch (KeeperException.NodeExistsException ne) {
      LOG.debug(nodeCreatePath + "" znode already exists !!"");
    } catch (Exception ex) {
      throw new IOException(ex);
    } finally {
      os.close();
    }
  }",,
hadoop,8085,LOG.info(e.getMessage()),info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/erasurecode/StripedBlockReader.java/#L182,"@Override
      public BlockReadStats call() throws Exception {
        try {
          getReadBuffer().limit(length);
          return actualReadFromBlock();
        } catch (ChecksumException e) {
          LOG.warn(""Found Checksum error for {} from {} at {}"", block,
              source, e.getPos());
          corruptedBlocks.addCorruptedBlock(block, source);
          throw e;
        } catch (IOException e) {
          
---------------Reference log start----------------
LOG.info(e.getMessage())
---------------Reference log end----------------
          throw e;
        } finally {
          DataNodeFaultInjector.get().interceptBlockReader();
        }
      }",,
hadoop,4125,"LOG.warn(""scanner close called but scanner is null"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-1/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java/#L585,"@Override
  public void close() throws IOException {
    if (flowRunScanner != null) {
      flowRunScanner.close();
    } else {
      
---------------Reference log start----------------
LOG.warn(""scanner close called but scanner is null"")
---------------Reference log end----------------
    }
  }",,
hadoop,10606,"LOG.debug(""Application {} has one mapper finished ({})."", appId, containerId)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/appmaster/MRAMSimulator.java/#L177,"@Override
  @SuppressWarnings(""unchecked"")
  protected void processResponseQueue() throws Exception {
    while (! responseQueue.isEmpty()) {
      AllocateResponse response = responseQueue.take();

      // check completed containers
      if (! response.getCompletedContainersStatuses().isEmpty()) {
        for (ContainerStatus cs : response.getCompletedContainersStatuses()) {
          ContainerId containerId = cs.getContainerId();
          if (cs.getExitStatus() == ContainerExitStatus.SUCCESS) {
            if (assignedMaps.containsKey(containerId)) {
              
---------------Reference log start----------------
LOG.debug(""Application {} has one mapper finished ({})."", appId, containerId)
---------------Reference log end----------------
              assignedMaps.remove(containerId);
              mapFinished ++;
              finishedContainers ++;
            } else if (assignedReduces.containsKey(containerId)) {
              LOG.debug(""Application {} has one reducer finished ({})."",
                  appId, containerId);
              assignedReduces.remove(containerId);
              reduceFinished ++;
              finishedContainers ++;
            } else if (amContainer.getId().equals(containerId)){
              // am container released event
              isFinished = true;
              LOG.info(""Application {} goes to finish."", appId);
            }

            if (mapFinished >= mapTotal && reduceFinished >= reduceTotal) {
              lastStep();
            }
          } else {
            // container to be killed
            if (assignedMaps.containsKey(containerId)) {
              LOG.debug(""Application {} has one mapper killed ({})."",
                  appId, containerId);
              pendingFailedMaps.add(assignedMaps.remove(containerId));
            } else if (assignedReduces.containsKey(containerId)) {
              LOG.debug(""Application {} has one reducer killed ({})."",
                  appId, containerId);
              pendingFailedReduces.add(assignedReduces.remove(containerId));
            } else if (amContainer.getId().equals(containerId)){
              LOG.info(""Application {}'s AM is "" +
                  ""going to be killed. Waiting for rescheduling..."", appId);
            }
          }
        }
      }

      // check finished
      if (isAMContainerRunning &&
              (mapFinished >= mapTotal) &&
              (reduceFinished >= reduceTotal)) {
        isAMContainerRunning = false;
        LOG.debug(""Application {} sends out event to clean up""
            + "" its AM container."", appId);
        isFinished = true;
        break;
      }

      // check allocated containers
      for (Container container : response.getAllocatedContainers()) {
        if (! scheduledMaps.isEmpty()) {
          ContainerSimulator cs = scheduledMaps.remove();
          LOG.debug(""Application {} starts to launch a mapper ({})."",
              appId, container.getId());
          assignedMaps.put(container.getId(), cs);
          se.getNmMap().get(container.getNodeId())
                  .addNewContainer(container, cs.getLifeTime());
        } else if (! this.scheduledReduces.isEmpty()) {
          ContainerSimulator cs = scheduledReduces.remove();
          LOG.debug(""Application {} starts to launch a reducer ({})."",
              appId, container.getId());
          assignedReduces.put(container.getId(), cs);
          se.getNmMap().get(container.getNodeId())
                  .addNewContainer(container, cs.getLifeTime());
        }
      }
    }
  }",,
hadoop,7721,"LOG.trace(s1, t)",trace,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java/#L315,"@Override
  public void run() {
    int opsProcessed = 0;
    Op op = null;

    try {
      synchronized(this) {
        xceiver = Thread.currentThread();
      }
      dataXceiverServer.addPeer(peer, Thread.currentThread(), this);
      peer.setWriteTimeout(datanode.getDnConf().socketWriteTimeout);
      InputStream input = socketIn;
      try {
        IOStreamPair saslStreams = datanode.saslServer.receive(peer, socketOut,
          socketIn, datanode.getXferAddress().getPort(),
          datanode.getDatanodeId());
        input = new BufferedInputStream(saslStreams.in,
            smallBufferSize);
        socketOut = saslStreams.out;
      } catch (InvalidMagicNumberException imne) {
        if (imne.isHandshake4Encryption()) {
          LOG.info(""Failed to read expected encryption handshake from client "" +
              ""at {}. Perhaps the client "" +
              ""is running an older version of Hadoop which does not support "" +
              ""encryption"", peer.getRemoteAddressString(), imne);
        } else {
          LOG.info(""Failed to read expected SASL data transfer protection "" +
              ""handshake from client at {}"" +
              "". Perhaps the client is running an older version of Hadoop "" +
              ""which does not support SASL data transfer protection"",
              peer.getRemoteAddressString(), imne);
        }
        return;
      }
      
      super.initialize(new DataInputStream(input));
      
      // We process requests in a loop, and stay around for a short timeout.
      // This optimistic behaviour allows the other end to reuse connections.
      // Setting keepalive timeout to 0 disable this behavior.
      do {
        updateCurrentThreadName(""Waiting for operation #"" + (opsProcessed + 1));

        try {
          if (opsProcessed != 0) {
            assert dnConf.socketKeepaliveTimeout > 0;
            peer.setReadTimeout(dnConf.socketKeepaliveTimeout);
          } else {
            peer.setReadTimeout(dnConf.socketTimeout);
          }
          op = readOp();
        } catch (InterruptedIOException ignored) {
          // Time out while we wait for client rpc
          break;
        } catch (EOFException | ClosedChannelException e) {
          // Since we optimistically expect the next op, it's quite normal to
          // get EOF here.
          LOG.debug(""Cached {} closing after {} ops.  "" +
              ""This message is usually benign."", peer, opsProcessed);
          break;
        } catch (IOException err) {
          incrDatanodeNetworkErrors();
          throw err;
        }

        // restore normal timeout
        if (opsProcessed != 0) {
          peer.setReadTimeout(dnConf.socketTimeout);
        }

        opStartTime = monotonicNow();
        processOp(op);
        ++opsProcessed;
      } while ((peer != null) &&
          (!peer.isClosed() && dnConf.socketKeepaliveTimeout > 0));
    } catch (Throwable t) {
      String s = datanode.getDisplayName() + "":DataXceiver error processing ""
          + ((op == null) ? ""unknown"" : op.name()) + "" operation ""
          + "" src: "" + remoteAddress + "" dst: "" + localAddress;
      if (op == Op.WRITE_BLOCK && t instanceof ReplicaAlreadyExistsException) {
        // For WRITE_BLOCK, it is okay if the replica already exists since
        // client and replication may write the same block to the same datanode
        // at the same time.
        if (LOG.isTraceEnabled()) {
          LOG.trace(s, t);
        } else {
          LOG.info(""{}; {}"", s, t.toString());
        }
      } else if (op == Op.READ_BLOCK && t instanceof SocketTimeoutException) {
        String s1 =
            ""Likely the client has stopped reading, disconnecting it"";
        s1 += "" ("" + s + "")"";
        if (LOG.isTraceEnabled()) {
          
---------------Reference log start----------------
LOG.trace(s1, t)
---------------Reference log end----------------
        } else {
          LOG.info(""{}; {}"", s1, t.toString());
        }
      } else if (t instanceof InvalidToken ||
          t.getCause() instanceof InvalidToken) {
        // The InvalidToken exception has already been logged in
        // checkAccess() method and this is not a server error.
        LOG.trace(s, t);
      } else {
        LOG.error(s, t);
      }
    } finally {
      collectThreadLocalStates();
      LOG.debug(""{}:Number of active connections is: {}"",
          datanode.getDisplayName(), datanode.getXceiverCount());
      updateCurrentThreadName(""Cleaning up"");
      if (peer != null) {
        dataXceiverServer.closePeer(peer);
        IOUtils.closeStream(in);
      }
    }
  }",,
hadoop,3252,"LOG.debug(""Added container="" + containerId + "" with tags=["" + StringUtils.join(allocationTags, "","") + ""]"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java/#L355,"@SuppressWarnings(""unchecked"")
  public void addContainer(NodeId nodeId, ContainerId containerId,
      Set<String> allocationTags) {
    // Do nothing for empty allocation tags.
    if (allocationTags == null || allocationTags.isEmpty()) {
      return;
    }
    ApplicationId applicationId =
        containerId.getApplicationAttemptId().getApplicationId();
    addTags(nodeId, applicationId, allocationTags);
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""Added container="" + containerId + "" with tags=["" + StringUtils.join(allocationTags, "","") + ""]"")
---------------Reference log end----------------
    }
  }",,
hadoop,8170,"LOG.warn(""Got a command from standby NN - ignoring command:"" + cmd.getAction())",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPOfferService.java/#L832,"private boolean processCommandFromStandby(DatanodeCommand cmd,
      BPServiceActor actor) throws IOException {
    switch(cmd.getAction()) {
    case DatanodeProtocol.DNA_ACCESSKEYUPDATE:
      LOG.info(""DatanodeCommand action from standby: DNA_ACCESSKEYUPDATE"");
      if (dn.isBlockTokenEnabled) {
        dn.blockPoolTokenSecretManager.addKeys(
            getBlockPoolId(), 
            ((KeyUpdateCommand) cmd).getExportedKeys());
      }
      break;
    case DatanodeProtocol.DNA_TRANSFER:
    case DatanodeProtocol.DNA_INVALIDATE:
    case DatanodeProtocol.DNA_SHUTDOWN:
    case DatanodeProtocol.DNA_FINALIZE:
    case DatanodeProtocol.DNA_RECOVERBLOCK:
    case DatanodeProtocol.DNA_BALANCERBANDWIDTHUPDATE:
    case DatanodeProtocol.DNA_CACHE:
    case DatanodeProtocol.DNA_UNCACHE:
    case DatanodeProtocol.DNA_ERASURE_CODING_RECONSTRUCTION:
      
---------------Reference log start----------------
LOG.warn(""Got a command from standby NN - ignoring command:"" + cmd.getAction())
---------------Reference log end----------------
      break;
    default:
      LOG.warn(""Unknown DatanodeCommand action: "" + cmd.getAction());
    }
    return true;
  }",,
hadoop,662,"LOG.info(""Waiting for Client to exit loop"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java/#L1411,"@VisibleForTesting
  protected void sendStopSignal() {
    LOG.info(""Sending stop Signal to Client"");
    stopSignalReceived.set(true);
    synchronized (objectLock) {
      objectLock.notifyAll();
    }
    int waitCount = 0;
    
---------------Reference log start----------------
LOG.info(""Waiting for Client to exit loop"")
---------------Reference log end----------------
    while (isRunning.get()) {
      try {
        Thread.sleep(50);
      } catch (InterruptedException ie) {
        // do nothing
      } finally {
        if (++waitCount > 2000) {
          break;
        }
      }
    }
    LOG.info(""Stopping yarnClient within the DS Client"");
    yarnClient.stop();
    LOG.info(""done stopping Client"");
  }",,
hadoop,9169,"LOG.debug(""Not updating {}"", record)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java/#L339,"@Override
  public <T extends BaseRecord> boolean putAll(
      List<T> records, boolean allowUpdate, boolean errorIfExists)
          throws StateStoreUnavailableException {
    verifyDriverReady();
    if (records.isEmpty()) {
      return true;
    }

    long start = monotonicNow();
    StateStoreMetrics metrics = getMetrics();

    // Check if any record exists
    Map<String, T> toWrite = new HashMap<>();
    for (T record : records) {
      Class<? extends BaseRecord> recordClass = record.getClass();
      String path = getPathForClass(recordClass);
      String primaryKey = getPrimaryKey(record);
      String recordPath = path + ""/"" + primaryKey;

      if (exists(recordPath)) {
        if (allowUpdate) {
          // Update the mod time stamp. Many backends will use their
          // own timestamp for the mod time.
          record.setDateModified(this.getTime());
          toWrite.put(recordPath, record);
        } else if (errorIfExists) {
          LOG.error(""Attempt to insert record {} that already exists"",
              recordPath);
          if (metrics != null) {
            metrics.addFailure(monotonicNow() - start);
          }
          return false;
        } else  {
          
---------------Reference log start----------------
LOG.debug(""Not updating {}"", record)
---------------Reference log end----------------
        }
      } else {
        toWrite.put(recordPath, record);
      }
    }

    // Write the records
    boolean success = true;
    for (Entry<String, T> entry : toWrite.entrySet()) {
      String recordPath = entry.getKey();
      String recordPathTemp = recordPath + ""."" + now() + TMP_MARK;
      BufferedWriter writer = getWriter(recordPathTemp);
      try {
        T record = entry.getValue();
        String line = serializeString(record);
        writer.write(line);
      } catch (IOException e) {
        LOG.error(""Cannot write {}"", recordPathTemp, e);
        success = false;
      } finally {
        if (writer != null) {
          try {
            writer.close();
          } catch (IOException e) {
            LOG.error(""Cannot close the writer for {}"", recordPathTemp, e);
          }
        }
      }
      // Commit
      if (!rename(recordPathTemp, recordPath)) {
        LOG.error(""Failed committing record into {}"", recordPath);
        success = false;
      }
    }

    long end = monotonicNow();
    if (metrics != null) {
      if (success) {
        metrics.addWrite(end - start);
      } else {
        metrics.addFailure(end - start);
      }
    }
    return success;
  }",,
hadoop,11070,"LOG.debug(""Found root directory"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java/#L3741,"@VisibleForTesting
  @Retries.RetryTranslated
  S3AFileStatus s3GetFileStatus(final Path path,
      final String key,
      final Set<StatusProbeEnum> probes,
      @Nullable final Set<Path> tombstones,
      final boolean needEmptyDirectoryFlag) throws IOException {
    LOG.debug(""S3GetFileStatus {}"", path);
    // either you aren't looking for the directory flag, or you are,
    // and if you are, the probe list must contain list.
    Preconditions.checkArgument(!needEmptyDirectoryFlag
        || probes.contains(StatusProbeEnum.List),
        ""s3GetFileStatus(%s) wants to know if a directory is empty but""
            + "" does not request a list probe"", path);

    if (key.isEmpty() && !needEmptyDirectoryFlag) {
      return new S3AFileStatus(Tristate.UNKNOWN, path, username);
    }

    if (!key.isEmpty() && !key.endsWith(""/"")
        && probes.contains(StatusProbeEnum.Head)) {
      try {
        // look for the simple file
        ObjectMetadata meta = getObjectMetadata(key);
        LOG.debug(""Found exact file: normal file {}"", key);
        return new S3AFileStatus(meta.getContentLength(),
            dateToLong(meta.getLastModified()),
            path,
            getDefaultBlockSize(path),
            username,
            meta.getETag(),
            meta.getVersionId());
      } catch (AmazonServiceException e) {
        // if the response is a 404 error, it just means that there is
        // no file at that path...the remaining checks will be needed.
        if (e.getStatusCode() != SC_404 || isUnknownBucket(e)) {
          throw translateException(""getFileStatus"", path, e);
        }
      } catch (AmazonClientException e) {
        throw translateException(""getFileStatus"", path, e);
      }
    }

    // execute the list
    if (probes.contains(StatusProbeEnum.List)) {
      try {
        // this will find a marker dir / as well as an entry.
        // When making a simple ""is this a dir check"" all is good.
        // but when looking for an empty dir, we need to verify there are no
        // children, so ask for two entries, so as to find
        // a child
        String dirKey = maybeAddTrailingSlash(key);
        // list size is dir marker + at least one non-tombstone entry
        // there's a corner case: more tombstones than you have in a
        // single page list. We assume that if you have been deleting
        // that many files, then the AWS listing will have purged some
        // by the time of listing so that the response includes some
        // which have not.

        int listSize;
        if (tombstones == null) {
          // no tombstones so look for a marker and at least one child.
          listSize = 2;
        } else {
          // build a listing > tombstones. If the caller has many thousands
          // of tombstones this won't work properly, which is why pruning
          // of expired tombstones matters.
          listSize = Math.min(2 + tombstones.size(), Math.max(2, maxKeys));
        }
        S3ListRequest request = createListObjectsRequest(dirKey, ""/"",
            listSize);
        // execute the request
        S3ListResult listResult = listObjects(request,
            getDurationTrackerFactory());

        if (listResult.hasPrefixesOrObjects(contextAccessors, tombstones)) {
          if (LOG.isDebugEnabled()) {
            LOG.debug(""Found path as directory (with /)"");
            listResult.logAtDebug(LOG);
          }
          // At least one entry has been found.
          // If looking for an empty directory, the marker must exist but no
          // children.
          // So the listing must contain the marker entry only.
          if (needEmptyDirectoryFlag
              && listResult.representsEmptyDirectory(
                  contextAccessors, dirKey, tombstones)) {
            return new S3AFileStatus(Tristate.TRUE, path, username);
          }
          // either an empty directory is not needed, or the
          // listing does not meet the requirements.
          return new S3AFileStatus(Tristate.FALSE, path, username);
        } else if (key.isEmpty()) {
          
---------------Reference log start----------------
LOG.debug(""Found root directory"")
---------------Reference log end----------------
          return new S3AFileStatus(Tristate.TRUE, path, username);
        }
      } catch (AmazonServiceException e) {
        if (e.getStatusCode() != SC_404 || isUnknownBucket(e)) {
          throw translateException(""getFileStatus"", path, e);
        }
      } catch (AmazonClientException e) {
        throw translateException(""getFileStatus"", path, e);
      }
    }

    LOG.debug(""Not Found: {}"", path);
    throw new FileNotFoundException(""No such file or directory: "" + path);
  }",,
hadoop,8180,"LOG.info(""Generated new storageID {} for directory {} {}"", sd.getStorageUuid(), sd.getRoot(), (oldStorageID == null ? """" : ("" to replace "" + oldStorageID)))",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataStorage.java/#L160,"public static boolean createStorageID(
      StorageDirectory sd, boolean regenerateStorageIds, Configuration conf) {
    final String oldStorageID = sd.getStorageUuid();
    if (sd.getStorageLocation() != null &&
        sd.getStorageLocation().getStorageType() == StorageType.PROVIDED) {
      // Only one provided storage id is supported.
      // TODO support multiple provided storage ids
      sd.setStorageUuid(conf.get(DFSConfigKeys.DFS_PROVIDER_STORAGEUUID,
          DFSConfigKeys.DFS_PROVIDER_STORAGEUUID_DEFAULT));
      return false;
    }
    if (oldStorageID == null || regenerateStorageIds) {
      sd.setStorageUuid(DatanodeStorage.generateUuid());
      
---------------Reference log start----------------
LOG.info(""Generated new storageID {} for directory {} {}"", sd.getStorageUuid(), sd.getRoot(), (oldStorageID == null ? """" : ("" to replace "" + oldStorageID)))
---------------Reference log end----------------
      return true;
    }
    return false;
  }",,
hadoop,4489,"LOG.info(""Storing state DB schema version info "" + getCurrentVersion())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java/#L719,"private void checkVersion() throws IOException {
    Version loadedVersion = loadVersion();
    LOG.info(""Loaded state DB schema version info "" + loadedVersion);
    if (loadedVersion.equals(getCurrentVersion())) {
      return;
    }
    if (loadedVersion.isCompatibleTo(getCurrentVersion())) {
      
---------------Reference log start----------------
LOG.info(""Storing state DB schema version info "" + getCurrentVersion())
---------------Reference log end----------------
      storeVersion();
    } else {
      throw new IOException(
        ""Incompatible version for state DB schema: expecting DB schema version "" 
            + getCurrentVersion() + "", but loading version "" + loadedVersion);
    }
  }",,
hadoop,2220,"LOG.info(""Activating next master key with id: "" + this.nextMasterKey.getMasterKey().getKeyId())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/amrmproxy/AMRMProxyTokenSecretManager.java/#L182,"@Private
  @VisibleForTesting
  public void activateNextMasterKey() {
    this.writeLock.lock();
    try {
      
---------------Reference log start----------------
LOG.info(""Activating next master key with id: "" + this.nextMasterKey.getMasterKey().getKeyId())
---------------Reference log end----------------
      this.currentMasterKey = this.nextMasterKey;
      this.nextMasterKey = null;
      if (this.nmStateStore != null) {
        try {
          this.nmStateStore.storeAMRMProxyCurrentMasterKey(
              this.currentMasterKey.getMasterKey());
          this.nmStateStore.storeAMRMProxyNextMasterKey(null);
        } catch (IOException e) {
          LOG.error(""Unable to update current master key in state store"", e);
        }
      }
    } finally {
      this.writeLock.unlock();
    }
  }",,
hadoop,1238,"LOG.debug(""Bootstrapping resource handler chain: {}"", resourceHandlerChain)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/LinuxContainerExecutor.java/#L347,"@Override
  public void init(Context context) throws IOException {
    Configuration conf = super.getConf();
    this.nmContext = context;

    // Send command to executor which will just start up,
    // verify configuration/permissions and exit
    try {
      PrivilegedOperation checkSetupOp = new PrivilegedOperation(
          PrivilegedOperation.OperationType.CHECK_SETUP);
      PrivilegedOperationExecutor privilegedOperationExecutor =
          getPrivilegedOperationExecutor();

      privilegedOperationExecutor.executePrivilegedOperation(checkSetupOp,
          false);
    } catch (PrivilegedOperationException e) {
      int exitCode = e.getExitCode();
      LOG.warn(""Exit code from container executor initialization is : {}"",
          exitCode, e);

      throw new IOException(""Linux container executor not configured properly""
          + "" (error="" + exitCode + "")"", e);
    }

    try {
      resourceHandlerChain = ResourceHandlerModule
          .getConfiguredResourceHandlerChain(conf, nmContext);
      LOG.debug(""Resource handler chain enabled = {}"",
          (resourceHandlerChain != null));
      if (resourceHandlerChain != null) {
        
---------------Reference log start----------------
LOG.debug(""Bootstrapping resource handler chain: {}"", resourceHandlerChain)
---------------Reference log end----------------
        resourceHandlerChain.bootstrap(conf);
      }
    } catch (ResourceHandlerException e) {
      LOG.error(""Failed to bootstrap configured resource subsystems! "", e);
      throw new IOException(
          ""Failed to bootstrap configured resource subsystems!"");
    }

    try {
      if (linuxContainerRuntime == null) {
        LinuxContainerRuntime runtime = new DelegatingLinuxContainerRuntime();

        runtime.initialize(conf, nmContext);
        this.linuxContainerRuntime = runtime;
      }
    } catch (ContainerExecutionException e) {
      LOG.error(""Failed to initialize linux container runtime(s)!"", e);
      throw new IOException(""Failed to initialize linux container runtime(s)!"");
    }

    resourcesHandler.init(this);
  }",,
hadoop,1191,"LOG.error(""Failed to kill unmanaged application master"", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/uam/UnmanagedAMPoolManager.java/#L123,"@Override
        public KillApplicationResponse call() throws Exception {
          try {
            LOG.info(""Force-killing UAM id "" + uamId + "" for application ""
                + appIdMap.get(uamId));
            return unmanagedAppMasterMap.remove(uamId).forceKillApplication();
          } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Failed to kill unmanaged application master"", e)
---------------Reference log end----------------
            return null;
          }
        }",,
hadoop,8509,"LOG.warn(""The volume[{}] with the available space (={} B) is "" + ""less than the block size (={} B)."", volume.getBaseURI(), availableVolumeSize, blockSize)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/RoundRobinVolumeChoosingPolicy.java/#L100,"private V chooseVolume(final int curVolumeIndex, final List<V> volumes,
                         long blockSize) throws IOException {
    // since volumes could've been removed because of the failure
    // make sure we are not out of bounds
    int curVolume = curVolumes[curVolumeIndex] < volumes.size()
            ? curVolumes[curVolumeIndex] : 0;

    int startVolume = curVolume;
    long maxAvailable = 0;

    while (true) {
      final V volume = volumes.get(curVolume);
      curVolume = (curVolume + 1) % volumes.size();
      long availableVolumeSize = volume.getAvailable();
      if (availableVolumeSize > blockSize) {
        curVolumes[curVolumeIndex] = curVolume;
        return volume;
      }

      if (availableVolumeSize > maxAvailable) {
        maxAvailable = availableVolumeSize;
      }

      if (curVolume == startVolume) {
        throw new DiskOutOfSpaceException(""Out of space: ""
            + ""The volume with the most available space (="" + maxAvailable
            + "" B) is less than the block size (="" + blockSize + "" B)."");
      } else {
        
---------------Reference log start----------------
LOG.warn(""The volume[{}] with the available space (={} B) is "" + ""less than the block size (={} B)."", volume.getBaseURI(), availableVolumeSize, blockSize)
---------------Reference log end----------------
      }
    }
  }",,
hadoop,8482,"LOG.info(""updateReplica: "" + oldBlock + "", recoveryId="" + recoveryId + "", length="" + newlength + "", replica="" + replica)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetImpl.java/#L2954,"@Override // FsDatasetSpi
  public Replica updateReplicaUnderRecovery(
                                    final ExtendedBlock oldBlock,
                                    final long recoveryId,
                                    final long newBlockId,
                                    final long newlength) throws IOException {
    long startTimeMs = Time.monotonicNow();
    try (AutoCloseableLock lock = datasetWriteLock.acquire()) {
      //get replica
      final String bpid = oldBlock.getBlockPoolId();
      final ReplicaInfo replica = volumeMap.get(bpid, oldBlock.getBlockId());
      
---------------Reference log start----------------
LOG.info(""updateReplica: "" + oldBlock + "", recoveryId="" + recoveryId + "", length="" + newlength + "", replica="" + replica)
---------------Reference log end----------------

      //check replica
      if (replica == null) {
        throw new ReplicaNotFoundException(oldBlock);
      }

      //check replica state
      if (replica.getState() != ReplicaState.RUR) {
        throw new IOException(""replica.getState() != "" + ReplicaState.RUR
            + "", replica="" + replica);
      }

      //check replica's byte on disk
      if (replica.getBytesOnDisk() != oldBlock.getNumBytes()) {
        throw new IOException(""THIS IS NOT SUPPOSED TO HAPPEN:""
            + "" replica.getBytesOnDisk() != block.getNumBytes(), block=""
            + oldBlock + "", replica="" + replica);
      }

      //check replica files before update
      checkReplicaFiles(replica);

      //update replica
      final ReplicaInfo finalized = updateReplicaUnderRecovery(oldBlock
          .getBlockPoolId(), replica, recoveryId,
          newBlockId, newlength);

      boolean copyTruncate = newBlockId != oldBlock.getBlockId();
      if (!copyTruncate) {
        assert finalized.getBlockId() == oldBlock.getBlockId()
            && finalized.getGenerationStamp() == recoveryId
            && finalized.getNumBytes() == newlength
            : ""Replica information mismatched: oldBlock="" + oldBlock
            + "", recoveryId="" + recoveryId + "", newlength="" + newlength
            + "", newBlockId="" + newBlockId + "", finalized="" + finalized;
      } else {
        assert finalized.getBlockId() == oldBlock.getBlockId()
            && finalized.getGenerationStamp() == oldBlock.getGenerationStamp()
            && finalized.getNumBytes() == oldBlock.getNumBytes()
            : ""Finalized and old information mismatched: oldBlock="" + oldBlock
            + "", genStamp="" + oldBlock.getGenerationStamp()
            + "", len="" + oldBlock.getNumBytes()
            + "", finalized="" + finalized;
      }
      //check replica files after update
      checkReplicaFiles(finalized);

      return finalized;
    } finally {
      if (dataNodeMetrics != null) {
        long updateReplicaUnderRecoveryMs = Time.monotonicNow() - startTimeMs;
        dataNodeMetrics.addUpdateReplicaUnderRecoveryOp(
            updateReplicaUnderRecoveryMs);
      }
    }
  }",,
hadoop,4393,"LOG.error(""Error getting logs for "" + logEntity, e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/tfile/TFileAggregatedLogsBlock.java/#L126,"@Override
  protected void render(Block html) {

    BlockParameters params = verifyAndParseParameters(html);
    if (params == null) {
      return;
    }

    RemoteIterator<FileStatus> nodeFiles;
    try {
      nodeFiles = LogAggregationUtils
          .getRemoteNodeFileDir(conf, params.getAppId(),
          params.getAppOwner(), remoteRootLogDir, remoteRootLogDirSuffix);
    } catch (RuntimeException e) {
      throw e;
    } catch (Exception ex) {
      html.h1(""No logs available for container ""
          + params.getContainerId().toString());
      return;
    }

    NodeId nodeId = params.getNodeId();
    String logEntity = params.getLogEntity();
    ApplicationId appId = params.getAppId();
    ContainerId containerId = params.getContainerId();
    long start = params.getStartIndex();
    long end = params.getEndIndex();
    long startTime = params.getStartTime();
    long endTime = params.getEndTime();

    boolean foundLog = false;
    String desiredLogType = $(CONTAINER_LOG_TYPE);
    try {
      while (nodeFiles.hasNext()) {
        AggregatedLogFormat.LogReader reader = null;
        try {
          FileStatus thisNodeFile = nodeFiles.next();
          if (thisNodeFile.getPath().getName().equals(
              params.getAppId() + "".har"")) {
            Path p = new Path(""har:///""
                + thisNodeFile.getPath().toUri().getRawPath());
            nodeFiles = HarFs.get(p.toUri(), conf).listStatusIterator(p);
            continue;
          }
          if (!thisNodeFile.getPath().getName()
              .contains(LogAggregationUtils.getNodeString(nodeId))
              || thisNodeFile.getPath().getName()
                  .endsWith(LogAggregationUtils.TMP_FILE_SUFFIX)) {
            continue;
          }
          long logUploadedTime = thisNodeFile.getModificationTime();
          if (logUploadedTime < startTime || logUploadedTime > endTime) {
            continue;
          }
          reader = new AggregatedLogFormat.LogReader(
              conf, thisNodeFile.getPath());

          String owner = null;
          Map<ApplicationAccessType, String> appAcls = null;
          try {
            owner = reader.getApplicationOwner();
            appAcls = reader.getApplicationAcls();
          } catch (IOException e) {
            
---------------Reference log start----------------
LOG.error(""Error getting logs for "" + logEntity, e)
---------------Reference log end----------------
            continue;
          }
          String remoteUser = request().getRemoteUser();

          if (!checkAcls(conf, appId, owner, appAcls, remoteUser)) {
            html.h1().__(""User ["" + remoteUser
                + ""] is not authorized to view the logs for "" + logEntity
                + "" in log file ["" + thisNodeFile.getPath().getName() + ""]"")
                .__();
            LOG.error(""User ["" + remoteUser
                + ""] is not authorized to view the logs for "" + logEntity);
            continue;
          }

          AggregatedLogFormat.ContainerLogsReader logReader = reader
              .getContainerLogsReader(containerId);
          if (logReader == null) {
            continue;
          }

          foundLog = readContainerLogs(html, logReader, start, end,
              desiredLogType, logUploadedTime, startTime, endTime);
        } catch (IOException ex) {
          LOG.error(""Error getting logs for "" + logEntity, ex);
          continue;
        } finally {
          if (reader != null) {
            reader.close();
          }
        }
      }
      if (!foundLog) {
        if (desiredLogType.isEmpty()) {
          html.h1(""No logs available for container ""
              + containerId.toString());
        } else {
          html.h1(""Unable to locate '"" + desiredLogType
              + ""' log for container "" + containerId.toString());
        }
      }
    } catch (IOException e) {
      html.h1().__(""Error getting logs for "" + logEntity).__();
      LOG.error(""Error getting logs for "" + logEntity, e);
    }
  }",,
hadoop,10627,"LOG.error(""Caught exception from allocate"", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/SLSFairScheduler.java/#L116,"@Override
  public Allocation allocate(ApplicationAttemptId attemptId,
      List<ResourceRequest> resourceRequests,
      List<SchedulingRequest> schedulingRequests, List<ContainerId> containerIds,
      List<String> blacklistAdditions, List<String> blacklistRemovals,
      ContainerUpdates updateRequests) {
    if (metricsON) {
      final Timer.Context context = schedulerMetrics.getSchedulerAllocateTimer()
          .time();
      Allocation allocation = null;
      try {
        allocation = super.allocate(attemptId, resourceRequests,
            schedulingRequests, containerIds,
            blacklistAdditions, blacklistRemovals, updateRequests);
        return allocation;
      } catch (Exception e) {
        
---------------Reference log start----------------
LOG.error(""Caught exception from allocate"", e)
---------------Reference log end----------------
        throw e;
      } finally {
        context.stop();
        schedulerMetrics.increaseSchedulerAllocationCounter();
        try {
          updateQueueWithAllocateRequest(allocation, attemptId,
              resourceRequests, containerIds);
        } catch (IOException e) {
          LOG.error(""Caught exception while executing finally block"", e);
        }
      }
    } else {
      return super.allocate(attemptId, resourceRequests, schedulingRequests,
          containerIds,
          blacklistAdditions, blacklistRemovals, updateRequests);
    }
  }",,
hadoop,1526,"LOG.info(""Found: {}"", ipFilePath)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/resourceplugin/fpga/IntelFpgaOpenclPlugin.java/#L242,"@Override
  public String retrieveIPfilePath(String id, String dstDir,
      Map<Path, List<String>> localizedResources) {
    // Assume .aocx IP file is distributed by DS to local dir
    String ipFilePath = null;

    LOG.info(""Got environment: "" + id +
        "", search IP file in localized resources"");
    if (null == id || id.isEmpty()) {
      LOG.warn(""IP_ID environment is empty, skip downloading"");
      return null;
    }

    if (localizedResources != null) {
      Optional<Path> aocxPath = localizedResources
          .keySet()
          .stream()
          .filter(path -> matchesIpid(path, id))
          .findFirst();

      if (aocxPath.isPresent()) {
        ipFilePath = aocxPath.get().toString();
        
---------------Reference log start----------------
LOG.info(""Found: {}"", ipFilePath)
---------------Reference log end----------------
      } else {
        LOG.warn(""Requested IP file not found"");
      }
    } else {
      LOG.warn(""Localized resource is null!"");
    }

    return ipFilePath;
  }",,
hadoop,11205,"LOG.info(""  files {}; directories {}"", files, subdirs)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/AuthoritativeAuditOperation.java/#L210,"@VisibleForTesting
  Pair<Integer, Integer> executeAudit(
      final Path path,
      final boolean requireAuth,
      final boolean recursive) throws IOException {
    int dirs = 0;
    int nonauth = 0;
    final Queue<DDBPathMetadata> queue = new ArrayDeque<>();
    final boolean isRoot = path.isRoot();
    final DDBPathMetadata baseData = metastore.get(path);
    if (baseData == null) {
      throw new ExitUtil.ExitException(LauncherExitCodes.EXIT_NOT_FOUND,
          ""No S3Guard entry for path "" + path);
    }

    if (isRoot || isDirectory(baseData)) {
      // we have the root entry or an authoritative a directory
      queue.add(baseData);
    } else {
      LOG.info(""Path represents file"");
      return Pair.of(0, 0);
    }

    while (!queue.isEmpty()) {
      dirs++;
      final DDBPathMetadata dir = queue.poll();
      final Path p = dir.getFileStatus().getPath();
      LOG.debug(""Directory {}"", dir.prettyPrint());
      // log a message about the dir state, with root treated specially
      if (!p.isRoot()) {
        if (!dir.isAuthoritativeDir()) {
          LOG.warn(""Directory {} is not authoritative"", p);
          nonauth++;
          verifyAuthDir(dir, requireAuth);
        } else {
          LOG.info(""Directory {}"", p);
        }
      } else {
        // this is done to avoid the confusing message about root not being
        // authoritative
        LOG.info(""Root directory {}"", p);
      }

      // list its children
      if (recursive) {
        final DirListingMetadata entry = metastore.listChildren(p);

        if (entry != null) {
          final Collection<PathMetadata> listing = entry.getListing();
          int files = 0, subdirs = 0;
          for (PathMetadata e : listing) {
            if (isDirectory(e)) {
              // queue for auditing
              queue.add((DDBPathMetadata) e);
              subdirs++;
            } else {
              files++;
            }
          }
          if (verbose && files > 0 || subdirs > 0) {
            
---------------Reference log start----------------
LOG.info(""  files {}; directories {}"", files, subdirs)
---------------Reference log end----------------
          }
        } else {
          LOG.info(""Directory {} has been deleted"", dir);
        }
      }
    }
    // end of scan
    if (dirs == 1 && isRoot) {
      LOG.info(""The store has no directories to scan"");
    } else {
      LOG.info(""Scanned {} directories - {} were not marked as authoritative"",
          dirs, nonauth);
    }
    return Pair.of(dirs, nonauth);
  }",,
hadoop,9515,"LOG.error(""read position[{}] destLen[{}] offset[{}] len[{}] failed, "" + ""retry time[{}], due to exception[{}]"", position, length, offset, bytesRead, READ_RETRY_TIME, exception)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-huaweicloud/src/main/java/org/apache/hadoop/fs/obs/OBSInputStream.java/#L1018,"private int randomReadWithNewInputStream(final long position,
      final byte[] buffer, final int offset, final int length)
      throws IOException {
    long startTime = System.currentTimeMillis();
    long threadId = Thread.currentThread().getId();
    int bytesRead = 0;
    InputStream inputStream = null;
    IOException exception = null;
    GetObjectRequest request = new GetObjectRequest(bucket, key);
    request.setRangeStart(position);
    request.setRangeEnd(position + length);
    if (fs.getSse().isSseCEnable()) {
      request.setSseCHeader(fs.getSse().getSseCHeader());
    }

    for (int retryTime = 1; retryTime <= READ_RETRY_TIME; retryTime++) {
      try {
        inputStream = client.getObject(request).getObjectContent();
        if (inputStream == null) {
          break;
        }
        bytesRead = tryToReadFromInputStream(inputStream, buffer,
            offset, length);
        if (bytesRead == -1) {
          return -1;
        }

        exception = null;
        break;
      } catch (ObsException | IOException e) {
        if (e instanceof ObsException) {
          exception = translateException(
              ""Read at position "" + position, uri, (ObsException) e);
        } else {
          exception = (IOException) e;
        }
        LOG.warn(
            ""read position[{}] destLen[{}] offset[{}] readLen[{}] ""
                + ""of [{}] failed, retry time[{}], due to ""
                + ""exception[{}] e[{}]"",
            position, length, offset, bytesRead, uri, retryTime,
            exception, e);
        if (retryTime < READ_RETRY_TIME) {
          try {
            Thread.sleep(DELAY_TIME);
          } catch (InterruptedException ie) {
            LOG.error(
                ""read position[{}] destLen[{}] offset[{}] ""
                    + ""readLen[{}] of [{}] failed, retry time[{}], ""
                    + ""due to exception[{}] e[{}]"",
                position, length, offset, bytesRead, uri, retryTime,
                exception, e);
            throw exception;
          }
        }
      } finally {
        if (inputStream != null) {
          inputStream.close();
        }
      }
    }

    if (inputStream == null || exception != null) {
      
---------------Reference log start----------------
LOG.error(""read position[{}] destLen[{}] offset[{}] len[{}] failed, "" + ""retry time[{}], due to exception[{}]"", position, length, offset, bytesRead, READ_RETRY_TIME, exception)
---------------Reference log end----------------
      throw new IOException(""read failed of "" + uri + "", inputStream is ""
          + (inputStream == null ? ""null"" : ""not null""), exception);

    }

    long endTime = System.currentTimeMillis();
    LOG.debug(
        ""Read-4args uri:{}, contentLength:{}, destLen:{}, readLen:{}, ""
            + ""position:{}, thread:{}, timeUsedMilliSec:{}"",
        uri, contentLength, length, bytesRead, position, threadId,
        endTime - startTime);
    return bytesRead;
  }",,
hadoop,13012,"LOG.info(""Recursively deleting "" + znodeWorkingDir + "" from ZK..."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ActiveStandbyElector.java/#L381,"public synchronized void clearParentZNode()
      throws IOException, InterruptedException {
    Preconditions.checkState(!wantToBeInElection,
        ""clearParentZNode() may not be called while in the election"");

    try {
      
---------------Reference log start----------------
LOG.info(""Recursively deleting "" + znodeWorkingDir + "" from ZK..."")
---------------Reference log end----------------

      zkDoWithRetries(new ZKAction<Void>() {
        @Override
        public Void run() throws KeeperException, InterruptedException {
          ZKUtil.deleteRecursive(zkClient, znodeWorkingDir);
          return null;
        }
      });
    } catch (KeeperException e) {
      throw new IOException(""Couldn't clear parent znode "" + znodeWorkingDir,
          e);
    }
    LOG.info(""Successfully deleted "" + znodeWorkingDir + "" from ZK."");
  }",,
hadoop,6705,"LOG.debug(""Processed cache report from {}, blocks: {}, "" + ""processing time: {} msecs"", datanodeID, blockIds.size(), (endTime - startTime))",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/CacheManager.java/#L1006,"public final void processCacheReport(final DatanodeID datanodeID,
      final List<Long> blockIds) throws IOException {
    if (!enabled) {
      LOG.debug(""Ignoring cache report from {} because {} = false. "" +
              ""number of blocks: {}"", datanodeID,
              DFS_NAMENODE_CACHING_ENABLED_KEY, blockIds.size());
      return;
    }
    namesystem.writeLock();
    final long startTime = Time.monotonicNow();
    final long endTime;
    try {
      final DatanodeDescriptor datanode = 
          blockManager.getDatanodeManager().getDatanode(datanodeID);
      if (datanode == null || !datanode.isRegistered()) {
        throw new IOException(
            ""processCacheReport from dead or unregistered datanode: "" +
            datanode);
      }
      processCacheReportImpl(datanode, blockIds);
    } finally {
      endTime = Time.monotonicNow();
      namesystem.writeUnlock(""processCacheReport"");
    }

    // Log the block report processing stats from Namenode perspective
    final NameNodeMetrics metrics = NameNode.getNameNodeMetrics();
    if (metrics != null) {
      metrics.addCacheBlockReport((int) (endTime - startTime));
    }
    
---------------Reference log start----------------
LOG.debug(""Processed cache report from {}, blocks: {}, "" + ""processing time: {} msecs"", datanodeID, blockIds.size(), (endTime - startTime))
---------------Reference log end----------------
  }
  }",,
hadoop,9982,"LOG.debug(""Loading identity map from file {}"", fileLocation)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/utils/TextFileBasedIdentityHandler.java/#L172,"private static void loadMap(HashMap<String, String> cache, String fileLocation, int noOfFields, int keyIndex)
      throws IOException {
    
---------------Reference log start----------------
LOG.debug(""Loading identity map from file {}"", fileLocation)
---------------Reference log end----------------
    int errorRecord = 0;
    File file = new File(fileLocation);
    LineIterator it = null;
    try {
      it = FileUtils.lineIterator(file, ""UTF-8"");
      while (it.hasNext()) {
        String line = it.nextLine();
        if (!Strings.isNullOrEmpty(line.trim()) && !line.startsWith(HASH)) {
          if (line.split(COLON).length != noOfFields) {
            errorRecord += 1;
            continue;
          }
          cache.put(line.split(COLON)[keyIndex], line);
        }
      }
      LOG.debug(""Loaded map stats - File: {}, Loaded: {}, Error: {} "", fileLocation, cache.size(), errorRecord);
    } catch (ArrayIndexOutOfBoundsException e) {
      LOG.error(""Error while parsing mapping file"", e);
    } finally {
      LineIterator.closeQuietly(it);
    }
  }",,
hadoop,13093,"LOG.warn(""Unable to fence - it is running but we cannot kill it"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/SshFenceByTcpPort.java/#L153,"private boolean doFence(Session session, InetSocketAddress serviceAddr)
      throws JSchException {
    int port = serviceAddr.getPort();
    try {
      LOG.info(""Looking for process running on port "" + port);
      int rc = execCommand(session,
          ""PATH=$PATH:/sbin:/usr/sbin fuser -v -k -n tcp "" + port);
      if (rc == 0) {
        LOG.info(""Successfully killed process that was "" +
            ""listening on port "" + port);
        // exit code 0 indicates the process was successfully killed.
        return true;
      } else if (rc == 1) {
        // exit code 1 indicates either that the process was not running
        // or that fuser didn't have root privileges in order to find it
        // (eg running as a different user)
        LOG.info(
            ""Indeterminate response from trying to kill service. "" +
            ""Verifying whether it is running using nc..."");
        rc = execCommand(session, ""nc -z "" + serviceAddr.getHostName() +
            "" "" + serviceAddr.getPort());
        if (rc == 0) {
          // the service is still listening - we are unable to fence
          
---------------Reference log start----------------
LOG.warn(""Unable to fence - it is running but we cannot kill it"")
---------------Reference log end----------------
          return false;
        } else {
          LOG.info(""Verified that the service is down."");
          return true;          
        }
      } else {
        // other 
      }
      LOG.info(""rc: "" + rc);
      return rc == 0;
    } catch (InterruptedException e) {
      LOG.warn(""Interrupted while trying to fence via ssh"", e);
      return false;
    } catch (IOException e) {
      LOG.warn(""Unknown failure while trying to fence via ssh"", e);
      return false;
    }
  }",,
hadoop,8847,"LOG.info(""Node {} is sufficiently replicated and healthy, "" + ""marked as {}."", dn, dn.getAdminState())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java/#L378,"private void processCompletedNodes(List<DatanodeDescriptor> toRemove) {
    if (toRemove.size() == 0) {
      // If there are no nodes to process simply return and avoid
      // taking the write lock at all.
      return;
    }
    namesystem.writeLock();
    try {
      for (DatanodeDescriptor dn : toRemove) {
        final boolean isHealthy =
            blockManager.isNodeHealthyForDecommissionOrMaintenance(dn);
        if (isHealthy) {
          if (dn.isDecommissionInProgress()) {
            dnAdmin.setDecommissioned(dn);
            outOfServiceNodeBlocks.remove(dn);
            pendingRep.remove(dn);
          } else if (dn.isEnteringMaintenance()) {
            // IN_MAINTENANCE node remains in the outOfServiceNodeBlocks to
            // to track maintenance expiration.
            dnAdmin.setInMaintenance(dn);
            pendingRep.remove(dn);
          } else if (dn.isInService()) {
            // Decom / maint was cancelled and the node is yet to be processed
            // from cancelledNodes
            LOG.info(""Node {} completed decommission and maintenance "" +
                ""but has been moved back to in service"", dn);
            pendingRep.remove(dn);
            outOfServiceNodeBlocks.remove(dn);
            continue;
          } else {
            // Should not happen
            LOG.error(""Node {} is in an unexpected state {} and has been ""+
                    ""removed from tracking for decommission or maintenance"",
                dn, dn.getAdminState());
            pendingRep.remove(dn);
            outOfServiceNodeBlocks.remove(dn);
            continue;
          }
          
---------------Reference log start----------------
LOG.info(""Node {} is sufficiently replicated and healthy, "" + ""marked as {}."", dn, dn.getAdminState())
---------------Reference log end----------------
        } else {
          LOG.info(""Node {} isn't healthy.""
                  + "" It needs to replicate {} more blocks.""
                  + "" {} is still in progress."", dn,
              getPendingCountForNode(dn), dn.getAdminState());
        }
      }
    } finally {
      namesystem.writeUnlock();
    }
  }",,
hadoop,6814,"LOG.debug(""File {} skipped re-encryption because edek's key version"" + "" name is not changed."", inode.getFullPathName())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ReencryptionHandler.java/#L661,"@Override
    public boolean processFileInode(INode inode, TraverseInfo traverseInfo)
        throws IOException, InterruptedException {
      assert dir.hasReadLock();
      if (LOG.isTraceEnabled()) {
        LOG.trace(""Processing {} for re-encryption"", inode.getFullPathName());
      }
      if (!inode.isFile()) {
        return false;
      }
      FileEncryptionInfo feInfo = FSDirEncryptionZoneOp.getFileEncryptionInfo(
          dir, INodesInPath.fromINode(inode));
      if (feInfo == null) {
        LOG.warn(""File {} skipped re-encryption because it is not encrypted! ""
            + ""This is very likely a bug."", inode.getId());
        return false;
      }
      if (traverseInfo instanceof ZoneTraverseInfo
          && ((ZoneTraverseInfo) traverseInfo).getEzKeyVerName().equals(
              feInfo.getEzKeyVersionName())) {
        if (LOG.isDebugEnabled()) {
          
---------------Reference log start----------------
LOG.debug(""File {} skipped re-encryption because edek's key version"" + "" name is not changed."", inode.getFullPathName())
---------------Reference log end----------------
        }
        return false;
      }
      currentBatch.add(inode.asFile());
      return true;
    }",,
hadoop,12368,"LOG.warn(""Large response size "" + response.length + "" for call "" + call.toString())",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java/#L3358,"private void setupResponse(RpcCall call,
      RpcResponseHeaderProto header, Writable rv) throws IOException {
    final byte[] response;
    if (rv == null || (rv instanceof RpcWritable.ProtobufWrapper)) {
      response = setupResponseForProtobuf(header, rv);
    } else {
      response = setupResponseForWritable(header, rv);
    }
    if (response.length > maxRespSize) {
      
---------------Reference log start----------------
LOG.warn(""Large response size "" + response.length + "" for call "" + call.toString())
---------------Reference log end----------------
    }
    call.setResponse(ByteBuffer.wrap(response));
  }",,
hadoop,1445,"LOG.info(""Found script: {}"", dir)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/resourceplugin/com/nec/NECVEPlugin.java/#L300,"private String getScriptFromSearchDirs(String binaryName,
      String[] scriptPaths) {
    String scriptPath = null;

    for (String dir : scriptPaths) {
      File f = new File(dir, binaryName);
      if (f.exists()) {
        
---------------Reference log start----------------
LOG.info(""Found script: {}"", dir)
---------------Reference log end----------------
        scriptPath = f.getAbsolutePath();
        break;
      }
    }

    return scriptPath;
  }",,
hadoop,12407,"LOG.warn(""Metrics system not started: "" + e.getMessage())",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/impl/MetricsSystemImpl.java/#L167,"@Override
  public synchronized MetricsSystem init(String prefix) {
    if (monitoring && !DefaultMetricsSystem.inMiniClusterMode()) {
      LOG.warn(this.prefix +"" metrics system already initialized!"");
      return this;
    }
    this.prefix = checkNotNull(prefix, ""prefix"");
    ++refCount;
    if (monitoring) {
      // in mini cluster mode
      LOG.info(this.prefix +"" metrics system started (again)"");
      return this;
    }
    switch (initMode()) {
      case NORMAL:
        try { start(); }
        catch (MetricsConfigException e) {
          // Configuration errors (e.g., typos) should not be fatal.
          // We can always start the metrics system later via JMX.
          
---------------Reference log start----------------
LOG.warn(""Metrics system not started: "" + e.getMessage())
---------------Reference log end----------------
          LOG.debug(""Stacktrace: "", e);
        }
        break;
      case STANDBY:
        LOG.info(prefix +"" metrics system started in standby mode"");
    }
    initSystemMBean();
    return this;
  }",,
hadoop,13121,"LOG.info(""ZK Election indicated that "" + localTarget + "" should become standby"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java/#L509,"private synchronized void becomeStandby() {
    
---------------Reference log start----------------
LOG.info(""ZK Election indicated that "" + localTarget + "" should become standby"")
---------------Reference log end----------------
    try {
      int timeout = FailoverController.getGracefulFenceTimeout(conf);
      localTarget.getProxy(conf, timeout).transitionToStandby(createReqInfo());
      LOG.info(""Successfully transitioned "" + localTarget +
          "" to standby state"");
    } catch (Exception e) {
      LOG.error(""Couldn't transition "" + localTarget + "" to standby state"",
          e);
      // TODO handle this. It's a likely case since we probably got fenced
      // at the same time.
    }
    serviceState = HAServiceState.STANDBY;
  }",,
hadoop,5675,"LOG.error(""Invalid RMDIR request"")",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java/#L1256,"@VisibleForTesting
  RMDIR3Response rmdir(XDR xdr, SecurityHandler securityHandler,
      SocketAddress remoteAddress) {
    RMDIR3Response response = new RMDIR3Response(Nfs3Status.NFS3_OK);

    RMDIR3Request request;
    try {
      request = RMDIR3Request.deserialize(xdr);
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.error(""Invalid RMDIR request"")
---------------Reference log end----------------
      return new RMDIR3Response(Nfs3Status.NFS3ERR_INVAL);
    }
    FileHandle dirHandle = request.getHandle();
    String fileName = request.getName();
    int namenodeId = dirHandle.getNamenodeId();
    if (LOG.isDebugEnabled()) {
      LOG.debug(""NFS RMDIR dir fileHandle: {} fileName: {} client: {}"",
          dirHandle.dumpFileHandle(), fileName, remoteAddress);
    }
    DFSClient dfsClient =
        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);
    if (dfsClient == null) {
      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);
      return response;
    }

    String dirFileIdPath = Nfs3Utils.getFileIdPath(dirHandle);
    Nfs3FileAttributes preOpDirAttr = null;
    Nfs3FileAttributes postOpDirAttr = null;
    try {
      preOpDirAttr = Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);
      if (preOpDirAttr == null) {
        LOG.info(""Can't get path for dir fileId: {}"", dirHandle.getFileId());
        return new RMDIR3Response(Nfs3Status.NFS3ERR_STALE);
      }

      WccData errWcc = new WccData(Nfs3Utils.getWccAttr(preOpDirAttr),
          preOpDirAttr);
      if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_WRITE)) {
        return new RMDIR3Response(Nfs3Status.NFS3ERR_ACCES, errWcc); 
      }

      String fileIdPath = dirFileIdPath + ""/"" + fileName;
      HdfsFileStatus fstat = Nfs3Utils.getFileStatus(dfsClient, fileIdPath);
      if (fstat == null) {
        return new RMDIR3Response(Nfs3Status.NFS3ERR_NOENT, errWcc);
      }
      if (!fstat.isDirectory()) {
        return new RMDIR3Response(Nfs3Status.NFS3ERR_NOTDIR, errWcc);
      }

      if (fstat.getChildrenNum() > 0) {
        return new RMDIR3Response(Nfs3Status.NFS3ERR_NOTEMPTY, errWcc);
      }

      boolean result = dfsClient.delete(fileIdPath, false);
      WccData dirWcc = Nfs3Utils.createWccData(
          Nfs3Utils.getWccAttr(preOpDirAttr), dfsClient, dirFileIdPath, iug);
      if (!result) {
        return new RMDIR3Response(Nfs3Status.NFS3ERR_ACCES, dirWcc);
      }

      return new RMDIR3Response(Nfs3Status.NFS3_OK, dirWcc);
    } catch (IOException e) {
      LOG.warn(""Exception"", e);
      // Try to return correct WccData
      if (postOpDirAttr == null) {
        try {
          postOpDirAttr = Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);
        } catch (IOException e1) {
          LOG.info(""Can't get postOpDirAttr for {}"", dirFileIdPath, e1);
        }
      }

      WccData dirWcc = new WccData(Nfs3Utils.getWccAttr(preOpDirAttr),
          postOpDirAttr);
      int status = mapErrorStatus(e);
      return new RMDIR3Response(status, dirWcc);
    }
  }",,
hadoop,7990,"LOG.info(""Shutdown complete."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java/#L2197,"public void shutdown() {
    stopMetricsLogger();
    if (plugins != null) {
      for (ServicePlugin p : plugins) {
        try {
          p.stop();
          LOG.info(""Stopped plug-in {}"", p);
        } catch (Throwable t) {
          LOG.warn(""ServicePlugin {} could not be stopped"", p, t);
        }
      }
    }

    List<BPOfferService> bposArray = (this.blockPoolManager == null)
        ? new ArrayList<BPOfferService>()
        : this.blockPoolManager.getAllNamenodeThreads();
    // If shutdown is not for restart, set shouldRun to false early. 
    if (!shutdownForUpgrade) {
      shouldRun = false;
    }

    // When shutting down for restart, DataXceiverServer is interrupted
    // in order to avoid any further acceptance of requests, but the peers
    // for block writes are not closed until the clients are notified.
    if (dataXceiverServer != null) {
      try {
        xserver.sendOOBToPeers();
        ((DataXceiverServer) this.dataXceiverServer.getRunnable()).kill();
        this.dataXceiverServer.interrupt();
      } catch (Exception e) {
        // Ignore, since the out of band messaging is advisory.
        LOG.trace(""Exception interrupting DataXceiverServer"", e);
      }
    }

    // Record the time of initial notification
    long timeNotified = Time.monotonicNow();

    if (localDataXceiverServer != null) {
      ((DataXceiverServer) this.localDataXceiverServer.getRunnable()).kill();
      this.localDataXceiverServer.interrupt();
    }

    // Terminate directory scanner and block scanner
    shutdownPeriodicScanners();
    shutdownDiskBalancer();

    // Stop the web server
    if (httpServer != null) {
      try {
        httpServer.close();
      } catch (Exception e) {
        LOG.warn(""Exception shutting down DataNode HttpServer"", e);
      }
    }

    volumeChecker.shutdownAndWait(1, TimeUnit.SECONDS);

    if (storageLocationChecker != null) {
      storageLocationChecker.shutdownAndWait(1, TimeUnit.SECONDS);
    }

    if (pauseMonitor != null) {
      pauseMonitor.stop();
    }

    // shouldRun is set to false here to prevent certain threads from exiting
    // before the restart prep is done.
    this.shouldRun = false;
    
    // wait reconfiguration thread, if any, to exit
    shutdownReconfigurationTask();

    LOG.info(""Waiting up to 30 seconds for transfer threads to complete"");
    HadoopExecutors.shutdown(this.xferService, LOG, 15L, TimeUnit.SECONDS);

    // wait for all data receiver threads to exit
    if (this.threadGroup != null) {
      int sleepMs = 2;
      while (true) {
        // When shutting down for restart, wait 2.5 seconds before forcing
        // termination of receiver threads.
        if (!this.shutdownForUpgrade ||
            (this.shutdownForUpgrade && (Time.monotonicNow() - timeNotified
                > 1000))) {
          this.threadGroup.interrupt();
          break;
        }
        LOG.info(""Waiting for threadgroup to exit, active threads is {}"",
                 this.threadGroup.activeCount());
        if (this.threadGroup.activeCount() == 0) {
          break;
        }
        try {
          Thread.sleep(sleepMs);
        } catch (InterruptedException e) {}
        sleepMs = sleepMs * 3 / 2; // exponential backoff
        if (sleepMs > 200) {
          sleepMs = 200;
        }
      }
      this.threadGroup = null;
    }
    if (this.dataXceiverServer != null) {
      // wait for dataXceiverServer to terminate
      try {
        this.dataXceiverServer.join();
      } catch (InterruptedException ie) {
      }
    }
    if (this.localDataXceiverServer != null) {
      // wait for localDataXceiverServer to terminate
      try {
        this.localDataXceiverServer.join();
      } catch (InterruptedException ie) {
      }
    }
    if (metrics != null) {
      metrics.setDataNodeActiveXceiversCount(0);
      metrics.setDataNodePacketResponderCount(0);
      metrics.setDataNodeBlockRecoveryWorkerCount(0);
    }

   // IPC server needs to be shutdown late in the process, otherwise
   // shutdown command response won't get sent.
   if (ipcServer != null) {
      ipcServer.stop();
    }

    if (ecWorker != null) {
      ecWorker.shutDown();
    }

    if(blockPoolManager != null) {
      try {
        this.blockPoolManager.shutDownAll(bposArray);
      } catch (InterruptedException ie) {
        LOG.warn(""Received exception in BlockPoolManager#shutDownAll"", ie);
      }
    }
    
    if (storage != null) {
      try {
        this.storage.unlockAll();
      } catch (IOException ie) {
        LOG.warn(""Exception when unlocking storage"", ie);
      }
    }
    if (data != null) {
      data.shutdown();
    }
    if (metrics != null) {
      metrics.shutdown();
    }
    if (diskMetrics != null) {
      diskMetrics.shutdownAndWait();
    }
    if (dataNodeInfoBeanName != null) {
      MBeans.unregister(dataNodeInfoBeanName);
      dataNodeInfoBeanName = null;
    }
    if (shortCircuitRegistry != null) shortCircuitRegistry.shutdown();
    
---------------Reference log start----------------
LOG.info(""Shutdown complete."")
---------------Reference log end----------------
    synchronized(this) {
      // it is already false, but setting it again to avoid a findbug warning.
      this.shouldRun = false;
      // Notify the main thread.
      notifyAll();
    }
    tracer.close();
  }",,
hadoop,7370,"LOG.info(""Skipping InMemoryAliasMap bootstrap as it was not configured"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ha/BootstrapStandby.java/#L252,"private int doRun() throws IOException {
    // find the active NN
    NamenodeProtocol proxy = null;
    NamespaceInfo nsInfo = null;
    boolean isUpgradeFinalized = false;
    RemoteNameNodeInfo proxyInfo = null;
    for (int i = 0; i < remoteNNs.size(); i++) {
      proxyInfo = remoteNNs.get(i);
      InetSocketAddress otherIpcAddress = proxyInfo.getIpcAddress();
      proxy = createNNProtocolProxy(otherIpcAddress);
      try {
        // Get the namespace from any active NN. If you just formatted the primary NN and are
        // bootstrapping the other NNs from that layout, it will only contact the single NN.
        // However, if there cluster is already running and you are adding a NN later (e.g.
        // replacing a failed NN), then this will bootstrap from any node in the cluster.
        nsInfo = proxy.versionRequest();
        isUpgradeFinalized = proxy.isUpgradeFinalized();
        break;
      } catch (IOException ioe) {
        LOG.warn(""Unable to fetch namespace information from remote NN at "" + otherIpcAddress
            + "": "" + ioe.getMessage());
        if (LOG.isDebugEnabled()) {
          LOG.debug(""Full exception trace"", ioe);
        }
      }
    }

    if (nsInfo == null) {
      LOG.error(
          ""Unable to fetch namespace information from any remote NN. Possible NameNodes: ""
              + remoteNNs);
      return ERR_CODE_FAILED_CONNECT;
    }

    if (!checkLayoutVersion(nsInfo)) {
      LOG.error(""Layout version on remote node ("" + nsInfo.getLayoutVersion()
          + "") does not match "" + ""this node's layout version (""
          + HdfsServerConstants.NAMENODE_LAYOUT_VERSION + "")"");
      return ERR_CODE_INVALID_VERSION;
    }

    System.out.println(
        ""=====================================================\n"" +
        ""About to bootstrap Standby ID "" + nnId + "" from:\n"" +
        ""           Nameservice ID: "" + nsId + ""\n"" +
        ""        Other Namenode ID: "" + proxyInfo.getNameNodeID() + ""\n"" +
        ""  Other NN's HTTP address: "" + proxyInfo.getHttpAddress() + ""\n"" +
        ""  Other NN's IPC  address: "" + proxyInfo.getIpcAddress() + ""\n"" +
        ""             Namespace ID: "" + nsInfo.getNamespaceID() + ""\n"" +
        ""            Block pool ID: "" + nsInfo.getBlockPoolID() + ""\n"" +
        ""               Cluster ID: "" + nsInfo.getClusterID() + ""\n"" +
        ""           Layout version: "" + nsInfo.getLayoutVersion() + ""\n"" +
        ""       isUpgradeFinalized: "" + isUpgradeFinalized + ""\n"" +
        ""====================================================="");
    
    NNStorage storage = new NNStorage(conf, dirsToFormat, editUrisToFormat);

    if (!isUpgradeFinalized) {
      // the remote NameNode is in upgrade state, this NameNode should also
      // create the previous directory. First prepare the upgrade and rename
      // the current dir to previous.tmp.
      LOG.info(""The active NameNode is in Upgrade. "" +
          ""Prepare the upgrade for the standby NameNode as well."");
      if (!doPreUpgrade(storage, nsInfo)) {
        return ERR_CODE_ALREADY_FORMATTED;
      }
    } else if (!format(storage, nsInfo)) { // prompt the user to format storage
      return ERR_CODE_ALREADY_FORMATTED;
    }

    // download the fsimage from active namenode
    int download = downloadImage(storage, proxy, proxyInfo);
    if (download != 0) {
      return download;
    }

    // finish the upgrade: rename previous.tmp to previous
    if (!isUpgradeFinalized) {
      doUpgrade(storage);
    }

    if (inMemoryAliasMapEnabled) {
      return formatAndDownloadAliasMap(aliasMapPath, proxyInfo);
    } else {
      
---------------Reference log start----------------
LOG.info(""Skipping InMemoryAliasMap bootstrap as it was not configured"")
---------------Reference log end----------------
    }
    return 0;
  }",,
hadoop,3839,"LOG.info(""Removing state for app "" + removeAppId)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/LeveldbRMStateStore.java/#L769,"@Override
  public synchronized void removeApplication(ApplicationId removeAppId)
      throws IOException {
    String appKey = getApplicationNodeKey(removeAppId);
    
---------------Reference log start----------------
LOG.info(""Removing state for app "" + removeAppId)
---------------Reference log end----------------
    try {
      db.delete(bytes(appKey));
    } catch (DBException e) {
      throw new IOException(e);
    }
  }",,
hadoop,4213,"LOG.debug(""Writing entity log for {} to {}"", groupId, entityLogPath)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/client/api/impl/FileSystemTimelineWriter.java/#L236,"@Override
  public TimelinePutResponse putEntities(
      ApplicationAttemptId appAttemptId, TimelineEntityGroupId groupId,
      TimelineEntity... entities) throws IOException, YarnException {
    if (appAttemptId == null) {
      return putEntities(entities);
    }

    List<TimelineEntity> entitiesToDBStore = new ArrayList<TimelineEntity>();
    List<TimelineEntity> entitiesToSummaryCache
        = new ArrayList<TimelineEntity>();
    List<TimelineEntity> entitiesToEntityCache
        = new ArrayList<TimelineEntity>();
    Path attemptDir = attemptDirCache.getAppAttemptDir(appAttemptId);

    for (TimelineEntity entity : entities) {
      if (summaryEntityTypes.contains(entity.getEntityType())) {
        entitiesToSummaryCache.add(entity);
      } else {
        if (groupId != null) {
          entitiesToEntityCache.add(entity);
        } else {
          entitiesToDBStore.add(entity);
        }
      }
    }

    if (!entitiesToSummaryCache.isEmpty()) {
      Path summaryLogPath =
          new Path(attemptDir, SUMMARY_LOG_PREFIX + appAttemptId.toString());
      LOG.debug(""Writing summary log for {} to {}"", appAttemptId,
          summaryLogPath);
      this.logFDsCache.writeSummaryEntityLogs(fs, summaryLogPath, objMapper,
          appAttemptId, entitiesToSummaryCache, isAppendSupported);
    }

    if (!entitiesToEntityCache.isEmpty()) {
      Path entityLogPath =
          new Path(attemptDir, ENTITY_LOG_PREFIX + groupId.toString());
      
---------------Reference log start----------------
LOG.debug(""Writing entity log for {} to {}"", groupId, entityLogPath)
---------------Reference log end----------------
      this.logFDsCache.writeEntityLogs(fs, entityLogPath, objMapper,
          appAttemptId, groupId, entitiesToEntityCache, isAppendSupported);
    }

    if (!entitiesToDBStore.isEmpty()) {
      putEntities(entitiesToDBStore.toArray(
          new TimelineEntity[entitiesToDBStore.size()]));
    }

    return new TimelinePutResponse();
  }",,
hadoop,6079,"LOG.trace(""{}: trying to construct BlockReaderLocalLegacy"", this)",trace,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/client/impl/BlockReaderFactory.java/#L429,"private BlockReader getLegacyBlockReaderLocal() throws IOException {
    
---------------Reference log start----------------
LOG.trace(""{}: trying to construct BlockReaderLocalLegacy"", this)
---------------Reference log end----------------
    if (!DFSUtilClient.isLocalAddress(inetSocketAddress)) {
      LOG.trace(""{}: can't construct BlockReaderLocalLegacy because the address""
          + ""{} is not local"", this, inetSocketAddress);
      return null;
    }
    if (clientContext.getDisableLegacyBlockReaderLocal()) {
      PerformanceAdvisory.LOG.debug(""{}: can't construct "" +
          ""BlockReaderLocalLegacy because "" +
          ""disableLegacyBlockReaderLocal is set."", this);
      return null;
    }
    IOException ioe;
    try {
      return BlockReaderLocalLegacy.newBlockReader(conf,
          userGroupInformation, configuration, fileName, block, token,
          datanode, startOffset, length, storageType);
    } catch (RemoteException remoteException) {
      ioe = remoteException.unwrapRemoteException(
                InvalidToken.class, AccessControlException.class);
    } catch (IOException e) {
      ioe = e;
    }
    if ((!(ioe instanceof AccessControlException)) &&
        isSecurityException(ioe)) {
      // Handle security exceptions.
      // We do not handle AccessControlException here, since
      // BlockReaderLocalLegacy#newBlockReader uses that exception to indicate
      // that the user is not in dfs.block.local-path-access.user, a condition
      // which requires us to disable legacy SCR.
      throw ioe;
    }
    LOG.warn(this + "": error creating legacy BlockReaderLocal.  "" +
        ""Disabling legacy local reads."", ioe);
    clientContext.setDisableLegacyBlockReaderLocal();
    return null;
  }",,
hadoop,9455,"LOG.debug(""delete: Path is a file"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-huaweicloud/src/main/java/org/apache/hadoop/fs/obs/OBSObjectBucketUtils.java/#L277,"static boolean objectDelete(final OBSFileSystem owner,
      final FileStatus status,
      final boolean recursive) throws IOException {
    Path f = status.getPath();
    String key = OBSCommonUtils.pathToKey(owner, f);

    if (status.isDirectory()) {
      LOG.debug(""delete: Path is a directory: {} - recursive {}"", f,
          recursive);

      key = OBSCommonUtils.maybeAddTrailingSlash(key);
      if (!key.endsWith(""/"")) {
        key = key + ""/"";
      }

      boolean isEmptyDir = OBSCommonUtils.isFolderEmpty(owner, key);
      if (key.equals(""/"")) {
        return OBSCommonUtils.rejectRootDirectoryDelete(
            owner.getBucket(), isEmptyDir, recursive);
      }

      if (!recursive && !isEmptyDir) {
        throw new PathIsNotEmptyDirectoryException(f.toString());
      }

      if (isEmptyDir) {
        LOG.debug(
            ""delete: Deleting fake empty directory {} - recursive {}"",
            f, recursive);
        OBSCommonUtils.deleteObject(owner, key);
      } else {
        LOG.debug(
            ""delete: Deleting objects for directory prefix {} ""
                + ""- recursive {}"",
            f, recursive);
        deleteNonEmptyDir(owner, recursive, key);
      }

    } else {
      
---------------Reference log start----------------
LOG.debug(""delete: Path is a file"")
---------------Reference log end----------------
      OBSCommonUtils.deleteObject(owner, key);
    }

    Path parent = f.getParent();
    if (parent != null) {
      createFakeDirectoryIfNecessary(owner, parent);
    }
    return true;
  }",,
hadoop,7908,"LOG.info(""Now scanning bpid {} on volume {}"", iter.getBlockPoolId(), volume)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.java/#L385,"private synchronized long findNextUsableBlockIter() {
    int numBlockIters = blockIters.size();
    if (numBlockIters == 0) {
      LOG.debug(""{}: no block pools are registered."", this);
      return Long.MAX_VALUE;
    }
    int curIdx;
    if (curBlockIter == null) {
      curIdx = 0;
    } else {
      curIdx = blockIters.indexOf(curBlockIter);
      Preconditions.checkState(curIdx >= 0);
    }
    // Note that this has to be wall-clock time, not monotonic time.  This is
    // because the time saved in the cursor file is a wall-clock time.  We do
    // not want to save a monotonic time in the cursor file, because it resets
    // every time the machine reboots (on most platforms).
    long nowMs = Time.now();
    long minTimeoutMs = Long.MAX_VALUE;
    for (int i = 0; i < numBlockIters; i++) {
      int idx = (curIdx + i + 1) % numBlockIters;
      BlockIterator iter = blockIters.get(idx);
      if (!iter.atEnd()) {
        
---------------Reference log start----------------
LOG.info(""Now scanning bpid {} on volume {}"", iter.getBlockPoolId(), volume)
---------------Reference log end----------------
        curBlockIter = iter;
        return 0L;
      }
      long iterStartMs = iter.getIterStartMs();
      long waitMs = (iterStartMs + conf.scanPeriodMs) - nowMs;
      if (waitMs <= 0) {
        iter.rewind();
        LOG.info(""Now rescanning bpid {} on volume {}, after more than "" +
            ""{} hour(s)"", iter.getBlockPoolId(), volume,
            TimeUnit.HOURS.convert(conf.scanPeriodMs, TimeUnit.MILLISECONDS));
        curBlockIter = iter;
        return 0L;
      }
      minTimeoutMs = Math.min(minTimeoutMs, waitMs);
    }
    LOG.info(""{}: no suitable block pools found to scan.  Waiting {} ms."",
        this, minTimeoutMs);
    return minTimeoutMs;
  }",,
hadoop,4912,"LOG.info(OutputUtil.NATIVE_TASK_OUTPUT_MANAGER + "" = "" + clazz.getName())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/java/org/apache/hadoop/mapred/nativetask/util/OutputUtil.java/#L37,"public static NativeTaskOutput createNativeTaskOutput(Configuration conf, String id) {
    Class<?> clazz = conf.getClass(OutputUtil.NATIVE_TASK_OUTPUT_MANAGER,
        NativeTaskOutputFiles.class);
    
---------------Reference log start----------------
LOG.info(OutputUtil.NATIVE_TASK_OUTPUT_MANAGER + "" = "" + clazz.getName())
---------------Reference log end----------------
    try {
      Constructor<?> ctor = clazz.getConstructor(Configuration.class, String.class);
      ctor.setAccessible(true);
      NativeTaskOutput instance = (NativeTaskOutput) ctor.newInstance(conf, id);
      return instance;
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
  }",,
hadoop,1683,"LOG.info(""Got APPLICATION_INIT for service "" + event.getServiceID())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/AuxServices.java/#L854,"@Override
  public void handle(AuxServicesEvent event) {
    LOG.info(""Got event "" + event.getType() + "" for appId ""
        + event.getApplicationID());
    switch (event.getType()) {
      case APPLICATION_INIT:
        
---------------Reference log start----------------
LOG.info(""Got APPLICATION_INIT for service "" + event.getServiceID())
---------------Reference log end----------------
        AuxiliaryService service = null;
        try {
          service = serviceMap.get(event.getServiceID());
          service
              .initializeApplication(new ApplicationInitializationContext(event
                  .getUser(), event.getApplicationID(), event.getServiceData()));
        } catch (Throwable th) {
          logWarningWhenAuxServiceThrowExceptions(service,
              AuxServicesEventType.APPLICATION_INIT, th);
        }
        break;
      case APPLICATION_STOP:
        for (AuxiliaryService serv : serviceMap.values()) {
          try {
            serv.stopApplication(new ApplicationTerminationContext(event
                .getApplicationID()));
          } catch (Throwable th) {
            logWarningWhenAuxServiceThrowExceptions(serv,
                AuxServicesEventType.APPLICATION_STOP, th);
          }
        }
        break;
      case CONTAINER_INIT:
        for (AuxiliaryService serv : serviceMap.values()) {
          try {
            serv.initializeContainer(new ContainerInitializationContext(
                event.getContainer().getUser(),
                event.getContainer().getContainerId(),
                event.getContainer().getResource(), event.getContainer()
                .getContainerTokenIdentifier().getContainerType()));
          } catch (Throwable th) {
            logWarningWhenAuxServiceThrowExceptions(serv,
                AuxServicesEventType.CONTAINER_INIT, th);
          }
        }
        break;
      case CONTAINER_STOP:
        for (AuxiliaryService serv : serviceMap.values()) {
          try {
            serv.stopContainer(new ContainerTerminationContext(
                event.getUser(), event.getContainer().getContainerId(),
                event.getContainer().getResource(), event.getContainer()
                .getContainerTokenIdentifier().getContainerType()));
          } catch (Throwable th) {
            logWarningWhenAuxServiceThrowExceptions(serv,
                AuxServicesEventType.CONTAINER_STOP, th);
          }
        }
        break;
      default:
        throw new RuntimeException(""Unknown type: "" + event.getType());
    }
  }",,
hadoop,3286,"LOG.debug(""Request for appInfo of unknown attempt {}"", appAttemptId)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java/#L441,"@Override
  public SchedulerAppReport getSchedulerAppInfo(
      ApplicationAttemptId appAttemptId) {
    SchedulerApplicationAttempt attempt = getApplicationAttempt(appAttemptId);
    if (attempt == null) {
      
---------------Reference log start----------------
LOG.debug(""Request for appInfo of unknown attempt {}"", appAttemptId)
---------------Reference log end----------------
      return null;
    }
    return new SchedulerAppReport(attempt);
  }",,
hadoop,10289,"LOG.info(""DataNode {} completed successfully, containerId={}"", completedIdx, containerStatus.getContainerId())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/ApplicationMaster.java/#L498,"@Override
    public void onContainersCompleted(
        List<ContainerStatus> completedContainers) {
      LOG.info(""Got response from RM for container ask, completedCnt=""
          + completedContainers.size());
      for (ContainerStatus containerStatus : completedContainers) {
        String containerInfo = ""containerID="" + containerStatus.getContainerId()
            + "", state="" + containerStatus.getState() + "", exitStatus=""
            + containerStatus.getExitStatus() + "", diagnostics=""
            + StringUtils.abbreviate(containerStatus.getDiagnostics(), 1000);
        String component;
        if (isNameNode(containerStatus.getContainerId())) {
          component = ""NAMENODE"";
        } else if (isDataNode(containerStatus.getContainerId())) {
          component = ""DATANODE"";
        } else {
          LOG.error(""Received container status for unknown container: ""
              + containerInfo);
          continue;
        }
        LOG.info(
            ""Got container status for "" + component + "": "" + containerInfo);

        // non complete containers should not be here
        assert (containerStatus.getState() == ContainerState.COMPLETE);

        if (component.equals(""NAMENODE"")) {
          LOG.info(""NameNode container completed; marking application as done"");
          markCompleted();
        }

        // increment counters for completed/failed containers
        int exitStatus = containerStatus.getExitStatus();
        int completedIdx = numCompletedDataNodeContainers.incrementAndGet();
        if (0 != exitStatus) {
          numFailedDataNodeContainers.incrementAndGet();
        } else {
          
---------------Reference log start----------------
LOG.info(""DataNode {} completed successfully, containerId={}"", completedIdx, containerStatus.getContainerId())
---------------Reference log end----------------
        }
      }

      if (numCompletedDataNodeContainers.get() == numTotalDataNodeContainers) {
        LOG.info(
            ""All datanode containers completed; marking application as done"");
        markCompleted();
      }
    }",,
hadoop,11601,"LOG.debug(""Match on record @ {} with children "", path)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-registry/src/main/java/org/apache/hadoop/registry/server/services/RegistryAdminService.java/#L427,"@VisibleForTesting
  public int purge(String path,
      NodeSelector selector,
      PurgePolicy purgePolicy,
      BackgroundCallback callback) throws IOException {


    boolean toDelete = false;
    // look at self to see if it has a service record
    Map<String, RegistryPathStatus> childEntries;
    Collection<RegistryPathStatus> entries;
    try {
      // list this path's children
      childEntries = RegistryUtils.statChildren(this, path);
      entries = childEntries.values();
    } catch (PathNotFoundException e) {
      // there's no record here, it may have been deleted already.
      // exit
      return 0;
    }

    try {
      RegistryPathStatus registryPathStatus = stat(path);
      ServiceRecord serviceRecord = resolve(path);
      // there is now an entry here.
      toDelete = selector.shouldSelect(path, registryPathStatus, serviceRecord);
    } catch (EOFException ignored) {
      // ignore
    } catch (InvalidRecordException ignored) {
      // ignore
    } catch (NoRecordException ignored) {
      // ignore
    } catch (PathNotFoundException e) {
      // there's no record here, it may have been deleted already.
      // exit
      return 0;
    }

    if (toDelete && !entries.isEmpty()) {
      if (LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
LOG.debug(""Match on record @ {} with children "", path)
---------------Reference log end----------------
      }
      // there's children
      switch (purgePolicy) {
        case SkipOnChildren:
          // don't do the deletion... continue to next record
          if (LOG.isDebugEnabled()) {
            LOG.debug(""Skipping deletion"");
          }
          toDelete = false;
          break;
        case PurgeAll:
          // mark for deletion
          if (LOG.isDebugEnabled()) {
            LOG.debug(""Scheduling for deletion with children"");
          }
          toDelete = true;
          entries = new ArrayList<RegistryPathStatus>(0);
          break;
        case FailOnChildren:
          if (LOG.isDebugEnabled()) {
            LOG.debug(""Failing deletion operation"");
          }
          throw new PathIsNotEmptyDirectoryException(path);
      }
    }

    int deleteOps = 0;
    if (toDelete) {
      try {
        zkDelete(path, true, callback);
      } catch (PathNotFoundException e) {
        // sign that the path was deleted during the operation.
        // this is a no-op, and all children can be skipped
        return deleteOps;
      }
      deleteOps++;
    }

    // now go through the children
    for (RegistryPathStatus status : entries) {
      String childname = status.path;
      String childpath = RegistryPathUtils.join(path, childname);
      deleteOps += purge(childpath,
          selector,
          purgePolicy,
          callback);
    }

    return deleteOps;
  }",,
hadoop,6568,"LOG.debug(""Sorting inodes"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java/#L247,"private static byte[][] loadINodeSection(InputStream in)
          throws IOException {
    FsImageProto.INodeSection s = FsImageProto.INodeSection
        .parseDelimitedFrom(in);
    LOG.info(""Loading "" + s.getNumInodes() + "" inodes."");
    final byte[][] inodes = new byte[(int) s.getNumInodes()][];

    for (int i = 0; i < s.getNumInodes(); ++i) {
      int size = CodedInputStream.readRawVarint32(in.read(), in);
      byte[] bytes = new byte[size];
      IOUtils.readFully(in, bytes, 0, size);
      inodes[i] = bytes;
    }
    
---------------Reference log start----------------
LOG.debug(""Sorting inodes"")
---------------Reference log end----------------
    Arrays.sort(inodes, INODE_BYTES_COMPARATOR);
    LOG.debug(""Finished sorting inodes"");
    return inodes;
  }",,
hadoop,5119,"LOG.warn(""Max block location exceeded for split: "" + split + "" splitsize: "" + locations.length + "" maxsize: "" + maxBlockLocations)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/split/JobSplitWriter.java/#L138,"@SuppressWarnings(""unchecked"")
  private static <T extends InputSplit> 
  SplitMetaInfo[] writeNewSplits(Configuration conf, 
      T[] array, FSDataOutputStream out)
  throws IOException, InterruptedException {

    SplitMetaInfo[] info = new SplitMetaInfo[array.length];
    if (array.length != 0) {
      SerializationFactory factory = new SerializationFactory(conf);
      int i = 0;
      int maxBlockLocations = conf.getInt(MRConfig.MAX_BLOCK_LOCATIONS_KEY,
          MRConfig.MAX_BLOCK_LOCATIONS_DEFAULT);
      long offset = out.getPos();
      for(T split: array) {
        long prevCount = out.getPos();
        Text.writeString(out, split.getClass().getName());
        Serializer<T> serializer = 
          factory.getSerializer((Class<T>) split.getClass());
        serializer.open(out);
        serializer.serialize(split);
        long currCount = out.getPos();
        String[] locations = split.getLocations();
        if (locations.length > maxBlockLocations) {
          
---------------Reference log start----------------
LOG.warn(""Max block location exceeded for split: "" + split + "" splitsize: "" + locations.length + "" maxsize: "" + maxBlockLocations)
---------------Reference log end----------------
          locations = Arrays.copyOf(locations, maxBlockLocations);
        }
        info[i++] = 
          new JobSplit.SplitMetaInfo( 
              locations, offset,
              split.getLength());
        offset += currCount - prevCount;
      }
    }
    return info;
  }",,
hadoop,12047,"LOG.debug(""Initializing SSL Context to channel mode {}"", preferredChannelMode)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/ssl/DelegatingSSLSocketFactory.java/#L155,"private void initializeSSLContext(SSLChannelMode preferredChannelMode)
      throws NoSuchAlgorithmException, KeyManagementException, IOException {
    
---------------Reference log start----------------
LOG.debug(""Initializing SSL Context to channel mode {}"", preferredChannelMode)
---------------Reference log end----------------
    switch (preferredChannelMode) {
    case Default:
      try {
        bindToOpenSSLProvider();
        channelMode = SSLChannelMode.OpenSSL;
      } catch (LinkageError | NoSuchAlgorithmException | RuntimeException e) {
        LOG.debug(""Failed to load OpenSSL. Falling back to the JSSE default."",
            e);
        ctx = SSLContext.getDefault();
        channelMode = SSLChannelMode.Default_JSSE;
      }
      break;
    case OpenSSL:
      bindToOpenSSLProvider();
      channelMode = SSLChannelMode.OpenSSL;
      break;
    case Default_JSSE:
      ctx = SSLContext.getDefault();
      channelMode = SSLChannelMode.Default_JSSE;
      break;
    case Default_JSSE_with_GCM:
      ctx = SSLContext.getDefault();
      channelMode = SSLChannelMode.Default_JSSE_with_GCM;
      break;
    default:
      throw new IOException(""Unknown channel mode: ""
          + preferredChannelMode);
    }
  }",,
hadoop,5305,"LOG.warn(""Could not delete "" + taskAttemptPath)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter.java/#L619,"@Private
  public void commitTask(TaskAttemptContext context, Path taskAttemptPath) 
      throws IOException {

    TaskAttemptID attemptId = context.getTaskAttemptID();
    if (hasOutputPath()) {
      context.progress();
      if(taskAttemptPath == null) {
        taskAttemptPath = getTaskAttemptPath(context);
      }
      FileSystem fs = taskAttemptPath.getFileSystem(context.getConfiguration());
      FileStatus taskAttemptDirStatus;
      try {
        taskAttemptDirStatus = fs.getFileStatus(taskAttemptPath);
      } catch (FileNotFoundException e) {
        taskAttemptDirStatus = null;
      }

      if (taskAttemptDirStatus != null) {
        if (algorithmVersion == 1) {
          Path committedTaskPath = getCommittedTaskPath(context);
          if (fs.exists(committedTaskPath)) {
             if (!fs.delete(committedTaskPath, true)) {
               throw new IOException(""Could not delete "" + committedTaskPath);
             }
          }
          if (!fs.rename(taskAttemptPath, committedTaskPath)) {
            throw new IOException(""Could not rename "" + taskAttemptPath + "" to ""
                + committedTaskPath);
          }
          LOG.info(""Saved output of task '"" + attemptId + ""' to "" +
              committedTaskPath);
        } else {
          // directly merge everything from taskAttemptPath to output directory
          mergePaths(fs, taskAttemptDirStatus, outputPath, context);
          LOG.info(""Saved output of task '"" + attemptId + ""' to "" +
              outputPath);

          if (context.getConfiguration().getBoolean(
              FILEOUTPUTCOMMITTER_TASK_CLEANUP_ENABLED,
              FILEOUTPUTCOMMITTER_TASK_CLEANUP_ENABLED_DEFAULT)) {
            LOG.debug(String.format(
                ""Deleting the temporary directory of '%s': '%s'"",
                attemptId, taskAttemptPath));
            if(!fs.delete(taskAttemptPath, true)) {
              
---------------Reference log start----------------
LOG.warn(""Could not delete "" + taskAttemptPath)
---------------Reference log end----------------
            }
          }
        }
      } else {
        LOG.warn(""No Output found for "" + attemptId);
      }
    } else {
      LOG.warn(""Output Path is null in commitTask()"");
    }
  }",,
hadoop,3438,"LOG.error(""Could not start Capacity Scheduler"", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/converter/ConvertedConfigValidator.java/#L75,"public void validateConvertedConfig(String outputDir)
      throws Exception {
    QueueMetrics.clearQueueMetrics();
    Path configPath = new Path(outputDir, ""capacity-scheduler.xml"");

    CapacitySchedulerConfiguration csConfig =
        new CapacitySchedulerConfiguration(
            new Configuration(false), false);
    csConfig.addResource(configPath);

    Path convertedSiteConfigPath = new Path(outputDir, ""yarn-site.xml"");
    Configuration siteConf = new YarnConfiguration(
        new Configuration(false));
    siteConf.addResource(convertedSiteConfigPath);

    RMContextImpl rmContext = new RMContextImpl();
    siteConf.set(YarnConfiguration.FS_BASED_RM_CONF_STORE, outputDir);
    ConfigurationProvider provider = new FileSystemBasedConfigurationProvider();
    provider.init(siteConf);
    rmContext.setConfigurationProvider(provider);
    RMNodeLabelsManager mgr = new RMNodeLabelsManager();
    mgr.init(siteConf);
    rmContext.setNodeLabelManager(mgr);

    try (CapacityScheduler cs = new CapacityScheduler()) {
      cs.setConf(siteConf);
      cs.setRMContext(rmContext);
      cs.serviceInit(csConfig);
      cs.serviceStart();
      LOG.info(""Capacity scheduler was successfully started"");
      cs.serviceStop();
    } catch (Exception e) {
      
---------------Reference log start----------------
LOG.error(""Could not start Capacity Scheduler"", e)
---------------Reference log end----------------
      throw new VerificationException(
          ""Verification of converted configuration failed"", e);
    }
  }",,
hadoop,256,"LOG.error(""No component instance exists for {}"", containerId)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceScheduler.java/#L848,"@Override
    public void onContainerReInitializeError(ContainerId containerId,
        Throwable t) {
      ComponentInstance instance = liveInstances.get(containerId);
      if (instance == null) {
        
---------------Reference log start----------------
LOG.error(""No component instance exists for {}"", containerId)
---------------Reference log end----------------
        return;
      }
      ComponentEvent event = new ComponentEvent(instance.getCompName(),
          ComponentEventType.CONTAINER_COMPLETED)
          .setInstance(instance).setContainerId(containerId);
      dispatcher.getEventHandler().handle(event);
    }",,
hadoop,1023,"LOG.info(""Processed URL "" + url + "" (Took "" + latency + "" ms.)"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/reader/TimelineReaderWebServices.java/#L1153,"@GET
  @Path(""/clusters/{clusterid}/users/{userid}/flows/{flowname}/""
      + ""runs/{flowrunid}/"")
  @Produces(MediaType.APPLICATION_JSON + ""; "" + JettyUtils.UTF_8)
  public TimelineEntity getFlowRun(
      @Context HttpServletRequest req,
      @Context HttpServletResponse res,
      @PathParam(""clusterid"") String clusterId,
      @PathParam(""userid"") String userId,
      @PathParam(""flowname"") String flowName,
      @PathParam(""flowrunid"") String flowRunId,
      @QueryParam(""metricstoretrieve"") String metricsToRetrieve) {
    String url = req.getRequestURI() +
        (req.getQueryString() == null ? """" :
            QUERY_STRING_SEP + req.getQueryString());
    UserGroupInformation callerUGI =
        TimelineReaderWebServicesUtils.getUser(req);
    LOG.info(""Received URL "" + url + "" from user "" +
        TimelineReaderWebServicesUtils.getUserName(callerUGI));
    long startTime = Time.monotonicNow();
    boolean succeeded = false;
    init(res);
    TimelineReaderManager timelineReaderManager = getTimelineReaderManager();
    TimelineEntity entity = null;
    try {
      TimelineReaderContext context = TimelineReaderWebServicesUtils
          .createTimelineReaderContext(clusterId, userId, flowName, flowRunId,
              null, TimelineEntityType.YARN_FLOW_RUN.toString(), null, null);
      // TODO to be removed or modified once ACL story is played
      checkAccess(timelineReaderManager, callerUGI, context.getUserId());

      entity = timelineReaderManager.getEntity(context,
          TimelineReaderWebServicesUtils
              .createTimelineDataToRetrieve(null, metricsToRetrieve, null, null,
                  null, null));
      succeeded = true;
    } catch (Exception e) {
      handleException(e, url, startTime, ""flowrunid"");
    } finally {
      long latency = Time.monotonicNow() - startTime;
      METRICS.addGetEntitiesLatency(latency, succeeded);
      
---------------Reference log start----------------
LOG.info(""Processed URL "" + url + "" (Took "" + latency + "" ms.)"")
---------------Reference log end----------------
    }
    if (entity == null) {
      LOG.info(""Processed URL "" + url + "" but flowrun not found (Took "" +
          (Time.monotonicNow() - startTime) + "" ms.)"");
      throw new NotFoundException(""Flow run {flow name: "" +
          TimelineReaderWebServicesUtils.parseStr(flowName) + "", run id: "" +
          TimelineReaderWebServicesUtils.parseLongStr(flowRunId) +
          "" } is not found"");
    }
    return entity;
  }",,
hadoop,2823,"LOG.info(""received container statuses on node manager register :"" + request.getNMContainerStatuses())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceTrackerService.java/#L562,"@SuppressWarnings(""unchecked"")
  @Override
  public RegisterNodeManagerResponse registerNodeManager(
      RegisterNodeManagerRequest request) throws YarnException,
      IOException {
    NodeId nodeId = request.getNodeId();
    String host = nodeId.getHost();
    int cmPort = nodeId.getPort();
    int httpPort = request.getHttpPort();
    Resource capability = request.getResource();
    String nodeManagerVersion = request.getNMVersion();
    Resource physicalResource = request.getPhysicalResource();
    NodeStatus nodeStatus = request.getNodeStatus();

    RegisterNodeManagerResponse response = recordFactory
        .newRecordInstance(RegisterNodeManagerResponse.class);

    if (!minimumNodeManagerVersion.equals(""NONE"")) {
      if (minimumNodeManagerVersion.equals(""EqualToRM"")) {
        minimumNodeManagerVersion = YarnVersionInfo.getVersion();
      }

      if ((nodeManagerVersion == null) ||
          (VersionUtil.compareVersions(nodeManagerVersion,minimumNodeManagerVersion)) < 0) {
        String message =
            ""Disallowed NodeManager Version "" + nodeManagerVersion
                + "", is less than the minimum version ""
                + minimumNodeManagerVersion + "" sending SHUTDOWN signal to ""
                + ""NodeManager."";
        LOG.info(message);
        response.setDiagnosticsMessage(message);
        response.setNodeAction(NodeAction.SHUTDOWN);
        return response;
      }
    }

    if (checkIpHostnameInRegistration) {
      InetSocketAddress nmAddress =
          NetUtils.createSocketAddrForHost(host, cmPort);
      InetAddress inetAddress = Server.getRemoteIp();
      if (inetAddress != null && nmAddress.isUnresolved()) {
        // Reject registration of unresolved nm to prevent resourcemanager
        // getting stuck at allocations.
        final String message =
            ""hostname cannot be resolved (ip="" + inetAddress.getHostAddress()
                + "", hostname="" + host + "")"";
        LOG.warn(""Unresolved nodemanager registration: "" + message);
        response.setDiagnosticsMessage(message);
        response.setNodeAction(NodeAction.SHUTDOWN);
        return response;
      }
    }

    // Check if this node is a 'valid' node
    if (!this.nodesListManager.isValidNode(host) &&
        !isNodeInDecommissioning(nodeId)) {
      String message =
          ""Disallowed NodeManager from  "" + host
              + "", Sending SHUTDOWN signal to the NodeManager."";
      LOG.info(message);
      response.setDiagnosticsMessage(message);
      response.setNodeAction(NodeAction.SHUTDOWN);
      return response;
    }

    // check if node's capacity is load from dynamic-resources.xml
    String nid = nodeId.toString();

    Resource dynamicLoadCapability = loadNodeResourceFromDRConfiguration(nid);
    if (dynamicLoadCapability != null) {
      LOG.debug(""Resource for node: {} is adjusted from: {} to: {} due to""
          + "" settings in dynamic-resources.xml."", nid, capability,
          dynamicLoadCapability);
      capability = dynamicLoadCapability;
      // sync back with new resource.
      response.setResource(capability);
    }

    // Check if this node has minimum allocations
    if (capability.getMemorySize() < minAllocMb
        || capability.getVirtualCores() < minAllocVcores) {
      String message = ""NodeManager from  "" + host
          + "" doesn't satisfy minimum allocations, Sending SHUTDOWN""
          + "" signal to the NodeManager. Node capabilities are "" + capability
          + ""; minimums are "" + minAllocMb + ""mb and "" + minAllocVcores
          + "" vcores"";
      LOG.info(message);
      response.setDiagnosticsMessage(message);
      response.setNodeAction(NodeAction.SHUTDOWN);
      return response;
    }

    response.setContainerTokenMasterKey(containerTokenSecretManager
        .getCurrentKey());
    response.setNMTokenMasterKey(nmTokenSecretManager
        .getCurrentKey());

    RMNode rmNode = new RMNodeImpl(nodeId, rmContext, host, cmPort, httpPort,
        resolve(host), capability, nodeManagerVersion, physicalResource);

    RMNode oldNode = this.rmContext.getRMNodes().putIfAbsent(nodeId, rmNode);
    if (oldNode == null) {
      RMNodeStartedEvent startEvent = new RMNodeStartedEvent(nodeId,
          request.getNMContainerStatuses(),
          request.getRunningApplications(), nodeStatus);
      if (request.getLogAggregationReportsForApps() != null
          && !request.getLogAggregationReportsForApps().isEmpty()) {
        if (LOG.isDebugEnabled()) {
          LOG.debug(""Found the number of previous cached log aggregation ""
              + ""status from nodemanager:"" + nodeId + "" is :""
              + request.getLogAggregationReportsForApps().size());
        }
        startEvent.setLogAggregationReportsForApps(request
            .getLogAggregationReportsForApps());
      }
      this.rmContext.getDispatcher().getEventHandler().handle(
          startEvent);
    } else {
      LOG.info(""Reconnect from the node at: "" + host);
      this.nmLivelinessMonitor.unregister(nodeId);

      if (CollectionUtils.isEmpty(request.getRunningApplications())
          && rmNode.getState() != NodeState.DECOMMISSIONING
          && rmNode.getHttpPort() != oldNode.getHttpPort()) {
        // Reconnected node differs, so replace old node and start new node
        switch (rmNode.getState()) {
        case RUNNING:
          ClusterMetrics.getMetrics().decrNumActiveNodes();
          break;
        case UNHEALTHY:
          ClusterMetrics.getMetrics().decrNumUnhealthyNMs();
          break;
        default:
          LOG.debug(""Unexpected Rmnode state"");
        }
        this.rmContext.getDispatcher().getEventHandler()
            .handle(new NodeRemovedSchedulerEvent(rmNode));

        this.rmContext.getRMNodes().put(nodeId, rmNode);
        this.rmContext.getDispatcher().getEventHandler()
            .handle(new RMNodeStartedEvent(nodeId, null, null, nodeStatus));
      } else {
        // Reset heartbeat ID since node just restarted.
        oldNode.resetLastNodeHeartBeatResponse();

        this.rmContext.getDispatcher().getEventHandler()
            .handle(new RMNodeReconnectEvent(nodeId, rmNode,
                request.getRunningApplications(),
                request.getNMContainerStatuses()));
      }
    }
    // On every node manager register we will be clearing NMToken keys if
    // present for any running application.
    this.nmTokenSecretManager.removeNodeKey(nodeId);
    this.nmLivelinessMonitor.register(nodeId);
    
    // Handle received container status, this should be processed after new
    // RMNode inserted
    if (!rmContext.isWorkPreservingRecoveryEnabled()) {
      if (!request.getNMContainerStatuses().isEmpty()) {
        
---------------Reference log start----------------
LOG.info(""received container statuses on node manager register :"" + request.getNMContainerStatuses())
---------------Reference log end----------------
        for (NMContainerStatus status : request.getNMContainerStatuses()) {
          handleNMContainerStatus(status, nodeId);
        }
      }
    }

    // Update node's labels to RM's NodeLabelManager.
    Set<String> nodeLabels = NodeLabelsUtils.convertToStringSet(
        request.getNodeLabels());
    if (isDistributedNodeLabelsConf && nodeLabels != null) {
      try {
        updateNodeLabelsFromNMReport(nodeLabels, nodeId);
        response.setAreNodeLabelsAcceptedByRM(true);
      } catch (IOException ex) {
        // Ensure the exception is captured in the response
        response.setDiagnosticsMessage(ex.getMessage());
        response.setAreNodeLabelsAcceptedByRM(false);
      }
    } else if (isDelegatedCentralizedNodeLabelsConf) {
      this.rmContext.getRMDelegatedNodeLabelsUpdater().updateNodeLabels(nodeId);
    }

    // Update node's attributes to RM's NodeAttributesManager.
    if (request.getNodeAttributes() != null) {
      try {
        // update node attributes if necessary then update heartbeat response
        updateNodeAttributesIfNecessary(nodeId, request.getNodeAttributes());
        response.setAreNodeAttributesAcceptedByRM(true);
      } catch (IOException ex) {
        //ensure the error message is captured and sent across in response
        String errorMsg = response.getDiagnosticsMessage() == null ?
            ex.getMessage() :
            response.getDiagnosticsMessage() + ""\n"" + ex.getMessage();
        response.setDiagnosticsMessage(errorMsg);
        response.setAreNodeAttributesAcceptedByRM(false);
      }
    }

    StringBuilder message = new StringBuilder();
    message.append(""NodeManager from node "").append(host).append(""(cmPort: "")
        .append(cmPort).append("" httpPort: "");
    message.append(httpPort).append("") "")
        .append(""registered with capability: "").append(capability);
    message.append("", assigned nodeId "").append(nodeId);
    if (response.getAreNodeLabelsAcceptedByRM()) {
      message.append("", node labels { "").append(
          StringUtils.join("","", nodeLabels) + "" } "");
    }
    if (response.getAreNodeAttributesAcceptedByRM()) {
      message.append("", node attributes { "")
          .append(request.getNodeAttributes() + "" } "");
    }

    LOG.info(message.toString());
    response.setNodeAction(NodeAction.NORMAL);
    response.setRMIdentifier(ResourceManager.getClusterTimeStamp());
    response.setRMVersion(YarnVersionInfo.getVersion());
    return response;
  }",,
hadoop,6222,"LOG.warn(""Original exception is "", ioe)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java/#L888,"private void shouldRetry(final IOException ioe, final int retry
    ) throws IOException {
      InetSocketAddress nnAddr = getCurrentNNAddr();
      if (checkRetry) {
        try {
          final RetryPolicy.RetryAction a = retryPolicy.shouldRetry(
              ioe, retry, 0, true);

          boolean isRetry =
              a.action == RetryPolicy.RetryAction.RetryDecision.RETRY;
          boolean isFailoverAndRetry =
              a.action == RetryPolicy.RetryAction.RetryDecision.FAILOVER_AND_RETRY;
          if (isRetry || isFailoverAndRetry) {
            LOG.info(""Retrying connect to namenode: {}. Already retried {}""
                    + "" time(s); retry policy is {}, delay {}ms."",
                nnAddr, retry, retryPolicy, a.delayMillis);

            if (isFailoverAndRetry) {
              resetStateToFailOver();
            }

            Thread.sleep(a.delayMillis);
            return;
          }
        } catch(Exception e) {
          
---------------Reference log start----------------
LOG.warn(""Original exception is "", ioe)
---------------Reference log end----------------
          throw toIOException(e);
        }
      }
      throw toIOException(ioe);
    }",,
hadoop,8297,"LOG.warn(""Unexpected error trying to "" + (trashDirectory == null ? ""delete"" : ""move"") + "" block "" + block.getBlockPoolId() + "" "" + block.getLocalBlock() + "" at file "" + replicaToDelete.getBlockURI() + "". Ignored."")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetAsyncDiskService.java/#L334,"@Override
    public void run() {
      try {
        final long blockLength = replicaToDelete.getBlockDataLength();
        final long metaLength = replicaToDelete.getMetadataLength();
        boolean result;

        result = (trashDirectory == null) ? deleteFiles() : moveFiles();

        if (!result) {
          
---------------Reference log start----------------
LOG.warn(""Unexpected error trying to "" + (trashDirectory == null ? ""delete"" : ""move"") + "" block "" + block.getBlockPoolId() + "" "" + block.getLocalBlock() + "" at file "" + replicaToDelete.getBlockURI() + "". Ignored."")
---------------Reference log end----------------
        } else {
          if (block.getLocalBlock().getNumBytes() != BlockCommand.NO_ACK) {
            datanode.notifyNamenodeDeletedBlock(block, volume.getStorageID());
          }
          volume.onBlockFileDeletion(block.getBlockPoolId(), blockLength);
          volume.onMetaFileDeletion(block.getBlockPoolId(), metaLength);
          LOG.info(""Deleted "" + block.getBlockPoolId() + "" "" +
              block.getLocalBlock() + "" URI "" + replicaToDelete.getBlockURI());
        }
        updateDeletedBlockId(block);
      } finally {
        IOUtils.cleanupWithLogger(null, this.volumeRef);
      }
    }",,
hadoop,9818,"LOG.warn(""Rename: CopyBlob: StorageException: Failed"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java/#L2891,"@Override
  public void rename(String srcKey, String dstKey, boolean acquireLease,
      SelfRenewingLease existingLease, boolean overwriteDestination) throws IOException {

    LOG.debug(""Moving {} to {}"", srcKey, dstKey);

    if (acquireLease && existingLease != null) {
      throw new IOException(""Cannot acquire new lease if one already exists."");
    }

    CloudBlobWrapper srcBlob = null;
    CloudBlobWrapper dstBlob = null;
    SelfRenewingLease lease = null;
    try {
      // Attempts rename may occur before opening any streams so first,
      // check if a session exists, if not create a session with the Azure
      // storage server.
      if (null == storageInteractionLayer) {
        final String errMsg = String.format(
            ""Storage session expected for URI '%s' but does not exist."",
            sessionUri);
        throw new AssertionError(errMsg);
      }

      checkContainer(ContainerAccessType.ReadThenWrite);
      // Get the source blob and assert its existence. If the source key
      // needs to be normalized then normalize it.
      //

      srcBlob = getBlobReference(srcKey);
      if (!srcBlob.exists(getInstrumentedContext())) {
        throw new AzureException(""Source blob "" + srcKey + "" does not exist."");
      }

      /**
       * Conditionally get a lease on the source blob to prevent other writers
       * from changing it. This is used for correctness in HBase when log files
       * are renamed. It generally should do no harm other than take a little
       * more time for other rename scenarios. When the HBase master renames a
       * log file folder, the lease locks out other writers.  This
       * prevents a region server that the master thinks is dead, but is still
       * alive, from committing additional updates.  This is different than
       * when HBase runs on HDFS, where the region server recovers the lease
       * on a log file, to gain exclusive access to it, before it splits it.
       */
      if (acquireLease) {
        lease = srcBlob.acquireLease();
      } else if (existingLease != null) {
        lease = existingLease;
      }

      // Get the destination blob. The destination key always needs to be
      // normalized.
      //
      dstBlob = getBlobReference(dstKey);

      // Rename the source blob to the destination blob by copying it to
      // the destination blob then deleting it.
      //
      // Copy blob operation in Azure storage is very costly. It will be highly
      // likely throttled during Azure storage gc. Short term fix will be using
      // a more intensive exponential retry policy when the cluster is getting
      // throttled.
      try {
        dstBlob.startCopyFromBlob(srcBlob, null,
            getInstrumentedContext(), overwriteDestination);
      } catch (StorageException se) {
        if (se.getHttpStatusCode() == HttpURLConnection.HTTP_UNAVAILABLE) {
          int copyBlobMinBackoff = sessionConfiguration.getInt(
            KEY_COPYBLOB_MIN_BACKOFF_INTERVAL,
            DEFAULT_COPYBLOB_MIN_BACKOFF_INTERVAL);

          int copyBlobMaxBackoff = sessionConfiguration.getInt(
            KEY_COPYBLOB_MAX_BACKOFF_INTERVAL,
            DEFAULT_COPYBLOB_MAX_BACKOFF_INTERVAL);

          int copyBlobDeltaBackoff = sessionConfiguration.getInt(
            KEY_COPYBLOB_BACKOFF_INTERVAL,
            DEFAULT_COPYBLOB_BACKOFF_INTERVAL);

          int copyBlobMaxRetries = sessionConfiguration.getInt(
            KEY_COPYBLOB_MAX_IO_RETRIES,
            DEFAULT_COPYBLOB_MAX_RETRY_ATTEMPTS);

          BlobRequestOptions options = new BlobRequestOptions();
          options.setRetryPolicyFactory(new RetryExponentialRetry(
            copyBlobMinBackoff, copyBlobDeltaBackoff, copyBlobMaxBackoff,
            copyBlobMaxRetries));
          dstBlob.startCopyFromBlob(srcBlob, options,
              getInstrumentedContext(), overwriteDestination);
        } else {
          throw se;
        }
      }
      waitForCopyToComplete(dstBlob, getInstrumentedContext());
      safeDelete(srcBlob, lease);
    } catch (StorageException e) {
      if (e.getHttpStatusCode() == HttpURLConnection.HTTP_UNAVAILABLE) {
        LOG.warn(""Rename: CopyBlob: StorageException: ServerBusy: Retry complete, will attempt client side copy for page blob"");
        InputStream ipStream = null;
        OutputStream opStream = null;
        try {
          if (srcBlob.getProperties().getBlobType() == BlobType.PAGE_BLOB){
            ipStream = openInputStream(srcBlob, Optional.empty());
            opStream = openOutputStream(dstBlob);
            byte[] buffer = new byte[PageBlobFormatHelpers.PAGE_SIZE];
            int len;
            while ((len = ipStream.read(buffer)) != -1) {
              opStream.write(buffer, 0, len);
            }
            opStream.flush();
            opStream.close();
            ipStream.close();
          } else {
            throw new AzureException(e);
          }
          safeDelete(srcBlob, lease);
        } catch(StorageException se) {
          
---------------Reference log start----------------
LOG.warn(""Rename: CopyBlob: StorageException: Failed"")
---------------Reference log end----------------
          throw new AzureException(se);
        } finally {
          IOUtils.closeStream(ipStream);
          IOUtils.closeStream(opStream);
        }
      } else {
        throw new AzureException(e);
      }
    } catch (URISyntaxException e) {
      // Re-throw exception as an Azure storage exception.
      throw new AzureException(e);
    }
  }",,
hadoop,10448,"LOG.debug(""Number of paths written to fileListing={}"", fileStatusInfoList.size())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java/#L437,"private void writeToFileListing(List<FileStatusInfo> fileStatusInfoList,
      SequenceFile.Writer fileListWriter) throws IOException {
    /**
     * In cloud storage systems, it is possible to get region hotspot.
     * Shuffling paths can avoid such cases and also ensure that
     * some mappers do not get lots of similar paths.
     */
    Collections.shuffle(fileStatusInfoList, rnd);
    for (FileStatusInfo fileStatusInfo : fileStatusInfoList) {
      LOG.debug(""Adding {}"", fileStatusInfo.fileStatus.getPath());
      writeToFileListing(fileListWriter, fileStatusInfo.fileStatus,
          fileStatusInfo.sourceRootPath);
    }
    
---------------Reference log start----------------
LOG.debug(""Number of paths written to fileListing={}"", fileStatusInfoList.size())
---------------Reference log end----------------
    fileStatusInfoList.clear();
  }",,
hadoop,5661,"LOG.error(""Can't get path for dirHandle: {}"", dirHandle)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/RpcProgramNfs3.java/#L972,"@VisibleForTesting
  CREATE3Response create(XDR xdr, SecurityHandler securityHandler,
      SocketAddress remoteAddress) {
    CREATE3Response response = new CREATE3Response(Nfs3Status.NFS3_OK);

    CREATE3Request request;

    try {
      request = CREATE3Request.deserialize(xdr);
    } catch (IOException e) {
      LOG.error(""Invalid CREATE request"");
      return new CREATE3Response(Nfs3Status.NFS3ERR_INVAL);
    }

    FileHandle dirHandle = request.getHandle();
    String fileName = request.getName();
    int namenodeId = dirHandle.getNamenodeId();
    if (LOG.isDebugEnabled()) {
      LOG.debug(""NFS CREATE dir fileHandle: {} filename: {} client: {}"",
          dirHandle.dumpFileHandle(), fileName, remoteAddress);
    }
    DFSClient dfsClient =
        clientCache.getDfsClient(securityHandler.getUser(), namenodeId);
    if (dfsClient == null) {
      response.setStatus(Nfs3Status.NFS3ERR_SERVERFAULT);
      return response;
    }

    int createMode = request.getMode();
    if ((createMode != Nfs3Constant.CREATE_EXCLUSIVE)
        && request.getObjAttr().getUpdateFields().contains(SetAttrField.SIZE)
        && request.getObjAttr().getSize() != 0) {
      LOG.error(""Setting file size is not supported when creating file: {} "" +
          ""dir fileId: {}"", fileName, dirHandle.getFileId());
      return new CREATE3Response(Nfs3Status.NFS3ERR_INVAL);
    }

    HdfsDataOutputStream fos = null;
    String dirFileIdPath = Nfs3Utils.getFileIdPath(dirHandle);
    Nfs3FileAttributes preOpDirAttr = null;
    Nfs3FileAttributes postOpObjAttr = null;
    FileHandle fileHandle = null;
    WccData dirWcc = null;
    try {
      preOpDirAttr = Nfs3Utils.getFileAttr(dfsClient, dirFileIdPath, iug);
      if (preOpDirAttr == null) {
        
---------------Reference log start----------------
LOG.error(""Can't get path for dirHandle: {}"", dirHandle)
---------------Reference log end----------------
        return new CREATE3Response(Nfs3Status.NFS3ERR_STALE);
      }

      if (!checkAccessPrivilege(remoteAddress, AccessPrivilege.READ_WRITE)) {
        return new CREATE3Response(Nfs3Status.NFS3ERR_ACCES, null,
            preOpDirAttr, new WccData(Nfs3Utils.getWccAttr(preOpDirAttr),
                preOpDirAttr));
      }

      String fileIdPath = Nfs3Utils.getFileIdPath(dirHandle) + ""/"" + fileName;
      SetAttr3 setAttr3 = request.getObjAttr();
      assert (setAttr3 != null);
      FsPermission permission = setAttr3.getUpdateFields().contains(
          SetAttrField.MODE) ? new FsPermission((short) setAttr3.getMode())
          : FsPermission.getDefault().applyUMask(umask);

      EnumSet<CreateFlag> flag = (createMode != Nfs3Constant.CREATE_EXCLUSIVE) ? 
          EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE) : 
          EnumSet.of(CreateFlag.CREATE);

      fos = dfsClient.createWrappedOutputStream(
          dfsClient.create(fileIdPath, permission, flag, false, replication,
              blockSize, null, bufferSize, null),
          null);

      if ((createMode == Nfs3Constant.CREATE_UNCHECKED)
          || (createMode == Nfs3Constant.CREATE_GUARDED)) {
        // Set group if it's not specified in the request.
        if (!setAttr3.getUpdateFields().contains(SetAttrField.GID)) {
          setAttr3.getUpdateFields().add(SetAttrField.GID);
          setAttr3.setGid(securityHandler.getGid());
        }
        setattrInternal(dfsClient, fileIdPath, setAttr3, false);
      }

      postOpObjAttr = Nfs3Utils.getFileAttr(dfsClient, fileIdPath, iug);
      dirWcc = Nfs3Utils.createWccData(Nfs3Utils.getWccAttr(preOpDirAttr),
          dfsClient, dirFileIdPath, iug);

      // Add open stream
      OpenFileCtx openFileCtx = new OpenFileCtx(fos, postOpObjAttr,
          writeDumpDir + ""/"" + postOpObjAttr.getFileId(), dfsClient, iug,
          aixCompatMode, config);
      fileHandle = new FileHandle(postOpObjAttr.getFileId(), namenodeId);
      if (!writeManager.addOpenFileStream(fileHandle, openFileCtx)) {
        LOG.warn(""Can't add more stream, close it.""
            + "" Future write will become append"");
        fos.close();
        fos = null;
      } else {
        LOG.debug(""Opened stream for file: {}, fileId: {}"",
            fileName, fileHandle.getFileId());
      }

    } catch (IOException e) {
      LOG.error(""Exception"", e);
      if (fos != null) {
        try {
          fos.close();
        } catch (IOException e1) {
          LOG.error(""Can't close stream for dirFileId: {} filename: {}"",
              dirHandle.getFileId(), fileName, e1);
        }
      }
      if (dirWcc == null) {
        try {
          dirWcc = Nfs3Utils.createWccData(Nfs3Utils.getWccAttr(preOpDirAttr),
              dfsClient, dirFileIdPath, iug);
        } catch (IOException e1) {
          LOG.info(""Can't get postOpDirAttr for dirFileId: {}"",
              dirHandle.getFileId(), e1);
        }
      }

      int status = mapErrorStatus(e);
      return new CREATE3Response(status, fileHandle, postOpObjAttr, dirWcc);
    }

    return new CREATE3Response(Nfs3Status.NFS3_OK, fileHandle, postOpObjAttr,
        dirWcc);
  }",,
hadoop,6166,"LOG.debug(""Connecting to datanode {}"", dnAddr)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DataStreamer.java/#L249,"static Socket createSocketForPipeline(final DatanodeInfo first,
      final int length, final DFSClient client) throws IOException {
    final DfsClientConf conf = client.getConf();
    final String dnAddr = first.getXferAddr(conf.isConnectToDnViaHostname());
    
---------------Reference log start----------------
LOG.debug(""Connecting to datanode {}"", dnAddr)
---------------Reference log end----------------
    final InetSocketAddress isa = NetUtils.createSocketAddr(dnAddr);
    final Socket sock = client.socketFactory.createSocket();
    final int timeout = client.getDatanodeReadTimeout(length);
    NetUtils.connect(sock, isa, client.getRandomLocalInterfaceAddr(),
        conf.getSocketTimeout());
    sock.setTcpNoDelay(conf.getDataTransferTcpNoDelay());
    sock.setSoTimeout(timeout);
    sock.setKeepAlive(true);
    if (conf.getSocketSendBufferSize() > 0) {
      sock.setSendBufferSize(conf.getSocketSendBufferSize());
    }
    LOG.debug(""Send buf size {}"", sock.getSendBufferSize());
    return sock;
  }",,
hadoop,12059,"LOG.debug(""Creating SASL "" + mechanism + ""("" + method + "") "" + "" client to authenticate to service at "" + saslServerName)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/SaslRpcClient.java/#L257,"private SaslClient createSaslClient(SaslAuth authType)
      throws SaslException, IOException {
    String saslUser = null;
    // SASL requires the client and server to use the same proto and serverId
    // if necessary, auth types below will verify they are valid
    final String saslProtocol = authType.getProtocol();
    final String saslServerName = authType.getServerId();
    Map<String, String> saslProperties =
      saslPropsResolver.getClientProperties(serverAddr.getAddress());  
    CallbackHandler saslCallback = null;
    
    final AuthMethod method = AuthMethod.valueOf(authType.getMethod());
    switch (method) {
      case TOKEN: {
        Token<?> token = getServerToken(authType);
        if (token == null) {
          LOG.debug(""tokens aren't supported for this protocol"" +
              "" or user doesn't have one"");
          return null;
        }
        saslCallback = new SaslClientCallbackHandler(token);
        break;
      }
      case KERBEROS: {
        if (ugi.getRealAuthenticationMethod().getAuthMethod() !=
            AuthMethod.KERBEROS) {
          LOG.debug(""client isn't using kerberos"");
          return null;
        }
        String serverPrincipal = getServerPrincipal(authType);
        if (serverPrincipal == null) {
          LOG.debug(""protocol doesn't use kerberos"");
          return null;
        }
        if (LOG.isDebugEnabled()) {
          LOG.debug(""RPC Server's Kerberos principal name for protocol=""
              + protocol.getCanonicalName() + "" is "" + serverPrincipal);
        }
        break;
      }
      default:
        throw new IOException(""Unknown authentication method "" + method);
    }

    String mechanism = method.getMechanismName();
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""Creating SASL "" + mechanism + ""("" + method + "") "" + "" client to authenticate to service at "" + saslServerName)
---------------Reference log end----------------
    }
    return saslFactory.createSaslClient(
        new String[] {mechanism}, saslUser, saslProtocol, saslServerName,
        saslProperties, saslCallback);
  }",,
hadoop,3248,"LOG.warn(""Trying to remove tags, however the tag "" + tag + "" no longer exists on this node/rack."")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/AllocationTagsManager.java/#L119,"private void removeTagFromInnerMap(Map<String, Long> innerMap, String tag) {
      Long count = innerMap.get(tag);
      if (count == null) {
        
---------------Reference log start----------------
LOG.warn(""Trying to remove tags, however the tag "" + tag + "" no longer exists on this node/rack."")
---------------Reference log end----------------
        return;
      }
      if (count > 1) {
        innerMap.put(tag, count - 1);
      } else {
        if (count <= 0) {
          LOG.warn(
              ""Trying to remove tags from node/rack, however the count already""
                  + "" becomes 0 or less, it could be a potential bug."");
        }
        innerMap.remove(tag);
      }
    }",,
hadoop,4063,"LOG.info(""closing the hbase Connection"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineReaderImpl.java/#L74,"@Override
  protected void serviceStop() throws Exception {
    if (conn != null) {
      
---------------Reference log start----------------
LOG.info(""closing the hbase Connection"")
---------------Reference log end----------------
      conn.close();
    }
    storageMonitor.stop();
    super.serviceStop();
  }",,
hadoop,5076,"LOG.debug(""starting downlink"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/BinaryProtocol.java/#L280,"public void start() throws IOException {
    
---------------Reference log start----------------
LOG.debug(""starting downlink"")
---------------Reference log end----------------
    WritableUtils.writeVInt(stream, MessageType.START.code);
    WritableUtils.writeVInt(stream, CURRENT_PROTOCOL_VERSION);
  }",,
hadoop,1655,"LOG.info(""Starting container ["" + container.getContainerId() + ""]"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/scheduler/ContainerScheduler.java/#L541,"private void startContainer(Container container) {
    
---------------Reference log start----------------
LOG.info(""Starting container ["" + container.getContainerId() + ""]"")
---------------Reference log end----------------
    // Skip to put into runningContainers and addUtilization when recover
    if (!runningContainers.containsKey(container.getContainerId())) {
      runningContainers.put(container.getContainerId(), container);
      this.utilizationTracker.addContainerResources(container);
    }
    if (container.getContainerTokenIdentifier().getExecutionType() ==
        ExecutionType.OPPORTUNISTIC) {
      this.metrics.startOpportunisticContainer(container.getResource());
    }
    container.sendLaunchEvent();
  }",,
hadoop,3035,"LOG.info(""Skipping activateApplications for "" + application.getApplicationAttemptId() + "" since cluster resource is "" + Resources.none())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java/#L970,"private void addApplicationAttempt(FiCaSchedulerApp application,
      User user) {
    writeLock.lock();
    try {
      applicationAttemptMap.put(application.getApplicationAttemptId(),
          application);

      if (application.isRunnable()) {
        runnableApps.add(application);
        LOG.debug(""Adding runnable application: {}"",
            application.getApplicationAttemptId());
      } else {
        nonRunnableApps.add(application);
        LOG.info(""Application attempt {} is not runnable,""
            + "" parallel limit reached"", application.getApplicationAttemptId());
        return;
      }

      // Accept
      user.submitApplication();
      getPendingAppsOrderingPolicy().addSchedulableEntity(application);

      // Activate applications
      if (Resources.greaterThan(resourceCalculator, lastClusterResource,
          lastClusterResource, Resources.none())) {
        activateApplications();
      } else {
        application.updateAMContainerDiagnostics(AMState.INACTIVATED,
            CSAMContainerLaunchDiagnosticsConstants.CLUSTER_RESOURCE_EMPTY);
        
---------------Reference log start----------------
LOG.info(""Skipping activateApplications for "" + application.getApplicationAttemptId() + "" since cluster resource is "" + Resources.none())
---------------Reference log end----------------
      }

      LOG.info(
          ""Application added -"" + "" appId: "" + application.getApplicationId()
              + "" user: "" + application.getUser() + "","" + "" leaf-queue: ""
              + getQueuePath() + "" #user-pending-applications: "" + user
              .getPendingApplications() + "" #user-active-applications: "" + user
              .getActiveApplications() + "" #queue-pending-applications: ""
              + getNumPendingApplications() + "" #queue-active-applications: ""
              + getNumActiveApplications()
              + "" #queue-nonrunnable-applications: ""
              + getNumNonRunnableApps());
    } finally {
      writeLock.unlock();
    }
  }",,
hadoop,9013,"LOG.error(""Cannot get available namenode for {} {} error: {}"", nsId, rpcAddress, ioe.getMessage())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcClient.java/#L511,"private Object invokeMethod(
      final UserGroupInformation ugi,
      final List<? extends FederationNamenodeContext> namenodes,
      final Class<?> protocol, final Method method, final Object... params)
          throws ConnectException, StandbyException, IOException {

    if (namenodes == null || namenodes.isEmpty()) {
      throw new IOException(""No namenodes to invoke "" + method.getName() +
          "" with params "" + Arrays.deepToString(params) + "" from ""
          + router.getRouterId());
    }

    appendClientIpToCallerContextIfAbsent();

    Object ret = null;
    if (rpcMonitor != null) {
      rpcMonitor.proxyOp();
    }
    boolean failover = false;
    Map<FederationNamenodeContext, IOException> ioes = new LinkedHashMap<>();
    for (FederationNamenodeContext namenode : namenodes) {
      ConnectionContext connection = null;
      String nsId = namenode.getNameserviceId();
      String rpcAddress = namenode.getRpcAddress();
      try {
        connection = this.getConnection(ugi, nsId, rpcAddress, protocol);
        ProxyAndInfo<?> client = connection.getClient();
        final Object proxy = client.getProxy();

        ret = invoke(nsId, 0, method, proxy, params);
        if (failover) {
          // Success on alternate server, update
          InetSocketAddress address = client.getAddress();
          namenodeResolver.updateActiveNamenode(nsId, address);
        }
        if (this.rpcMonitor != null) {
          this.rpcMonitor.proxyOpComplete(true);
        }
        return ret;
      } catch (IOException ioe) {
        ioes.put(namenode, ioe);
        if (ioe instanceof StandbyException) {
          // Fail over indicated by retry policy and/or NN
          if (this.rpcMonitor != null) {
            this.rpcMonitor.proxyOpFailureStandby();
          }
          failover = true;
        } else if (isUnavailableException(ioe)) {
          if (this.rpcMonitor != null) {
            this.rpcMonitor.proxyOpFailureCommunicate();
          }
          failover = true;
        } else if (ioe instanceof RemoteException) {
          if (this.rpcMonitor != null) {
            this.rpcMonitor.proxyOpComplete(true);
          }
          RemoteException re = (RemoteException) ioe;
          ioe = re.unwrapRemoteException();
          ioe = getCleanException(ioe);
          // RemoteException returned by NN
          throw ioe;
        } else if (ioe instanceof ConnectionNullException) {
          if (this.rpcMonitor != null) {
            this.rpcMonitor.proxyOpFailureCommunicate();
          }
          LOG.error(""Get connection for {} {} error: {}"", nsId, rpcAddress,
              ioe.getMessage());
          // Throw StandbyException so that client can retry
          StandbyException se = new StandbyException(ioe.getMessage());
          se.initCause(ioe);
          throw se;
        } else if (ioe instanceof NoNamenodesAvailableException) {
          if (this.rpcMonitor != null) {
            this.rpcMonitor.proxyOpNoNamenodes();
          }
          
---------------Reference log start----------------
LOG.error(""Cannot get available namenode for {} {} error: {}"", nsId, rpcAddress, ioe.getMessage())
---------------Reference log end----------------
          // Throw RetriableException so that client can retry
          throw new RetriableException(ioe);
        } else {
          // Other communication error, this is a failure
          // Communication retries are handled by the retry policy
          if (this.rpcMonitor != null) {
            this.rpcMonitor.proxyOpFailureCommunicate();
            this.rpcMonitor.proxyOpComplete(false);
          }
          throw ioe;
        }
      } finally {
        if (connection != null) {
          connection.release();
        }
      }
    }
    if (this.rpcMonitor != null) {
      this.rpcMonitor.proxyOpComplete(false);
    }

    // All namenodes were unavailable or in standby
    String msg = ""No namenode available to invoke "" + method.getName() + "" "" +
        Arrays.deepToString(params) + "" in "" + namenodes + "" from "" +
        router.getRouterId();
    LOG.error(msg);
    int exConnect = 0;
    for (Entry<FederationNamenodeContext, IOException> entry :
        ioes.entrySet()) {
      FederationNamenodeContext namenode = entry.getKey();
      String nnKey = namenode.getNamenodeKey();
      String addr = namenode.getRpcAddress();
      IOException ioe = entry.getValue();
      if (ioe instanceof StandbyException) {
        LOG.error(""{} at {} is in Standby: {}"",
            nnKey, addr, ioe.getMessage());
      } else if (isUnavailableException(ioe)) {
        exConnect++;
        LOG.error(""{} at {} cannot be reached: {}"",
            nnKey, addr, ioe.getMessage());
      } else {
        LOG.error(""{} at {} error: \""{}\"""", nnKey, addr, ioe.getMessage());
      }
    }
    if (exConnect == ioes.size()) {
      throw new ConnectException(msg);
    } else {
      throw new StandbyException(msg);
    }
  }",,
hadoop,7810,"LOG.error(""{} encountered fatal exception and exit."", getName(), t)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java/#L1368,"@Override
    public void run() {
      try {
        processQueue();
      } catch (Throwable t) {
        
---------------Reference log start----------------
LOG.error(""{} encountered fatal exception and exit."", getName(), t)
---------------Reference log end----------------
        runningState = RunningState.FAILED;
      } finally {
        LOG.warn(""Ending command processor service for: "" + this);
        shouldServiceRun = false;
      }
    }",,
hadoop,12746,"LOG.debug(""parsing URL "" + url)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java/#L2998,"private XMLStreamReader parse(URL url, boolean restricted)
      throws IOException, XMLStreamException {
    if (!quietmode) {
      if (LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
LOG.debug(""parsing URL "" + url)
---------------Reference log end----------------
      }
    }
    if (url == null) {
      return null;
    }

    URLConnection connection = url.openConnection();
    if (connection instanceof JarURLConnection) {
      // Disable caching for JarURLConnection to avoid sharing JarFile
      // with other users.
      connection.setUseCaches(false);
    }
    return parse(connection.getInputStream(), url.toString(), restricted);
  }",,
hadoop,1289,"LOG.info(""Rolling master-key for container-tokens, got key with id "" + masterKeyRecord.getKeyId())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/security/NMContainerTokenSecretManager.java/#L143,"@Private
  public synchronized void setMasterKey(MasterKey masterKeyRecord) {
    // Update keys only if the key has changed.
    if (super.currentMasterKey == null || super.currentMasterKey.getMasterKey()
          .getKeyId() != masterKeyRecord.getKeyId()) {
      
---------------Reference log start----------------
LOG.info(""Rolling master-key for container-tokens, got key with id "" + masterKeyRecord.getKeyId())
---------------Reference log end----------------
      if (super.currentMasterKey != null) {
        updatePreviousMasterKey(super.currentMasterKey);
      }
      updateCurrentMasterKey(new MasterKeyData(masterKeyRecord,
          createSecretKey(masterKeyRecord.getBytes().array())));
    }
  }",,
hadoop,9417,"LOG.debug(""create: Overwriting file {}"", f)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-huaweicloud/src/main/java/org/apache/hadoop/fs/obs/OBSFileSystem.java/#L711,"@Override
  public FSDataOutputStream create(
      final Path f,
      final FsPermission permission,
      final boolean overwrite,
      final int bufferSize,
      final short replication,
      final long blkSize,
      final Progressable progress)
      throws IOException {
    String key = OBSCommonUtils.pathToKey(this, f);
    FileStatus status;
    long objectLen = 0;
    try {
      // get the status or throw an exception
      status = getFileStatus(f);
      objectLen = status.getLen();
      // if the thread reaches here, there is something at the path
      if (status.isDirectory()) {
        // path references a directory: automatic error
        throw new FileAlreadyExistsException(f + "" is a directory"");
      }
      if (!overwrite) {
        // path references a file and overwrite is disabled
        throw new FileAlreadyExistsException(f + "" already exists"");
      }
      
---------------Reference log start----------------
LOG.debug(""create: Overwriting file {}"", f)
---------------Reference log end----------------
    } catch (FileNotFoundException e) {
      // this means the file is not found
      LOG.debug(""create: Creating new file {}"", f);
    }
    return new FSDataOutputStream(
        new OBSBlockOutputStream(
            this,
            key,
            objectLen,
            new SemaphoredDelegatingExecutor(
                boundedMultipartUploadThreadPool,
                blockOutputActiveBlocks, true),
            false),
        null);
  }",,
hadoop,10153,"LOG.error(""Missing "" + fileCount + "" distributed cache files under the "" + "" directory\n"" + distCachePath + ""\nthat are needed for gridmix"" + "" to emulate distributed cache load. Either use -generate\noption"" + "" to generate distributed cache data along with input data OR "" + ""disable\ndistributed cache emulation by configuring '"" + DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE + ""' to false."")",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java/#L468,"private int writeDistCacheFilesList()
      throws IOException {
    // Sort the distributed cache files in the decreasing order of file sizes.
    List dcFiles = new ArrayList(distCacheFiles.entrySet());
    Collections.sort(dcFiles, new Comparator() {
      public int compare(Object dc1, Object dc2) {
        return ((Comparable) ((Map.Entry) (dc2)).getValue())
            .compareTo(((Map.Entry) (dc1)).getValue());
      }
    });

    // write the sorted distributed cache files to the sequence file
    FileSystem fs = FileSystem.get(conf);
    Path distCacheFilesList = new Path(distCachePath, ""_distCacheFiles.txt"");
    conf.set(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_LIST,
        distCacheFilesList.toString());
    SequenceFile.Writer src_writer = SequenceFile.createWriter(fs, conf,
        distCacheFilesList, LongWritable.class, BytesWritable.class,
        SequenceFile.CompressionType.NONE);

    // Total number of unique distributed cache files
    int fileCount = dcFiles.size();
    long byteCount = 0;// Total size of all distributed cache files
    long bytesSync = 0;// Bytes after previous sync;used to add sync marker

    for (Iterator it = dcFiles.iterator(); it.hasNext();) {
      Map.Entry entry = (Map.Entry)it.next();
      LongWritable fileSize =
          new LongWritable(Long.parseLong(entry.getValue().toString()));
      BytesWritable filePath =
          new BytesWritable(
          entry.getKey().toString().getBytes(charsetUTF8));

      byteCount += fileSize.get();
      bytesSync += fileSize.get();
      if (bytesSync > AVG_BYTES_PER_MAP) {
        src_writer.sync();
        bytesSync = fileSize.get();
      }
      src_writer.append(fileSize, filePath);
    }
    if (src_writer != null) {
      src_writer.close();
    }
    // Set delete on exit for 'dist cache files list' as it is not needed later.
    fs.deleteOnExit(distCacheFilesList);

    conf.setInt(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_COUNT, fileCount);
    conf.setLong(GenerateDistCacheData.GRIDMIX_DISTCACHE_BYTE_COUNT, byteCount);
    LOG.info(""Number of HDFS based distributed cache files to be generated is ""
        + fileCount + "". Total size of HDFS based distributed cache files ""
        + ""to be generated is "" + byteCount);

    if (!shouldGenerateDistCacheData() && fileCount > 0) {
      
---------------Reference log start----------------
LOG.error(""Missing "" + fileCount + "" distributed cache files under the "" + "" directory\n"" + distCachePath + ""\nthat are needed for gridmix"" + "" to emulate distributed cache load. Either use -generate\noption"" + "" to generate distributed cache data along with input data OR "" + ""disable\ndistributed cache emulation by configuring '"" + DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE + ""' to false."")
---------------Reference log end----------------
      return Gridmix.MISSING_DIST_CACHE_FILES_ERROR;
    }
    return 0;
  }",,
hadoop,12606,"LOG.debug(""Filesystem glob {}"", pathPatternString)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Globber.java/#L220,"private FileStatus[] doGlob() throws IOException {
    // First we get the scheme and authority of the pattern that was passed
    // in.
    String scheme = schemeFromPath(pathPattern);
    String authority = authorityFromPath(pathPattern);

    // Next we strip off everything except the pathname itself, and expand all
    // globs.  Expansion is a process which turns ""grouping"" clauses,
    // expressed as brackets, into separate path patterns.
    String pathPatternString = pathPattern.toUri().getPath();
    List<String> flattenedPatterns = GlobExpander.expand(pathPatternString);

    
---------------Reference log start----------------
LOG.debug(""Filesystem glob {}"", pathPatternString)
---------------Reference log end----------------
    // Now loop over all flattened patterns.  In every case, we'll be trying to
    // match them to entries in the filesystem.
    ArrayList<FileStatus> results = 
        new ArrayList<>(flattenedPatterns.size());
    boolean sawWildcard = false;
    for (String flatPattern : flattenedPatterns) {
      // Get the absolute path for this flattened pattern.  We couldn't do 
      // this prior to flattening because of patterns like {/,a}, where which
      // path you go down influences how the path must be made absolute.
      Path absPattern = fixRelativePart(new Path(
          flatPattern.isEmpty() ? Path.CUR_DIR : flatPattern));
      LOG.debug(""Pattern: {}"", absPattern);
      // Now we break the flattened, absolute pattern into path components.
      // For example, /a/*/c would be broken into the list [a, *, c]
      List<String> components =
          getPathComponents(absPattern.toUri().getPath());
      // Starting out at the root of the filesystem, we try to match
      // filesystem entries against pattern components.
      ArrayList<FileStatus> candidates = new ArrayList<>(1);
      // To get the ""real"" FileStatus of root, we'd have to do an expensive
      // RPC to the NameNode.  So we create a placeholder FileStatus which has
      // the correct path, but defaults for the rest of the information.
      // Later, if it turns out we actually want the FileStatus of root, we'll
      // replace the placeholder with a real FileStatus obtained from the
      // NameNode.
      FileStatus rootPlaceholder;
      if (Path.WINDOWS && !components.isEmpty()
          && Path.isWindowsAbsolutePath(absPattern.toUri().getPath(), true)) {
        // On Windows the path could begin with a drive letter, e.g. /E:/foo.
        // We will skip matching the drive letter and start from listing the
        // root of the filesystem on that drive.
        String driveLetter = components.remove(0);
        rootPlaceholder = new FileStatus(0, true, 0, 0, 0, new Path(scheme,
            authority, Path.SEPARATOR + driveLetter + Path.SEPARATOR));
      } else {
        rootPlaceholder = new FileStatus(0, true, 0, 0, 0,
            new Path(scheme, authority, Path.SEPARATOR));
      }
      candidates.add(rootPlaceholder);
      
      for (int componentIdx = 0; componentIdx < components.size();
          componentIdx++) {
        ArrayList<FileStatus> newCandidates =
            new ArrayList<>(candidates.size());
        GlobFilter globFilter = new GlobFilter(components.get(componentIdx));
        String component = unescapePathComponent(components.get(componentIdx));
        if (globFilter.hasPattern()) {
          sawWildcard = true;
        }
        LOG.debug(""Component {}, patterned={}"", component, sawWildcard);
        if (candidates.isEmpty() && sawWildcard) {
          // Optimization: if there are no more candidates left, stop examining 
          // the path components.  We can only do this if we've already seen
          // a wildcard component-- otherwise, we still need to visit all path 
          // components in case one of them is a wildcard.
          break;
        }
        if ((componentIdx < components.size() - 1) &&
            (!globFilter.hasPattern())) {
          // Optimization: if this is not the terminal path component, and we 
          // are not matching against a glob, assume that it exists.  If it 
          // doesn't exist, we'll find out later when resolving a later glob
          // or the terminal path component.
          for (FileStatus candidate : candidates) {
            candidate.setPath(new Path(candidate.getPath(), component));
          }
          continue;
        }
        for (FileStatus candidate : candidates) {
          if (globFilter.hasPattern()) {
            FileStatus[] children = listStatus(candidate.getPath());
            if (children.length == 1) {
              // If we get back only one result, this could be either a listing
              // of a directory with one entry, or it could reflect the fact
              // that what we listed resolved to a file.
              //
              // Unfortunately, we can't just compare the returned paths to
              // figure this out.  Consider the case where you have /a/b, where
              // b is a symlink to "".."".  In that case, listing /a/b will give
              // back ""/a/b"" again.  If we just went by returned pathname, we'd
              // incorrectly conclude that /a/b was a file and should not match
              // /a/*/*.  So we use getFileStatus of the path we just listed to
              // disambiguate.
              if (resolveSymlinks) {
                LOG.debug(""listStatus found one entry; disambiguating {}"",
                    children[0]);
                Path path = candidate.getPath();
                FileStatus status = getFileStatus(path);
                if (status == null) {
                  // null means the file was not found
                  LOG.warn(""File/directory {} not found:""
                      + "" it may have been deleted.""
                      + "" If this is an object store, this can be a sign of""
                      + "" eventual consistency problems."",
                      path);
                  continue;
                }
                if (!status.isDirectory()) {
                  LOG.debug(""Resolved entry is a file; skipping: {}"", status);
                  continue;
                }
              } else {
                // there's no symlinks in this store, so no need to issue
                // another call, just see if the result is a directory or a file
                if (children[0].getPath().equals(candidate.getPath())) {
                  // the listing status is of a file
                  continue;
                }
              }
            }
            for (FileStatus child : children) {
              if (componentIdx < components.size() - 1) {
                // Don't try to recurse into non-directories.  See HADOOP-10957.
                if (!child.isDirectory()) continue; 
              }
              // Set the child path based on the parent path.
              child.setPath(new Path(candidate.getPath(),
                      child.getPath().getName()));
              if (globFilter.accept(child.getPath())) {
                newCandidates.add(child);
              }
            }
          } else {
            // When dealing with non-glob components, use getFileStatus 
            // instead of listStatus.  This is an optimization, but it also
            // is necessary for correctness in HDFS, since there are some
            // special HDFS directories like .reserved and .snapshot that are
            // not visible to listStatus, but which do exist.  (See HADOOP-9877)
            FileStatus childStatus = getFileStatus(
                new Path(candidate.getPath(), component));
            if (childStatus != null) {
              newCandidates.add(childStatus);
            }
          }
        }
        candidates = newCandidates;
      }
      for (FileStatus status : candidates) {
        // Use object equality to see if this status is the root placeholder.
        // See the explanation for rootPlaceholder above for more information.
        if (status == rootPlaceholder) {
          status = getFileStatus(rootPlaceholder.getPath());
          if (status == null) continue;
        }
        // HADOOP-3497 semantics: the user-defined filter is applied at the
        // end, once the full path is built up.
        if (filter.accept(status.getPath())) {
          results.add(status);
        }
      }
    }
    /*
     * When the input pattern ""looks"" like just a simple filename, and we
     * can't find it, we return null rather than an empty array.
     * This is a special case which the shell relies on.
     *
     * To be more precise: if there were no results, AND there were no
     * groupings (aka brackets), and no wildcards in the input (aka stars),
     * we return null.
     */
    if ((!sawWildcard) && results.isEmpty() &&
        (flattenedPatterns.size() <= 1)) {
      LOG.debug(""No matches found and there was no wildcard in the path {}"",
          pathPattern);
      return null;
    }
    /*
     * In general, the results list will already be sorted, since listStatus
     * returns results in sorted order for many Hadoop filesystems.  However,
     * not all Hadoop filesystems have this property.  So we sort here in order
     * to get consistent results.  See HADOOP-10798 for details.
     */
    FileStatus ret[] = results.toArray(new FileStatus[0]);
    Arrays.sort(ret);
    return ret;
  }",,
hadoop,2294,"LOG.info(""Instantiating NMWebApp at "" + bindAddress)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/webapp/WebServer.java/#L108,"@Override
  protected void serviceStart() throws Exception {
    Configuration conf = getConfig();
    Map<String, String> params = new HashMap<String, String>();
    Map<String, String> terminalParams = new HashMap<String, String>();
    terminalParams.put(""resourceBase"", WebServer.class
        .getClassLoader().getResource(""TERMINAL"").toExternalForm());
    terminalParams.put(""dirAllowed"", ""false"");
    terminalParams.put(""pathInfoOnly"", ""true"");
    String bindAddress = WebAppUtils.getWebAppBindURL(conf,
                          YarnConfiguration.NM_BIND_HOST,
                          WebAppUtils.getNMWebAppURLWithoutScheme(conf));
    boolean enableCors = conf
        .getBoolean(YarnConfiguration.NM_WEBAPP_ENABLE_CORS_FILTER,
            YarnConfiguration.DEFAULT_NM_WEBAPP_ENABLE_CORS_FILTER);
    if (enableCors) {
      getConfig().setBoolean(HttpCrossOriginFilterInitializer.PREFIX
          + HttpCrossOriginFilterInitializer.ENABLED_SUFFIX, true);
    }

    // Always load pseudo authentication filter to parse ""user.name"" in an URL
    // to identify a HTTP request's user.
    boolean hasHadoopAuthFilterInitializer = false;
    String filterInitializerConfKey = ""hadoop.http.filter.initializers"";
    Class<?>[] initializersClasses =
            conf.getClasses(filterInitializerConfKey);
    List<String> targets = new ArrayList<String>();
    if (initializersClasses != null) {
      for (Class<?> initializer : initializersClasses) {
        if (initializer.getName().equals(
            AuthenticationFilterInitializer.class.getName())) {
          hasHadoopAuthFilterInitializer = true;
          break;
        }
        targets.add(initializer.getName());
      }
    }
    if (!hasHadoopAuthFilterInitializer) {
      targets.add(AuthenticationFilterInitializer.class.getName());
      conf.set(filterInitializerConfKey, StringUtils.join("","", targets));
    }
    ContainerShellWebSocket.init(nmContext);
    
---------------Reference log start----------------
LOG.info(""Instantiating NMWebApp at "" + bindAddress)
---------------Reference log end----------------
    try {
      this.webApp =
          WebApps
            .$for(""node"", Context.class, this.nmContext, ""ws"")
            .at(bindAddress)
            .withServlet(""ContainerShellWebSocket"", ""/container/*"",
                ContainerShellWebSocketServlet.class, params, false)
            .withServlet(""Terminal"", ""/terminal/*"",
                TerminalServlet.class, terminalParams, false)
            .with(conf)
            .withHttpSpnegoPrincipalKey(
              YarnConfiguration.NM_WEBAPP_SPNEGO_USER_NAME_KEY)
            .withHttpSpnegoKeytabKey(
                YarnConfiguration.NM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)
              .withCSRFProtection(YarnConfiguration.NM_CSRF_PREFIX)
              .withXFSProtection(YarnConfiguration.NM_XFS_PREFIX)
            .start(this.nmWebApp);
      this.port = this.webApp.httpServer().getConnectorAddress(0).getPort();
    } catch (Exception e) {
      String msg = ""NMWebapps failed to start."";
      LOG.error(msg, e);
      throw new YarnRuntimeException(msg, e);
    }
    super.serviceStart();
  }",,
hadoop,12307,"LOG.error(""Failed to setup deferred successful response. ThreadName="" + Thread.currentThread().getName() + "", Call="" + this)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java/#L1224,"@Override
    public void setDeferredResponse(Writable response) {
      if (this.connection.getServer().running) {
        try {
          setupResponse(this, RpcStatusProto.SUCCESS, null, response,
              null, null);
        } catch (IOException e) {
          // For synchronous calls, application code is done once it has
          // returned from a method. It does not expect to receive an error.
          // This is equivalent to what happens in synchronous calls when the
          // response cannot be sent.
          
---------------Reference log start----------------
LOG.error(""Failed to setup deferred successful response. ThreadName="" + Thread.currentThread().getName() + "", Call="" + this)
---------------Reference log end----------------
          return;
        }
        sendDeferedResponse();
      }
    }",,
hadoop,5884,"LOG.debug(""{}: cache cleaner running at {}"", this, curMs)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.java/#L107,"@Override
    public void run() {
      ShortCircuitCache.this.lock.lock();
      try {
        if (ShortCircuitCache.this.closed) return;
        long curMs = Time.monotonicNow();

        
---------------Reference log start----------------
LOG.debug(""{}: cache cleaner running at {}"", this, curMs)
---------------Reference log end----------------

        int numDemoted = demoteOldEvictableMmaped(curMs);
        int numPurged = 0;
        Long evictionTimeNs;
        while (!evictable.isEmpty()) {
          Object eldestKey = evictable.firstKey();
          evictionTimeNs = (Long)eldestKey;
          long evictionTimeMs =
              TimeUnit.MILLISECONDS.convert(evictionTimeNs, TimeUnit.NANOSECONDS);
          if (evictionTimeMs + maxNonMmappedEvictableLifespanMs >= curMs) break;
          ShortCircuitReplica replica = (ShortCircuitReplica)evictable.get(
              eldestKey);
          if (LOG.isTraceEnabled()) {
            LOG.trace(""CacheCleaner: purging "" + replica + "": "" +
                StringUtils.getStackTrace(Thread.currentThread()));
          }
          purge(replica);
          numPurged++;
        }

        LOG.debug(""{}: finishing cache cleaner run started at {}. Demoted {} ""
                + ""mmapped replicas; purged {} replicas."",
            this, curMs, numDemoted, numPurged);
      } finally {
        ShortCircuitCache.this.lock.unlock();
      }
    }",,
hadoop,9473,"LOG.debug(""Found file (with /): real file? should not "" + ""happen: {}"", key)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-huaweicloud/src/main/java/org/apache/hadoop/fs/obs/OBSObjectBucketUtils.java/#L781,"static OBSFileStatus innerGetObjectStatus(final OBSFileSystem owner,
      final Path f)
      throws IOException {
    final Path path = OBSCommonUtils.qualify(owner, f);
    String key = OBSCommonUtils.pathToKey(owner, path);
    LOG.debug(""Getting path status for {}  ({})"", path, key);
    if (!StringUtils.isEmpty(key)) {
      try {
        ObjectMetadata meta = getObjectMetadata(owner, key);

        if (OBSCommonUtils.objectRepresentsDirectory(key,
            meta.getContentLength())) {
          LOG.debug(""Found exact file: fake directory"");
          return new OBSFileStatus(path, owner.getUsername());
        } else {
          LOG.debug(""Found exact file: normal file"");
          return new OBSFileStatus(meta.getContentLength(),
              OBSCommonUtils.dateToLong(meta.getLastModified()),
              path, owner.getDefaultBlockSize(path),
              owner.getUsername());
        }
      } catch (ObsException e) {
        if (e.getResponseCode() != OBSCommonUtils.NOT_FOUND_CODE) {
          throw OBSCommonUtils.translateException(""getFileStatus"",
              path, e);
        }
      }

      if (!key.endsWith(""/"")) {
        String newKey = key + ""/"";
        try {
          ObjectMetadata meta = getObjectMetadata(owner, newKey);

          if (OBSCommonUtils.objectRepresentsDirectory(newKey,
              meta.getContentLength())) {
            LOG.debug(""Found file (with /): fake directory"");
            return new OBSFileStatus(path, owner.getUsername());
          } else {
            
---------------Reference log start----------------
LOG.debug(""Found file (with /): real file? should not "" + ""happen: {}"", key)
---------------Reference log end----------------

            return new OBSFileStatus(meta.getContentLength(),
                OBSCommonUtils.dateToLong(meta.getLastModified()),
                path,
                owner.getDefaultBlockSize(path),
                owner.getUsername());
          }
        } catch (ObsException e) {
          if (e.getResponseCode() != OBSCommonUtils.NOT_FOUND_CODE) {
            throw OBSCommonUtils.translateException(""getFileStatus"",
                newKey, e);
          }
        }
      }
    }

    try {
      boolean isEmpty = OBSCommonUtils.innerIsFolderEmpty(owner, key);
      LOG.debug(""Is dir ({}) empty? {}"", path, isEmpty);
      return new OBSFileStatus(path, owner.getUsername());
    } catch (ObsException e) {
      if (e.getResponseCode() != OBSCommonUtils.NOT_FOUND_CODE) {
        throw OBSCommonUtils.translateException(""getFileStatus"", key,
            e);
      }
    }

    LOG.debug(""Not Found: {}"", path);
    throw new FileNotFoundException(""No such file or directory: "" + path);
  }",,
hadoop,13085,"LOG.warn(""Unable to connect to "" + host + "" as user "" + args.user, e)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/SshFenceByTcpPort.java/#L101,"@Override
  public boolean tryFence(HAServiceTarget target, String argsStr)
      throws BadFencingConfigurationException {

    Args args = new Args(argsStr);
    InetSocketAddress serviceAddr = target.getAddress();
    String host = serviceAddr.getHostName();
    
    Session session;
    try {
      session = createSession(serviceAddr.getHostName(), args);
    } catch (JSchException e) {
      LOG.warn(""Unable to create SSH session"", e);
      return false;
    }

    LOG.info(""Connecting to "" + host + ""..."");
    
    try {
      session.connect(getSshConnectTimeout());
    } catch (JSchException e) {
      
---------------Reference log start----------------
LOG.warn(""Unable to connect to "" + host + "" as user "" + args.user, e)
---------------Reference log end----------------
      return false;
    }
    LOG.info(""Connected to "" + host);

    try {
      return doFence(session, serviceAddr);
    } catch (JSchException e) {
      LOG.warn(""Unable to achieve fencing on remote host"", e);
      return false;
    } finally {
      session.disconnect();
    }
  }",,
hadoop,1198,"LOG.info(""Finishing UAM id {} for application {}"", uamId, this.appIdMap.get(uamId))",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/uam/UnmanagedAMPoolManager.java/#L360,"public FinishApplicationMasterResponse finishApplicationMaster(String uamId,
      FinishApplicationMasterRequest request)
      throws YarnException, IOException {
    if (!this.unmanagedAppMasterMap.containsKey(uamId)) {
      throw new YarnException(""UAM "" + uamId + "" does not exist"");
    }
    
---------------Reference log start----------------
LOG.info(""Finishing UAM id {} for application {}"", uamId, this.appIdMap.get(uamId))
---------------Reference log end----------------
    FinishApplicationMasterResponse response =
        this.unmanagedAppMasterMap.get(uamId).finishApplicationMaster(request);

    if (response.getIsUnregistered()) {
      // Only remove the UAM when the unregister finished
      this.unmanagedAppMasterMap.remove(uamId);
      this.appIdMap.remove(uamId);
      LOG.info(""UAM id {} is unregistered"", uamId);
    }
    return response;
  }",,
hadoop,9760,"LOG.debug(""Block compaction: {} blocks for {}"", maxSegmentEnd - maxSegmentBegin, key)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/BlockBlobAppendStream.java/#L1021,"private void blockCompaction() throws IOException {
      //current segment [segmentBegin, segmentEnd) and file offset/size of the
      // current segment
      int segmentBegin = 0, segmentEnd = 0;
      long segmentOffsetBegin = 0, segmentOffsetEnd = 0;

      //longest segment [maxSegmentBegin, maxSegmentEnd) and file offset/size of
      // the longest segment
      int maxSegmentBegin = 0, maxSegmentEnd = 0;
      long maxSegmentOffsetBegin = 0, maxSegmentOffsetEnd = 0;

      for (BlockEntry block : blockEntries) {
        segmentEnd++;
        segmentOffsetEnd += block.getSize();
        if (segmentOffsetEnd - segmentOffsetBegin > maxBlockSize.get()) {
          if (segmentEnd - segmentBegin > 2) {
            if (maxSegmentEnd - maxSegmentBegin < segmentEnd - segmentBegin) {
              maxSegmentBegin = segmentBegin;
              maxSegmentEnd = segmentEnd;
              maxSegmentOffsetBegin = segmentOffsetBegin;
              maxSegmentOffsetEnd = segmentOffsetEnd - block.getSize();
            }
          }
          segmentBegin = segmentEnd - 1;
          segmentOffsetBegin = segmentOffsetEnd - block.getSize();
        }
      }

      if (maxSegmentEnd - maxSegmentBegin > 1) {

        
---------------Reference log start----------------
LOG.debug(""Block compaction: {} blocks for {}"", maxSegmentEnd - maxSegmentBegin, key)
---------------Reference log end----------------

        // download synchronously all the blocks from the azure storage
        ByteArrayOutputStreamInternal blockOutputStream
            = new ByteArrayOutputStreamInternal(maxBlockSize.get());

        try {
          long length = maxSegmentOffsetEnd - maxSegmentOffsetBegin;
          blob.downloadRange(maxSegmentOffsetBegin, length, blockOutputStream,
              new BlobRequestOptions(), opContext);
        } catch(StorageException ex) {
          LOG.error(
              ""Storage exception encountered during block compaction phase""
                  + "" : {} Storage Exception : {} Error Code: {}"",
              key, ex, ex.getErrorCode());
          throw new AzureException(
              ""Encountered Exception while committing append blocks "" + ex, ex);
        }

        // upload synchronously new block to the azure storage
        String blockId = generateBlockId();

        ByteBuffer byteBuffer = ByteBuffer.wrap(
            blockOutputStream.getByteArray());
        byteBuffer.position(blockOutputStream.size());

        writeBlockRequestInternal(blockId, byteBuffer, false);

        // replace blocks from the longest segment with new block id
        blockEntries.subList(maxSegmentBegin + 1, maxSegmentEnd - 1).clear();
        BlockEntry newBlock = blockEntries.get(maxSegmentBegin);
        newBlock.setId(blockId);
        newBlock.setSearchMode(BlockSearchMode.LATEST);
        newBlock.setSize(maxSegmentOffsetEnd - maxSegmentOffsetBegin);
      }
    }",,
hadoop,8502,"LOG.warn(""Exception in getting reader from provided alias map"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ProvidedVolumeImpl.java/#L456,"@Override
    public void rewind() {
      BlockAliasMap.Reader<FileRegion> reader = null;
      try {
        reader = blockAliasMap.getReader(null, bpid);
      } catch (IOException e) {
        
---------------Reference log start----------------
LOG.warn(""Exception in getting reader from provided alias map"")
---------------Reference log end----------------
      }
      if (reader != null) {
        blockIterator = reader.iterator();
      } else {
        blockIterator = null;
      }
      state = new ProvidedBlockIteratorState();
    }",,
hadoop,12735,"LOG.warn(""Unexpected SecurityException in Configuration"", se)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java/#L1172,"private String substituteVars(String expr) {
    if (expr == null) {
      return null;
    }
    String eval = expr;
    for(int s = 0; s < MAX_SUBST; s++) {
      final int[] varBounds = findSubVariable(eval);
      if (varBounds[SUB_START_IDX] == -1) {
        return eval;
      }
      final String var = eval.substring(varBounds[SUB_START_IDX],
          varBounds[SUB_END_IDX]);
      String val = null;
      try {
        // evaluate system properties or environment variables even when
        // the configuration is restricted -the restrictions are enforced
        // in the getenv/getProperty calls
        if (var.startsWith(""env."") && 4 < var.length()) {
          String v = var.substring(4);
          int i = 0;
          for (; i < v.length(); i++) {
            char c = v.charAt(i);
            if (c == ':' && i < v.length() - 1 && v.charAt(i + 1) == '-') {
              val = getenv(v.substring(0, i));
              if (val == null || val.length() == 0) {
                val = v.substring(i + 2);
              }
              break;
            } else if (c == '-') {
              val = getenv(v.substring(0, i));
              if (val == null) {
                val = v.substring(i + 1);
              }
              break;
            }
          }
          if (i == v.length()) {
            val = getenv(v);
          }
        } else {
          val = getProperty(var);
        }
      } catch (SecurityException se) {
        
---------------Reference log start----------------
LOG.warn(""Unexpected SecurityException in Configuration"", se)
---------------Reference log end----------------
      }
      if (val == null) {
        val = getRaw(var);
      }
      if (val == null) {
        return eval; // return literal ${var}: var is unbound
      }

      final int dollar = varBounds[SUB_START_IDX] - ""${"".length();
      final int afterRightBrace = varBounds[SUB_END_IDX] + ""}"".length();
      final String refVar = eval.substring(dollar, afterRightBrace);

      // detect self-referential values
      if (val.contains(refVar)) {
        return expr; // return original expression if there is a loop
      }

      // substitute
      eval = eval.substring(0, dollar)
             + val
             + eval.substring(afterRightBrace);
    }
    throw new IllegalStateException(""Variable substitution depth too large: "" 
                                    + MAX_SUBST + "" "" + expr);
  }",,
hadoop,12253,"LOG.debug(getName() + "": stopped, remaining connections "" + connections.size())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java/#L1111,"@Override
    public void run() {
      if (LOG.isDebugEnabled())
        LOG.debug(getName() + "": starting, having connections "" 
            + connections.size());

      try {
        while (waitForWork()) {//wait here for work - read or close connection
          receiveRpcResponse();
        }
      } catch (Throwable t) {
        // This truly is unexpected, since we catch IOException in receiveResponse
        // -- this is only to be really sure that we don't leave a client hanging
        // forever.
        LOG.warn(""Unexpected error reading responses on connection "" + this, t);
        markClosed(new IOException(""Error reading responses"", t));
      }
      
      close();
      
      if (LOG.isDebugEnabled())
        
---------------Reference log start----------------
LOG.debug(getName() + "": stopped, remaining connections "" + connections.size())
---------------Reference log end----------------
    }
    }",,
hadoop,2829,LOG.info(message),info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceTrackerService.java/#L694,"@SuppressWarnings(""unchecked"")
  @Override
  public NodeHeartbeatResponse nodeHeartbeat(NodeHeartbeatRequest request)
      throws YarnException, IOException {

    NodeStatus remoteNodeStatus = request.getNodeStatus();
    /**
     * Here is the node heartbeat sequence...
     * 1. Check if it's a valid (i.e. not excluded) node
     * 2. Check if it's a registered node
     * 3. Check if it's a 'fresh' heartbeat i.e. not duplicate heartbeat
     * 4. Send healthStatus to RMNode
     * 5. Update node's labels if distributed Node Labels configuration is enabled
     */
    NodeId nodeId = remoteNodeStatus.getNodeId();

    // 1. Check if it's a valid (i.e. not excluded) node, if not, see if it is
    // in decommissioning.
    if (!this.nodesListManager.isValidNode(nodeId.getHost())
        && !isNodeInDecommissioning(nodeId)) {
      String message =
          ""Disallowed NodeManager nodeId: "" + nodeId + "" hostname: ""
              + nodeId.getHost();
      LOG.info(message);
      return YarnServerBuilderUtils.newNodeHeartbeatResponse(
          NodeAction.SHUTDOWN, message);
    }

    // 2. Check if it's a registered node
    RMNode rmNode = this.rmContext.getRMNodes().get(nodeId);
    if (rmNode == null) {
      /* node does not exist */
      String message = ""Node not found resyncing "" + remoteNodeStatus.getNodeId();
      LOG.info(message);
      return YarnServerBuilderUtils.newNodeHeartbeatResponse(NodeAction.RESYNC,
          message);
    }

    // Send ping
    this.nmLivelinessMonitor.receivedPing(nodeId);
    this.decommissioningWatcher.update(rmNode, remoteNodeStatus);

    // 3. Check if it's a 'fresh' heartbeat i.e. not duplicate heartbeat
    NodeHeartbeatResponse lastNodeHeartbeatResponse = rmNode.getLastNodeHeartBeatResponse();
    if (getNextResponseId(
        remoteNodeStatus.getResponseId()) == lastNodeHeartbeatResponse
            .getResponseId()) {
      LOG.info(""Received duplicate heartbeat from node ""
          + rmNode.getNodeAddress()+ "" responseId="" + remoteNodeStatus.getResponseId());
      return lastNodeHeartbeatResponse;
    } else if (remoteNodeStatus.getResponseId() != lastNodeHeartbeatResponse
        .getResponseId()) {
      String message =
          ""Too far behind rm response id:""
              + lastNodeHeartbeatResponse.getResponseId() + "" nm response id:""
              + remoteNodeStatus.getResponseId();
      LOG.info(message);
      // TODO: Just sending reboot is not enough. Think more.
      this.rmContext.getDispatcher().getEventHandler().handle(
          new RMNodeEvent(nodeId, RMNodeEventType.REBOOTING));
      return YarnServerBuilderUtils.newNodeHeartbeatResponse(NodeAction.RESYNC,
          message);
    }

    // Evaluate whether a DECOMMISSIONING node is ready to be DECOMMISSIONED.
    if (rmNode.getState() == NodeState.DECOMMISSIONING &&
        decommissioningWatcher.checkReadyToBeDecommissioned(
            rmNode.getNodeID())) {
      String message = ""DECOMMISSIONING "" + nodeId +
          "" is ready to be decommissioned"";
      
---------------Reference log start----------------
LOG.info(message)
---------------Reference log end----------------
      this.rmContext.getDispatcher().getEventHandler().handle(
          new RMNodeEvent(nodeId, RMNodeEventType.DECOMMISSION));
      this.nmLivelinessMonitor.unregister(nodeId);
      return YarnServerBuilderUtils.newNodeHeartbeatResponse(
          NodeAction.SHUTDOWN, message);
    }

    if (timelineServiceV2Enabled) {
      // Check & update collectors info from request.
      updateAppCollectorsMap(request);
    }

    // Heartbeat response
    long newInterval = nextHeartBeatInterval;
    if (heartBeatIntervalScalingEnable) {
      newInterval = rmNode.calculateHeartBeatInterval(
          nextHeartBeatInterval, heartBeatIntervalMin,
          heartBeatIntervalMax, heartBeatIntervalSpeedupFactor,
          heartBeatIntervalSlowdownFactor);
    }
    NodeHeartbeatResponse nodeHeartBeatResponse =
        YarnServerBuilderUtils.newNodeHeartbeatResponse(
            getNextResponseId(lastNodeHeartbeatResponse.getResponseId()),
            NodeAction.NORMAL, null, null, null, null, newInterval);
    rmNode.setAndUpdateNodeHeartbeatResponse(nodeHeartBeatResponse);

    populateKeys(request, nodeHeartBeatResponse);

    populateTokenSequenceNo(request, nodeHeartBeatResponse);

    if (timelineServiceV2Enabled) {
      // Return collectors' map that NM needs to know
      setAppCollectorsMapToResponse(rmNode.getRunningApps(),
          nodeHeartBeatResponse);
    }

    // 4. Send status to RMNode, saving the latest response.
    RMNodeStatusEvent nodeStatusEvent =
        new RMNodeStatusEvent(nodeId, remoteNodeStatus);
    if (request.getLogAggregationReportsForApps() != null
        && !request.getLogAggregationReportsForApps().isEmpty()) {
      nodeStatusEvent.setLogAggregationReportsForApps(request
        .getLogAggregationReportsForApps());
    }
    this.rmContext.getDispatcher().getEventHandler().handle(nodeStatusEvent);

    // 5. Update node's labels to RM's NodeLabelManager.
    if (isDistributedNodeLabelsConf && request.getNodeLabels() != null) {
      try {
        updateNodeLabelsFromNMReport(
            NodeLabelsUtils.convertToStringSet(request.getNodeLabels()),
            nodeId);
        nodeHeartBeatResponse.setAreNodeLabelsAcceptedByRM(true);
      } catch (IOException ex) {
        //ensure the error message is captured and sent across in response
        nodeHeartBeatResponse.setDiagnosticsMessage(ex.getMessage());
        nodeHeartBeatResponse.setAreNodeLabelsAcceptedByRM(false);
      }
    }

    // 6. check if node's capacity is load from dynamic-resources.xml
    // if so, send updated resource back to NM.
    String nid = nodeId.toString();
    Resource capability = loadNodeResourceFromDRConfiguration(nid);
    // sync back with new resource if not null.
    if (capability != null) {
      nodeHeartBeatResponse.setResource(capability);
    }
    // Check if we got an event (AdminService) that updated the resources
    if (rmNode.isUpdatedCapability()) {
      nodeHeartBeatResponse.setResource(rmNode.getTotalCapability());
      rmNode.resetUpdatedCapability();
    }

    // 7. Send Container Queuing Limits back to the Node. This will be used by
    // the node to truncate the number of Containers queued for execution.
    if (this.rmContext.getNodeManagerQueueLimitCalculator() != null) {
      nodeHeartBeatResponse.setContainerQueuingLimit(
          this.rmContext.getNodeManagerQueueLimitCalculator()
              .createContainerQueuingLimit());
    }

    // 8. Get node's attributes and update node-to-attributes mapping
    // in RMNodeAttributeManager.
    if (request.getNodeAttributes() != null) {
      try {
        // update node attributes if necessary then update heartbeat response
        updateNodeAttributesIfNecessary(nodeId, request.getNodeAttributes());
        nodeHeartBeatResponse.setAreNodeAttributesAcceptedByRM(true);
      } catch (IOException ex) {
        //ensure the error message is captured and sent across in response
        String errorMsg =
            nodeHeartBeatResponse.getDiagnosticsMessage() == null ?
                ex.getMessage() :
                nodeHeartBeatResponse.getDiagnosticsMessage() + ""\n"" + ex
                    .getMessage();
        nodeHeartBeatResponse.setDiagnosticsMessage(errorMsg);
        nodeHeartBeatResponse.setAreNodeAttributesAcceptedByRM(false);
      }
    }

    return nodeHeartBeatResponse;
  }",,
hadoop,12661,"LOG.warn(""RuntimeException during Trash.Emptier.run(): "", e)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java/#L304,"@Override
    public void run() {
      if (emptierInterval == 0)
        return;                                   // trash disabled
      long now, end;
      while (true) {
        now = Time.now();
        end = ceiling(now, emptierInterval);
        try {                                     // sleep for interval
          Thread.sleep(end - now);
        } catch (InterruptedException e) {
          break;                                  // exit on interrupt
        }

        try {
          now = Time.now();
          if (now >= end) {
            Collection<FileStatus> trashRoots;
            trashRoots = fs.getTrashRoots(true);      // list all trash dirs

            for (FileStatus trashRoot : trashRoots) {   // dump each trash
              if (!trashRoot.isDirectory())
                continue;
              try {
                TrashPolicyDefault trash = new TrashPolicyDefault(fs, conf);
                trash.deleteCheckpoint(trashRoot.getPath(), false);
                trash.createCheckpoint(trashRoot.getPath(), new Date(now));
              } catch (IOException e) {
                LOG.warn(""Trash caught: ""+e+"". Skipping "" +
                    trashRoot.getPath() + ""."");
              } 
            }
          }
        } catch (Exception e) {
          
---------------Reference log start----------------
LOG.warn(""RuntimeException during Trash.Emptier.run(): "", e)
---------------Reference log end----------------
        }
      }
      try {
        fs.close();
      } catch(IOException e) {
        LOG.warn(""Trash cannot close FileSystem: "", e);
      }
    }",,
hadoop,7413,"NameNode.LOG.info(""EDEKCacheLoader interrupted during retry."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirEncryptionZoneOp.java/#L606,"@Override
    public void run() {
      NameNode.LOG.info(""Warming up {} EDEKs... (initialDelay={}, ""
          + ""retryInterval={})"", keyNames.length, initialDelay, retryInterval);
      try {
        Thread.sleep(initialDelay);
      } catch (InterruptedException ie) {
        NameNode.LOG.info(""EDEKCacheLoader interrupted before warming up."");
        return;
      }

      final int logCoolDown = 10000; // periodically print error log (if any)
      int sinceLastLog = logCoolDown; // always print the first failure
      boolean success = false;
      IOException lastSeenIOE = null;
      long warmUpEDEKStartTime = monotonicNow();
      while (true) {
        try {
          kp.warmUpEncryptedKeys(keyNames);
          NameNode.LOG
              .info(""Successfully warmed up {} EDEKs."", keyNames.length);
          success = true;
          break;
        } catch (IOException ioe) {
          lastSeenIOE = ioe;
          if (sinceLastLog >= logCoolDown) {
            NameNode.LOG.info(""Failed to warm up EDEKs."", ioe);
            sinceLastLog = 0;
          } else {
            NameNode.LOG.debug(""Failed to warm up EDEKs."", ioe);
          }
        } catch (Exception e) {
          NameNode.LOG.error(""Cannot warm up EDEKs."", e);
          throw e;
        }
        try {
          Thread.sleep(retryInterval);
        } catch (InterruptedException ie) {
          
---------------Reference log start----------------
NameNode.LOG.info(""EDEKCacheLoader interrupted during retry."")
---------------Reference log end----------------
          break;
        }
        sinceLastLog += retryInterval;
      }
      long warmUpEDEKTime = monotonicNow() - warmUpEDEKStartTime;
      NameNode.getNameNodeMetrics().addWarmUpEDEKTime(warmUpEDEKTime);
      if (!success) {
        NameNode.LOG.warn(""Unable to warm up EDEKs."");
        if (lastSeenIOE != null) {
          NameNode.LOG.warn(""Last seen exception:"", lastSeenIOE);
        }
      }
    }",,
hadoop,2812,"LOG.error(""Received finished container : "" + containerStatus.getContainerId() + "" for unknown application "" + appAttemptId.getApplicationId() + "" Skipping."")",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceTrackerService.java/#L368,"@SuppressWarnings(""unchecked"")
  @VisibleForTesting
  void handleNMContainerStatus(NMContainerStatus containerStatus, NodeId nodeId) {
    ApplicationAttemptId appAttemptId =
        containerStatus.getContainerId().getApplicationAttemptId();
    RMApp rmApp =
        rmContext.getRMApps().get(appAttemptId.getApplicationId());
    if (rmApp == null) {
      
---------------Reference log start----------------
LOG.error(""Received finished container : "" + containerStatus.getContainerId() + "" for unknown application "" + appAttemptId.getApplicationId() + "" Skipping."")
---------------Reference log end----------------
      return;
    }

    if (rmApp.getApplicationSubmissionContext().getUnmanagedAM()) {
      LOG.debug(""Ignoring container completion status for unmanaged AM {}"",
          rmApp.getApplicationId());
      return;
    }

    RMAppAttempt rmAppAttempt = rmApp.getRMAppAttempt(appAttemptId);
    if (rmAppAttempt == null) {
      LOG.info(""Ignoring not found attempt "" + appAttemptId);
      return;
    }

    Container masterContainer = rmAppAttempt.getMasterContainer();
    if (masterContainer.getId().equals(containerStatus.getContainerId())
        && containerStatus.getContainerState() == ContainerState.COMPLETE) {
      ContainerStatus status =
          ContainerStatus.newInstance(containerStatus.getContainerId(),
            containerStatus.getContainerState(), containerStatus.getDiagnostics(),
            containerStatus.getContainerExitStatus());
      // sending master container finished event.
      RMAppAttemptContainerFinishedEvent evt =
          new RMAppAttemptContainerFinishedEvent(appAttemptId, status,
              nodeId);
      rmContext.getDispatcher().getEventHandler().handle(evt);
    }
  }",,
hadoop,1035,"LOG.info(""Processed URL "" + url + "" (Took "" + latency + "" ms.)"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/reader/TimelineReaderWebServices.java/#L1827,"@GET
  @Path(""/clusters/{clusterid}/apps/{appid}/"")
  @Produces(MediaType.APPLICATION_JSON + ""; "" + JettyUtils.UTF_8)
  public TimelineEntity getApp(
      @Context HttpServletRequest req,
      @Context HttpServletResponse res,
      @PathParam(""clusterid"") String clusterId,
      @PathParam(""appid"") String appId,
      @QueryParam(""flowname"") String flowName,
      @QueryParam(""flowrunid"") String flowRunId,
      @QueryParam(""userid"") String userId,
      @QueryParam(""confstoretrieve"") String confsToRetrieve,
      @QueryParam(""metricstoretrieve"") String metricsToRetrieve,
      @QueryParam(""fields"") String fields,
      @QueryParam(""metricslimit"") String metricsLimit,
      @QueryParam(""metricstimestart"") String metricsTimeStart,
      @QueryParam(""metricstimeend"") String metricsTimeEnd) {
    String url = req.getRequestURI() +
        (req.getQueryString() == null ? """" :
            QUERY_STRING_SEP + req.getQueryString());
    UserGroupInformation callerUGI =
        TimelineReaderWebServicesUtils.getUser(req);
    LOG.info(""Received URL "" + url + "" from user "" +
        TimelineReaderWebServicesUtils.getUserName(callerUGI));
    long startTime = Time.monotonicNow();
    boolean succeeded = false;
    init(res);
    TimelineReaderManager timelineReaderManager = getTimelineReaderManager();
    TimelineEntity entity = null;
    try {
      entity = timelineReaderManager.getEntity(
          TimelineReaderWebServicesUtils.createTimelineReaderContext(
          clusterId, userId, flowName, flowRunId, appId,
              TimelineEntityType.YARN_APPLICATION.toString(), null, null),
          TimelineReaderWebServicesUtils.createTimelineDataToRetrieve(
          confsToRetrieve, metricsToRetrieve, fields, metricsLimit,
          metricsTimeStart, metricsTimeEnd));
      checkAccessForAppEntity(entity, callerUGI);
      succeeded = true;
    } catch (Exception e) {
      handleException(e, url, startTime, ""Either flowrunid or metricslimit or""
          + "" metricstime start/end"");
    } finally {
      long latency = Time.monotonicNow() - startTime;
      METRICS.addGetEntitiesLatency(latency, succeeded);
      
---------------Reference log start----------------
LOG.info(""Processed URL "" + url + "" (Took "" + latency + "" ms.)"")
---------------Reference log end----------------
    }
    if (entity == null) {
      LOG.info(""Processed URL "" + url + "" but app not found"" + "" (Took "" +
          (Time.monotonicNow() - startTime) + "" ms.)"");
      throw new NotFoundException(""App "" + appId + "" not found"");
    }
    return entity;
  }",,
hadoop,5064,"LOG.debug(""Waiting for authentication response"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Application.java/#L206,"void waitForAuthentication() throws IOException,
      InterruptedException {
    downlink.flush();
    
---------------Reference log start----------------
LOG.debug(""Waiting for authentication response"")
---------------Reference log end----------------
    handler.waitForAuthentication();
  }",,
hadoop,9031,"LOG.error(""Cannot parse JMX output for {} from server {}: {}"", beanQuery, webAddress, e.getMessage())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/FederationUtil.java/#L111,"public static JSONArray getJmx(String beanQuery, String webAddress,
      URLConnectionFactory connectionFactory, String scheme) {
    JSONArray ret = null;
    BufferedReader reader = null;
    try {
      String host = webAddress;
      int port = -1;
      if (webAddress.indexOf("":"") > 0) {
        String[] webAddressSplit = webAddress.split("":"");
        host = webAddressSplit[0];
        port = Integer.parseInt(webAddressSplit[1]);
      }
      URL jmxURL = new URL(scheme, host, port, ""/jmx?qry="" + beanQuery);
      LOG.debug(""JMX URL: {}"", jmxURL);
      // Create a URL connection
      URLConnection conn = connectionFactory.openConnection(
          jmxURL, UserGroupInformation.isSecurityEnabled());
      conn.setConnectTimeout(5 * 1000);
      conn.setReadTimeout(5 * 1000);
      InputStream in = conn.getInputStream();
      InputStreamReader isr = new InputStreamReader(in, ""UTF-8"");
      reader = new BufferedReader(isr);

      StringBuilder sb = new StringBuilder();
      String line = null;
      while ((line = reader.readLine()) != null) {
        sb.append(line);
      }
      String jmxOutput = sb.toString();

      // Parse JSON
      JSONObject json = new JSONObject(jmxOutput);
      ret = json.getJSONArray(""beans"");
    } catch (IOException e) {
      LOG.error(""Cannot read JMX bean {} from server {}"",
          beanQuery, webAddress, e);
    } catch (JSONException e) {
      // We shouldn't need more details if the JSON parsing fails.
      
---------------Reference log start----------------
LOG.error(""Cannot parse JMX output for {} from server {}: {}"", beanQuery, webAddress, e.getMessage())
---------------Reference log end----------------
    } catch (Exception e) {
      LOG.error(""Cannot parse JMX output for {} from server {}"",
          beanQuery, webAddress, e);
    } finally {
      if (reader != null) {
        try {
          reader.close();
        } catch (IOException e) {
          LOG.error(""Problem closing {}"", webAddress, e);
        }
      }
    }
    return ret;
  }",,
hadoop,1334,"LOG.error(""Unable to remove container "" + cid + "" in store"", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/NodeStatusUpdaterImpl.java/#L795,"@Private
  @VisibleForTesting
  public void removeVeryOldStoppedContainersFromCache() {
    synchronized (recentlyStoppedContainers) {
      long currentTime = System.currentTimeMillis();
      Iterator<Entry<ContainerId, Long>> i =
          recentlyStoppedContainers.entrySet().iterator();
      while (i.hasNext()) {
        Entry<ContainerId, Long> mapEntry = i.next();
        ContainerId cid = mapEntry.getKey();
        if (mapEntry.getValue() >= currentTime) {
          break;
        }
        if (!context.getContainers().containsKey(cid)) {
          ApplicationId appId =
              cid.getApplicationAttemptId().getApplicationId();
          if (isApplicationStopped(appId)) {
            i.remove();
            try {
              context.getNMStateStore().removeContainer(cid);
            } catch (IOException e) {
              
---------------Reference log start----------------
LOG.error(""Unable to remove container "" + cid + "" in store"", e)
---------------Reference log end----------------
            }
          }
        }
      }
    }
  }",,
hadoop,10629,"LOG.error(""Scheduler Metrics failed to tear down."", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/scheduler/SLSFairScheduler.java/#L199,"@Override
  public void handle(SchedulerEvent schedulerEvent) {
    // metrics off
    if (!metricsON) {
      super.handle(schedulerEvent);
      return;
    }

    // metrics on
    if(!schedulerMetrics.isRunning()) {
      schedulerMetrics.setRunning(true);
    }

    Timer.Context handlerTimer = null;
    Timer.Context operationTimer = null;

    NodeUpdateSchedulerEventWrapper eventWrapper;
    try {
      if (schedulerEvent.getType() == SchedulerEventType.NODE_UPDATE
          && schedulerEvent instanceof NodeUpdateSchedulerEvent) {
        eventWrapper = new NodeUpdateSchedulerEventWrapper(
            (NodeUpdateSchedulerEvent)schedulerEvent);
        schedulerEvent = eventWrapper;
        updateQueueWithNodeUpdate(eventWrapper);
      } else if (
          schedulerEvent.getType() == SchedulerEventType.APP_ATTEMPT_REMOVED
          && schedulerEvent instanceof AppAttemptRemovedSchedulerEvent) {
        // check if having AM Container, update resource usage information
        AppAttemptRemovedSchedulerEvent appRemoveEvent =
            (AppAttemptRemovedSchedulerEvent) schedulerEvent;
        ApplicationAttemptId appAttemptId =
            appRemoveEvent.getApplicationAttemptID();
        String queueName = getSchedulerApp(appAttemptId).getQueue().getName();
        SchedulerAppReport app = getSchedulerAppInfo(appAttemptId);
        if (!app.getLiveContainers().isEmpty()) {  // have 0 or 1
          // should have one container which is AM container
          RMContainer rmc = app.getLiveContainers().iterator().next();
          schedulerMetrics.updateQueueMetricsByRelease(
              rmc.getContainer().getResource(), queueName);
        }
      }

      handlerTimer = schedulerMetrics.getSchedulerHandleTimer().time();
      operationTimer = schedulerMetrics.getSchedulerHandleTimer(
          schedulerEvent.getType()).time();

      super.handle(schedulerEvent);
    } finally {
      if (handlerTimer != null) {
        handlerTimer.stop();
      }
      if (operationTimer != null) {
        operationTimer.stop();
      }
      schedulerMetrics.increaseSchedulerHandleCounter(schedulerEvent.getType());

      if (schedulerEvent.getType() == SchedulerEventType.APP_ATTEMPT_REMOVED
          && schedulerEvent instanceof AppAttemptRemovedSchedulerEvent) {
        SLSRunner.decreaseRemainingApps();
        if (SLSRunner.getRemainingApps() == 0) {
          try {
            getSchedulerMetrics().tearDown();
            SLSRunner.exitSLSRunner();
          } catch (Exception e) {
            
---------------Reference log start----------------
LOG.error(""Scheduler Metrics failed to tear down."", e)
---------------Reference log end----------------
          }
        }
      }
    }
  }",,
hadoop,7684,"LOG.error(""Cancelling plan on  {} failed. Result: {}, Message: {}"", nodeAddress, ex.getResult().toString(), ex.getMessage())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.java/#L122,"private void cancelPlanUsingHash(String nodeAddress, String hash) throws
      IOException {
    Preconditions.checkNotNull(nodeAddress);
    Preconditions.checkNotNull(hash);
    ClientDatanodeProtocol dataNode = getDataNodeProxy(nodeAddress);
    try {
      dataNode.cancelDiskBalancePlan(hash);
    } catch (DiskBalancerException ex) {
      
---------------Reference log start----------------
LOG.error(""Cancelling plan on  {} failed. Result: {}, Message: {}"", nodeAddress, ex.getResult().toString(), ex.getMessage())
---------------Reference log end----------------
      throw ex;
    }
  }",,
hadoop,3082,"LOG.debug(""Skip allocating AM container to app_attempt={},"" + "" don't allow to allocate AM container in non-exclusive mode"", application.getApplicationAttemptId())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/allocator/RegularContainerAllocator.java/#L131,"private ContainerAllocation preCheckForNodeCandidateSet(
      Resource clusterResource, FiCaSchedulerNode node,
      SchedulingMode schedulingMode, ResourceLimits resourceLimits,
      SchedulerRequestKey schedulerKey) {
    PendingAsk offswitchPendingAsk = application.getPendingAsk(schedulerKey,
        ResourceRequest.ANY);

    if (offswitchPendingAsk.getCount() <= 0) {
      ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(
          activitiesManager, node, application, schedulerKey,
          ActivityDiagnosticConstant.REQUEST_DO_NOT_NEED_RESOURCE,
          ActivityLevel.REQUEST);
      return ContainerAllocation.PRIORITY_SKIPPED;
    }

    // Required resource
    Resource required = offswitchPendingAsk.getPerAllocationResource();

    // Do we need containers at this 'priority'?
    if (application.getOutstandingAsksCount(schedulerKey) <= 0) {
      ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(
          activitiesManager, node, application, schedulerKey,
          ActivityDiagnosticConstant.REQUEST_DO_NOT_NEED_RESOURCE,
          ActivityLevel.REQUEST);
      return ContainerAllocation.PRIORITY_SKIPPED;
    }

    // AM container allocation doesn't support non-exclusive allocation to
    // avoid painful of preempt an AM container
    if (schedulingMode == SchedulingMode.IGNORE_PARTITION_EXCLUSIVITY) {
      if (application.isWaitingForAMContainer()) {
        
---------------Reference log start----------------
LOG.debug(""Skip allocating AM container to app_attempt={},"" + "" don't allow to allocate AM container in non-exclusive mode"", application.getApplicationAttemptId())
---------------Reference log end----------------
        application.updateAppSkipNodeDiagnostics(
            ""Skipping assigning to Node in Ignore Exclusivity mode. "");
        ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(
            activitiesManager, node, application, schedulerKey,
            ActivityDiagnosticConstant.
                REQUEST_SKIPPED_IN_IGNORE_EXCLUSIVITY_MODE,
            ActivityLevel.REQUEST);
        return ContainerAllocation.APP_SKIPPED;
      }
    }

    // Is the nodePartition of pending request matches the node's partition
    // If not match, jump to next priority.
    Optional<DiagnosticsCollector> dcOpt = activitiesManager == null ?
        Optional.empty() :
        activitiesManager.getOptionalDiagnosticsCollector();
    if (!appInfo.precheckNode(schedulerKey, node, schedulingMode, dcOpt)) {
      ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(
          activitiesManager, node, application, schedulerKey,
          ActivityDiagnosticConstant.
              NODE_DO_NOT_MATCH_PARTITION_OR_PLACEMENT_CONSTRAINTS
              + ActivitiesManager.getDiagnostics(dcOpt),
          ActivityLevel.NODE);
      return ContainerAllocation.PRIORITY_SKIPPED;
    }

    if (!application.getCSLeafQueue().getReservationContinueLooking()) {
      if (!shouldAllocOrReserveNewContainer(schedulerKey, required)) {
        LOG.debug(""doesn't need containers based on reservation algo!"");
        ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(
            activitiesManager, node, application, schedulerKey,
            ActivityDiagnosticConstant.REQUEST_SKIPPED_BECAUSE_OF_RESERVATION,
            ActivityLevel.REQUEST);
        return ContainerAllocation.PRIORITY_SKIPPED;
      }
    }

    if (!checkHeadroom(clusterResource, resourceLimits, required,
        node.getPartition())) {
      LOG.debug(""cannot allocate required resource={} because of headroom"",
          required);
      ActivitiesLogger.APP.recordAppActivityWithoutAllocation(
          activitiesManager, node, application, schedulerKey,
          ActivityDiagnosticConstant.QUEUE_DO_NOT_HAVE_ENOUGH_HEADROOM,
          ActivityState.REJECTED,
          ActivityLevel.REQUEST);
      return ContainerAllocation.QUEUE_SKIPPED;
    }

    // Increase missed-non-partitioned-resource-request-opportunity.
    // This is to make sure non-partitioned-resource-request will prefer
    // to be allocated to non-partitioned nodes
    int missedNonPartitionedRequestSchedulingOpportunity = 0;
    AppPlacementAllocator appPlacementAllocator =
        appInfo.getAppPlacementAllocator(schedulerKey);
    if (null == appPlacementAllocator){
      // This is possible when #pending resource decreased by a different
      // thread.
      ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(
          activitiesManager, node, application, schedulerKey,
          ActivityDiagnosticConstant.REQUEST_SKIPPED_BECAUSE_NULL_ANY_REQUEST,
          ActivityLevel.REQUEST);
      return ContainerAllocation.PRIORITY_SKIPPED;
    }
    String requestPartition =
        appPlacementAllocator.getPrimaryRequestedNodePartition();

    // Only do this when request associated with given scheduler key accepts
    // NO_LABEL under RESPECT_EXCLUSIVITY mode
    if (StringUtils.equals(RMNodeLabelsManager.NO_LABEL, requestPartition)) {
      missedNonPartitionedRequestSchedulingOpportunity =
          application.addMissedNonPartitionedRequestSchedulingOpportunity(
              schedulerKey);
    }

    if (schedulingMode == SchedulingMode.IGNORE_PARTITION_EXCLUSIVITY) {
      // Before doing allocation, we need to check scheduling opportunity to
      // make sure : non-partitioned resource request should be scheduled to
      // non-partitioned partition first.
      if (missedNonPartitionedRequestSchedulingOpportunity < rmContext
          .getScheduler().getNumClusterNodes()) {
        if (LOG.isDebugEnabled()) {
          LOG.debug(""Skip app_attempt="" + application.getApplicationAttemptId()
              + "" priority="" + schedulerKey.getPriority()
              + "" because missed-non-partitioned-resource-request""
              + "" opportunity under required:"" + "" Now=""
              + missedNonPartitionedRequestSchedulingOpportunity + "" required=""
              + rmContext.getScheduler().getNumClusterNodes());
        }
        ActivitiesLogger.APP.recordSkippedAppActivityWithoutAllocation(
            activitiesManager, node, application, schedulerKey,
            ActivityDiagnosticConstant.
                REQUEST_SKIPPED_BECAUSE_NON_PARTITIONED_PARTITION_FIRST,
            ActivityLevel.REQUEST);
        return ContainerAllocation.APP_SKIPPED;
      }
    }

    return null;
  }",,
hadoop,6998,"LOG.trace(""Got journal, "" + ""state = "" + bnState + ""; firstTxId = "" + firstTxId + ""; numTxns = "" + numTxns)",trace,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupImage.java/#L165,"synchronized void journal(long firstTxId, int numTxns, byte[] data) throws IOException {
    if (LOG.isTraceEnabled()) {
      
---------------Reference log start----------------
LOG.trace(""Got journal, "" + ""state = "" + bnState + ""; firstTxId = "" + firstTxId + ""; numTxns = "" + numTxns)
---------------Reference log end----------------
    }
    
    switch(bnState) {
      case DROP_UNTIL_NEXT_ROLL:
        return;

      case IN_SYNC:
        // update NameSpace in memory
        applyEdits(firstTxId, numTxns, data);
        break;
      
      case JOURNAL_ONLY:
        break;
      
      default:
        throw new AssertionError(""Unhandled state: "" + bnState);
    }
    
    // write to BN's local edit log.
    editLog.journal(firstTxId, numTxns, data);
  }",,
hadoop,7271,LOG.error(prompt),error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/MetaRecoveryContext.java/#L97,"public static void editLogLoaderPrompt(String prompt,
        MetaRecoveryContext recovery, String contStr)
        throws IOException, RequestStopException
  {
    if (recovery == null) {
      throw new IOException(prompt);
    }
    
---------------Reference log start----------------
LOG.error(prompt)
---------------Reference log end----------------
    String answer = recovery.ask(""\nEnter 'c' to continue, "" + contStr + ""\n"" +
      ""Enter 's' to stop reading the edit log here, abandoning any later "" +
        ""edits\n"" +
      ""Enter 'q' to quit without saving\n"" +
      ""Enter 'a' to always select the first choice in the future "" +
      ""without prompting. "" + 
      ""(c/s/q/a)\n"", ""c"", ""s"", ""q"", ""a"");
    if (answer.equals(""c"")) {
      LOG.info(""Continuing"");
      return;
    } else if (answer.equals(""s"")) {
      throw new RequestStopException(""user requested stop"");
    } else if (answer.equals(""q"")) {
      recovery.quit();
    } else {
      recovery.setForce(FORCE_FIRST_CHOICE);
      return;
    }
  }",,
hadoop,615,"LOG.error(""App Attempt "" + (appEvent.equals(DSEvent.DS_APP_ATTEMPT_START) ? ""start"" : ""end"") + "" event could not be published for "" + appAttemptID, e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java/#L1716,"private void publishApplicationAttemptEvent(
      final TimelineClient timelineClient, String appAttemptId,
      DSEvent appEvent, String domainId, UserGroupInformation ugi) {
    final TimelineEntity entity = new TimelineEntity();
    entity.setEntityId(appAttemptId);
    entity.setEntityType(DSEntity.DS_APP_ATTEMPT.toString());
    entity.setDomainId(domainId);
    entity.addPrimaryFilter(USER_TIMELINE_FILTER_NAME, ugi.getShortUserName());
    TimelineEvent event = new TimelineEvent();
    event.setEventType(appEvent.toString());
    event.setTimestamp(System.currentTimeMillis());
    entity.addEvent(event);
    try {
      TimelinePutResponse response = timelineClient.putEntities(entity);
      processTimelineResponseErrors(response);
    } catch (YarnException | IOException | ClientHandlerException e) {
      
---------------Reference log start----------------
LOG.error(""App Attempt "" + (appEvent.equals(DSEvent.DS_APP_ATTEMPT_START) ? ""start"" : ""end"") + "" event could not be published for "" + appAttemptID, e)
---------------Reference log end----------------
    }
  }",,
hadoop,13139,"LOG.info(""Local service "" + localTarget + "" entered state: "" + newState)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java/#L926,"protected synchronized void setLastHealthState(HealthMonitor.State newState) {
    
---------------Reference log start----------------
LOG.info(""Local service "" + localTarget + "" entered state: "" + newState)
---------------Reference log end----------------
    lastHealthState = newState;
  }",,
hadoop,5365,"LOG.warn(""Waiting to remove IN_INTERMEDIATE state histories "" + ""(e.g. "" + firstInIntermediateKey + "") from JobListCache "" + ""because it is not in done yet. Total count is "" + inIntermediateCount + ""."")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java/#L273,"public HistoryFileInfo addIfAbsent(HistoryFileInfo fileInfo) {
      JobId jobId = fileInfo.getJobId();
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Adding "" + jobId + "" to job list cache with ""
            + fileInfo.getJobIndexInfo());
      }
      HistoryFileInfo old = cache.putIfAbsent(jobId, fileInfo);
      if (cache.size() > maxSize) {
        //There is a race here, where more then one thread could be trying to
        // remove entries.  This could result in too many entries being removed
        // from the cache.  This is considered OK as the size of the cache
        // should be rather large, and we would rather have performance over
        // keeping the cache size exactly at the maximum.
        Iterator<JobId> keys = cache.navigableKeySet().iterator();
        long cutoff = System.currentTimeMillis() - maxAge;

        // MAPREDUCE-6436: In order to reduce the number of logs written
        // in case of a lot of move pending histories.
        JobId firstInIntermediateKey = null;
        int inIntermediateCount = 0;
        JobId firstMoveFailedKey = null;
        int moveFailedCount = 0;

        while (cache.size() > maxSize && keys.hasNext()) {
          JobId key = keys.next();
          HistoryFileInfo firstValue = cache.get(key);
          if (firstValue != null) {
            if (firstValue.isMovePending()) {
              if (firstValue.didMoveFail() &&
                  firstValue.jobIndexInfo.getFinishTime() <= cutoff) {
                cache.remove(key);
                // Now lets try to delete it
                try {
                  firstValue.delete();
                } catch (IOException e) {
                  LOG.error(""Error while trying to delete history files"" +
                      "" that could not be moved to done."", e);
                }
              } else {
                if (firstValue.didMoveFail()) {
                  if (moveFailedCount == 0) {
                    firstMoveFailedKey = key;
                  }
                  moveFailedCount += 1;
                } else {
                  if (inIntermediateCount == 0) {
                    firstInIntermediateKey = key;
                  }
                  inIntermediateCount += 1;
                }
              }
            } else {
              cache.remove(key);
            }
          }
        }
        // Log output only for first jobhisotry in pendings to restrict
        // the total number of logs.
        if (inIntermediateCount > 0) {
          
---------------Reference log start----------------
LOG.warn(""Waiting to remove IN_INTERMEDIATE state histories "" + ""(e.g. "" + firstInIntermediateKey + "") from JobListCache "" + ""because it is not in done yet. Total count is "" + inIntermediateCount + ""."")
---------------Reference log end----------------
        }
        if (moveFailedCount > 0) {
          LOG.warn(""Waiting to remove MOVE_FAILED state histories "" +
                  ""(e.g. "" + firstMoveFailedKey + "") from JobListCache "" +
                  ""because it is not in done yet. Total count is "" +
                  moveFailedCount + ""."");
        }
      }
      return old;
    }",,
hadoop,3467,"LOG.debug(""Trying to fulfill reservation for application "" + getApplicationAttemptId() + "" on node: "" + node)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java/#L1140,"boolean assignReservedContainer(FSSchedulerNode node) {
    RMContainer rmContainer = node.getReservedContainer();
    SchedulerRequestKey reservedSchedulerKey =
        rmContainer.getReservedSchedulerKey();

    if (!isValidReservation(node)) {
      // Don't hold the reservation if app can no longer use it
      LOG.info(""Releasing reservation that cannot be satisfied for "" +
          ""application "" + getApplicationAttemptId() + "" on node "" + node);
      unreserve(reservedSchedulerKey, node);
      return false;
    }

    // Reservation valid; try to fulfill the reservation
    if (LOG.isDebugEnabled()) {
      
---------------Reference log start----------------
LOG.debug(""Trying to fulfill reservation for application "" + getApplicationAttemptId() + "" on node: "" + node)
---------------Reference log end----------------
    }

    // Fail early if the reserved container won't fit.
    // Note that we have an assumption here that
    // there's only one container size per priority.
    if (Resources.fitsIn(node.getReservedContainer().getReservedResource(),
        node.getUnallocatedResource())) {
      assignContainer(node, true);
    }
    return true;
  }",,
hadoop,801,"LOG.debug(""Removing master key {}"", key.getKeyId())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/security/TimelineV1DelegationTokenSecretManagerService.java/#L154,"@Override
    protected void removeStoredMasterKey(DelegationKey key) {
      
---------------Reference log start----------------
LOG.debug(""Removing master key {}"", key.getKeyId())
---------------Reference log end----------------
      try {
        if (stateStore != null) {
          stateStore.removeTokenMasterKey(key);
        }
      } catch (IOException e) {
        LOG.error(""Unable to remove master key "" + key.getKeyId(), e);
      }
    }",,
hadoop,12523,"LOG.debug(""Failed to find datanode (scope=\""{}\"" excludedScope=\""{}\"")."" + "" numOfDatanodes={}"", scope, excludedScope, numOfDatanodes)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/NetworkTopology.java/#L514,"protected Node chooseRandom(final String scope, String excludedScope,
      final Collection<Node> excludedNodes) {
    if (excludedScope != null) {
      if (isChildScope(scope, excludedScope)) {
        return null;
      }
      if (!isChildScope(excludedScope, scope)) {
        excludedScope = null;
      }
    }
    Node node = getNode(scope);
    if (!(node instanceof InnerNode)) {
      return excludedNodes != null && excludedNodes.contains(node) ?
          null : node;
    }
    InnerNode innerNode = (InnerNode)node;
    int numOfDatanodes = innerNode.getNumOfLeaves();
    if (excludedScope == null) {
      node = null;
    } else {
      node = getNode(excludedScope);
      if (!(node instanceof InnerNode)) {
        numOfDatanodes -= 1;
      } else {
        numOfDatanodes -= ((InnerNode)node).getNumOfLeaves();
      }
    }
    if (numOfDatanodes <= 0) {
      
---------------Reference log start----------------
LOG.debug(""Failed to find datanode (scope=\""{}\"" excludedScope=\""{}\"")."" + "" numOfDatanodes={}"", scope, excludedScope, numOfDatanodes)
---------------Reference log end----------------
      return null;
    }
    final int availableNodes;
    if (excludedScope == null) {
      availableNodes = countNumOfAvailableNodes(scope, excludedNodes);
    } else {
      netlock.readLock().lock();
      try {
        availableNodes = countNumOfAvailableNodes(scope, excludedNodes) -
            countNumOfAvailableNodes(excludedScope, excludedNodes);
      } finally {
        netlock.readLock().unlock();
      }
    }
    LOG.debug(""Choosing random from {} available nodes on node {},""
        + "" scope={}, excludedScope={}, excludeNodes={}. numOfDatanodes={}."",
        availableNodes, innerNode, scope, excludedScope, excludedNodes,
        numOfDatanodes);
    Node ret = null;
    if (availableNodes > 0) {
      ret = chooseRandom(innerNode, node, excludedNodes, numOfDatanodes,
          availableNodes);
    }
    LOG.debug(""chooseRandom returning {}"", ret);
    return ret;
  }",,
hadoop,3897,"LOG.info(""updating the following ReservationRequest: "" + contract)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/planning/GreedyReservationAgent.java/#L107,"@Override
  public boolean updateReservation(ReservationId reservationId, String user,
      Plan plan, ReservationDefinition contract) throws PlanningException {

    
---------------Reference log start----------------
LOG.info(""updating the following ReservationRequest: "" + contract)
---------------Reference log end----------------

    return planner.updateReservation(reservationId, user, plan, contract);

  }",,
hadoop,1543,"LOG.debug(""Using default scheduler. Allowed:"" + allowed + "",Used:"" + used + "", containerId:"" + containerId)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/resourceplugin/deviceframework/DeviceMappingManager.java/#L352,"private void defaultScheduleAction(Set<Device> allowed,
      Map<Device, ContainerId> used, Set<Device> assigned,
      ContainerId containerId, int count) {
    
---------------Reference log start----------------
LOG.debug(""Using default scheduler. Allowed:"" + allowed + "",Used:"" + used + "", containerId:"" + containerId)
---------------Reference log end----------------
    for (Device device : allowed) {
      if (!used.containsKey(device)) {
        used.put(device, containerId);
        assigned.add(device);
        if (assigned.size() == count) {
          return;
        }
      }
    } // end for
  }",,
hadoop,4048,"LOG.info(""Application {} with appId {} submitted on {}"", context.getApplicationName(), applicationId, subClusterId)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationInterceptorREST.java/#L518,"@Override
  public Response submitApplication(ApplicationSubmissionContextInfo newApp,
      HttpServletRequest hsr)
      throws AuthorizationException, IOException, InterruptedException {

    long startTime = clock.getTime();

    if (newApp == null || newApp.getApplicationId() == null) {
      routerMetrics.incrAppsFailedSubmitted();
      String errMsg = ""Missing ApplicationSubmissionContextInfo or ""
          + ""applicationSubmissionContex information."";
      return Response
          .status(Status.BAD_REQUEST)
          .entity(errMsg)
          .build();
    }

    ApplicationId applicationId = null;
    try {
      applicationId = ApplicationId.fromString(newApp.getApplicationId());
    } catch (IllegalArgumentException e) {
      routerMetrics.incrAppsFailedSubmitted();
      return Response
          .status(Status.BAD_REQUEST)
          .entity(e.getLocalizedMessage())
          .build();
    }

    List<SubClusterId> blacklist = new ArrayList<SubClusterId>();

    for (int i = 0; i < numSubmitRetries; ++i) {

      ApplicationSubmissionContext context =
          RMWebAppUtil.createAppSubmissionContext(newApp, this.getConf());

      SubClusterId subClusterId = null;
      try {
        subClusterId = policyFacade.getHomeSubcluster(context, blacklist);
      } catch (YarnException e) {
        routerMetrics.incrAppsFailedSubmitted();
        return Response
            .status(Status.SERVICE_UNAVAILABLE)
            .entity(e.getLocalizedMessage())
            .build();
      }
      LOG.info(""submitApplication appId {} try #{} on SubCluster {}"",
          applicationId, i, subClusterId);

      ApplicationHomeSubCluster appHomeSubCluster =
          ApplicationHomeSubCluster.newInstance(applicationId, subClusterId);

      if (i == 0) {
        try {
          // persist the mapping of applicationId and the subClusterId which has
          // been selected as its home
          subClusterId =
              federationFacade.addApplicationHomeSubCluster(appHomeSubCluster);
        } catch (YarnException e) {
          routerMetrics.incrAppsFailedSubmitted();
          String errMsg = ""Unable to insert the ApplicationId "" + applicationId
              + "" into the FederationStateStore"";
          return Response
              .status(Status.SERVICE_UNAVAILABLE)
              .entity(errMsg + "" "" + e.getLocalizedMessage())
              .build();
        }
      } else {
        try {
          // update the mapping of applicationId and the home subClusterId to
          // the new subClusterId we have selected
          federationFacade.updateApplicationHomeSubCluster(appHomeSubCluster);
        } catch (YarnException e) {
          String errMsg = ""Unable to update the ApplicationId "" + applicationId
              + "" into the FederationStateStore"";
          SubClusterId subClusterIdInStateStore;
          try {
            subClusterIdInStateStore =
                federationFacade.getApplicationHomeSubCluster(applicationId);
          } catch (YarnException e1) {
            routerMetrics.incrAppsFailedSubmitted();
            return Response
                .status(Status.SERVICE_UNAVAILABLE)
                .entity(e1.getLocalizedMessage())
                .build();
          }
          if (subClusterId == subClusterIdInStateStore) {
            LOG.info(""Application {} already submitted on SubCluster {}"",
                applicationId, subClusterId);
          } else {
            routerMetrics.incrAppsFailedSubmitted();
            return Response
                .status(Status.SERVICE_UNAVAILABLE)
                .entity(errMsg)
                .build();
          }
        }
      }

      SubClusterInfo subClusterInfo;
      try {
        subClusterInfo = federationFacade.getSubCluster(subClusterId);
      } catch (YarnException e) {
        routerMetrics.incrAppsFailedSubmitted();
        return Response
            .status(Status.SERVICE_UNAVAILABLE)
            .entity(e.getLocalizedMessage())
            .build();
      }

      Response response = null;
      try {
        response = getOrCreateInterceptorForSubCluster(subClusterId,
            subClusterInfo.getRMWebServiceAddress()).submitApplication(newApp,
                hsr);
      } catch (Exception e) {
        LOG.warn(""Unable to submit the application {} to SubCluster {}"",
            applicationId, subClusterId.getId(), e);
      }

      if (response != null &&
          response.getStatus() == HttpServletResponse.SC_ACCEPTED) {
        
---------------Reference log start----------------
LOG.info(""Application {} with appId {} submitted on {}"", context.getApplicationName(), applicationId, subClusterId)
---------------Reference log end----------------

        long stopTime = clock.getTime();
        routerMetrics.succeededAppsSubmitted(stopTime - startTime);

        return response;
      } else {
        // Empty response from the ResourceManager.
        // Blacklist this subcluster for this request.
        blacklist.add(subClusterId);
      }
    }

    routerMetrics.incrAppsFailedSubmitted();
    String errMsg = ""Application "" + newApp.getApplicationName()
        + "" with appId "" + applicationId + "" failed to be submitted."";
    LOG.error(errMsg);
    return Response
        .status(Status.SERVICE_UNAVAILABLE)
        .entity(errMsg)
        .build();
  }",,
hadoop,10552,"LOG.info(""Creating temp file: {}"", tempFile)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/RetriableFileCopyCommand.java/#L269,"private Path getTempFile(Path target, Mapper.Context context) {
    Path targetWorkPath = new Path(context.getConfiguration().
        get(DistCpConstants.CONF_LABEL_TARGET_WORK_PATH));

    Path root = target.equals(targetWorkPath) ? targetWorkPath.getParent()
        : targetWorkPath;
    Path tempFile = new Path(root, "".distcp.tmp."" +
        context.getTaskAttemptID().toString() +
        ""."" + String.valueOf(System.currentTimeMillis()));
    
---------------Reference log start----------------
LOG.info(""Creating temp file: {}"", tempFile)
---------------Reference log end----------------
    return tempFile;
  }",,
hadoop,1407,LOG.info(message),info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/ContainerLaunch.java/#L1007,"public void resumeContainer() throws IOException {
    ContainerId containerId = container.getContainerId();
    String containerIdStr = containerId.toString();
    LOG.info(""Resuming the container "" + containerIdStr);

    // The resume event is only handled if the container is in a paused state
    // so we don't check for the launched flag here.

    // paused flag will be set to true if process already paused
    boolean alreadyPaused = !shouldPauseContainer.compareAndSet(false, true);
    if (!alreadyPaused) {
      LOG.info(""Container "" + containerIdStr + "" not paused.""
          + "" No resume necessary"");
      return;
    }

    // If the container has already started
    try {
      exec.resumeContainer(container);
      // ResumeContainer is a blocking call. We are here almost means the
      // container is resumed, so send out the event.
      dispatcher.getEventHandler().handle(new ContainerEvent(
          containerId,
          ContainerEventType.CONTAINER_RESUMED));

      try {
        this.context.getNMStateStore().removeContainerPaused(
            container.getContainerId());
      } catch (IOException e) {
        LOG.warn(""Could not store container ["" + container.getContainerId()
            + ""] state. The Container has been resumed."", e);
      }
    } catch (Exception e) {
      String message =
          ""Exception when trying to resume container "" + containerIdStr
              + "": "" + StringUtils.stringifyException(e);
      
---------------Reference log start----------------
LOG.info(message)
---------------Reference log end----------------
      container.handle(new ContainerKillEvent(container.getContainerId(),
          ContainerExitStatus.PREEMPTED, ""Container preempted as there was ""
          + "" an exception in pausing it.""));
    }
  }",,
hadoop,1942,"LOG.warn(""FPGA plugin failed to downloaded IP, please check the"" + "" value of environment viable: "" + REQUEST_FPGA_IP_ID_KEY + "" if you want YARN to program the device"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/resources/fpga/FpgaResourceHandlerImpl.java/#L183,"@Override
  public List<PrivilegedOperation> preStart(Container container)
      throws ResourceHandlerException {
    // 1. Get requested FPGA type and count, choose corresponding FPGA plugin(s)
    // 2. Use allocator.assignFpga(type, count) to get FPGAAllocation
    // 3. If required, download to ensure IP file exists and configure IP file for all devices
    List<PrivilegedOperation> ret = new ArrayList<>();
    String containerIdStr = container.getContainerId().toString();
    Resource requestedResource = container.getResource();

    // Create device cgroups for the container
    cGroupsHandler.createCGroup(CGroupsHandler.CGroupController.DEVICES,
      containerIdStr);

    long deviceCount = requestedResource.getResourceValue(FPGA_URI);
    LOG.info(containerIdStr + "" requested "" + deviceCount + "" Intel FPGA(s)"");
    String ipFilePath = null;
    try {

      // allocate even request 0 FPGA because we need to deny all device numbers for this container
      final String requestedIPID = getRequestedIPID(container);
      String localizedIPIDHash = null;
      ipFilePath = vendorPlugin.retrieveIPfilePath(
          requestedIPID, container.getWorkDir(),
          container.getResourceSet().getLocalizedResources());
      if (ipFilePath != null) {
        try (FileInputStream fis = new FileInputStream(ipFilePath)) {
          localizedIPIDHash = DigestUtils.sha256Hex(fis);
        } catch (IOException e) {
          throw new ResourceHandlerException(""Could not calculate SHA-256"", e);
        }
      }

      FpgaResourceAllocator.FpgaAllocation allocation = allocator.assignFpga(
          vendorPlugin.getFpgaType(), deviceCount,
          container, localizedIPIDHash);
      LOG.info(""FpgaAllocation:"" + allocation);

      PrivilegedOperation privilegedOperation =
          new PrivilegedOperation(PrivilegedOperation.OperationType.FPGA,
          Arrays.asList(CONTAINER_ID_CLI_OPTION, containerIdStr));
      if (!allocation.getDenied().isEmpty()) {
        List<Integer> denied = new ArrayList<>();
        allocation.getDenied().forEach(device -> denied.add(device.getMinor()));
        privilegedOperation.appendArgs(Arrays.asList(EXCLUDED_FPGAS_CLI_OPTION,
            StringUtils.join("","", denied)));
      }
      privilegedOperationExecutor.executePrivilegedOperation(
          privilegedOperation, true);

      if (deviceCount > 0) {
        /**
         * We only support flashing one IP for all devices now. If user don't set this
         * environment variable, we assume that user's application can find the IP file by
         * itself.
         * Note that the IP downloading and reprogramming in advance in YARN is not necessary because
         * the OpenCL application may find the IP file and reprogram device on the fly. But YARN do this
         * for the containers will achieve the quickest reprogram path
         *
         * For instance, REQUESTED_FPGA_IP_ID = ""matrix_mul"" will make all devices
         * programmed with matrix multiplication IP
         *
         * In the future, we may support ""matrix_mul:1,gzip:2"" format to support different IP
         * for different devices
         *
         * */
        ipFilePath = vendorPlugin.retrieveIPfilePath(
            getRequestedIPID(container),
            container.getWorkDir(),
            container.getResourceSet().getLocalizedResources());
        if (ipFilePath == null) {
          
---------------Reference log start----------------
LOG.warn(""FPGA plugin failed to downloaded IP, please check the"" + "" value of environment viable: "" + REQUEST_FPGA_IP_ID_KEY + "" if you want YARN to program the device"")
---------------Reference log end----------------
        } else {
          LOG.info(""IP file path:"" + ipFilePath);
          List<FpgaDevice> allowed = allocation.getAllowed();
          String majorMinorNumber;
          for (int i = 0; i < allowed.size(); i++) {
            FpgaDevice device = allowed.get(i);
            majorMinorNumber = device.getMajor() + "":"" + device.getMinor();
            String currentHash = allowed.get(i).getAocxHash();
            if (currentHash != null &&
                currentHash.equalsIgnoreCase(localizedIPIDHash)) {
              LOG.info(""IP already in device \""""
                  + allowed.get(i).getAliasDevName() + "","" +
                  majorMinorNumber + ""\"", skip reprogramming"");
              continue;
            }
            if (vendorPlugin.configureIP(ipFilePath, device)) {
              // update the allocator that we update an IP of a device
              allocator.updateFpga(containerIdStr, allowed.get(i),
                  requestedIPID, localizedIPIDHash);
              //TODO: update the node constraint label
            }
          }
        }
      }
    } catch (ResourceHandlerException re) {
      allocator.cleanupAssignFpgas(containerIdStr);
      cGroupsHandler.deleteCGroup(CGroupsHandler.CGroupController.DEVICES,
          containerIdStr);
      throw re;
    } catch (PrivilegedOperationException e) {
      allocator.cleanupAssignFpgas(containerIdStr);
      cGroupsHandler.deleteCGroup(CGroupsHandler.CGroupController.DEVICES,
          containerIdStr);
      LOG.warn(""Could not update cgroup for container"", e);
      throw new ResourceHandlerException(e);
    }
    //isolation operation
    ret.add(new PrivilegedOperation(
        PrivilegedOperation.OperationType.ADD_PID_TO_CGROUP,
        PrivilegedOperation.CGROUP_ARG_PREFIX
        + cGroupsHandler.getPathForCGroupTasks(
        CGroupsHandler.CGroupController.DEVICES, containerIdStr)));
    return ret;
  }",,
hadoop,545,"LOG.info(""Application has completed successfully."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-unmanaged-am-launcher/src/main/java/org/apache/hadoop/yarn/applications/unmanagedamlauncher/UnmanagedAMLauncher.java/#L371,"public boolean run() throws IOException, YarnException {
    LOG.info(""Starting Client"");
    
    // Connect to ResourceManager
    rmClient.start();
    try {  
      // Create launch context for app master
      LOG.info(""Setting up application submission context for ASM"");
      ApplicationSubmissionContext appContext = rmClient.createApplication()
          .getApplicationSubmissionContext();
      ApplicationId appId = appContext.getApplicationId();

      // set the application name
      appContext.setApplicationName(appName);
  
      // Set the priority for the application master
      Priority pri = Records.newRecord(Priority.class);
      pri.setPriority(amPriority);
      appContext.setPriority(pri);
  
      // Set the queue to which this application is to be submitted in the RM
      appContext.setQueue(amQueue);
  
      // Set up the container launch context for the application master
      ContainerLaunchContext amContainer = Records
          .newRecord(ContainerLaunchContext.class);
      appContext.setAMContainerSpec(amContainer);
  
      // unmanaged AM
      appContext.setUnmanagedAM(true);
      LOG.info(""Setting unmanaged AM"");
  
      // Submit the application to the applications manager
      LOG.info(""Submitting application to ASM"");
      rmClient.submitApplication(appContext);

      ApplicationReport appReport =
          monitorApplication(appId, EnumSet.of(YarnApplicationState.ACCEPTED,
            YarnApplicationState.KILLED, YarnApplicationState.FAILED,
            YarnApplicationState.FINISHED));

      if (appReport.getYarnApplicationState() == YarnApplicationState.ACCEPTED) {
        // Monitor the application attempt to wait for launch state
        ApplicationAttemptReport attemptReport =
            monitorCurrentAppAttempt(appId,
              YarnApplicationAttemptState.LAUNCHED);
        ApplicationAttemptId attemptId =
            attemptReport.getApplicationAttemptId();
        LOG.info(""Launching AM with application attempt id "" + attemptId);
        // launch AM
        launchAM(attemptId);
        // Monitor the application for end state
        appReport =
            monitorApplication(appId, EnumSet.of(YarnApplicationState.KILLED,
              YarnApplicationState.FAILED, YarnApplicationState.FINISHED));
      }

      YarnApplicationState appState = appReport.getYarnApplicationState();
      FinalApplicationStatus appStatus = appReport.getFinalApplicationStatus();
  
      LOG.info(""App ended with state: "" + appReport.getYarnApplicationState()
          + "" and status: "" + appStatus);
      
      boolean success;
      if (YarnApplicationState.FINISHED == appState
          && FinalApplicationStatus.SUCCEEDED == appStatus) {
        
---------------Reference log start----------------
LOG.info(""Application has completed successfully."")
---------------Reference log end----------------
        success = true;
      } else {
        LOG.info(""Application did finished unsuccessfully."" + "" YarnState=""
            + appState.toString() + "", FinalStatus="" + appStatus.toString());
        success = false;
      }
      
      return success;
    } finally {
      rmClient.stop();
    }
  }",,
hadoop,2944,"LOG.info(getQueuePath() + "": re-configured queue: "" + childQueue)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/ParentQueue.java/#L681,"@Override
  public void reinitialize(CSQueue newlyParsedQueue,
      Resource clusterResource) throws IOException {
    writeLock.lock();
    try {
      // We skip reinitialize for dynamic queues, when this is called, and
      // new queue is different from this queue, we will make this queue to be
      // static queue.
      if (newlyParsedQueue != this) {
        this.setDynamicQueue(false);
      }

      // Sanity check
      if (!(newlyParsedQueue instanceof ParentQueue) || !newlyParsedQueue
          .getQueuePath().equals(getQueuePath())) {
        throw new IOException(
            ""Trying to reinitialize "" + getQueuePath() + "" from ""
                + newlyParsedQueue.getQueuePath());
      }

      ParentQueue newlyParsedParentQueue = (ParentQueue) newlyParsedQueue;

      // Set new configs
      setupQueueConfigs(clusterResource, csContext.getConfiguration());

      // Re-configure existing child queues and add new ones
      // The CS has already checked to ensure all existing child queues are present!
      Map<String, CSQueue> currentChildQueues = getQueuesMap(childQueues);
      Map<String, CSQueue> newChildQueues = getQueuesMap(
          newlyParsedParentQueue.childQueues);

      // Reinitialize dynamic queues as well, because they are not parsed
      for (String queue : Sets.difference(currentChildQueues.keySet(),
          newChildQueues.keySet())) {
        CSQueue candidate = currentChildQueues.get(queue);
        if (candidate instanceof AbstractCSQueue) {
          if (((AbstractCSQueue) candidate).isDynamicQueue()) {
            candidate.reinitialize(candidate, clusterResource);
          }
        }
      }

      for (Map.Entry<String, CSQueue> e : newChildQueues.entrySet()) {
        String newChildQueueName = e.getKey();
        CSQueue newChildQueue = e.getValue();

        CSQueue childQueue = currentChildQueues.get(newChildQueueName);

        // Check if the child-queue already exists
        if (childQueue != null) {
          // Check if the child-queue has been converted into parent queue or
          // parent Queue has been converted to child queue. The CS has already
          // checked to ensure that this child-queue is in STOPPED state if
          // Child queue has been converted to ParentQueue.
          if ((childQueue instanceof LeafQueue
              && newChildQueue instanceof ParentQueue)
              || (childQueue instanceof ParentQueue
                  && newChildQueue instanceof LeafQueue)) {
            // We would convert this LeafQueue to ParentQueue, or vice versa.
            // consider this as the combination of DELETE then ADD.
            newChildQueue.setParent(this);
            currentChildQueues.put(newChildQueueName, newChildQueue);
            // inform CapacitySchedulerQueueManager
            CapacitySchedulerQueueManager queueManager =
                this.csContext.getCapacitySchedulerQueueManager();
            queueManager.addQueue(newChildQueueName, newChildQueue);
            continue;
          }
          // Re-init existing queues
          childQueue.reinitialize(newChildQueue, clusterResource);
          
---------------Reference log start----------------
LOG.info(getQueuePath() + "": re-configured queue: "" + childQueue)
---------------Reference log end----------------
        } else{
          // New child queue, do not re-init

          // Set parent to 'this'
          newChildQueue.setParent(this);

          // Save in list of current child queues
          currentChildQueues.put(newChildQueueName, newChildQueue);

          LOG.info(
              getQueuePath() + "": added new child queue: "" + newChildQueue);
        }
      }

      // remove the deleted queue in the refreshed xml.
      for (Iterator<Map.Entry<String, CSQueue>> itr = currentChildQueues
          .entrySet().iterator(); itr.hasNext();) {
        Map.Entry<String, CSQueue> e = itr.next();
        String queueName = e.getKey();
        if (!newChildQueues.containsKey(queueName)) {
          if (((AbstractCSQueue)e.getValue()).isDynamicQueue()) {
            // Don't remove dynamic queue if we cannot find it in the config.
            continue;
          }
          itr.remove();
        }
      }

      // Re-sort all queues
      setChildQueues(currentChildQueues.values());

      // Make sure we notifies QueueOrderingPolicy
      queueOrderingPolicy.setQueues(childQueues);
    } finally {
      writeLock.unlock();
    }
  }",,
hadoop,3866,"LOG.info(""Updating RMDelegationToken_"" + identifier.getSequenceNumber())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/FileSystemRMStateStore.java/#L561,"private void storeOrUpdateRMDelegationTokenState(
      RMDelegationTokenIdentifier identifier, Long renewDate,
      boolean isUpdate) throws Exception {
    Path nodeCreatePath =
        getNodePath(rmDTSecretManagerRoot,
          DELEGATION_TOKEN_PREFIX + identifier.getSequenceNumber());
    RMDelegationTokenIdentifierData identifierData =
        new RMDelegationTokenIdentifierData(identifier, renewDate);
    if (isUpdate) {
      
---------------Reference log start----------------
LOG.info(""Updating RMDelegationToken_"" + identifier.getSequenceNumber())
---------------Reference log end----------------
      updateFile(nodeCreatePath, identifierData.toByteArray(), true);
    } else {
      LOG.info(""Storing RMDelegationToken_"" + identifier.getSequenceNumber());
      writeFileWithRetries(nodeCreatePath, identifierData.toByteArray(), true);

      // store sequence number
      Path latestSequenceNumberPath = getNodePath(rmDTSecretManagerRoot,
            DELEGATION_TOKEN_SEQUENCE_NUMBER_PREFIX
            + identifier.getSequenceNumber());
      LOG.info(""Storing "" + DELEGATION_TOKEN_SEQUENCE_NUMBER_PREFIX
          + identifier.getSequenceNumber());
      if (dtSequenceNumberPath == null) {
        if (!createFileWithRetries(latestSequenceNumberPath)) {
          throw new Exception(""Failed to create "" + latestSequenceNumberPath);
        }
      } else {
        if (!renameFileWithRetries(dtSequenceNumberPath,
            latestSequenceNumberPath)) {
          throw new Exception(""Failed to rename "" + dtSequenceNumberPath);
        }
      }
      dtSequenceNumberPath = latestSequenceNumberPath;
    }
  }",,
hadoop,4423,"LOG.info(""Exception while executing an FS operation."", e)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/LogAggregationIndexedFileController.java/#L1278,"T runWithRetries() throws Exception {
      int retry = 0;
      while (true) {
        try {
          return run();
        } catch (IOException e) {
          
---------------Reference log start----------------
LOG.info(""Exception while executing an FS operation."", e)
---------------Reference log end----------------
          if (++retry > fsNumRetries) {
            LOG.info(""Maxed out FS retries. Giving up!"");
            throw e;
          }
          LOG.info(""Retrying operation on FS. Retry no. "" + retry);
          Thread.sleep(fsRetryInterval);
        }
      }
    }",,
hadoop,2443,"LOG.debug(""scanForLogs on {}"", statAttempt.getPath().getName())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/EntityGroupFSTimelineStore.java/#L753,"@InterfaceAudience.Private
    @VisibleForTesting
    long scanForLogs() throws IOException {
      LOG.debug(""scanForLogs on {}"", appDirPath);
      long newestModTime = 0;
      RemoteIterator<FileStatus> iterAttempt = list(appDirPath);
      while (iterAttempt.hasNext()) {
        FileStatus statAttempt = iterAttempt.next();
        
---------------Reference log start----------------
LOG.debug(""scanForLogs on {}"", statAttempt.getPath().getName())
---------------Reference log end----------------
        if (!statAttempt.isDirectory()
            || !statAttempt.getPath().getName()
            .startsWith(ApplicationAttemptId.appAttemptIdStrPrefix)) {
          LOG.debug(""Scanner skips for unknown dir/file {}"",
              statAttempt.getPath());
          continue;
        }
        String attemptDirName = statAttempt.getPath().getName();
        RemoteIterator<FileStatus> iterCache = list(statAttempt.getPath());
        while (iterCache.hasNext()) {
          FileStatus statCache = iterCache.next();
          if (!statCache.isFile()) {
            continue;
          }
          String filename = statCache.getPath().getName();
          // We should only update time for log files.
          boolean shouldSetTime = true;
          LOG.debug(""scan for log file: {}"", filename);
          if (filename.startsWith(DOMAIN_LOG_PREFIX)) {
            addSummaryLog(attemptDirName, filename, statCache.getOwner(), true);
          } else if (filename.startsWith(SUMMARY_LOG_PREFIX)) {
            addSummaryLog(attemptDirName, filename, statCache.getOwner(),
                false);
          } else if (filename.startsWith(ENTITY_LOG_PREFIX)) {
            addDetailLog(attemptDirName, filename, statCache.getOwner());
          } else {
            shouldSetTime = false;
          }
          if (shouldSetTime) {
            newestModTime
              = Math.max(statCache.getModificationTime(), newestModTime);
          }
        }
      }

      // if there are no logs in the directory then use the modification
      // time of the directory itself
      if (newestModTime == 0) {
        newestModTime = fs.getFileStatus(appDirPath).getModificationTime();
      }

      return newestModTime;
    }",,
hadoop,3590,"LOG.info(""Recovery ended"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceManager.java/#L997,"@Override
    protected void serviceStart() throws Exception {
      RMStateStore rmStore = rmContext.getStateStore();
      // The state store needs to start irrespective of recoveryEnabled as apps
      // need events to move to further states.
      rmStore.start();

      if(recoveryEnabled) {
        try {
          LOG.info(""Recovery started"");
          rmStore.checkVersion();
          if (rmContext.isWorkPreservingRecoveryEnabled()) {
            rmContext.setEpoch(rmStore.getAndIncrementEpoch());
          }
          RMState state = rmStore.loadState();
          recover(state);
          
---------------Reference log start----------------
LOG.info(""Recovery ended"")
---------------Reference log end----------------
        } catch (Exception e) {
          // the Exception from loadState() needs to be handled for
          // HA and we need to give up master status if we got fenced
          LOG.error(""Failed to load/recover state"", e);
          throw e;
        }
      } else {
        if (HAUtil.isFederationEnabled(conf)) {
          long epoch = conf.getLong(YarnConfiguration.RM_EPOCH,
              YarnConfiguration.DEFAULT_RM_EPOCH);
          rmContext.setEpoch(epoch);
          LOG.info(""Epoch set for Federation: "" + epoch);
        }
      }

      super.serviceStart();
    }",,
hadoop,579,"LOG.info(""Timeline service V1 client is enabled"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java/#L966,"@Override
        public Void run() throws Exception {
          if (YarnConfiguration.timelineServiceEnabled(conf)) {
            timelineServiceV1Enabled =
                YarnConfiguration.timelineServiceV1Enabled(conf);
            timelineServiceV2Enabled =
                YarnConfiguration.timelineServiceV2Enabled(conf);
            // Creating the Timeline Client
            if (timelineServiceV1Enabled) {
              timelineClient = TimelineClient.createTimelineClient();
              timelineClient.init(conf);
              timelineClient.start();
              
---------------Reference log start----------------
LOG.info(""Timeline service V1 client is enabled"")
---------------Reference log end----------------
            }
            if (timelineServiceV2Enabled) {
              timelineV2Client = TimelineV2Client.createTimelineClient(
                  appAttemptID.getApplicationId());
              timelineV2Client.init(conf);
              timelineV2Client.start();
              LOG.info(""Timeline service V2 client is enabled"");
            }
          } else {
            timelineClient = null;
            timelineV2Client = null;
            LOG.warn(""Timeline service is not enabled"");
          }
          return null;
        }",,
hadoop,10560,"LOG.info(""SLSRunner is waiting for all nodes RUNNING."" + "" {} of {} NMs initialized."", numRunningNodes, numNMs)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java/#L426,"private void waitForNodesRunning() throws InterruptedException {
    long startTimeMS = System.currentTimeMillis();
    while (true) {
      int numRunningNodes = 0;
      for (RMNode node : rm.getRMContext().getRMNodes().values()) {
        if (node.getState() == NodeState.RUNNING) {
          numRunningNodes++;
        }
      }
      if (numRunningNodes == numNMs) {
        break;
      }
      
---------------Reference log start----------------
LOG.info(""SLSRunner is waiting for all nodes RUNNING."" + "" {} of {} NMs initialized."", numRunningNodes, numNMs)
---------------Reference log end----------------
      Thread.sleep(1000);
    }
    LOG.info(""SLSRunner takes {} ms to launch all nodes."",
        System.currentTimeMillis() - startTimeMS);
  }",,
hadoop,12106,"LOG.info(""Starting to load {} cache."", cacheName)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/delegation/ZKDelegationTokenSecretManager.java/#L437,"private void loadFromZKCache(final boolean isTokenCache) {
    final String cacheName = isTokenCache ? ""token"" : ""key"";
    
---------------Reference log start----------------
LOG.info(""Starting to load {} cache."", cacheName)
---------------Reference log end----------------
    final List<ChildData> children;
    if (isTokenCache) {
      children = tokenCache.getCurrentData();
    } else {
      children = keyCache.getCurrentData();
    }

    int count = 0;
    for (ChildData child : children) {
      try {
        if (isTokenCache) {
          processTokenAddOrUpdate(child.getData());
        } else {
          processKeyAddOrUpdate(child.getData());
        }
      } catch (Exception e) {
        LOG.info(""Ignoring node {} because it failed to load."",
            child.getPath());
        LOG.debug(""Failure exception:"", e);
        ++count;
      }
    }
    if (isTokenCache) {
      syncTokenOwnerStats();
    }
    if (count > 0) {
      LOG.warn(""Ignored {} nodes while loading {} cache."", count, cacheName);
    }
    LOG.info(""Loaded {} cache."", cacheName);
  }",,
hadoop,9940,"LOG.debug(""read ahead enabled issuing readheads num = {}"", numReadAheads)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java/#L483,"private int readInternal(final long position, final byte[] b, final int offset, final int length,
                           final boolean bypassReadAhead) throws IOException {
    if (readAheadEnabled && !bypassReadAhead) {
      // try reading from read-ahead
      if (offset != 0) {
        throw new IllegalArgumentException(""readahead buffers cannot have non-zero buffer offsets"");
      }
      int receivedBytes;

      // queue read-aheads
      int numReadAheads = this.readAheadQueueDepth;
      long nextOffset = position;
      // First read to queue needs to be of readBufferSize and later
      // of readAhead Block size
      long nextSize = min((long) bufferSize, contentLength - nextOffset);
      
---------------Reference log start----------------
LOG.debug(""read ahead enabled issuing readheads num = {}"", numReadAheads)
---------------Reference log end----------------
      TracingContext readAheadTracingContext = new TracingContext(tracingContext);
      readAheadTracingContext.setPrimaryRequestID();
      while (numReadAheads > 0 && nextOffset < contentLength) {
        LOG.debug(""issuing read ahead requestedOffset = {} requested size {}"",
            nextOffset, nextSize);
        ReadBufferManager.getBufferManager().queueReadAhead(this, nextOffset, (int) nextSize,
                new TracingContext(readAheadTracingContext));
        nextOffset = nextOffset + nextSize;
        numReadAheads--;
        // From next round onwards should be of readahead block size.
        nextSize = min((long) readAheadBlockSize, contentLength - nextOffset);
      }

      // try reading from buffers first
      receivedBytes = ReadBufferManager.getBufferManager().getBlock(this, position, length, b);
      bytesFromReadAhead += receivedBytes;
      if (receivedBytes > 0) {
        incrementReadOps();
        LOG.debug(""Received data from read ahead, not doing remote read"");
        if (streamStatistics != null) {
          streamStatistics.readAheadBytesRead(receivedBytes);
        }
        return receivedBytes;
      }

      // got nothing from read-ahead, do our own read now
      receivedBytes = readRemote(position, b, offset, length, new TracingContext(tracingContext));
      return receivedBytes;
    } else {
      LOG.debug(""read ahead disabled, reading remote"");
      return readRemote(position, b, offset, length, new TracingContext(tracingContext));
    }
  }",,
hadoop,9187,"LOG.error(""Did not remove \""{}\"""", existingRecord)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreZooKeeperImpl.java/#L246,"@Override
  public <T extends BaseRecord> int remove(
      Class<T> clazz, Query<T> query) throws IOException {
    verifyDriverReady();
    if (query == null) {
      return 0;
    }

    // Read the current data
    long start = monotonicNow();
    List<T> records = null;
    try {
      QueryResult<T> result = get(clazz);
      records = result.getRecords();
    } catch (IOException ex) {
      LOG.error(""Cannot get existing records"", ex);
      getMetrics().addFailure(monotonicNow() - start);
      return 0;
    }

    // Check the records to remove
    String znode = getZNodeForClass(clazz);
    List<T> recordsToRemove = filterMultiple(query, records);

    // Remove the records
    int removed = 0;
    for (T existingRecord : recordsToRemove) {
      LOG.info(""Removing \""{}\"""", existingRecord);
      try {
        String primaryKey = getPrimaryKey(existingRecord);
        String path = getNodePath(znode, primaryKey);
        if (zkManager.delete(path)) {
          removed++;
        } else {
          
---------------Reference log start----------------
LOG.error(""Did not remove \""{}\"""", existingRecord)
---------------Reference log end----------------
        }
      } catch (Exception e) {
        LOG.error(""Cannot remove \""{}\"""", existingRecord, e);
        getMetrics().addFailure(monotonicNow() - start);
      }
    }
    long end = monotonicNow();
    if (removed > 0) {
      getMetrics().addRemove(end - start);
    }
    return removed;
  }",,
hadoop,4150,"LOG.warn(""Recovering old formatted token"")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java/#L339,"@Override
  public void readFields(DataInput in) throws IOException {
    byte[] data = IOUtils.readFullyToByteArray(in);
    try {
      proto = ContainerTokenIdentifierProto.parseFrom(data);
    } catch (InvalidProtocolBufferException e) {
      
---------------Reference log start----------------
LOG.warn(""Recovering old formatted token"")
---------------Reference log end----------------
      readFieldsInOldFormat(
          new DataInputStream(new ByteArrayInputStream(data)));
    }
  }",,
hadoop,7561,"LOG.warn(""No mover threads available: skip moving "" + p)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/balancer/Dispatcher.java/#L1157,"public void executePendingMove(final PendingMove p) {
    // move the reportedBlock
    final DDatanode targetDn = p.target.getDDatanode();
    ExecutorService moveExecutor = targetDn.getMoveExecutor();
    if (moveExecutor == null) {
      final int nThreads = moverThreadAllocator.allocate();
      if (nThreads > 0) {
        moveExecutor = targetDn.initMoveExecutor(nThreads);
      }
    }
    if (moveExecutor == null) {
      
---------------Reference log start----------------
LOG.warn(""No mover threads available: skip moving "" + p)
---------------Reference log end----------------
      targetDn.removePendingBlock(p);
      p.proxySource.removePendingBlock(p);
      return;
    }
    moveExecutor.execute(p::dispatch);
  }",,
hadoop,617,"LOG.debug(""Timeline entities are successfully put"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java/#L1727,"private TimelinePutResponse processTimelineResponseErrors(
      TimelinePutResponse response) {
    List<TimelinePutResponse.TimelinePutError> errors = response.getErrors();
    if (errors.size() == 0) {
      
---------------Reference log start----------------
LOG.debug(""Timeline entities are successfully put"")
---------------Reference log end----------------
    } else {
      for (TimelinePutResponse.TimelinePutError error : errors) {
        LOG.error(
            ""Error when publishing entity ["" + error.getEntityType() + "",""
                + error.getEntityId() + ""], server side error code: ""
                + error.getErrorCode());
      }
    }
    return response;
  }",,
hadoop,2509,"LOG.debug(""blacklist size {} is less than failure threshold ratio {}"" + "" out of total usable nodes {}"", currentBlacklistSize, blacklistDisableFailureThreshold, numberOfNodeManagerHosts)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/blacklist/SimpleBlacklistManager.java/#L70,"@Override
  public ResourceBlacklistRequest getBlacklistUpdates() {
    ResourceBlacklistRequest ret;
    List<String> blacklist = new ArrayList<>(blacklistNodes);
    final int currentBlacklistSize = blacklist.size();
    final double failureThreshold = this.blacklistDisableFailureThreshold *
        numberOfNodeManagerHosts;
    if (currentBlacklistSize < failureThreshold) {
      
---------------Reference log start----------------
LOG.debug(""blacklist size {} is less than failure threshold ratio {}"" + "" out of total usable nodes {}"", currentBlacklistSize, blacklistDisableFailureThreshold, numberOfNodeManagerHosts)
---------------Reference log end----------------
      ret = ResourceBlacklistRequest.newInstance(blacklist, EMPTY_LIST);
    } else {
      LOG.warn(""Ignoring Blacklists, blacklist size "" + currentBlacklistSize
          + "" is more than failure threshold ratio ""
          + blacklistDisableFailureThreshold + "" out of total usable nodes ""
          + numberOfNodeManagerHosts);
      // TODO: After the threshold hits, we will keep sending a long list
      // every time a new AM is to be scheduled.
      ret = ResourceBlacklistRequest.newInstance(EMPTY_LIST, blacklist);
    }
    return ret;
  }",,
hadoop,6682,"NameNode.stateChangeLog.warn(""DIR* FSDirectory.unprotectedRenameTo: "" + error)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirRenameOp.java/#L585,"private static void validateRenameSource(FSDirectory fsd,
      INodesInPath srcIIP, List<INodeDirectory> snapshottableDirs)
      throws IOException {
    String error;
    final INode srcInode = srcIIP.getLastINode();
    // validate source
    if (srcInode == null) {
      error = ""rename source "" + srcIIP.getPath() + "" is not found."";
      
---------------Reference log start----------------
NameNode.stateChangeLog.warn(""DIR* FSDirectory.unprotectedRenameTo: "" + error)
---------------Reference log end----------------
      throw new FileNotFoundException(error);
    }
    if (srcIIP.length() == 1) {
      error = ""rename source cannot be the root"";
      NameNode.stateChangeLog.warn(""DIR* FSDirectory.unprotectedRenameTo: ""
          + error);
      throw new IOException(error);
    }
    // srcInode and its subtree cannot contain snapshottable directories with
    // snapshots
    FSDirSnapshotOp.checkSnapshot(fsd, srcIIP, snapshottableDirs);
  }",,
hadoop,11299,"LOG.debug(""Start iterating the provided status."")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/Listing.java/#L602,"@Retries.RetryTranslated
    private boolean sourceHasNext() throws IOException {
      if (statusBatchIterator.hasNext() || requestNextBatch()) {
        return true;
      } else {
        // turn to file status that are only in provided list
        if (providedStatusIterator == null) {
          
---------------Reference log start----------------
LOG.debug(""Start iterating the provided status."")
---------------Reference log end----------------
          providedStatusIterator = providedStatus.values().iterator();
        }
        return false;
      }
    }",,
hadoop,6406,"log.error(""Could not set service [{}] programmatically -server shutting down-, {}"", klass, ex)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/lib/server/Server.java/#L765,"public void setService(Class<? extends Service> klass) throws ServerException {
    ensureOperational();
    Check.notNull(klass, ""serviceKlass"");
    if (getStatus() == Status.SHUTTING_DOWN) {
      throw new IllegalStateException(""Server shutting down"");
    }
    try {
      Service newService = klass.newInstance();
      Service oldService = services.get(newService.getInterface());
      if (oldService != null) {
        try {
          oldService.destroy();
        } catch (Throwable ex) {
          log.error(""Could not destroy service [{}], {}"",
                    new Object[]{oldService.getInterface(), ex.getMessage(), ex});
        }
      }
      newService.init(this);
      services.put(newService.getInterface(), newService);
    } catch (Exception ex) {
      
---------------Reference log start----------------
log.error(""Could not set service [{}] programmatically -server shutting down-, {}"", klass, ex)
---------------Reference log end----------------
      destroy();
      throw new ServerException(ServerException.ERROR.S09, klass, ex.getMessage(), ex);
    }
  }",,
hadoop,4518,"LOG.info(String.format(""Localized %s as %s"", resourcePath, path))",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalDistributedCacheManager.java/#L164,"public synchronized void setup(JobConf conf, JobID jobId) throws IOException {
    File workDir = new File(System.getProperty(""user.dir""));
    
    // Generate YARN local resources objects corresponding to the distributed
    // cache configuration
    Map<String, LocalResource> localResources = 
      new LinkedHashMap<String, LocalResource>();
    MRApps.setupDistributedCache(conf, localResources);
    // Generating unique numbers for FSDownload.

    // Find which resources are to be put on the local classpath
    Map<String, Path> classpaths = new HashMap<String, Path>();
    Path[] archiveClassPaths = DistributedCache.getArchiveClassPaths(conf);
    if (archiveClassPaths != null) {
      for (Path p : archiveClassPaths) {
        classpaths.put(p.toUri().getPath().toString(), p);
      }
    }
    Path[] fileClassPaths = DistributedCache.getFileClassPaths(conf);
    if (fileClassPaths != null) {
      for (Path p : fileClassPaths) {
        classpaths.put(p.toUri().getPath().toString(), p);
      }
    }
    
    // Localize the resources
    LocalDirAllocator localDirAllocator =
      new LocalDirAllocator(MRConfig.LOCAL_DIR);
    FileContext localFSFileContext = FileContext.getLocalFSFileContext();
    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();
    
    ExecutorService exec = null;
    try {
      ThreadFactory tf = new ThreadFactoryBuilder()
      .setNameFormat(""LocalDistributedCacheManager Downloader #%d"")
      .build();
      exec = HadoopExecutors.newCachedThreadPool(tf);
      Path destPath = localDirAllocator.getLocalPathForWrite(""."", conf);
      Map<LocalResource, Future<Path>> resourcesToPaths = Maps.newHashMap();
      for (LocalResource resource : localResources.values()) {
        Path destPathForDownload = new Path(destPath,
            jobId.toString() + ""_"" + UUID.randomUUID().toString());
        Callable<Path> download =
            new FSDownload(localFSFileContext, ugi, conf, destPathForDownload,
                resource);
        Future<Path> future = exec.submit(download);
        resourcesToPaths.put(resource, future);
      }
      for (Entry<String, LocalResource> entry : localResources.entrySet()) {
        LocalResource resource = entry.getValue();
        Path path;
        try {
          path = resourcesToPaths.get(resource).get();
        } catch (InterruptedException e) {
          throw new IOException(e);
        } catch (ExecutionException e) {
          throw new IOException(e);
        }
        String pathString = path.toUri().toString();
        String link = entry.getKey();
        String target = new File(path.toUri()).getPath();
        symlink(workDir, target, link);
        
        if (resource.getType() == LocalResourceType.ARCHIVE) {
          localArchives.add(pathString);
        } else if (resource.getType() == LocalResourceType.FILE) {
          localFiles.add(pathString);
        } else if (resource.getType() == LocalResourceType.PATTERN) {
          //PATTERN is not currently used in local mode
          throw new IllegalArgumentException(""Resource type PATTERN is not "" +
          		""implemented yet. "" + resource.getResource());
        }
        Path resourcePath;
        try {
          resourcePath = resource.getResource().toPath();
        } catch (URISyntaxException e) {
          throw new IOException(e);
        }
        
---------------Reference log start----------------
LOG.info(String.format(""Localized %s as %s"", resourcePath, path))
---------------Reference log end----------------
        String cp = resourcePath.toUri().getPath();
        if (classpaths.keySet().contains(cp)) {
          localClasspaths.add(path.toUri().getPath().toString());
        }
      }
    } finally {
      if (exec != null) {
        exec.shutdown();
      }
    }    
    // Update the configuration object with localized data.
    if (!localArchives.isEmpty()) {
      conf.set(MRJobConfig.CACHE_LOCALARCHIVES, StringUtils
          .arrayToString(localArchives.toArray(new String[localArchives
              .size()])));
    }
    if (!localFiles.isEmpty()) {
      conf.set(MRJobConfig.CACHE_LOCALFILES, StringUtils
          .arrayToString(localFiles.toArray(new String[localArchives
              .size()])));
    }
    setupCalled = true;
  }",,
hadoop,7804,"LOG.error(thread + "" terminating on unexpected exception"", t)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BPServiceActor.java/#L1068,"@Override
            public void uncaughtException(Thread thread, Throwable t) {
              
---------------Reference log start----------------
LOG.error(thread + "" terminating on unexpected exception"", t)
---------------Reference log end----------------
            }
            }",,
hadoop,7679,"LOG.info(""Executing \""query plan\"" command."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.java/#L58,"@Override
  public void execute(CommandLine cmd) throws Exception {
    
---------------Reference log start----------------
LOG.info(""Executing \""query plan\"" command."")
---------------Reference log end----------------
    Preconditions.checkState(cmd.hasOption(DiskBalancerCLI.QUERY));
    verifyCommandOptions(DiskBalancerCLI.QUERY, cmd);
    String nodeName = cmd.getOptionValue(DiskBalancerCLI.QUERY);
    Preconditions.checkNotNull(nodeName);
    nodeName = nodeName.trim();
    String nodeAddress = nodeName;

    // if the string is not name:port format use the default port.
    if (!nodeName.matches(""[^\\:]+:[0-9]{2,5}"")) {
      int defaultIPC = NetUtils.createSocketAddr(
          getConf().getTrimmed(DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_KEY,
              DFSConfigKeys.DFS_DATANODE_IPC_ADDRESS_DEFAULT)).getPort();
      nodeAddress = nodeName + "":"" + defaultIPC;
      LOG.debug(""Using default data node port :  {}"", nodeAddress);
    }

    ClientDatanodeProtocol dataNode = getDataNodeProxy(nodeAddress);
    try {
      DiskBalancerWorkStatus workStatus = dataNode.queryDiskBalancerPlan();
      System.out.printf(""Plan File: %s%nPlan ID: %s%nResult: %s%n"",
              workStatus.getPlanFile(),
              workStatus.getPlanID(),
              workStatus.getResult().toString());

      if (cmd.hasOption(DiskBalancerCLI.VERBOSE)) {
        System.out.printf(""%s"", workStatus.currentStateString());
      }
    } catch (DiskBalancerException ex) {
      LOG.error(""Query plan failed. ex: {}"", ex);
      throw ex;
    }
  }",,
hadoop,5108,"LOG.debug(""Added Memory Segment to List. List Size is "" + segmentList.size())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/BackupStore.java/#L514,"void createInMemorySegment () throws IOException {

      // If nothing was written in this block because the record size
      // was greater than the allocated block size, just return.
      if (usedSize == 0) {
        ramManager.unreserve(blockSize);
        return;
      }

      // spaceAvailable would have ensured that there is enough space
      // left for the EOF markers.
      assert ((blockSize - usedSize) >= EOF_MARKER_SIZE);
  
      WritableUtils.writeVInt(dataOut, IFile.EOF_MARKER);
      WritableUtils.writeVInt(dataOut, IFile.EOF_MARKER);

      usedSize += EOF_MARKER_SIZE;

      ramManager.unreserve(blockSize - usedSize);

      Reader<K, V> reader = 
        new org.apache.hadoop.mapreduce.task.reduce.InMemoryReader<K, V>(null, 
            (org.apache.hadoop.mapred.TaskAttemptID) tid, 
            dataOut.getData(), 0, usedSize, conf);
      Segment<K, V> segment = new Segment<K, V>(reader, false);
      segmentList.add(segment);
      
---------------Reference log start----------------
LOG.debug(""Added Memory Segment to List. List Size is "" + segmentList.size())
---------------Reference log end----------------
    }
    }",,
hadoop,2456,"LOG.debug(""Active scan complete"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/EntityGroupFSTimelineStore.java/#L901,"@Override
    public void run() {
      LOG.debug(""Active scan starting"");
      try {
        int scanned = scanActiveLogs();
        LOG.debug(""Scanned {} active applications"", scanned);
      } catch (Exception e) {
        Throwable t = extract(e);
        if (t instanceof InterruptedException) {
          LOG.info(""File scanner interrupted"");
        } else {
          LOG.error(""Error scanning active files"", t);
        }
      }
      
---------------Reference log start----------------
LOG.debug(""Active scan complete"")
---------------Reference log end----------------
    }
    }",,
hadoop,9864,"LOG.debug(""isNamespaceEnabled is UNKNOWN; fall back and determine through"" + "" getAcl server call"", e)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java/#L319,"public boolean getIsNamespaceEnabled(TracingContext tracingContext)
      throws AzureBlobFileSystemException {
    try {
      return this.isNamespaceEnabled.toBoolean();
    } catch (TrileanConversionException e) {
      
---------------Reference log start----------------
LOG.debug(""isNamespaceEnabled is UNKNOWN; fall back and determine through"" + "" getAcl server call"", e)
---------------Reference log end----------------
    }

    LOG.debug(""Get root ACL status"");
    try (AbfsPerfInfo perfInfo = startTracking(""getIsNamespaceEnabled"",
        ""getAclStatus"")) {
      AbfsRestOperation op = client
          .getAclStatus(AbfsHttpConstants.ROOT_PATH, tracingContext);
      perfInfo.registerResult(op.getResult());
      isNamespaceEnabled = Trilean.getTrilean(true);
      perfInfo.registerSuccess(true);
    } catch (AbfsRestOperationException ex) {
      // Get ACL status is a HEAD request, its response doesn't contain
      // errorCode
      // So can only rely on its status code to determine its account type.
      if (HttpURLConnection.HTTP_BAD_REQUEST != ex.getStatusCode()) {
        throw ex;
      }

      isNamespaceEnabled = Trilean.getTrilean(false);
    }

    return isNamespaceEnabled.toBoolean();
  }",,
hadoop,8640,"LOG.debug(""Adjusting block totals from {}/{} to {}/{}"", blockSafe, blockTotal, blockSafe + deltaSafe, blockTotal + deltaTotal)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManagerSafeMode.java/#L253,"void adjustBlockTotals(int deltaSafe, int deltaTotal) {
    assert namesystem.hasWriteLock();
    if (!isSafeModeTrackingBlocks()) {
      return;
    }

    long newBlockTotal;
    synchronized (this) {
      
---------------Reference log start----------------
LOG.debug(""Adjusting block totals from {}/{} to {}/{}"", blockSafe, blockTotal, blockSafe + deltaSafe, blockTotal + deltaTotal)
---------------Reference log end----------------
      assert blockSafe + deltaSafe >= 0 : ""Can't reduce blockSafe "" +
          blockSafe + "" by "" + deltaSafe + "": would be negative"";
      assert blockTotal + deltaTotal >= 0 : ""Can't reduce blockTotal "" +
          blockTotal + "" by "" + deltaTotal + "": would be negative"";

      blockSafe += deltaSafe;
      newBlockTotal = blockTotal + deltaTotal;
    }
    setBlockTotal(newBlockTotal);
    checkSafeMode();
  }",,
hadoop,3809,"LOG.info(""Update RMDT with sequence number "" + rmDTIdentifier.getSequenceNumber())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/MemoryRMStateStore.java/#L223,"@Override
  protected synchronized void updateRMDelegationTokenState(
      RMDelegationTokenIdentifier rmDTIdentifier, Long renewDate)
      throws Exception {
    removeRMDelegationTokenState(rmDTIdentifier);
    storeOrUpdateRMDT(rmDTIdentifier, renewDate, true);
    
---------------Reference log start----------------
LOG.info(""Update RMDT with sequence number "" + rmDTIdentifier.getSequenceNumber())
---------------Reference log end----------------
  }
  }",,
hadoop,8852,"LOG.debug(""{} blocks are now pending replication"", pendingCount)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.java/#L534,"private void moveBlocksToPending() {
    int blocksProcessed = 0;
    int pendingCount = getPendingCount();
    int yetToBeProcessed = getYetToBeProcessedCount();

    if (pendingCount == 0 && yetToBeProcessed == 0) {
      // There are no blocks to process so just return
      LOG.debug(""There are no pending or blocks yet to be processed"");
      return;
    }

    namesystem.writeLock();
    try {
      long repQueueSize = blockManager.getLowRedundancyBlocksCount();

      LOG.info(""There are {} blocks pending replication and the limit is ""+
          ""{}. A further {} blocks are waiting to be processed. ""+
          ""The replication queue currently has {} blocks"",
          pendingCount, pendingRepLimit, yetToBeProcessed, repQueueSize);

      if (pendingCount >= pendingRepLimit) {
        // Only add more blocks to the replication queue if we don't already
        // have too many pending
        return;
      }

      // Create a ""Block Iterator"" for each node decommissioning or entering
      // maintenance. These iterators will be used ""round robined"" to add blocks
      // to the replication queue and PendingRep
      HashMap<DatanodeDescriptor, Iterator<BlockInfo>>
          iterators = new HashMap<>();
      for (Map.Entry<DatanodeDescriptor, HashMap<BlockInfo, Integer>> e
          : outOfServiceNodeBlocks.entrySet()) {
        iterators.put(e.getKey(), e.getValue().keySet().iterator());
      }

      // Now loop until we fill the pendingRep map with pendingRepLimit blocks
      // or run out of blocks to add.
      Iterator<DatanodeDescriptor> nodeIter =
          Iterables.cycle(iterators.keySet()).iterator();
      while (nodeIter.hasNext()) {
        // Cycle through each node with blocks which still need processed
        DatanodeDescriptor dn = nodeIter.next();
        Iterator<BlockInfo> blockIt = iterators.get(dn);
        while (blockIt.hasNext()) {
          // Process the blocks for the node until we find one that needs
          // replication
          if (blocksProcessed >= blocksPerLock) {
            blocksProcessed = 0;
            namesystem.writeUnlock();
            namesystem.writeLock();
          }
          blocksProcessed++;
          if (nextBlockAddedToPending(blockIt, dn)) {
            // Exit the inner ""block"" loop so an iterator for the next datanode
            // is used for the next block.
            pendingCount++;
            break;
          }
        }
        if (!blockIt.hasNext()) {
          // remove the iterator as there are no blocks left in it
          nodeIter.remove();
        }
        if (pendingCount >= pendingRepLimit) {
          // We have scheduled the limit of blocks for replication, so do
          // not add any more
          break;
        }
      }
    } finally {
      namesystem.writeUnlock();
    }
    
---------------Reference log start----------------
LOG.debug(""{} blocks are now pending replication"", pendingCount)
---------------Reference log end----------------
  }
  }",,
hadoop,8338,"FsDatasetImpl.LOG.debug(""Volume "" + target + "" does not exist or is removed by others."")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeList.java/#L392,"private void removeVolume(FsVolumeImpl target) {
    if (volumes.remove(target)) {
      if (isSameDiskTieringApplied(target)) {
        mountVolumeMap.removeVolume(target);
      }
      if (blockScanner != null) {
        blockScanner.removeVolumeScanner(target);
      }
      try {
        target.setClosed();
      } catch (IOException e) {
        FsDatasetImpl.LOG.warn(
            ""Error occurs when waiting volume to close: "" + target, e);
      }
      target.shutdown();
      volumesBeingRemoved.add(target);
      FsDatasetImpl.LOG.info(""Removed volume: "" + target);
    } else {
      if (FsDatasetImpl.LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
FsDatasetImpl.LOG.debug(""Volume "" + target + "" does not exist or is removed by others."")
---------------Reference log end----------------
      }
    }
  }",,
hadoop,12456,"LOG.debug(""Parsing URL for {}"", jar)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/impl/MetricsConfig.java/#L242,"ClassLoader getPluginLoader() {
    if (pluginLoader != null) {
      return pluginLoader;
    }
    final ClassLoader defaultLoader = getClass().getClassLoader();
    Object purls = super.getProperty(PLUGIN_URLS_KEY);
    if (purls == null) {
      return defaultLoader;
    }
    Iterable<String> jars = SPLITTER.split((String) purls);
    int len = Iterables.size(jars);
    if (len > 0) {
      final URL[] urls = new URL[len];
      try {
        int i = 0;
        for (String jar : jars) {
          
---------------Reference log start----------------
LOG.debug(""Parsing URL for {}"", jar)
---------------Reference log end----------------
          urls[i++] = new URL(jar);
        }
      } catch (Exception e) {
        throw new MetricsConfigException(e);
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using plugin jars: {}"", Iterables.toString(jars));
      }
      pluginLoader = doPrivileged(new PrivilegedAction<ClassLoader>() {
        @Override public ClassLoader run() {
          return new URLClassLoader(urls, defaultLoader);
        }
      });
      return pluginLoader;
    }
    if (parent instanceof MetricsConfig) {
      return ((MetricsConfig) parent).getPluginLoader();
    }
    return defaultLoader;
  }",,
hadoop,9750,"LOG.debug(""upload block finished for {} ms. block {} "", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime), blockId)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/BlockBlobAppendStream.java/#L724,"private void writeBlockRequestInternal(String blockId,
                                         ByteBuffer dataPayload,
                                         boolean bufferPoolBuffer) {
    IOException lastLocalException = null;

    int uploadRetryAttempts = 0;
    while (uploadRetryAttempts < MAX_BLOCK_UPLOAD_RETRIES) {
      try {
        long startTime = System.nanoTime();

        blob.uploadBlock(blockId, accessCondition, new ByteArrayInputStream(
            dataPayload.array()), dataPayload.position(),
            new BlobRequestOptions(), opContext);

        
---------------Reference log start----------------
LOG.debug(""upload block finished for {} ms. block {} "", TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime), blockId)
---------------Reference log end----------------
        break;

      } catch(Exception ioe) {
        LOG.debug(""Encountered exception during uploading block for Blob {}""
            + "" Exception : {}"", key, ioe);
        uploadRetryAttempts++;
        lastLocalException = new AzureException(
            ""Encountered Exception while uploading block: "" + ioe, ioe);
        try {
          Thread.sleep(
              BLOCK_UPLOAD_RETRY_INTERVAL * (uploadRetryAttempts + 1));
        } catch(InterruptedException ie) {
          Thread.currentThread().interrupt();
          break;
        }
      }
    }

    if (bufferPoolBuffer) {
      poolReadyByteBuffers.putBuffer(dataPayload);
    }

    if (uploadRetryAttempts == MAX_BLOCK_UPLOAD_RETRIES) {
      maybeSetFirstError(lastLocalException);
    }
  }",,
hadoop,9494,"LOG.warn(""IOException occurred in lazySeek, retry: {}"", i, e)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-huaweicloud/src/main/java/org/apache/hadoop/fs/obs/OBSInputStream.java/#L405,"private void lazySeek(final long targetPos, final long len)
      throws IOException {
    for (int i = 0; i < SEEK_RETRY_TIME; i++) {
      try {
        // For lazy seek
        seekInStream(targetPos);

        // re-open at specific location if needed
        if (wrappedStream == null) {
          reopen(""read from new offset"", targetPos, len);
        }

        break;
      } catch (IOException e) {
        if (wrappedStream != null) {
          closeStream(""lazySeek() seekInStream has exception "",
              this.contentRangeFinish);
        }
        Throwable cause = e.getCause();
        if (cause instanceof ObsException) {
          ObsException obsException = (ObsException) cause;
          int status = obsException.getResponseCode();
          switch (status) {
          case OBSCommonUtils.UNAUTHORIZED_CODE:
          case OBSCommonUtils.FORBIDDEN_CODE:
          case OBSCommonUtils.NOT_FOUND_CODE:
          case OBSCommonUtils.GONE_CODE:
          case OBSCommonUtils.EOF_CODE:
            throw e;
          default:
            break;
          }
        }

        
---------------Reference log start----------------
LOG.warn(""IOException occurred in lazySeek, retry: {}"", i, e)
---------------Reference log end----------------
        if (i == SEEK_RETRY_TIME - 1) {
          throw e;
        }
        try {
          Thread.sleep(DELAY_TIME);
        } catch (InterruptedException ie) {
          throw e;
        }
      }
    }
  }",,
hadoop,7292,"FSNamesystem.LOG.debug(""Reopening an already-closed file "" + ""for append"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.java/#L449,"@SuppressWarnings(""deprecation"")
  private long applyEditLogOp(FSEditLogOp op, FSDirectory fsDir,
      StartupOption startOpt, int logVersion, long lastInodeId) throws IOException {
    long inodeId = HdfsConstants.GRANDFATHER_INODE_ID;
    if (LOG.isTraceEnabled()) {
      LOG.trace(""replaying edit log: "" + op);
    }
    final boolean toAddRetryCache = fsNamesys.hasRetryCache() && op.hasRpcIds();

    switch (op.opCode) {
    case OP_ADD: {
      AddCloseOp addCloseOp = (AddCloseOp)op;
      final String path =
          renameReservedPathsOnUpgrade(addCloseOp.path, logVersion);
      if (FSNamesystem.LOG.isDebugEnabled()) {
        FSNamesystem.LOG.debug(op.opCode + "": "" + path +
            "" numblocks : "" + addCloseOp.blocks.length +
            "" clientHolder "" + addCloseOp.clientName +
            "" clientMachine "" + addCloseOp.clientMachine);
      }
      // There are 3 cases here:
      // 1. OP_ADD to create a new file
      // 2. OP_ADD to update file blocks
      // 3. OP_ADD to open file for append (old append)

      // See if the file already exists (persistBlocks call)
      INodesInPath iip = fsDir.getINodesInPath(path, DirOp.WRITE);
      INodeFile oldFile = INodeFile.valueOf(iip.getLastINode(), path, true);
      if (oldFile != null && addCloseOp.overwrite) {
        // This is OP_ADD with overwrite
        FSDirDeleteOp.deleteForEditLog(fsDir, iip, addCloseOp.mtime);
        iip = INodesInPath.replace(iip, iip.length() - 1, null);
        oldFile = null;
      }
      INodeFile newFile = oldFile;
      if (oldFile == null) { // this is OP_ADD on a new file (case 1)
        // versions > 0 support per file replication
        // get name and replication
        final short replication = fsNamesys.getBlockManager()
            .adjustReplication(addCloseOp.replication);
        assert addCloseOp.blocks.length == 0;

        // add to the file tree
        inodeId = getAndUpdateLastInodeId(addCloseOp.inodeId, logVersion, lastInodeId);
        newFile = FSDirWriteFileOp.addFileForEditLog(fsDir, inodeId,
            iip.getExistingINodes(), iip.getLastLocalName(),
            addCloseOp.permissions, addCloseOp.aclEntries,
            addCloseOp.xAttrs, replication, addCloseOp.mtime,
            addCloseOp.atime, addCloseOp.blockSize, true,
            addCloseOp.clientName, addCloseOp.clientMachine,
            addCloseOp.storagePolicyId, addCloseOp.erasureCodingPolicyId);
        assert newFile != null;
        iip = INodesInPath.replace(iip, iip.length() - 1, newFile);
        fsNamesys.leaseManager.addLease(addCloseOp.clientName, newFile.getId());

        // add the op into retry cache if necessary
        if (toAddRetryCache) {
          HdfsFileStatus stat =
              FSDirStatAndListingOp.createFileStatusForEditLog(fsDir, iip);
          fsNamesys.addCacheEntryWithPayload(addCloseOp.rpcClientId,
              addCloseOp.rpcCallId, stat);
        }
      } else { // This is OP_ADD on an existing file (old append)
        if (!oldFile.isUnderConstruction()) {
          // This is case 3: a call to append() on an already-closed file.
          if (FSNamesystem.LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
FSNamesystem.LOG.debug(""Reopening an already-closed file "" + ""for append"")
---------------Reference log end----------------
          }
          LocatedBlock lb = FSDirAppendOp.prepareFileForAppend(fsNamesys, iip,
              addCloseOp.clientName, addCloseOp.clientMachine, false, false,
              false);
          // add the op into retry cache if necessary
          if (toAddRetryCache) {
            HdfsFileStatus stat =
                FSDirStatAndListingOp.createFileStatusForEditLog(fsDir, iip);
            fsNamesys.addCacheEntryWithPayload(addCloseOp.rpcClientId,
                addCloseOp.rpcCallId, new LastBlockWithStatus(lb, stat));
          }
        }
      }
      // Fall-through for case 2.
      // Regardless of whether it's a new file or an updated file,
      // update the block list.
      
      // Update the salient file attributes.
      newFile.setAccessTime(addCloseOp.atime, Snapshot.CURRENT_STATE_ID, false);
      newFile.setModificationTime(addCloseOp.mtime, Snapshot.CURRENT_STATE_ID);
      ErasureCodingPolicy ecPolicy =
          FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(
              fsDir.getFSNamesystem(), iip);
      updateBlocks(fsDir, addCloseOp, iip, newFile, ecPolicy);
      break;
    }
    case OP_CLOSE: {
      AddCloseOp addCloseOp = (AddCloseOp)op;
      final String path =
          renameReservedPathsOnUpgrade(addCloseOp.path, logVersion);
      if (FSNamesystem.LOG.isDebugEnabled()) {
        FSNamesystem.LOG.debug(op.opCode + "": "" + path +
            "" numblocks : "" + addCloseOp.blocks.length +
            "" clientHolder "" + addCloseOp.clientName +
            "" clientMachine "" + addCloseOp.clientMachine);
      }

      final INodesInPath iip = fsDir.getINodesInPath(path, DirOp.READ);
      final INodeFile file = INodeFile.valueOf(iip.getLastINode(), path);

      // Update the salient file attributes.
      file.setAccessTime(addCloseOp.atime, Snapshot.CURRENT_STATE_ID, false);
      file.setModificationTime(addCloseOp.mtime, Snapshot.CURRENT_STATE_ID);
      ErasureCodingPolicy ecPolicy =
          FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(
              fsDir.getFSNamesystem(), iip);
      updateBlocks(fsDir, addCloseOp, iip, file, ecPolicy);

      // Now close the file
      if (!file.isUnderConstruction() &&
          logVersion <= LayoutVersion.BUGFIX_HDFS_2991_VERSION) {
        // There was a bug (HDFS-2991) in hadoop < 0.23.1 where OP_CLOSE
        // could show up twice in a row. But after that version, this
        // should be fixed, so we should treat it as an error.
        throw new IOException(
            ""File is not under construction: "" + path);
      }
      // One might expect that you could use removeLease(holder, path) here,
      // but OP_CLOSE doesn't serialize the holder. So, remove the inode.
      if (file.isUnderConstruction()) {
        fsNamesys.getLeaseManager().removeLease(file.getId());
        file.toCompleteFile(file.getModificationTime(), 0,
            fsNamesys.getBlockManager().getMinReplication());
      }
      break;
    }
    case OP_APPEND: {
      AppendOp appendOp = (AppendOp) op;
      final String path = renameReservedPathsOnUpgrade(appendOp.path,
          logVersion);
      if (FSNamesystem.LOG.isDebugEnabled()) {
        FSNamesystem.LOG.debug(op.opCode + "": "" + path +
            "" clientName "" + appendOp.clientName +
            "" clientMachine "" + appendOp.clientMachine +
            "" newBlock "" + appendOp.newBlock);
      }
      INodesInPath iip = fsDir.getINodesInPath(path, DirOp.WRITE);
      INodeFile file = INodeFile.valueOf(iip.getLastINode(), path);
      if (!file.isUnderConstruction()) {
        LocatedBlock lb = FSDirAppendOp.prepareFileForAppend(fsNamesys, iip,
            appendOp.clientName, appendOp.clientMachine, appendOp.newBlock,
            false, false);
        // add the op into retry cache if necessary
        if (toAddRetryCache) {
          HdfsFileStatus stat =
              FSDirStatAndListingOp.createFileStatusForEditLog(fsDir, iip);
          fsNamesys.addCacheEntryWithPayload(appendOp.rpcClientId,
              appendOp.rpcCallId, new LastBlockWithStatus(lb, stat));
        }
      }
      break;
    }
    case OP_UPDATE_BLOCKS: {
      UpdateBlocksOp updateOp = (UpdateBlocksOp)op;
      final String path =
          renameReservedPathsOnUpgrade(updateOp.path, logVersion);
      if (FSNamesystem.LOG.isDebugEnabled()) {
        FSNamesystem.LOG.debug(op.opCode + "": "" + path +
            "" numblocks : "" + updateOp.blocks.length);
      }
      INodesInPath iip = fsDir.getINodesInPath(path, DirOp.READ);
      INodeFile oldFile = INodeFile.valueOf(iip.getLastINode(), path);
      // Update in-memory data structures
      ErasureCodingPolicy ecPolicy =
          FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(
              fsDir.getFSNamesystem(), iip);
      updateBlocks(fsDir, updateOp, iip, oldFile, ecPolicy);

      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(updateOp.rpcClientId, updateOp.rpcCallId);
      }
      break;
    }
    case OP_ADD_BLOCK: {
      AddBlockOp addBlockOp = (AddBlockOp) op;
      String path = renameReservedPathsOnUpgrade(addBlockOp.getPath(), logVersion);
      if (FSNamesystem.LOG.isDebugEnabled()) {
        FSNamesystem.LOG.debug(op.opCode + "": "" + path +
            "" new block id : "" + addBlockOp.getLastBlock().getBlockId());
      }
      INodesInPath iip = fsDir.getINodesInPath(path, DirOp.READ);
      INodeFile oldFile = INodeFile.valueOf(iip.getLastINode(), path);
      // add the new block to the INodeFile
      ErasureCodingPolicy ecPolicy =
          FSDirErasureCodingOp.unprotectedGetErasureCodingPolicy(
              fsDir.getFSNamesystem(), iip);
      addNewBlock(addBlockOp, oldFile, ecPolicy);
      break;
    }
    case OP_SET_REPLICATION: {
      SetReplicationOp setReplicationOp = (SetReplicationOp)op;
      String src = renameReservedPathsOnUpgrade(
          setReplicationOp.path, logVersion);
      INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE);
      short replication = fsNamesys.getBlockManager().adjustReplication(
          setReplicationOp.replication);
      FSDirAttrOp.unprotectedSetReplication(fsDir, iip, replication);
      break;
    }
    case OP_CONCAT_DELETE: {
      ConcatDeleteOp concatDeleteOp = (ConcatDeleteOp)op;
      String trg = renameReservedPathsOnUpgrade(concatDeleteOp.trg, logVersion);
      String[] srcs = new String[concatDeleteOp.srcs.length];
      for (int i=0; i<srcs.length; i++) {
        srcs[i] =
            renameReservedPathsOnUpgrade(concatDeleteOp.srcs[i], logVersion);
      }
      INodesInPath targetIIP = fsDir.getINodesInPath(trg, DirOp.WRITE);
      INodeFile[] srcFiles = new INodeFile[srcs.length];
      for (int i = 0; i < srcs.length; i++) {
        INodesInPath srcIIP = fsDir.getINodesInPath(srcs[i], DirOp.WRITE);
        srcFiles[i] = srcIIP.getLastINode().asFile();
      }
      FSDirConcatOp.unprotectedConcat(fsDir, targetIIP, srcFiles,
          concatDeleteOp.timestamp);
      
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(concatDeleteOp.rpcClientId,
            concatDeleteOp.rpcCallId);
      }
      break;
    }
    case OP_RENAME_OLD: {
      RenameOldOp renameOp = (RenameOldOp)op;
      final String src = renameReservedPathsOnUpgrade(renameOp.src, logVersion);
      final String dst = renameReservedPathsOnUpgrade(renameOp.dst, logVersion);
      FSDirRenameOp.renameForEditLog(fsDir, src, dst, renameOp.timestamp);
      
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(renameOp.rpcClientId, renameOp.rpcCallId);
      }
      break;
    }
    case OP_DELETE: {
      DeleteOp deleteOp = (DeleteOp)op;
      final String src = renameReservedPathsOnUpgrade(
          deleteOp.path, logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE_LINK);
      FSDirDeleteOp.deleteForEditLog(fsDir, iip, deleteOp.timestamp);

      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(deleteOp.rpcClientId, deleteOp.rpcCallId);
      }
      break;
    }
    case OP_MKDIR: {
      MkdirOp mkdirOp = (MkdirOp)op;
      inodeId = getAndUpdateLastInodeId(mkdirOp.inodeId, logVersion,
          lastInodeId);
      FSDirMkdirOp.mkdirForEditLog(fsDir, inodeId,
          renameReservedPathsOnUpgrade(mkdirOp.path, logVersion),
          mkdirOp.permissions, mkdirOp.aclEntries, mkdirOp.timestamp);
      break;
    }
    case OP_SET_GENSTAMP_V1: {
      SetGenstampV1Op setGenstampV1Op = (SetGenstampV1Op)op;
      blockManager.getBlockIdManager().setLegacyGenerationStamp(
          setGenstampV1Op.genStampV1);
      break;
    }
    case OP_SET_PERMISSIONS: {
      SetPermissionsOp setPermissionsOp = (SetPermissionsOp)op;
      final String src =
          renameReservedPathsOnUpgrade(setPermissionsOp.src, logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE);
      FSDirAttrOp.unprotectedSetPermission(fsDir, iip,
          setPermissionsOp.permissions);
      break;
    }
    case OP_SET_OWNER: {
      SetOwnerOp setOwnerOp = (SetOwnerOp)op;
      final String src = renameReservedPathsOnUpgrade(
          setOwnerOp.src, logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE);
      FSDirAttrOp.unprotectedSetOwner(fsDir, iip,
          setOwnerOp.username, setOwnerOp.groupname);
      break;
    }
    case OP_SET_NS_QUOTA: {
      SetNSQuotaOp setNSQuotaOp = (SetNSQuotaOp)op;
      final String src = renameReservedPathsOnUpgrade(
          setNSQuotaOp.src, logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE);
      FSDirAttrOp.unprotectedSetQuota(fsDir, iip,
          setNSQuotaOp.nsQuota, HdfsConstants.QUOTA_DONT_SET, null);
      break;
    }
    case OP_CLEAR_NS_QUOTA: {
      ClearNSQuotaOp clearNSQuotaOp = (ClearNSQuotaOp)op;
      final String src = renameReservedPathsOnUpgrade(
          clearNSQuotaOp.src, logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE);
      FSDirAttrOp.unprotectedSetQuota(fsDir, iip,
          HdfsConstants.QUOTA_RESET, HdfsConstants.QUOTA_DONT_SET, null);
      break;
    }
    case OP_SET_QUOTA: {
      SetQuotaOp setQuotaOp = (SetQuotaOp) op;
      final String src = renameReservedPathsOnUpgrade(
          setQuotaOp.src, logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE);
      FSDirAttrOp.unprotectedSetQuota(fsDir, iip,
          setQuotaOp.nsQuota, setQuotaOp.dsQuota, null);
      break;
    }
    case OP_SET_QUOTA_BY_STORAGETYPE: {
      FSEditLogOp.SetQuotaByStorageTypeOp setQuotaByStorageTypeOp =
          (FSEditLogOp.SetQuotaByStorageTypeOp) op;
      final String src = renameReservedPathsOnUpgrade(
          setQuotaByStorageTypeOp.src, logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE);
      FSDirAttrOp.unprotectedSetQuota(fsDir, iip,
          HdfsConstants.QUOTA_DONT_SET, setQuotaByStorageTypeOp.dsQuota,
          setQuotaByStorageTypeOp.type);
      break;
    }
    case OP_TIMES: {
      TimesOp timesOp = (TimesOp)op;
      final String src = renameReservedPathsOnUpgrade(
          timesOp.path, logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(src, DirOp.WRITE);
      FSDirAttrOp.unprotectedSetTimes(fsDir, iip,
          timesOp.mtime, timesOp.atime, true);
      break;
    }
    case OP_SYMLINK: {
      if (!FileSystem.areSymlinksEnabled()) {
        throw new IOException(""Symlinks not supported - please remove symlink before upgrading to this version of HDFS"");
      }
      SymlinkOp symlinkOp = (SymlinkOp)op;
      inodeId = getAndUpdateLastInodeId(symlinkOp.inodeId, logVersion,
          lastInodeId);
      final String path = renameReservedPathsOnUpgrade(symlinkOp.path,
          logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(path, DirOp.WRITE_LINK);
      FSDirSymlinkOp.unprotectedAddSymlink(fsDir, iip.getExistingINodes(),
          iip.getLastLocalName(), inodeId, symlinkOp.value, symlinkOp.mtime,
          symlinkOp.atime, symlinkOp.permissionStatus);
      
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(symlinkOp.rpcClientId, symlinkOp.rpcCallId);
      }
      break;
    }
    case OP_RENAME: {
      RenameOp renameOp = (RenameOp)op;
      FSDirRenameOp.renameForEditLog(fsDir,
          renameReservedPathsOnUpgrade(renameOp.src, logVersion),
          renameReservedPathsOnUpgrade(renameOp.dst, logVersion),
          renameOp.timestamp, renameOp.options);
      
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(renameOp.rpcClientId, renameOp.rpcCallId);
      }
      break;
    }
    case OP_GET_DELEGATION_TOKEN: {
      GetDelegationTokenOp getDelegationTokenOp
        = (GetDelegationTokenOp)op;

      fsNamesys.getDelegationTokenSecretManager()
        .addPersistedDelegationToken(getDelegationTokenOp.token,
                                     getDelegationTokenOp.expiryTime);
      break;
    }
    case OP_RENEW_DELEGATION_TOKEN: {
      RenewDelegationTokenOp renewDelegationTokenOp
        = (RenewDelegationTokenOp)op;
      fsNamesys.getDelegationTokenSecretManager()
        .updatePersistedTokenRenewal(renewDelegationTokenOp.token,
                                     renewDelegationTokenOp.expiryTime);
      break;
    }
    case OP_CANCEL_DELEGATION_TOKEN: {
      CancelDelegationTokenOp cancelDelegationTokenOp
        = (CancelDelegationTokenOp)op;
      fsNamesys.getDelegationTokenSecretManager()
          .updatePersistedTokenCancellation(
              cancelDelegationTokenOp.token);
      break;
    }
    case OP_UPDATE_MASTER_KEY: {
      UpdateMasterKeyOp updateMasterKeyOp = (UpdateMasterKeyOp)op;
      fsNamesys.getDelegationTokenSecretManager()
        .updatePersistedMasterKey(updateMasterKeyOp.key);
      break;
    }
    case OP_REASSIGN_LEASE: {
      ReassignLeaseOp reassignLeaseOp = (ReassignLeaseOp)op;

      Lease lease = fsNamesys.leaseManager.getLease(
          reassignLeaseOp.leaseHolder);
      final String path =
          renameReservedPathsOnUpgrade(reassignLeaseOp.path, logVersion);
      INodeFile pendingFile = fsDir.getINode(path, DirOp.READ).asFile();
      Preconditions.checkState(pendingFile.isUnderConstruction());
      fsNamesys.reassignLeaseInternal(lease, reassignLeaseOp.newHolder,
              pendingFile);
      break;
    }
    case OP_START_LOG_SEGMENT:
    case OP_END_LOG_SEGMENT: {
      // no data in here currently.
      break;
    }
    case OP_CREATE_SNAPSHOT: {
      CreateSnapshotOp createSnapshotOp = (CreateSnapshotOp) op;
      final String snapshotRoot =
          renameReservedPathsOnUpgrade(createSnapshotOp.snapshotRoot,
              logVersion);
      INodesInPath iip = fsDir.unprotectedResolvePath(snapshotRoot);
      String path = fsNamesys.getSnapshotManager().createSnapshot(
          fsDir.getFSNamesystem().getLeaseManager(),
          iip, snapshotRoot, createSnapshotOp.snapshotName,
          createSnapshotOp.mtime);
      if (toAddRetryCache) {
        fsNamesys.addCacheEntryWithPayload(createSnapshotOp.rpcClientId,
            createSnapshotOp.rpcCallId, path);
      }
      break;
    }
    case OP_DELETE_SNAPSHOT: {
      DeleteSnapshotOp deleteSnapshotOp = (DeleteSnapshotOp) op;
      BlocksMapUpdateInfo collectedBlocks = new BlocksMapUpdateInfo();
      List<INode> removedINodes = new ChunkedArrayList<INode>();
      final String snapshotRoot =
          renameReservedPathsOnUpgrade(deleteSnapshotOp.snapshotRoot,
              logVersion);
      INodesInPath iip = fsDir.unprotectedResolvePath(snapshotRoot);
      fsNamesys.getSnapshotManager().deleteSnapshot(iip,
          deleteSnapshotOp.snapshotName,
          new INode.ReclaimContext(fsNamesys.dir.getBlockStoragePolicySuite(),
              collectedBlocks, removedINodes, null), deleteSnapshotOp.mtime);
      fsNamesys.getBlockManager().removeBlocksAndUpdateSafemodeTotal(
          collectedBlocks);
      collectedBlocks.clear();
      fsNamesys.dir.removeFromInodeMap(removedINodes);
      removedINodes.clear();

      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(deleteSnapshotOp.rpcClientId,
            deleteSnapshotOp.rpcCallId);
      }
      break;
    }
    case OP_RENAME_SNAPSHOT: {
      RenameSnapshotOp renameSnapshotOp = (RenameSnapshotOp) op;
      final String snapshotRoot =
          renameReservedPathsOnUpgrade(renameSnapshotOp.snapshotRoot,
              logVersion);
      INodesInPath iip = fsDir.unprotectedResolvePath(snapshotRoot);
      fsNamesys.getSnapshotManager().renameSnapshot(iip,
          snapshotRoot, renameSnapshotOp.snapshotOldName,
          renameSnapshotOp.snapshotNewName, renameSnapshotOp.mtime);
      
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(renameSnapshotOp.rpcClientId,
            renameSnapshotOp.rpcCallId);
      }
      break;
    }
    case OP_ALLOW_SNAPSHOT: {
      AllowSnapshotOp allowSnapshotOp = (AllowSnapshotOp) op;
      final String snapshotRoot =
          renameReservedPathsOnUpgrade(allowSnapshotOp.snapshotRoot, logVersion);
      fsNamesys.getSnapshotManager().setSnapshottable(
          snapshotRoot, false);
      break;
    }
    case OP_DISALLOW_SNAPSHOT: {
      DisallowSnapshotOp disallowSnapshotOp = (DisallowSnapshotOp) op;
      final String snapshotRoot =
          renameReservedPathsOnUpgrade(disallowSnapshotOp.snapshotRoot,
              logVersion);
      fsNamesys.getSnapshotManager().resetSnapshottable(
          snapshotRoot);
      break;
    }
    case OP_SET_GENSTAMP_V2: {
      SetGenstampV2Op setGenstampV2Op = (SetGenstampV2Op) op;
      // update the impending gen stamp, but not the actual genstamp,
      // see HDFS-14941
      blockManager.getBlockIdManager()
          .setImpendingGenerationStamp(setGenstampV2Op.genStampV2);
      break;
    }
    case OP_ALLOCATE_BLOCK_ID: {
      AllocateBlockIdOp allocateBlockIdOp = (AllocateBlockIdOp) op;
      if (BlockIdManager.isStripedBlockID(allocateBlockIdOp.blockId)) {
        // ALLOCATE_BLOCK_ID is added for sequential block id, thus if the id
        // is negative, it must belong to striped blocks
        blockManager.getBlockIdManager().setLastAllocatedStripedBlockId(
            allocateBlockIdOp.blockId);
      } else {
        blockManager.getBlockIdManager().setLastAllocatedContiguousBlockId(
            allocateBlockIdOp.blockId);
      }
      break;
    }
    case OP_ROLLING_UPGRADE_START: {
      if (startOpt == StartupOption.ROLLINGUPGRADE) {
        final RollingUpgradeStartupOption rollingUpgradeOpt
            = startOpt.getRollingUpgradeStartupOption(); 
        if (rollingUpgradeOpt == RollingUpgradeStartupOption.ROLLBACK) {
          throw new RollingUpgradeOp.RollbackException();
        }
      }
      // start rolling upgrade
      final long startTime = ((RollingUpgradeOp) op).getTime();
      fsNamesys.startRollingUpgradeInternal(startTime);
      fsNamesys.triggerRollbackCheckpoint();
      break;
    }
    case OP_ROLLING_UPGRADE_FINALIZE: {
      final long finalizeTime = ((RollingUpgradeOp) op).getTime();
      if (fsNamesys.isRollingUpgrade()) {
        // Only do it when NN is actually doing rolling upgrade.
        // We can get FINALIZE without corresponding START, if NN is restarted
        // before this op is consumed and a new checkpoint is created.
        fsNamesys.finalizeRollingUpgradeInternal(finalizeTime);
      }
      fsNamesys.getFSImage().updateStorageVersion();
      fsNamesys.getFSImage().renameCheckpoint(NameNodeFile.IMAGE_ROLLBACK,
          NameNodeFile.IMAGE);
      break;
    }
    case OP_ADD_CACHE_DIRECTIVE: {
      AddCacheDirectiveInfoOp addOp = (AddCacheDirectiveInfoOp) op;
      CacheDirectiveInfo result = fsNamesys.
          getCacheManager().addDirectiveFromEditLog(addOp.directive);
      if (toAddRetryCache) {
        Long id = result.getId();
        fsNamesys.addCacheEntryWithPayload(op.rpcClientId, op.rpcCallId, id);
      }
      break;
    }
    case OP_MODIFY_CACHE_DIRECTIVE: {
      ModifyCacheDirectiveInfoOp modifyOp =
          (ModifyCacheDirectiveInfoOp) op;
      fsNamesys.getCacheManager().modifyDirectiveFromEditLog(
          modifyOp.directive);
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(op.rpcClientId, op.rpcCallId);
      }
      break;
    }
    case OP_REMOVE_CACHE_DIRECTIVE: {
      RemoveCacheDirectiveInfoOp removeOp =
          (RemoveCacheDirectiveInfoOp) op;
      fsNamesys.getCacheManager().removeDirective(removeOp.id, null);
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(op.rpcClientId, op.rpcCallId);
      }
      break;
    }
    case OP_ADD_CACHE_POOL: {
      AddCachePoolOp addOp = (AddCachePoolOp) op;
      fsNamesys.getCacheManager().addCachePool(addOp.info);
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(op.rpcClientId, op.rpcCallId);
      }
      break;
    }
    case OP_MODIFY_CACHE_POOL: {
      ModifyCachePoolOp modifyOp = (ModifyCachePoolOp) op;
      fsNamesys.getCacheManager().modifyCachePool(modifyOp.info);
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(op.rpcClientId, op.rpcCallId);
      }
      break;
    }
    case OP_REMOVE_CACHE_POOL: {
      RemoveCachePoolOp removeOp = (RemoveCachePoolOp) op;
      fsNamesys.getCacheManager().removeCachePool(removeOp.poolName);
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(op.rpcClientId, op.rpcCallId);
      }
      break;
    }
    case OP_SET_ACL: {
      SetAclOp setAclOp = (SetAclOp) op;
      INodesInPath iip = fsDir.getINodesInPath(setAclOp.src, DirOp.WRITE);
      FSDirAclOp.unprotectedSetAcl(fsDir, iip, setAclOp.aclEntries, true);
      break;
    }
    case OP_SET_XATTR: {
      SetXAttrOp setXAttrOp = (SetXAttrOp) op;
      INodesInPath iip = fsDir.getINodesInPath(setXAttrOp.src, DirOp.WRITE);
      FSDirXAttrOp.unprotectedSetXAttrs(fsDir, iip,
                                        setXAttrOp.xAttrs,
                                        EnumSet.of(XAttrSetFlag.CREATE,
                                                   XAttrSetFlag.REPLACE));
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(setXAttrOp.rpcClientId, setXAttrOp.rpcCallId);
      }
      break;
    }
    case OP_REMOVE_XATTR: {
      RemoveXAttrOp removeXAttrOp = (RemoveXAttrOp) op;
      INodesInPath iip = fsDir.getINodesInPath(removeXAttrOp.src, DirOp.WRITE);
      FSDirXAttrOp.unprotectedRemoveXAttrs(fsDir, iip,
                                           removeXAttrOp.xAttrs);
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(removeXAttrOp.rpcClientId,
            removeXAttrOp.rpcCallId);
      }
      break;
    }
    case OP_TRUNCATE: {
      TruncateOp truncateOp = (TruncateOp) op;
      INodesInPath iip = fsDir.getINodesInPath(truncateOp.src, DirOp.WRITE);
      FSDirTruncateOp.unprotectedTruncate(fsNamesys, iip,
          truncateOp.clientName, truncateOp.clientMachine,
          truncateOp.newLength, truncateOp.timestamp, truncateOp.truncateBlock);
      break;
    }
    case OP_SET_STORAGE_POLICY: {
      SetStoragePolicyOp setStoragePolicyOp = (SetStoragePolicyOp) op;
      final String path = renameReservedPathsOnUpgrade(setStoragePolicyOp.path,
          logVersion);
      final INodesInPath iip = fsDir.getINodesInPath(path, DirOp.WRITE);
      FSDirAttrOp.unprotectedSetStoragePolicy(
          fsDir, fsNamesys.getBlockManager(), iip,
          setStoragePolicyOp.policyId);
      break;
    }
    case OP_ADD_ERASURE_CODING_POLICY:
      AddErasureCodingPolicyOp addOp = (AddErasureCodingPolicyOp) op;
      fsNamesys.getErasureCodingPolicyManager().addPolicy(
          addOp.getEcPolicy());

      if (toAddRetryCache) {
        fsNamesys.addCacheEntryWithPayload(op.rpcClientId, op.rpcCallId,
            addOp.getEcPolicy());
      }
      break;
    case OP_ENABLE_ERASURE_CODING_POLICY:
      EnableErasureCodingPolicyOp enableOp = (EnableErasureCodingPolicyOp) op;
      fsNamesys.getErasureCodingPolicyManager().enablePolicy(
          enableOp.getEcPolicy());
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(op.rpcClientId, op.rpcCallId);
      }
      break;
    case OP_DISABLE_ERASURE_CODING_POLICY:
      DisableErasureCodingPolicyOp disableOp =
          (DisableErasureCodingPolicyOp) op;
      fsNamesys.getErasureCodingPolicyManager().disablePolicy(
          disableOp.getEcPolicy());
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(op.rpcClientId, op.rpcCallId);
      }
      break;
    case OP_REMOVE_ERASURE_CODING_POLICY:
      RemoveErasureCodingPolicyOp removeOp = (RemoveErasureCodingPolicyOp) op;
      fsNamesys.getErasureCodingPolicyManager().removePolicy(
          removeOp.getEcPolicy());
      if (toAddRetryCache) {
        fsNamesys.addCacheEntry(op.rpcClientId, op.rpcCallId);
      }
      break;
    default:
      throw new IOException(""Invalid operation read "" + op.opCode);
    }
    return inodeId;
  }",,
hadoop,11539,"LOG.debug(""Multiple child entries but entry has data: assume partitioned"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeFileSystemStore.java/#L954,"public boolean delete(Path absolutePath, boolean recursive) throws IOException {
    Path swiftPath = getCorrectSwiftPath(absolutePath);
    SwiftUtils.debug(LOG, ""Deleting path '%s' recursive=%b"",
                     absolutePath,
                     recursive);
    boolean askForNewest = true;
    SwiftFileStatus fileStatus = getObjectMetadata(swiftPath, askForNewest);

    //ask for the file/dir status, but don't demand the newest, as we
    //don't mind if the directory has changed
    //list all entries under this directory.
    //this will throw FileNotFoundException if the file isn't there
    FileStatus[] statuses = listSubPaths(absolutePath, true, askForNewest);
    if (statuses == null) {
      //the directory went away during the non-atomic stages of the operation.
      // Return false as it was not this thread doing the deletion.
      SwiftUtils.debug(LOG, ""Path '%s' has no status -it has 'gone away'"",
                       absolutePath,
                       recursive);
      return false;
    }
    int filecount = statuses.length;
    SwiftUtils.debug(LOG, ""Path '%s' %d status entries'"",
                     absolutePath,
                     filecount);

    if (filecount == 0) {
      //it's an empty directory or a path
      rmdir(absolutePath);
      return true;
    }

    if (LOG.isDebugEnabled()) {
      SwiftUtils.debug(LOG, ""%s"", SwiftUtils.fileStatsToString(statuses, ""\n""));
    }

    if (filecount == 1 && swiftPath.equals(statuses[0].getPath())) {
      // 1 entry => simple file and it is the target
      //simple file: delete it
      SwiftUtils.debug(LOG, ""Deleting simple file %s"", absolutePath);
      deleteObject(absolutePath);
      return true;
    }

    //>1 entry implies directory with children. Run through them,
    // but first check for the recursive flag and reject it *unless it looks
    // like a partitioned file (len > 0 && has children)
    if (!fileStatus.isDirectory()) {
      
---------------Reference log start----------------
LOG.debug(""Multiple child entries but entry has data: assume partitioned"")
---------------Reference log end----------------
    } else if (!recursive) {
      //if there are children, unless this is a recursive operation, fail immediately
      throw new SwiftOperationFailedException(""Directory "" + fileStatus
                                              + "" is not empty: ""
                                              + SwiftUtils.fileStatsToString(
                                                        statuses, ""; ""));
    }

    //delete the entries. including ourselves.
    for (FileStatus entryStatus : statuses) {
      Path entryPath = entryStatus.getPath();
      try {
        boolean deleted = deleteObject(entryPath);
        if (!deleted) {
          SwiftUtils.debug(LOG, ""Failed to delete entry '%s'; continuing"",
                           entryPath);
        }
      } catch (FileNotFoundException e) {
        //the path went away -race conditions.
        //do not fail, as the outcome is still OK.
        SwiftUtils.debug(LOG, ""Path '%s' is no longer present; continuing"",
                         entryPath);
      }
      throttle();
    }
    //now delete self
    SwiftUtils.debug(LOG, ""Deleting base entry %s"", absolutePath);
    deleteObject(absolutePath);

    return true;
  }",,
hadoop,4181,"LOG.error(""Unable to create proxy to the ResourceManager"", ioe.getMessage())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/client/AutoRefreshNoHARMFailoverProxyProvider.java/#L68,"protected T getProxyInternal() {
    try {
      final InetSocketAddress rmAddress = rmProxy.getRMAddress(conf, protocol);
      return rmProxy.getProxy(conf, protocol, rmAddress);
    } catch (IOException ioe) {
      
---------------Reference log start----------------
LOG.error(""Unable to create proxy to the ResourceManager"", ioe.getMessage())
---------------Reference log end----------------
      return null;
    }
  }",,
hadoop,5144,"LOG.warn(""validateSpillIndexFileCB.. could not retrieve indexFile.. "" + ""Path: {}"", path)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/security/SpillCallBackPathsFinder.java/#L154,"@Override
  public void validateSpillIndexFileCB(Path path, Configuration conf) {
    if (path == null) {
      return;
    }
    if (indexSpillFiles.contains(path)) {
      LOG.debug(""validateSpillIndexFileCB.. Path: {}"", path);
      return;
    }
    
---------------Reference log start----------------
LOG.warn(""validateSpillIndexFileCB.. could not retrieve indexFile.. "" + ""Path: {}"", path)
---------------Reference log end----------------
    negativeCache.add(path);
  }",,
hadoop,9131,"LOG.debug(""Failed to get number of live in maintenance nodes"", e.getMessage())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java/#L714,"@Override
  public int getNumInMaintenanceLiveDataNodes() {
    try {
      return getRBFMetrics().getNumInMaintenanceLiveDataNodes();
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.debug(""Failed to get number of live in maintenance nodes"", e.getMessage())
---------------Reference log end----------------
    }
    return 0;
  }",,
hadoop,2030,"LOG.warn(""InterruptedException executing command: "", ie)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/DefaultLinuxContainerRuntime.java/#L234,"@Override
  public IOStreamPair execContainer(ContainerExecContext ctx)
      throws ContainerExecutionException {
    IOStreamPair output;
    try {
      PrivilegedOperation privOp = new PrivilegedOperation(
          PrivilegedOperation.OperationType.EXEC_CONTAINER);
      String commandFile = writeCommandToTempFile(ctx);
      privOp.appendArgs(commandFile);
      privOp.disableFailureLogging();
      output =
          privilegedOperationExecutor.executePrivilegedInteractiveOperation(
              null, privOp);
    } catch (PrivilegedOperationException e) {
      throw new ContainerExecutionException(
          ""Execute container interactive shell failed"", e.getExitCode(),
          e.getOutput(), e.getErrorOutput());
    } catch (InterruptedException ie) {
      
---------------Reference log start----------------
LOG.warn(""InterruptedException executing command: "", ie)
---------------Reference log end----------------
      throw new ContainerExecutionException(ie.getMessage());
    }
    return output;
  }",,
hadoop,13005,"LOG.error(""====== Fencing on target failed, skipping fencing "" + ""on source ======"")",error,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/NodeFencer.java/#L110,"public boolean fence(HAServiceTarget fromSvc, HAServiceTarget toSvc) {
    LOG.info(""====== Beginning Service Fencing Process... ======"");
    int i = 0;
    for (FenceMethodWithArg method : methods) {
      LOG.info(""Trying method "" + (++i) + ""/"" + methods.size() +"": "" + method);
      
      try {
        // only true when target node is given, AND fencing on it failed
        boolean toSvcFencingFailed = false;
        // if target is given, try to fence on target first. Only if fencing
        // on target succeeded, do fencing on source node.
        if (toSvc != null) {
          toSvcFencingFailed = !method.method.tryFence(toSvc, method.arg);
        }
        if (toSvcFencingFailed) {
          
---------------Reference log start----------------
LOG.error(""====== Fencing on target failed, skipping fencing "" + ""on source ======"")
---------------Reference log end----------------
        } else {
          if (method.method.tryFence(fromSvc, method.arg)) {
            LOG.info(""====== Fencing successful by method ""
                + method + "" ======"");
            return true;
          }
        }
      } catch (BadFencingConfigurationException e) {
        LOG.error(""Fencing method "" + method + "" misconfigured"", e);
        continue;
      } catch (Throwable t) {
        LOG.error(""Fencing method "" + method + "" failed with an unexpected error."", t);
        continue;
      }
      LOG.warn(""Fencing method "" + method + "" was unsuccessful."");
    }
    
    LOG.error(""Unable to fence service by any configured method."");
    return false;
  }",,
hadoop,9110,"LOG.debug(""Failed to get number of blocks under replicated"", e.getMessage())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java/#L350,"@Override
  public long getLowRedundancyBlocks() {
    try {
      return getRBFMetrics().getNumOfBlocksUnderReplicated();
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.debug(""Failed to get number of blocks under replicated"", e.getMessage())
---------------Reference log end----------------
    }
    return 0;
  }",,
hadoop,9532,LOG.error(errorMsg),error,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-cos/src/main/java/org/apache/hadoop/fs/cosn/CosNativeFileSystemStore.java/#L358,"private FileMetadata queryObjectMetadata(String key) throws IOException {
    GetObjectMetadataRequest getObjectMetadataRequest =
        new GetObjectMetadataRequest(bucketName, key);
    try {
      ObjectMetadata objectMetadata =
          (ObjectMetadata) callCOSClientWithRetry(getObjectMetadataRequest);
      long mtime = 0;
      if (objectMetadata.getLastModified() != null) {
        mtime = objectMetadata.getLastModified().getTime();
      }
      long fileSize = objectMetadata.getContentLength();
      FileMetadata fileMetadata = new FileMetadata(key, fileSize, mtime,
          !key.endsWith(CosNFileSystem.PATH_DELIMITER));
      LOG.debug(""Retrieve file metadata. COS key: [{}], ETag: [{}], ""
              + ""length: [{}]."", key, objectMetadata.getETag(),
          objectMetadata.getContentLength());
      return fileMetadata;
    } catch (CosServiceException e) {
      if (e.getStatusCode() != HttpStatus.SC_NOT_FOUND) {
        String errorMsg = String.format(""Retrieve file metadata file failed. ""
            + ""COS key: [%s], CosServiceException: [%s]."", key, e.toString());
        
---------------Reference log start----------------
LOG.error(errorMsg)
---------------Reference log end----------------
        handleException(new Exception(errorMsg), key);
      }
    }
    return null;
  }",,
hadoop,7947,"LOG.warn(String.format(""Exception in updating balancer max concurrent movers %s to %s"", property, newVal), rootException)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java/#L598,"@Override
  public String reconfigurePropertyImpl(String property, String newVal)
      throws ReconfigurationException {
    switch (property) {
      case DFS_DATANODE_DATA_DIR_KEY: {
        IOException rootException = null;
        try {
          LOG.info(""Reconfiguring {} to {}"", property, newVal);
          this.refreshVolumes(newVal);
          return getConf().get(DFS_DATANODE_DATA_DIR_KEY);
        } catch (IOException e) {
          rootException = e;
        } finally {
          // Send a full block report to let NN acknowledge the volume changes.
          try {
            triggerBlockReport(
                new BlockReportOptions.Factory().setIncremental(false).build());
          } catch (IOException e) {
            LOG.warn(""Exception while sending the block report after refreshing""
                + "" volumes {} to {}"", property, newVal, e);
            if (rootException == null) {
              rootException = e;
            }
          } finally {
            if (rootException != null) {
              throw new ReconfigurationException(property, newVal,
                  getConf().get(property), rootException);
            }
          }
        }
        break;
      }
      case DFS_DATANODE_BALANCE_MAX_NUM_CONCURRENT_MOVES_KEY: {
        ReconfigurationException rootException = null;
        try {
          LOG.info(""Reconfiguring {} to {}"", property, newVal);
          int movers;
          if (newVal == null) {
            // set to default
            movers = DFS_DATANODE_BALANCE_MAX_NUM_CONCURRENT_MOVES_DEFAULT;
          } else {
            movers = Integer.parseInt(newVal);
            if (movers <= 0) {
              rootException = new ReconfigurationException(
                  property,
                  newVal,
                  getConf().get(property),
                  new IllegalArgumentException(
                      ""balancer max concurrent movers must be larger than 0""));
            }
          }
          boolean success = xserver.updateBalancerMaxConcurrentMovers(movers);
          if (!success) {
            rootException = new ReconfigurationException(
                property,
                newVal,
                getConf().get(property),
                new IllegalArgumentException(
                    ""Could not modify concurrent moves thread count""));
          }
          return Integer.toString(movers);
        } catch (NumberFormatException nfe) {
          rootException = new ReconfigurationException(
              property, newVal, getConf().get(property), nfe);
        } finally {
          if (rootException != null) {
            
---------------Reference log start----------------
LOG.warn(String.format(""Exception in updating balancer max concurrent movers %s to %s"", property, newVal), rootException)
---------------Reference log end----------------
            throw rootException;
          }
        }
        break;
      }
      default:
        break;
    }
    throw new ReconfigurationException(
        property, newVal, getConf().get(property));
  }",,
hadoop,5851,"DFSClient.LOG.info(""Could not obtain "" + block.getBlock() + "" from any node: "" + errMsg + "". Will get new block locations from namenode and retry..."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java/#L1014,"private LocatedBlock refetchLocations(LocatedBlock block,
      Collection<DatanodeInfo> ignoredNodes) throws IOException {
    String errMsg = getBestNodeDNAddrPairErrorString(block.getLocations(),
            dfsClient.getDeadNodes(this), ignoredNodes);
    String blockInfo = block.getBlock() + "" file="" + src;
    if (failures >= dfsClient.getConf().getMaxBlockAcquireFailures()) {
      String description = ""Could not obtain block: "" + blockInfo;
      DFSClient.LOG.warn(description + errMsg
          + "". Throwing a BlockMissingException"");
      throw new BlockMissingException(src, description,
          block.getStartOffset());
    }

    DatanodeInfo[] nodes = block.getLocations();
    if (nodes == null || nodes.length == 0) {
      DFSClient.LOG.info(""No node available for "" + blockInfo);
    }
    
---------------Reference log start----------------
DFSClient.LOG.info(""Could not obtain "" + block.getBlock() + "" from any node: "" + errMsg + "". Will get new block locations from namenode and retry..."")
---------------Reference log end----------------
    try {
      // Introducing a random factor to the wait time before another retry.
      // The wait time is dependent on # of failures and a random factor.
      // At the first time of getting a BlockMissingException, the wait time
      // is a random number between 0..3000 ms. If the first retry
      // still fails, we will wait 3000 ms grace period before the 2nd retry.
      // Also at the second retry, the waiting window is expanded to 6000 ms
      // alleviating the request rate from the server. Similarly the 3rd retry
      // will wait 6000ms grace period before retry and the waiting window is
      // expanded to 9000ms.
      final int timeWindow = dfsClient.getConf().getTimeWindow();
      // grace period for the last round of attempt
      double waitTime = timeWindow * failures +
          // expanding time window for each failure
          timeWindow * (failures + 1) *
          ThreadLocalRandom.current().nextDouble();
      DFSClient.LOG.warn(""DFS chooseDataNode: got # "" + (failures + 1) +
          "" IOException, will wait for "" + waitTime + "" msec."");
      Thread.sleep((long)waitTime);
    } catch (InterruptedException e) {
      Thread.currentThread().interrupt();
      throw new InterruptedIOException(
          ""Interrupted while choosing DataNode for read."");
    }
    clearLocalDeadNodes(); //2nd option is to remove only nodes[blockId]
    openInfo(true);
    block = refreshLocatedBlock(block);
    failures++;
    return block;
  }",,
hadoop,5826,"LOG.info(""Can't close stream for fileId: {}, error: {}"", latestAttr.getFileId(), e.toString())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java/#L1240,"synchronized void cleanup() {
    if (!activeState) {
      LOG.info(""Current OpenFileCtx is already inactive, no need to cleanup."");
      return;
    }
    activeState = false;

    // stop the dump thread
    if (dumpThread != null && dumpThread.isAlive()) {
      dumpThread.interrupt();
      try {
        dumpThread.join(3000);
      } catch (InterruptedException ignored) {
      }
    }
    
    // Close stream
    try {
      if (fos != null) {
        fos.close();
      }
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.info(""Can't close stream for fileId: {}, error: {}"", latestAttr.getFileId(), e.toString())
---------------Reference log end----------------
    }
    
    // Reply error for pending writes
    LOG.info(""There are {} pending writes."", pendingWrites.size());
    WccAttr preOpAttr = latestAttr.getWccAttr();
    while (!pendingWrites.isEmpty()) {
      OffsetRange key = pendingWrites.firstKey();
      LOG.info(""Fail pending write: {}, nextOffset={}"", key, nextOffset.get());
      
      WriteCtx writeCtx = pendingWrites.remove(key);
      if (!writeCtx.getReplied()) {
        WccData fileWcc = new WccData(preOpAttr, latestAttr);
        WRITE3Response response = new WRITE3Response(Nfs3Status.NFS3ERR_IO,
            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);
        Nfs3Utils.writeChannel(writeCtx.getChannel(), response
            .serialize(new XDR(), writeCtx.getXid(),
                new VerifierNone()), writeCtx.getXid());
      }
    }
    
    // Cleanup dump file
    if (dumpOut != null) {
      try {
        dumpOut.close();
      } catch (IOException e) {
        LOG.error(""Failed to close outputstream of dump file {}"",
            dumpFilePath, e);
      }
      File dumpFile = new File(dumpFilePath);
      if (dumpFile.exists() && !dumpFile.delete()) {
        LOG.error(""Failed to delete dumpfile: {}"", dumpFile);
      }
    }
    if (raf != null) {
      try {
        raf.close();
      } catch (IOException e) {
        LOG.error(""Got exception when closing input stream of dump file."", e);
      }
    }
  }",,
hadoop,10075,"LOG.debug(""Creating "" + nextSegment + "" for a job with a submit time of "" + job.getSubmitTime())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/Folder.java/#L336,"public int run() throws IOException {
    class JobEntryComparator implements
        Comparator<Pair<LoggedJob, JobTraceReader>> {
      public int compare(Pair<LoggedJob, JobTraceReader> p1,
          Pair<LoggedJob, JobTraceReader> p2) {
        LoggedJob j1 = p1.first();
        LoggedJob j2 = p2.first();

        return (j1.getSubmitTime() < j2.getSubmitTime()) ? -1 : (j1
            .getSubmitTime() == j2.getSubmitTime()) ? 0 : 1;
      }
    }

    // we initialize an empty heap so if we take an error before establishing
    // a real one the finally code goes through
    Queue<Pair<LoggedJob, JobTraceReader>> heap =
        new PriorityQueue<Pair<LoggedJob, JobTraceReader>>();

    try {
      LoggedJob job = reader.nextJob();

      if (job == null) {
        LOG.error(""The job trace is empty"");

        return EMPTY_JOB_TRACE;
      }
      
      // If starts-after time is specified, skip the number of jobs till we reach
      // the starting time limit.
      if (startsAfter > 0) {
        LOG.info(""starts-after time is specified. Initial job submit time : "" 
                 + job.getSubmitTime());

        long approximateTime = job.getSubmitTime() + startsAfter;
        job = reader.nextJob();
        long skippedCount = 0;
        while (job != null && job.getSubmitTime() < approximateTime) {
          job = reader.nextJob();
          skippedCount++;
        }

        LOG.debug(""Considering jobs with submit time greater than "" 
                  + startsAfter + "" ms. Skipped "" + skippedCount + "" jobs."");

        if (job == null) {
          LOG.error(""No more jobs to process in the trace with 'starts-after'""+
                    "" set to "" + startsAfter + ""ms."");
          return EMPTY_JOB_TRACE;
        }
        LOG.info(""The first job has a submit time of "" + job.getSubmitTime());
      }

      firstJobSubmitTime = job.getSubmitTime();
      long lastJobSubmitTime = firstJobSubmitTime;

      int numberJobs = 0;

      long currentIntervalEnd = Long.MIN_VALUE;

      Path nextSegment = null;
      Outputter<LoggedJob> tempGen = null;

      if (debug) {
        LOG.debug(""The first job has a submit time of "" + firstJobSubmitTime);
      }

      final Configuration conf = getConf();

      try {
        // At the top of this loop, skewBuffer has at most
        // skewBufferLength entries.
        while (job != null) {
          final Random tempNameGenerator = new Random();

          lastJobSubmitTime = job.getSubmitTime();

          ++numberJobs;

          if (job.getSubmitTime() >= currentIntervalEnd) {
            if (tempGen != null) {
              tempGen.close();
            }
            
            nextSegment = null;
            for (int i = 0; i < 3 && nextSegment == null; ++i) {
              try {
                nextSegment =
                    new Path(tempDir, ""segment-"" + tempNameGenerator.nextLong()
                        + "".json.gz"");

                if (debug) {
                  LOG.debug(""The next segment name is "" + nextSegment);
                }

                FileSystem fs = nextSegment.getFileSystem(conf);

                try {
                  if (!fs.exists(nextSegment)) {
                    break;
                  }

                  continue;
                } catch (IOException e) {
                  // no code -- file did not already exist
                }
              } catch (IOException e) {
                // no code -- file exists now, or directory bad. We try three
                // times.
              }
            }

            if (nextSegment == null) {
              throw new RuntimeException(""Failed to create a new file!"");
            }
            
            if (debug) {
              
---------------Reference log start----------------
LOG.debug(""Creating "" + nextSegment + "" for a job with a submit time of "" + job.getSubmitTime())
---------------Reference log end----------------
            }

            deletees.add(nextSegment);

            tempPaths.add(nextSegment);

            tempGen = new DefaultOutputter<LoggedJob>();
            tempGen.init(nextSegment, conf);

            long currentIntervalNumber =
                (job.getSubmitTime() - firstJobSubmitTime) / inputCycle;

            currentIntervalEnd =
                firstJobSubmitTime + ((currentIntervalNumber + 1) * inputCycle);
          }

          // the temp files contain UDadjusted times, but each temp file's
          // content is in the same input cycle interval.
          if (tempGen != null) {
            tempGen.output(job);
          }

          job = reader.nextJob();
        }
      } catch (DeskewedJobTraceReader.OutOfOrderException e) {
        return OUT_OF_ORDER_JOBS;
      } finally {
        if (tempGen != null) {
          tempGen.close();
        }
      }

      if (lastJobSubmitTime <= firstJobSubmitTime) {
        LOG.error(""All of your job[s] have the same submit time.""
            + ""  Please just use your input file."");

        return ALL_JOBS_SIMULTANEOUS;
      }

      double submitTimeSpan = lastJobSubmitTime - firstJobSubmitTime;

      LOG.warn(""Your input trace spans ""
          + (lastJobSubmitTime - firstJobSubmitTime) + "" ticks."");

      double foldingRatio =
          submitTimeSpan * (numberJobs + 1) / numberJobs / inputCycle;

      if (debug) {
        LOG.warn(""run: submitTimeSpan = "" + submitTimeSpan + "", numberJobs = ""
            + numberJobs + "", inputCycle = "" + inputCycle);
      }

      if (reader.neededSkewBufferSize() > 0) {
        LOG.warn(""You needed a -skew-buffer-length of ""
            + reader.neededSkewBufferSize() + "" but no more, for this input."");
      }

      double tProbability = timeDilation * concentration / foldingRatio;

      if (debug) {
        LOG.warn(""run: timeDilation = "" + timeDilation + "", concentration = ""
            + concentration + "", foldingRatio = "" + foldingRatio);
        LOG.warn(""The transcription probability is "" + tProbability);
      }

      transcriptionRateInteger = (int) Math.floor(tProbability);
      transcriptionRateFraction = tProbability - Math.floor(tProbability);

      // Now read all the inputs in parallel
      heap =
          new PriorityQueue<Pair<LoggedJob, JobTraceReader>>(tempPaths.size(),
              new JobEntryComparator());

      for (Path tempPath : tempPaths) {
        JobTraceReader thisReader = new JobTraceReader(tempPath, conf);

        closees.add(thisReader);

        LoggedJob streamFirstJob = thisReader.getNext();

        long thisIndex =
            (streamFirstJob.getSubmitTime() - firstJobSubmitTime) / inputCycle;

        if (debug) {
          LOG.debug(""A job with submit time of ""
              + streamFirstJob.getSubmitTime() + "" is in interval # ""
              + thisIndex);
        }

        adjustJobTimes(streamFirstJob);

        if (debug) {
          LOG.debug(""That job's submit time is adjusted to ""
              + streamFirstJob.getSubmitTime());
        }

        heap
            .add(new Pair<LoggedJob, JobTraceReader>(streamFirstJob, thisReader));
      }

      Pair<LoggedJob, JobTraceReader> next = heap.poll();

      while (next != null) {
        maybeOutput(next.first());

        if (debug) {
          LOG.debug(""The most recent job has an adjusted submit time of ""
              + next.first().getSubmitTime());
          LOG.debug("" Its replacement in the heap will come from input engine ""
              + next.second());
        }

        LoggedJob replacement = next.second().getNext();

        if (replacement == null) {
          next.second().close();

          if (debug) {
            LOG.debug(""That input engine is depleted."");
          }
        } else {
          adjustJobTimes(replacement);

          if (debug) {
            LOG.debug(""The replacement has an adjusted submit time of ""
                + replacement.getSubmitTime());
          }

          heap.add(new Pair<LoggedJob, JobTraceReader>(replacement, next
              .second()));
        }

        next = heap.poll();
      }
    } finally {
      IOUtils.cleanupWithLogger(null, reader);
      if (outGen != null) {
        outGen.close();
      }
      for (Pair<LoggedJob, JobTraceReader> heapEntry : heap) {
        heapEntry.second().close();
      }
      for (Closeable closee : closees) {
        closee.close();
      }
      if (!debug) {
        Configuration conf = getConf();

        for (Path deletee : deletees) {
          FileSystem fs = deletee.getFileSystem(conf);

          try {
            fs.delete(deletee, false);
          } catch (IOException e) {
            // no code
          }
        }
      }
    }

    return 0;
  }",,
hadoop,2855,"LOG.info(""Update max queue length of app activities from {} to {}"" + "" when multi-node placement enabled."", appActivitiesMaxQueueLength, configuredAppActivitiesMaxQueueLength)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/activities/ActivitiesManager.java/#L291,"private void dynamicallyUpdateAppActivitiesMaxQueueLengthIfNeeded() {
    if (rmContext.getRMNodes() == null) {
      return;
    }
    if (rmContext.getScheduler() instanceof CapacityScheduler) {
      CapacityScheduler cs = (CapacityScheduler) rmContext.getScheduler();
      if (!cs.isMultiNodePlacementEnabled()) {
        int numNodes = rmContext.getRMNodes().size();
        int newAppActivitiesMaxQueueLength;
        int numAsyncSchedulerThreads = cs.getNumAsyncSchedulerThreads();
        if (numAsyncSchedulerThreads > 0) {
          newAppActivitiesMaxQueueLength =
              Math.max(configuredAppActivitiesMaxQueueLength,
                  numNodes * numAsyncSchedulerThreads);
        } else {
          newAppActivitiesMaxQueueLength =
              Math.max(configuredAppActivitiesMaxQueueLength,
                  (int) (numNodes * 1.2));
        }
        if (appActivitiesMaxQueueLength != newAppActivitiesMaxQueueLength) {
          LOG.info(""Update max queue length of app activities from {} to {},""
                  + "" configured={}, numNodes={}, numAsyncSchedulerThreads={}""
                  + "" when multi-node placement disabled."",
              appActivitiesMaxQueueLength, newAppActivitiesMaxQueueLength,
              configuredAppActivitiesMaxQueueLength, numNodes,
              numAsyncSchedulerThreads);
          appActivitiesMaxQueueLength = newAppActivitiesMaxQueueLength;
        }
      } else if (appActivitiesMaxQueueLength
          != configuredAppActivitiesMaxQueueLength) {
        
---------------Reference log start----------------
LOG.info(""Update max queue length of app activities from {} to {}"" + "" when multi-node placement enabled."", appActivitiesMaxQueueLength, configuredAppActivitiesMaxQueueLength)
---------------Reference log end----------------
        appActivitiesMaxQueueLength = configuredAppActivitiesMaxQueueLength;
      }
    }
  }",,
hadoop,10068,"LOG.error(""The job trace is empty"")",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/Folder.java/#L242,"public int run() throws IOException {
    class JobEntryComparator implements
        Comparator<Pair<LoggedJob, JobTraceReader>> {
      public int compare(Pair<LoggedJob, JobTraceReader> p1,
          Pair<LoggedJob, JobTraceReader> p2) {
        LoggedJob j1 = p1.first();
        LoggedJob j2 = p2.first();

        return (j1.getSubmitTime() < j2.getSubmitTime()) ? -1 : (j1
            .getSubmitTime() == j2.getSubmitTime()) ? 0 : 1;
      }
    }

    // we initialize an empty heap so if we take an error before establishing
    // a real one the finally code goes through
    Queue<Pair<LoggedJob, JobTraceReader>> heap =
        new PriorityQueue<Pair<LoggedJob, JobTraceReader>>();

    try {
      LoggedJob job = reader.nextJob();

      if (job == null) {
        
---------------Reference log start----------------
LOG.error(""The job trace is empty"")
---------------Reference log end----------------

        return EMPTY_JOB_TRACE;
      }
      
      // If starts-after time is specified, skip the number of jobs till we reach
      // the starting time limit.
      if (startsAfter > 0) {
        LOG.info(""starts-after time is specified. Initial job submit time : "" 
                 + job.getSubmitTime());

        long approximateTime = job.getSubmitTime() + startsAfter;
        job = reader.nextJob();
        long skippedCount = 0;
        while (job != null && job.getSubmitTime() < approximateTime) {
          job = reader.nextJob();
          skippedCount++;
        }

        LOG.debug(""Considering jobs with submit time greater than "" 
                  + startsAfter + "" ms. Skipped "" + skippedCount + "" jobs."");

        if (job == null) {
          LOG.error(""No more jobs to process in the trace with 'starts-after'""+
                    "" set to "" + startsAfter + ""ms."");
          return EMPTY_JOB_TRACE;
        }
        LOG.info(""The first job has a submit time of "" + job.getSubmitTime());
      }

      firstJobSubmitTime = job.getSubmitTime();
      long lastJobSubmitTime = firstJobSubmitTime;

      int numberJobs = 0;

      long currentIntervalEnd = Long.MIN_VALUE;

      Path nextSegment = null;
      Outputter<LoggedJob> tempGen = null;

      if (debug) {
        LOG.debug(""The first job has a submit time of "" + firstJobSubmitTime);
      }

      final Configuration conf = getConf();

      try {
        // At the top of this loop, skewBuffer has at most
        // skewBufferLength entries.
        while (job != null) {
          final Random tempNameGenerator = new Random();

          lastJobSubmitTime = job.getSubmitTime();

          ++numberJobs;

          if (job.getSubmitTime() >= currentIntervalEnd) {
            if (tempGen != null) {
              tempGen.close();
            }
            
            nextSegment = null;
            for (int i = 0; i < 3 && nextSegment == null; ++i) {
              try {
                nextSegment =
                    new Path(tempDir, ""segment-"" + tempNameGenerator.nextLong()
                        + "".json.gz"");

                if (debug) {
                  LOG.debug(""The next segment name is "" + nextSegment);
                }

                FileSystem fs = nextSegment.getFileSystem(conf);

                try {
                  if (!fs.exists(nextSegment)) {
                    break;
                  }

                  continue;
                } catch (IOException e) {
                  // no code -- file did not already exist
                }
              } catch (IOException e) {
                // no code -- file exists now, or directory bad. We try three
                // times.
              }
            }

            if (nextSegment == null) {
              throw new RuntimeException(""Failed to create a new file!"");
            }
            
            if (debug) {
              LOG.debug(""Creating "" + nextSegment
                  + "" for a job with a submit time of "" + job.getSubmitTime());
            }

            deletees.add(nextSegment);

            tempPaths.add(nextSegment);

            tempGen = new DefaultOutputter<LoggedJob>();
            tempGen.init(nextSegment, conf);

            long currentIntervalNumber =
                (job.getSubmitTime() - firstJobSubmitTime) / inputCycle;

            currentIntervalEnd =
                firstJobSubmitTime + ((currentIntervalNumber + 1) * inputCycle);
          }

          // the temp files contain UDadjusted times, but each temp file's
          // content is in the same input cycle interval.
          if (tempGen != null) {
            tempGen.output(job);
          }

          job = reader.nextJob();
        }
      } catch (DeskewedJobTraceReader.OutOfOrderException e) {
        return OUT_OF_ORDER_JOBS;
      } finally {
        if (tempGen != null) {
          tempGen.close();
        }
      }

      if (lastJobSubmitTime <= firstJobSubmitTime) {
        LOG.error(""All of your job[s] have the same submit time.""
            + ""  Please just use your input file."");

        return ALL_JOBS_SIMULTANEOUS;
      }

      double submitTimeSpan = lastJobSubmitTime - firstJobSubmitTime;

      LOG.warn(""Your input trace spans ""
          + (lastJobSubmitTime - firstJobSubmitTime) + "" ticks."");

      double foldingRatio =
          submitTimeSpan * (numberJobs + 1) / numberJobs / inputCycle;

      if (debug) {
        LOG.warn(""run: submitTimeSpan = "" + submitTimeSpan + "", numberJobs = ""
            + numberJobs + "", inputCycle = "" + inputCycle);
      }

      if (reader.neededSkewBufferSize() > 0) {
        LOG.warn(""You needed a -skew-buffer-length of ""
            + reader.neededSkewBufferSize() + "" but no more, for this input."");
      }

      double tProbability = timeDilation * concentration / foldingRatio;

      if (debug) {
        LOG.warn(""run: timeDilation = "" + timeDilation + "", concentration = ""
            + concentration + "", foldingRatio = "" + foldingRatio);
        LOG.warn(""The transcription probability is "" + tProbability);
      }

      transcriptionRateInteger = (int) Math.floor(tProbability);
      transcriptionRateFraction = tProbability - Math.floor(tProbability);

      // Now read all the inputs in parallel
      heap =
          new PriorityQueue<Pair<LoggedJob, JobTraceReader>>(tempPaths.size(),
              new JobEntryComparator());

      for (Path tempPath : tempPaths) {
        JobTraceReader thisReader = new JobTraceReader(tempPath, conf);

        closees.add(thisReader);

        LoggedJob streamFirstJob = thisReader.getNext();

        long thisIndex =
            (streamFirstJob.getSubmitTime() - firstJobSubmitTime) / inputCycle;

        if (debug) {
          LOG.debug(""A job with submit time of ""
              + streamFirstJob.getSubmitTime() + "" is in interval # ""
              + thisIndex);
        }

        adjustJobTimes(streamFirstJob);

        if (debug) {
          LOG.debug(""That job's submit time is adjusted to ""
              + streamFirstJob.getSubmitTime());
        }

        heap
            .add(new Pair<LoggedJob, JobTraceReader>(streamFirstJob, thisReader));
      }

      Pair<LoggedJob, JobTraceReader> next = heap.poll();

      while (next != null) {
        maybeOutput(next.first());

        if (debug) {
          LOG.debug(""The most recent job has an adjusted submit time of ""
              + next.first().getSubmitTime());
          LOG.debug("" Its replacement in the heap will come from input engine ""
              + next.second());
        }

        LoggedJob replacement = next.second().getNext();

        if (replacement == null) {
          next.second().close();

          if (debug) {
            LOG.debug(""That input engine is depleted."");
          }
        } else {
          adjustJobTimes(replacement);

          if (debug) {
            LOG.debug(""The replacement has an adjusted submit time of ""
                + replacement.getSubmitTime());
          }

          heap.add(new Pair<LoggedJob, JobTraceReader>(replacement, next
              .second()));
        }

        next = heap.poll();
      }
    } finally {
      IOUtils.cleanupWithLogger(null, reader);
      if (outGen != null) {
        outGen.close();
      }
      for (Pair<LoggedJob, JobTraceReader> heapEntry : heap) {
        heapEntry.second().close();
      }
      for (Closeable closee : closees) {
        closee.close();
      }
      if (!debug) {
        Configuration conf = getConf();

        for (Path deletee : deletees) {
          FileSystem fs = deletee.getFileSystem(conf);

          try {
            fs.delete(deletee, false);
          } catch (IOException e) {
            // no code
          }
        }
      }
    }

    return 0;
  }",,
hadoop,2365,"LOG.warn(""Ignore the log aggregation status update request "" + ""for the application:"" + appId + "". The cached log aggregation "" + ""status is "" + tracker.getLogAggregationStatus() + ""."")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/logaggregation/tracker/NMLogAggregationStatusTracker.java/#L141,"public void updateLogAggregationStatus(ApplicationId appId,
      LogAggregationStatus logAggregationStatus, long updateTime,
      String diagnosis, boolean finalized) {
    if (disabled) {
      LOG.warn(""The log aggregation is disabled. No need to update ""
          + ""the log aggregation status"");
    }
    // In NM, each application has exactly one appLogAggregator thread
    // to handle the log aggregation. So, it is fine which multiple
    // appLogAggregator thread to update log aggregation status for its
    // own application. This is why we are using readLocker here.
    this.readLocker.lock();
    try {
      AppLogAggregationStatusForRMRecovery tracker = recoveryStatuses
          .get(appId);
      if (tracker == null) {
        Application application = this.nmContext.getApplications().get(appId);
        if (application == null) {
          LOG.warn(""The application:"" + appId + "" has already finished,""
              + "" and has been removed from NodeManager, we should not ""
              + ""receive the log aggregation status update for ""
              + ""this application."");
          return;
        }
        AppLogAggregationStatusForRMRecovery newTracker =
            new AppLogAggregationStatusForRMRecovery(logAggregationStatus,
                diagnosis);
        newTracker.setLastModifiedTime(updateTime);
        newTracker.setFinalized(finalized);
        recoveryStatuses.put(appId, newTracker);
      } else {
        if (tracker.isFinalized()) {
          
---------------Reference log start----------------
LOG.warn(""Ignore the log aggregation status update request "" + ""for the application:"" + appId + "". The cached log aggregation "" + ""status is "" + tracker.getLogAggregationStatus() + ""."")
---------------Reference log end----------------
        } else {
          if (tracker.getLastModifiedTime() > updateTime) {
            LOG.warn(""Ignore the log aggregation status update request ""
                + ""for the application:"" + appId + "". The request log ""
                + ""aggregation status update is older than the cached ""
                + ""log aggregation status."");
          } else {
            tracker.setLogAggregationStatus(logAggregationStatus);
            tracker.setDiagnosis(diagnosis);
            tracker.setLastModifiedTime(updateTime);
            tracker.setFinalized(finalized);
            recoveryStatuses.put(appId, tracker);
          }
        }
      }
    } finally {
      this.readLocker.unlock();
    }
  }",,
hadoop,4829,LOG.info(systemPropsToLog),info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java/#L1679,"public static void main(String[] args) {
    try {
      mainStarted = true;
      Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());
      String containerIdStr =
          System.getenv(Environment.CONTAINER_ID.name());
      String nodeHostString = System.getenv(Environment.NM_HOST.name());
      String nodePortString = System.getenv(Environment.NM_PORT.name());
      String nodeHttpPortString =
          System.getenv(Environment.NM_HTTP_PORT.name());
      String appSubmitTimeStr =
          System.getenv(ApplicationConstants.APP_SUBMIT_TIME_ENV);
      
      validateInputParam(containerIdStr,
          Environment.CONTAINER_ID.name());
      validateInputParam(nodeHostString, Environment.NM_HOST.name());
      validateInputParam(nodePortString, Environment.NM_PORT.name());
      validateInputParam(nodeHttpPortString,
          Environment.NM_HTTP_PORT.name());
      validateInputParam(appSubmitTimeStr,
          ApplicationConstants.APP_SUBMIT_TIME_ENV);

      ContainerId containerId = ContainerId.fromString(containerIdStr);
      ApplicationAttemptId applicationAttemptId =
          containerId.getApplicationAttemptId();
      if (applicationAttemptId != null) {
        CallerContext.setCurrent(new CallerContext.Builder(
            ""mr_appmaster_"" + applicationAttemptId.toString()).build());
      }
      long appSubmitTime = Long.parseLong(appSubmitTimeStr);
      
      
      MRAppMaster appMaster =
          new MRAppMaster(applicationAttemptId, containerId, nodeHostString,
              Integer.parseInt(nodePortString),
              Integer.parseInt(nodeHttpPortString), appSubmitTime);
      ShutdownHookManager.get().addShutdownHook(
        new MRAppMasterShutdownHook(appMaster), SHUTDOWN_HOOK_PRIORITY);
      JobConf conf = new JobConf(new YarnConfiguration());
      conf.addResource(new Path(MRJobConfig.JOB_CONF_FILE));
      
      MRWebAppUtil.initialize(conf);
      // log the system properties
      String systemPropsToLog = MRApps.getSystemPropertiesToLog(conf);
      if (systemPropsToLog != null) {
        
---------------Reference log start----------------
LOG.info(systemPropsToLog)
---------------Reference log end----------------
      }

      String jobUserName = System
          .getenv(ApplicationConstants.Environment.USER.name());
      conf.set(MRJobConfig.USER_NAME, jobUserName);
      initAndStartAppMaster(appMaster, conf, jobUserName);
    } catch (Throwable t) {
      LOG.error(""Error starting MRAppMaster"", t);
      ExitUtil.terminate(1, t);
    }
  }",,
hadoop,11615,"LOG.debug(""Stat {}"", fullpath)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-registry/src/main/java/org/apache/hadoop/registry/client/impl/zk/CuratorService.java/#L483,"public Stat zkStat(String path) throws IOException {
    checkServiceLive();
    String fullpath = createFullPath(path);
    Stat stat;
    try {
      if (LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
LOG.debug(""Stat {}"", fullpath)
---------------Reference log end----------------
      }
      stat = curator.checkExists().forPath(fullpath);
    } catch (Exception e) {
      throw operationFailure(fullpath, ""read()"", e);
    }
    if (stat == null) {
      throw new PathNotFoundException(path);
    }
    return stat;
  }",,
hadoop,6417,"LOG.error(""Failed to create directory for downloading log "" + ""segments: {}. Stopping Journal Node Sync."", journal.getStorage().getEditsSyncDir())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNodeSyncer.java/#L177,"private void startSyncJournalsDaemon() {
    syncJournalDaemon = new Daemon(() -> {
      // Wait for journal to be formatted to create edits.sync directory
      while(!journal.isFormatted()) {
        try {
          Thread.sleep(journalSyncInterval);
        } catch (InterruptedException e) {
          LOG.error(""JournalNodeSyncer daemon received Runtime exception."", e);
          Thread.currentThread().interrupt();
          return;
        }
      }
      if (!createEditsSyncDir()) {
        
---------------Reference log start----------------
LOG.error(""Failed to create directory for downloading log "" + ""segments: {}. Stopping Journal Node Sync."", journal.getStorage().getEditsSyncDir())
---------------Reference log end----------------
        return;
      }
      while(shouldSync) {
        try {
          if (!journal.isFormatted()) {
            LOG.warn(""Journal cannot sync. Not formatted."");
          } else {
            syncJournals();
          }
        } catch (Throwable t) {
          if (!shouldSync) {
            if (t instanceof InterruptedException) {
              LOG.info(""Stopping JournalNode Sync."");
              Thread.currentThread().interrupt();
              return;
            } else {
              LOG.warn(""JournalNodeSyncer received an exception while "" +
                  ""shutting down."", t);
            }
            break;
          } else {
            if (t instanceof InterruptedException) {
              LOG.warn(""JournalNodeSyncer interrupted"", t);
              Thread.currentThread().interrupt();
              return;
            }
          }
          LOG.error(
              ""JournalNodeSyncer daemon received Runtime exception. "", t);
        }
        try {
          Thread.sleep(journalSyncInterval);
        } catch (InterruptedException e) {
          if (!shouldSync) {
            LOG.info(""Stopping JournalNode Sync."");
          } else {
            LOG.warn(""JournalNodeSyncer interrupted"", e);
          }
          Thread.currentThread().interrupt();
          return;
        }
      }
    });
    syncJournalDaemon.start();
  }",,
hadoop,9649,LOG.error(errorMsg),error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/SecureStorageInterfaceImpl.java/#L274,"@Override
    public CloudBlobWrapper getPageBlobReference(String relativePath)
        throws URISyntaxException, StorageException {
      try {
        CloudPageBlob blob   = (sasKeyGenerator!=null)
          ? new CloudPageBlob(sasKeyGenerator.getRelativeBlobSASUri(storageAccount, getName(), relativePath))
          : container.getPageBlobReference(relativePath);

        blob.getServiceClient().setDefaultRequestOptions(
                container.getServiceClient().getDefaultRequestOptions());
        return new SASCloudPageBlobWrapperImpl(blob);
      } catch (SASKeyGenerationException sasEx) {
        String errorMsg = ""Encountered SASKeyGeneration exception while ""
            + ""generating SAS Key for relativePath : "" + relativePath
            + "" inside container : "" + getName()
            + "" Storage account : "" + storageAccount;
        
---------------Reference log start----------------
LOG.error(errorMsg)
---------------Reference log end----------------
        throw new StorageException(SAS_ERROR_CODE, errorMsg, sasEx);
      }
    }",,
hadoop,5096,"LOG.debug(""seed: "" + seed)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/lib/InputSampler.java/#L167,"@SuppressWarnings(""unchecked"") // ArrayList::toArray doesn't preserve type
    public K[] getSample(InputFormat<K,V> inf, JobConf job) throws IOException {
      InputSplit[] splits = inf.getSplits(job, job.getNumMapTasks());
      ArrayList<K> samples = new ArrayList<K>(numSamples);
      int splitsToSample = Math.min(maxSplitsSampled, splits.length);

      Random r = new Random();
      long seed = r.nextLong();
      r.setSeed(seed);
      
---------------Reference log start----------------
LOG.debug(""seed: "" + seed)
---------------Reference log end----------------
      // shuffle splits
      for (int i = 0; i < splits.length; ++i) {
        InputSplit tmp = splits[i];
        int j = r.nextInt(splits.length);
        splits[i] = splits[j];
        splits[j] = tmp;
      }
      // our target rate is in terms of the maximum number of sample splits,
      // but we accept the possibility of sampling additional splits to hit
      // the target sample keyset
      for (int i = 0; i < splitsToSample ||
                     (i < splits.length && samples.size() < numSamples); ++i) {
        RecordReader<K,V> reader = inf.getRecordReader(splits[i], job,
            Reporter.NULL);
        K key = reader.createKey();
        V value = reader.createValue();
        while (reader.next(key, value)) {
          if (r.nextDouble() <= freq) {
            if (samples.size() < numSamples) {
              samples.add(key);
            } else {
              // When exceeding the maximum number of samples, replace a
              // random element with this one, then adjust the frequency
              // to reflect the possibility of existing elements being
              // pushed out
              int ind = r.nextInt(numSamples);
              if (ind != numSamples) {
                samples.set(ind, key);
              }
              freq *= (numSamples - 1) / (double) numSamples;
            }
            key = reader.createKey();
          }
        }
        reader.close();
      }
      return (K[])samples.toArray();
    }",,
hadoop,2921,"LOG.error(""node to unreserve doesn't exist, nodeid: "" + idToUnreserve)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/common/fica/FiCaSchedulerApp.java/#L936,"@VisibleForTesting
  public RMContainer findNodeToUnreserve(FiCaSchedulerNode node,
      SchedulerRequestKey schedulerKey, Resource minimumUnreservedResource) {
    readLock.lock();
    try {
      // need to unreserve some other container first
      NodeId idToUnreserve = getNodeIdToUnreserve(schedulerKey,
          minimumUnreservedResource, rc);
      if (idToUnreserve == null) {
        LOG.debug(""checked to see if could unreserve for app but nothing ""
            + ""reserved that matches for this app"");
        return null;
      }
      FiCaSchedulerNode nodeToUnreserve =
          ((CapacityScheduler) scheduler).getNode(idToUnreserve);
      if (nodeToUnreserve == null) {
        
---------------Reference log start----------------
LOG.error(""node to unreserve doesn't exist, nodeid: "" + idToUnreserve)
---------------Reference log end----------------
        return null;
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug(""unreserving for app: "" + getApplicationId() + "" on nodeId: ""
            + idToUnreserve
            + "" in order to replace reserved application and place it on node: ""
            + node.getNodeID() + "" needing: "" + minimumUnreservedResource);
      }

      // headroom
      Resources.addTo(getHeadroom(),
          nodeToUnreserve.getReservedContainer().getReservedResource());

      return nodeToUnreserve.getReservedContainer();
    } finally {
      readLock.unlock();
    }
  }",,
hadoop,10431,"LOG.error(""Exception encountered "", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/DistCp.java/#L169,"@Override
  public int run(String[] argv) {
    if (argv.length < 1) {
      OptionsParser.usage();
      return DistCpConstants.INVALID_ARGUMENT;
    }
    
    try {
      context = new DistCpContext(OptionsParser.parse(argv));
      checkSplitLargeFile();
      setTargetPathExists();
      LOG.info(""Input Options: "" + context);
    } catch (Throwable e) {
      LOG.error(""Invalid arguments: "", e);
      System.err.println(""Invalid arguments: "" + e.getMessage());
      OptionsParser.usage();      
      return DistCpConstants.INVALID_ARGUMENT;
    }

    Job job = null;
    try {
      job = execute();
    } catch (InvalidInputException e) {
      LOG.error(""Invalid input: "", e);
      return DistCpConstants.INVALID_ARGUMENT;
    } catch (DuplicateFileException e) {
      LOG.error(""Duplicate files in input path: "", e);
      return DistCpConstants.DUPLICATE_INPUT;
    } catch (AclsNotSupportedException e) {
      LOG.error(""ACLs not supported on at least one file system: "", e);
      return DistCpConstants.ACLS_NOT_SUPPORTED;
    } catch (XAttrsNotSupportedException e) {
      LOG.error(""XAttrs not supported on at least one file system: "", e);
      return DistCpConstants.XATTRS_NOT_SUPPORTED;
    } catch (Exception e) {
      
---------------Reference log start----------------
LOG.error(""Exception encountered "", e)
---------------Reference log end----------------
      return DistCpConstants.UNKNOWN_ERROR;
    } finally {
      //Blocking distcp so close the job after its done
      if (job != null && context.shouldBlock()) {
        try {
          job.close();
        } catch (IOException e) {
          LOG.error(""Exception encountered while closing distcp job"", e);
        }
      }
    }
    return DistCpConstants.SUCCESS;
  }",,
hadoop,11712,"LOG.trace(""Exiting createKey Method."")",trace,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/KMS.java/#L181,"@POST
  @Path(KMSRESTConstants.KEYS_RESOURCE)
  @Consumes(MediaType.APPLICATION_JSON)
  @Produces(MediaType.APPLICATION_JSON + ""; "" + JettyUtils.UTF_8)
  @SuppressWarnings(""unchecked"")
  public Response createKey(Map jsonKey) throws Exception {
    try{
      LOG.trace(""Entering createKey Method."");
      KMSWebApp.getAdminCallsMeter().mark();
      UserGroupInformation user = HttpUserGroupInformation.get();
      final String name = (String) jsonKey.get(KMSRESTConstants.NAME_FIELD);
      checkNotEmpty(name, KMSRESTConstants.NAME_FIELD);
      assertAccess(KMSACLs.Type.CREATE, user, KMSOp.CREATE_KEY, name);
      String cipher = (String) jsonKey.get(KMSRESTConstants.CIPHER_FIELD);
      final String material;
      material = (String) jsonKey.get(KMSRESTConstants.MATERIAL_FIELD);
      int length = (jsonKey.containsKey(KMSRESTConstants.LENGTH_FIELD))
                   ? (Integer) jsonKey.get(KMSRESTConstants.LENGTH_FIELD) : 0;
      String description = (String)
          jsonKey.get(KMSRESTConstants.DESCRIPTION_FIELD);
      LOG.debug(""Creating key with name {}, cipher being used{}, "" +
              ""length of key {}, description of key {}"", name, cipher,
               length, description);
      Map<String, String> attributes = (Map<String, String>)
          jsonKey.get(KMSRESTConstants.ATTRIBUTES_FIELD);
      if (material != null) {
        assertAccess(KMSACLs.Type.SET_KEY_MATERIAL, user,
            KMSOp.CREATE_KEY, name);
      }
      final KeyProvider.Options options = new KeyProvider.Options(
          KMSWebApp.getConfiguration());
      if (cipher != null) {
        options.setCipher(cipher);
      }
      if (length != 0) {
        options.setBitLength(length);
      }
      options.setDescription(description);
      options.setAttributes(attributes);

      KeyProvider.KeyVersion keyVersion = user.doAs(
          new PrivilegedExceptionAction<KeyVersion>() {
            @Override
            public KeyVersion run() throws Exception {
              KeyProvider.KeyVersion keyVersion = (material != null)
                  ? provider.createKey(name, Base64.decodeBase64(material),
                      options)
                  : provider.createKey(name, options);
              provider.flush();
              return keyVersion;
            }
          }
      );

      kmsAudit.ok(user, KMSOp.CREATE_KEY, name, ""UserProvidedMaterial:"" +
          (material != null) + "" Description:"" + description);

      if (!KMSWebApp.getACLs().hasAccess(KMSACLs.Type.GET, user)) {
        keyVersion = removeKeyMaterial(keyVersion);
      }
      Map json = KMSUtil.toJSON(keyVersion);
      String requestURL = KMSMDCFilter.getURL();
      int idx = requestURL.lastIndexOf(KMSRESTConstants.KEYS_RESOURCE);
      requestURL = requestURL.substring(0, idx);
      
---------------Reference log start----------------
LOG.trace(""Exiting createKey Method."")
---------------Reference log end----------------
      return Response.created(getKeyURI(KMSRESTConstants.SERVICE_VERSION, name))
          .type(MediaType.APPLICATION_JSON)
          .header(""Location"", getKeyURI(requestURL, name)).entity(json).build();
    } catch (Exception e) {
      LOG.debug(""Exception in createKey."", e);
      throw e;
    }
  }",,
hadoop,11841,"LOG.debug(""Remaining arguments {}"", remainingArgs)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/service/launcher/ServiceLauncher.java/#L938,"protected List<String> parseCommandArgs(Configuration conf,
      List<String> args) {
    Preconditions.checkNotNull(commandOptions,
        ""Command options have not been created"");
    StringBuilder argString = new StringBuilder(args.size() * 32);
    for (String arg : args) {
      argString.append(""\"""").append(arg).append(""\"" "");
    }
    LOG.debug(""Command line: {}"", argString);
    try {
      String[] argArray = args.toArray(new String[args.size()]);
      // parse this the standard way. This will
      // update the configuration in the parser, and potentially
      // patch the user credentials
      GenericOptionsParser parser = createGenericOptionsParser(conf, argArray);
      if (!parser.isParseSuccessful()) {
        throw new ServiceLaunchException(EXIT_COMMAND_ARGUMENT_ERROR,
            E_PARSE_FAILED + "" %s"", argString);
      }
      CommandLine line = parser.getCommandLine();
      List<String> remainingArgs = Arrays.asList(parser.getRemainingArgs());
      
---------------Reference log start----------------
LOG.debug(""Remaining arguments {}"", remainingArgs)
---------------Reference log end----------------

      // Scan the list of configuration files
      // and bail out if they don't exist
      if (line.hasOption(ARG_CONF)) {
        String[] filenames = line.getOptionValues(ARG_CONF);
        verifyConfigurationFilesExist(filenames);
        // Add URLs of files as list of URLs to load
        for (String filename : filenames) {
          File file = new File(filename);
          LOG.debug(""Configuration files {}"", file);
          confResourceUrls.add(file.toURI().toURL());
        }
      }
      if (line.hasOption(ARG_CONFCLASS)) {
        // new resources to instantiate as configurations
        List<String> classnameList = Arrays.asList(
            line.getOptionValues(ARG_CONFCLASS));
        LOG.debug(""Configuration classes {}"", classnameList);
        confClassnames.addAll(classnameList);
      }
      // return the remainder
      return remainingArgs;
    } catch (IOException e) {
      // parsing problem: convert to a command argument error with
      // the original text
      throw new ServiceLaunchException(EXIT_COMMAND_ARGUMENT_ERROR, e);
    } catch (RuntimeException e) {
      // lower level issue such as XML parse failure
      throw new ServiceLaunchException(EXIT_COMMAND_ARGUMENT_ERROR, e,
          E_PARSE_FAILED + "" %s : %s"", argString, e);
    }
  }",,
hadoop,2452,"LOG.debug(""Active scan starting"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timeline-pluginstorage/src/main/java/org/apache/hadoop/yarn/server/timeline/EntityGroupFSTimelineStore.java/#L889,"@Override
    public void run() {
      
---------------Reference log start----------------
LOG.debug(""Active scan starting"")
---------------Reference log end----------------
      try {
        int scanned = scanActiveLogs();
        LOG.debug(""Scanned {} active applications"", scanned);
      } catch (Exception e) {
        Throwable t = extract(e);
        if (t instanceof InterruptedException) {
          LOG.info(""File scanner interrupted"");
        } else {
          LOG.error(""Error scanning active files"", t);
        }
      }
      LOG.debug(""Active scan complete"");
    }",,
hadoop,65,"LOG.debug(""Check the condition for main loop."")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/async/AMRMClientAsync.java/#L468,"public void waitFor(Supplier<Boolean> check, int checkEveryMillis,
      int logInterval) throws InterruptedException {
    Preconditions.checkNotNull(check, ""check should not be null"");
    Preconditions.checkArgument(checkEveryMillis >= 0,
        ""checkEveryMillis should be positive value"");
    Preconditions.checkArgument(logInterval >= 0,
        ""logInterval should be positive value"");

    int loggingCounter = logInterval;
    do {
      
---------------Reference log start----------------
LOG.debug(""Check the condition for main loop."")
---------------Reference log end----------------
      boolean result = check.get();
      if (result) {
        LOG.info(""Exits the main loop."");
        return;
      }
      if (--loggingCounter <= 0) {
        LOG.info(""Waiting in main loop."");
        loggingCounter = logInterval;
      }

      Thread.sleep(checkEveryMillis);
    } while (true);
  }",,
hadoop,9654,"LOG.debug(""JSON Parsing exception: {} while parsing {}"", e.getMessage(), jsonString)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/security/JsonUtils.java/#L43,"public static Map<?, ?> parse(final String jsonString) throws IOException {
    try {
      return JsonSerialization.mapReader().readValue(jsonString);
    } catch (Exception e) {
      
---------------Reference log start----------------
LOG.debug(""JSON Parsing exception: {} while parsing {}"", e.getMessage(), jsonString)
---------------Reference log end----------------
      if (jsonString.toLowerCase(Locale.ENGLISH).contains(""server error"")) {
        LOG.error(
            ""Internal Server Error was encountered while making a request"");
      }
      throw new IOException(""JSON Parsing Error: "" + e.getMessage(), e);
    }
  }",,
hadoop,3059,"LOG.warn(NODEEXISTS_MSG, e)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/ZKConfigurationStore.java/#L256,"private boolean createNewZkPath(String path) throws Exception {
    if (!zkManager.exists(path)) {
      try {
        zkManager.create(path);
      } catch(NodeExistsException e) {
        
---------------Reference log start----------------
LOG.warn(NODEEXISTS_MSG, e)
---------------Reference log end----------------
        return false;
      }
      return true;
    } else {
      return false;
    }
  }",,
hadoop,11168,logger.warn(text),warn,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/S3Guard.java/#L1138,"public static void logS3GuardDisabled(Logger logger, String warnLevelStr,
      String bucket)
      throws ExitUtil.ExitException, IllegalArgumentException {
    final DisabledWarnLevel warnLevel;
    try {
      warnLevel = DisabledWarnLevel.valueOf(warnLevelStr.toUpperCase(Locale.US));
    } catch (IllegalArgumentException e) {
      throw new IllegalArgumentException(UNKNOWN_WARN_LEVEL + warnLevelStr, e);
    }

    String text = String.format(DISABLED_LOG_MSG, bucket);
    switch (warnLevel) {
    case SILENT:
      logger.debug(text);
      break;
    case INFORM:
      logger.info(text);
      break;
    case WARN:
      
---------------Reference log start----------------
logger.warn(text)
---------------Reference log end----------------
      break;
    case FAIL:
      logger.error(text);
      throw new ExitUtil.ExitException(EXIT_BAD_CONFIGURATION, text);
    default:
      throw new IllegalArgumentException(UNKNOWN_WARN_LEVEL + warnLevelStr);
    }
  }",,
hadoop,791,"LOG.debug(""Deleting entity type:{} id:{} primary filter entry {} {}"", entityType, entityId, name, value)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java/#L1453,"@VisibleForTesting
  boolean deleteNextEntity(String entityType, byte[] reverseTimestamp,
      LeveldbIterator iterator, LeveldbIterator pfIterator, boolean seeked)
      throws IOException {
    WriteBatch writeBatch = null;
    try {
      KeyBuilder kb = KeyBuilder.newInstance().add(ENTITY_ENTRY_PREFIX)
          .add(entityType);
      byte[] typePrefix = kb.getBytesForLookup();
      kb.add(reverseTimestamp);
      if (!seeked) {
        iterator.seek(kb.getBytesForLookup());
      }
      if (!iterator.hasNext()) {
        return false;
      }
      byte[] entityKey = iterator.peekNext().getKey();
      if (!prefixMatches(typePrefix, typePrefix.length, entityKey)) {
        return false;
      }

      // read the start time and entity id from the current key
      KeyParser kp = new KeyParser(entityKey, typePrefix.length + 8);
      String entityId = kp.getNextString();
      int prefixlen = kp.getOffset();
      byte[] deletePrefix = new byte[prefixlen];
      System.arraycopy(entityKey, 0, deletePrefix, 0, prefixlen);

      writeBatch = db.createWriteBatch();

      LOG.debug(""Deleting entity type:{} id:{}"", entityType, entityId);
      // remove start time from cache and db
      writeBatch.delete(createStartTimeLookupKey(entityId, entityType));
      EntityIdentifier entityIdentifier =
          new EntityIdentifier(entityId, entityType);
      startTimeReadCache.remove(entityIdentifier);
      startTimeWriteCache.remove(entityIdentifier);

      // delete current entity
      for (; iterator.hasNext(); iterator.next()) {
        byte[] key = iterator.peekNext().getKey();
        if (!prefixMatches(entityKey, prefixlen, key)) {
          break;
        }
        writeBatch.delete(key);

        if (key.length == prefixlen) {
          continue;
        }
        if (key[prefixlen] == PRIMARY_FILTERS_COLUMN[0]) {
          kp = new KeyParser(key,
              prefixlen + PRIMARY_FILTERS_COLUMN.length);
          String name = kp.getNextString();
          Object value = GenericObjectMapper.read(key, kp.getOffset());
          deleteKeysWithPrefix(writeBatch, addPrimaryFilterToKey(name, value,
              deletePrefix), pfIterator);
          
---------------Reference log start----------------
LOG.debug(""Deleting entity type:{} id:{} primary filter entry {} {}"", entityType, entityId, name, value)
---------------Reference log end----------------
        } else if (key[prefixlen] == RELATED_ENTITIES_COLUMN[0]) {
          kp = new KeyParser(key,
              prefixlen + RELATED_ENTITIES_COLUMN.length);
          String type = kp.getNextString();
          String id = kp.getNextString();
          byte[] relatedEntityStartTime = getStartTime(id, type);
          if (relatedEntityStartTime == null) {
            LOG.warn(""Found no start time for "" +
                ""related entity "" + id + "" of type "" + type + "" while "" +
                ""deleting "" + entityId + "" of type "" + entityType);
            continue;
          }
          writeBatch.delete(createReverseRelatedEntityKey(id, type,
              relatedEntityStartTime, entityId, entityType));
          LOG.debug(""Deleting entity type:{} id:{} from invisible reverse""
              + "" related entity entry of type:{} id:{}"", entityType,
              entityId, type, id);
        } else if (key[prefixlen] ==
            INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN[0]) {
          kp = new KeyParser(key, prefixlen +
              INVISIBLE_REVERSE_RELATED_ENTITIES_COLUMN.length);
          String type = kp.getNextString();
          String id = kp.getNextString();
          byte[] relatedEntityStartTime = getStartTime(id, type);
          if (relatedEntityStartTime == null) {
            LOG.warn(""Found no start time for reverse "" +
                ""related entity "" + id + "" of type "" + type + "" while "" +
                ""deleting "" + entityId + "" of type "" + entityType);
            continue;
          }
          writeBatch.delete(createRelatedEntityKey(id, type,
              relatedEntityStartTime, entityId, entityType));
          LOG.debug(""Deleting entity type:{} id:{} from related entity entry""
              +"" of type:{} id:{}"", entityType, entityId, type, id);
        }
      }
      WriteOptions writeOptions = new WriteOptions();
      writeOptions.sync(true);
      db.write(writeBatch, writeOptions);
      return true;
    } catch(DBException e) {
      throw new IOException(e);
    } finally {
      IOUtils.cleanupWithLogger(LOG, writeBatch);
    }
  }",,
hadoop,9104,"LOG.debug(""Failed to get provided capacity"", e.getMessage())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java/#L228,"@Override
  public long getProvidedCapacity() {
    try {
      return getRBFMetrics().getProvidedSpace();
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.debug(""Failed to get provided capacity"", e.getMessage())
---------------Reference log end----------------
    }
    return 0;
  }",,
hadoop,11982,"LOG.error(""error looking up the name of group "" + groupId + "": "" + error)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/JniBasedUnixGroupsMapping.java/#L76,"static private void logError(int groupId, String error) {
    
---------------Reference log start----------------
LOG.error(""error looking up the name of group "" + groupId + "": "" + error)
---------------Reference log end----------------
  }
  }",,
hadoop,5061,"LOG.info(""Error : "" + pe)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java/#L506,"@Override
  public int run(String[] args) throws Exception {
    CommandLineParser cli = new CommandLineParser();
    if (args.length == 0) {
      cli.printUsage();
      return 1;
    }
    cli.addOption(""input"", false, ""input path to the maps"", ""path"");
    cli.addOption(""output"", false, ""output path from the reduces"", ""path"");
    
    cli.addOption(""jar"", false, ""job jar file"", ""path"");
    cli.addOption(""inputformat"", false, ""java classname of InputFormat"", 
                  ""class"");
    //cli.addArgument(""javareader"", false, ""is the RecordReader in Java"");
    cli.addOption(""map"", false, ""java classname of Mapper"", ""class"");
    cli.addOption(""partitioner"", false, ""java classname of Partitioner"", 
                  ""class"");
    cli.addOption(""reduce"", false, ""java classname of Reducer"", ""class"");
    cli.addOption(""writer"", false, ""java classname of OutputFormat"", ""class"");
    cli.addOption(""program"", false, ""URI to application executable"", ""class"");
    cli.addOption(""reduces"", false, ""number of reduces"", ""num"");
    cli.addOption(""jobconf"", false, 
        ""\""n1=v1,n2=v2,..\"" (Deprecated) Optional. Add or override a JobConf property."",
        ""key=val"");
    cli.addOption(""lazyOutput"", false, ""Optional. Create output lazily"",
                  ""boolean"");
    Parser parser = cli.createParser();
    try {
      
      GenericOptionsParser genericParser = new GenericOptionsParser(getConf(), args);
      CommandLine results = parser.parse(cli.options, genericParser.getRemainingArgs());
      
      JobConf job = new JobConf(getConf());
      
      if (results.hasOption(""input"")) {
        FileInputFormat.setInputPaths(job, results.getOptionValue(""input""));
      }
      if (results.hasOption(""output"")) {
        FileOutputFormat.setOutputPath(job, 
          new Path(results.getOptionValue(""output"")));
      }
      if (results.hasOption(""jar"")) {
        job.setJar(results.getOptionValue(""jar""));
      }
      if (results.hasOption(""inputformat"")) {
        setIsJavaRecordReader(job, true);
        job.setInputFormat(getClass(results, ""inputformat"", job,
                                     InputFormat.class));
      }
      if (results.hasOption(""javareader"")) {
        setIsJavaRecordReader(job, true);
      }
      if (results.hasOption(""map"")) {
        setIsJavaMapper(job, true);
        job.setMapperClass(getClass(results, ""map"", job, Mapper.class));
      }
      if (results.hasOption(""partitioner"")) {
        job.setPartitionerClass(getClass(results, ""partitioner"", job,
                                          Partitioner.class));
      }
      if (results.hasOption(""reduce"")) {
        setIsJavaReducer(job, true);
        job.setReducerClass(getClass(results, ""reduce"", job, Reducer.class));
      }
      if (results.hasOption(""reduces"")) {
        job.setNumReduceTasks(Integer.parseInt( 
                                           results.getOptionValue(""reduces"")));
      }
      if (results.hasOption(""writer"")) {
        setIsJavaRecordWriter(job, true);
        job.setOutputFormat(getClass(results, ""writer"", job, 
                                      OutputFormat.class));
      }
      
      if (results.hasOption(""lazyOutput"")) {
        if (Boolean.parseBoolean(results.getOptionValue(""lazyOutput""))) {
          LazyOutputFormat.setOutputFormatClass(job,
              job.getOutputFormat().getClass());
        }
      }
      
      if (results.hasOption(""program"")) {
        setExecutable(job, results.getOptionValue(""program""));
      }
      if (results.hasOption(""jobconf"")) {
        LOG.warn(""-jobconf option is deprecated, please use -D instead."");
        String options = results.getOptionValue(""jobconf"");
        StringTokenizer tokenizer = new StringTokenizer(options, "","");
        while (tokenizer.hasMoreTokens()) {
          String keyVal = tokenizer.nextToken().trim();
          String[] keyValSplit = keyVal.split(""="");
          job.set(keyValSplit[0], keyValSplit[1]);
        }
      }
      // if they gave us a jar file, include it into the class path
      String jarFile = job.getJar();
      if (jarFile != null) {
        final URL[] urls = new URL[]{ FileSystem.getLocal(job).
            pathToFile(new Path(jarFile)).toURL()};
        //FindBugs complains that creating a URLClassLoader should be
        //in a doPrivileged() block. 
        ClassLoader loader =
          AccessController.doPrivileged(
              new PrivilegedAction<ClassLoader>() {
                public ClassLoader run() {
                  return new URLClassLoader(urls);
                }
              }
            );
        job.setClassLoader(loader);
      }
      
      runJob(job);
      return 0;
    } catch (ParseException pe) {
      
---------------Reference log start----------------
LOG.info(""Error : "" + pe)
---------------Reference log end----------------
      cli.printUsage();
      return 1;
    }
    
  }",,
hadoop,4104,"LOG.debug(""Current row key: "" + Arrays.toString(currRowKey))",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/reader/EntityTypeReader.java/#L106,"public Set<String> readEntityTypes(Configuration hbaseConf,
      Connection conn) throws IOException {

    validateParams();
    augmentParams(hbaseConf, conn);

    Set<String> types = new TreeSet<>();
    TimelineReaderContext context = getContext();
    EntityRowKeyPrefix prefix = new EntityRowKeyPrefix(context.getClusterId(),
        context.getUserId(), context.getFlowName(), context.getFlowRunId(),
        context.getAppId());
    byte[] currRowKey = prefix.getRowKeyPrefix();
    byte[] nextRowKey = prefix.getRowKeyPrefix();
    nextRowKey[nextRowKey.length - 1]++;

    FilterList typeFilterList = new FilterList();
    typeFilterList.addFilter(new FirstKeyOnlyFilter());
    typeFilterList.addFilter(new KeyOnlyFilter());
    typeFilterList.addFilter(new PageFilter(1));
    LOG.debug(""FilterList created for scan is - {}"", typeFilterList);

    int counter = 0;
    while (true) {
      try (ResultScanner results =
          getResult(hbaseConf, conn, typeFilterList, currRowKey, nextRowKey)) {
        TimelineEntity entity = parseEntityForType(results.next());
        if (entity == null) {
          break;
        }
        ++counter;
        if (!types.add(entity.getType())) {
          LOG.warn(""Failed to add type "" + entity.getType()
              + "" to the result set because there is a duplicated copy. "");
        }
        String currType = entity.getType();
        if (LOG.isDebugEnabled()) {
          
---------------Reference log start----------------
LOG.debug(""Current row key: "" + Arrays.toString(currRowKey))
---------------Reference log end----------------
          LOG.debug(""New entity type discovered: "" + currType);
        }
        currRowKey = getNextRowKey(prefix.getRowKeyPrefix(), currType);
      }
    }
    LOG.debug(""Scanned {} records for {} types"", counter, types.size());
    return types;
  }",,
hadoop,6457,"LOG.info(""Updating lastPromisedEpoch from "" + lastPromisedEpoch.get() + "" to "" + newEpoch + "" for client "" + Server.getRemoteIp() + "" ; journal id: "" + journalId)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java/#L368,"private void updateLastPromisedEpoch(long newEpoch) throws IOException {
    
---------------Reference log start----------------
LOG.info(""Updating lastPromisedEpoch from "" + lastPromisedEpoch.get() + "" to "" + newEpoch + "" for client "" + Server.getRemoteIp() + "" ; journal id: "" + journalId)
---------------Reference log end----------------
    lastPromisedEpoch.set(newEpoch);
    
    // Since we have a new writer, reset the IPC serial - it will start
    // counting again from 0 for this writer.
    currentEpochIpcSerial = -1;
  }",,
hadoop,12276,"LOG.debug(""Current Caller: {}  Priority: {} "", obj.getUserGroupInformation().getUserName(), obj.getPriorityLevel())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/DecayRpcScheduler.java/#L703,"@Override
  public boolean shouldBackOff(Schedulable obj) {
    Boolean backOff = false;
    if (backOffByResponseTimeEnabled) {
      int priorityLevel = obj.getPriorityLevel();
      if (LOG.isDebugEnabled()) {
        double[] responseTimes = getAverageResponseTime();
        
---------------Reference log start----------------
LOG.debug(""Current Caller: {}  Priority: {} "", obj.getUserGroupInformation().getUserName(), obj.getPriorityLevel())
---------------Reference log end----------------
        for (int i = 0; i < numLevels; i++) {
          LOG.debug(""Queue: {} responseTime: {} backoffThreshold: {}"", i,
              responseTimes[i], backOffResponseTimeThresholds[i]);
        }
      }
      // High priority rpc over threshold triggers back off of low priority rpc
      for (int i = 0; i < priorityLevel + 1; i++) {
        if (responseTimeAvgInLastWindow.get(i) >
            backOffResponseTimeThresholds[i]) {
          backOff = true;
          break;
        }
      }
    }
    return backOff;
  }",,
hadoop,12012,"LOG.debug(""Renewed ticket. kinit output: {}"", output)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java/#L1061,"@Override
    public void relogin() throws IOException {
      String output = Shell.execCommand(kinitCmd, ""-R"");
      
---------------Reference log start----------------
LOG.debug(""Renewed ticket. kinit output: {}"", output)
---------------Reference log end----------------
      reloginFromTicketCache();
    }",,
hadoop,1231,"LOG.debug(""Interrupted while waiting to put on response queue"", ex)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/AMHeartbeatRequestHandler.java/#L175,"public void allocateAsync(AllocateRequest request,
      AsyncCallback<AllocateResponse> callback) throws YarnException {
    try {
      this.requestQueue.put(new AsyncAllocateRequestInfo(request, callback));
    } catch (InterruptedException ex) {
      // Should not happen as we have MAX_INT queue length
      
---------------Reference log start----------------
LOG.debug(""Interrupted while waiting to put on response queue"", ex)
---------------Reference log end----------------
    }
  }",,
hadoop,4769,"LOG.info(""Ignoring killed event for successful reduce task attempt"" + taskAttempt.getID().toString())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java/#L2281,"@SuppressWarnings(""unchecked"")
    @Override
    public TaskAttemptStateInternal transition(TaskAttemptImpl taskAttempt,
        TaskAttemptEvent event) {
      taskAttempt.appContext.getTaskAttemptFinishingMonitor().unregister(
          taskAttempt.attemptId);
      sendContainerCleanup(taskAttempt, event);
      if(taskAttempt.getID().getTaskId().getTaskType() == TaskType.REDUCE) {
        // after a reduce task has succeeded, its outputs are in safe in HDFS.
        // logically such a task should not be killed. we only come here when
        // there is a race condition in the event queue. E.g. some logic sends
        // a kill request to this attempt when the successful completion event
        // for this task is already in the event queue. so the kill event will
        // get executed immediately after the attempt is marked successful and
        // result in this transition being exercised.
        // ignore this for reduce tasks
        
---------------Reference log start----------------
LOG.info(""Ignoring killed event for successful reduce task attempt"" + taskAttempt.getID().toString())
---------------Reference log end----------------
        return TaskAttemptStateInternal.SUCCESS_CONTAINER_CLEANUP;
      } else if (taskAttempt.getID().getTaskId().getTaskType() == TaskType.MAP
          && taskAttempt.conf.getNumReduceTasks() == 0) {
        // same reason as above for map only job after map task has succeeded.
        // ignore this for map only tasks
        LOG.info(""Ignoring killed event for successful map only task attempt"" +
            taskAttempt.getID().toString());
        return TaskAttemptStateInternal.SUCCESS_CONTAINER_CLEANUP;
      } else {
        // Store reschedule flag so that after clean up is completed, new
        // attempt is scheduled/rescheduled based on it.
        if (event instanceof TaskAttemptKillEvent) {
          taskAttempt.setRescheduleNextAttempt(
              ((TaskAttemptKillEvent)event).getRescheduleAttempt());
        }
        return TaskAttemptStateInternal.KILL_CONTAINER_CLEANUP;
      }
    }",,
hadoop,12192,"LOG.debug(""Cancelling delegation token {} with url:{}, as:{}"", dToken, url, doAsUser)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java/#L1096,"@Override
            public Void run() throws Exception {
              final URL url = createURL(null, null, null, null);
              
---------------Reference log start----------------
LOG.debug(""Cancelling delegation token {} with url:{}, as:{}"", dToken, url, doAsUser)
---------------Reference log end----------------
              final DelegationTokenAuthenticatedURL authUrl =
                  createAuthenticatedURL();
              authUrl.cancelDelegationToken(url, token, doAsUser);
              return null;
            }",,
hadoop,14,"LOG.debug(""Got valid challenge for host {}"", serverName)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/util/YarnClientUtils.java/#L242,"@Override
          public String run() throws Exception {
            try {
              GSSManager manager = GSSManager.getInstance();
              // GSS name for server
              GSSName serverName = manager.createName(""HTTP@"" + server,
                  GSSName.NT_HOSTBASED_SERVICE);
              // Create a GSSContext for authentication with the service.
              // We're passing client credentials as null since we want them to
              // be read from the Subject.
              // We're passing Oid as null to use the default.
              GSSContext gssContext = manager.createContext(
                  serverName.canonicalize(null), null, null,
                  GSSContext.DEFAULT_LIFETIME);
              gssContext.requestMutualAuth(true);
              gssContext.requestCredDeleg(true);
              // Establish context
              byte[] inToken = new byte[0];
              byte[] outToken = gssContext.initSecContext(inToken, 0,
                  inToken.length);
              gssContext.dispose();
              // Base64 encoded and stringified token for server
              
---------------Reference log start----------------
LOG.debug(""Got valid challenge for host {}"", serverName)
---------------Reference log end----------------
              return new String(BASE_64_CODEC.encode(outToken),
                  StandardCharsets.US_ASCII);
            } catch (GSSException e) {
              LOG.error(""Error: "", e);
              throw new AuthenticationException(e);
            }
          }",,
hadoop,2348,"LOG.info(""Directory "" + dir + "" passed disk check, adding to list of valid directories."")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DirectoryCollection.java/#L492,"boolean checkDirs() {
    boolean setChanged = false;
    Set<String> preCheckGoodDirs = null;
    Set<String> preCheckFullDirs = null;
    Set<String> preCheckOtherErrorDirs = null;
    List<String> failedDirs = null;
    List<String> allLocalDirs = null;
    this.readLock.lock();
    try {
      preCheckGoodDirs = new HashSet<String>(localDirs);
      preCheckFullDirs = new HashSet<String>(fullDirs);
      preCheckOtherErrorDirs = new HashSet<String>(errorDirs);
      failedDirs = DirectoryCollection.concat(errorDirs, fullDirs);
      allLocalDirs = DirectoryCollection.concat(localDirs, failedDirs);
    } finally {
      this.readLock.unlock();
    }

    // move testDirs out of any lock as it could wait for very long time in
    // case of busy IO
    Map<String, DiskErrorInformation> dirsFailedCheck = testDirs(allLocalDirs,
        preCheckGoodDirs);

    this.writeLock.lock();
    try {
      localDirs.clear();
      errorDirs.clear();
      fullDirs.clear();
      directoryErrorInfo.clear();

      for (Map.Entry<String, DiskErrorInformation> entry : dirsFailedCheck
          .entrySet()) {
        String dir = entry.getKey();
        DiskErrorInformation errorInformation = entry.getValue();

        switch (entry.getValue().cause) {
        case DISK_FULL:
          fullDirs.add(entry.getKey());
          break;
        case OTHER:
          errorDirs.add(entry.getKey());
          break;
        default:
          LOG.warn(entry.getValue().cause + "" is unknown for disk error."");
          break;
        }
        directoryErrorInfo.put(entry.getKey(), errorInformation);

        if (preCheckGoodDirs.contains(dir)) {
          LOG.warn(""Directory "" + dir + "" error, "" + errorInformation.message
              + "", removing from list of valid directories"");
          setChanged = true;
          numFailures++;
        }
      }
      for (String dir : allLocalDirs) {
        if (!dirsFailedCheck.containsKey(dir)) {
          localDirs.add(dir);
          if (preCheckFullDirs.contains(dir)
              || preCheckOtherErrorDirs.contains(dir)) {
            setChanged = true;
            
---------------Reference log start----------------
LOG.info(""Directory "" + dir + "" passed disk check, adding to list of valid directories."")
---------------Reference log end----------------
          }
        }
      }
      Set<String> postCheckFullDirs = new HashSet<String>(fullDirs);
      Set<String> postCheckOtherDirs = new HashSet<String>(errorDirs);
      for (String dir : preCheckFullDirs) {
        if (postCheckOtherDirs.contains(dir)) {
          LOG.warn(""Directory "" + dir + "" error ""
              + dirsFailedCheck.get(dir).message);
        }
      }

      for (String dir : preCheckOtherErrorDirs) {
        if (postCheckFullDirs.contains(dir)) {
          LOG.warn(""Directory "" + dir + "" error ""
              + dirsFailedCheck.get(dir).message);
        }
      }
      setGoodDirsDiskUtilizationPercentage();
      if (setChanged) {
        for (DirsChangeListener listener : dirsChangeListeners) {
          listener.onDirsChanged();
        }
      }
      return setChanged;
    } finally {
      this.writeLock.unlock();
    }
  }",,
hadoop,12286,LOG.warn(msg),warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/ProtobufRpcEngine.java/#L453,"static RpcWritable processCall(RPC.Server server,
        String connectionProtocolName, RpcWritable.Buffer request,
        String methodName, ProtoClassProtoImpl protocolImpl) throws Exception {
      BlockingService service = (BlockingService) protocolImpl.protocolImpl;
      MethodDescriptor methodDescriptor = service.getDescriptorForType()
          .findMethodByName(methodName);
      if (methodDescriptor == null) {
        String msg = ""Unknown method "" + methodName + "" called on ""
                              + connectionProtocolName + "" protocol."";
        
---------------Reference log start----------------
LOG.warn(msg)
---------------Reference log end----------------
        throw new RpcNoSuchMethodException(msg);
      }
      Message prototype = service.getRequestPrototype(methodDescriptor);
      Message param = request.getValue(prototype);

      Message result;
      Call currentCall = Server.getCurCall().get();
      try {
        server.rpcDetailedMetrics.init(protocolImpl.protocolClass);
        CURRENT_CALL_INFO.set(new CallInfo(server, methodName));
        currentCall.setDetailedMetricsName(methodName);
        result = service.callBlockingMethod(methodDescriptor, null, param);
        // Check if this needs to be a deferred response,
        // by checking the ThreadLocal callback being set
        if (currentCallback.get() != null) {
          currentCall.deferResponse();
          currentCallback.set(null);
          return null;
        }
      } catch (ServiceException e) {
        Exception exception = (Exception) e.getCause();
        currentCall
            .setDetailedMetricsName(exception.getClass().getSimpleName());
        throw (Exception) e.getCause();
      } catch (Exception e) {
        currentCall.setDetailedMetricsName(e.getClass().getSimpleName());
        throw e;
      } finally {
        CURRENT_CALL_INFO.set(null);
      }
      return RpcWritable.wrap(result);
    }",,
hadoop,7022,"LOG.debug(""Found gap in logs at "" + curStartTxId + "": "" + ""not returning previous logs in manifest."")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/JournalSet.java/#L686,"public synchronized RemoteEditLogManifest getEditLogManifest(long fromTxId) {
    // Collect RemoteEditLogs available from each FileJournalManager
    List<RemoteEditLog> allLogs = new ArrayList<>();
    for (JournalAndStream j : journals) {
      if (j.getManager() instanceof FileJournalManager) {
        FileJournalManager fjm = (FileJournalManager)j.getManager();
        try {
          allLogs.addAll(fjm.getRemoteEditLogs(fromTxId, false));
        } catch (Throwable t) {
          LOG.warn(""Cannot list edit logs in "" + fjm, t);
        }
      }
    }
    // Group logs by their starting txid
    final Map<Long, List<RemoteEditLog>> logsByStartTxId = new HashMap<>();
    allLogs.forEach(input -> {
      long key = RemoteEditLog.GET_START_TXID.apply(input);
      logsByStartTxId.computeIfAbsent(key, k-> new ArrayList<>()).add(input);
    });
    long curStartTxId = fromTxId;
    List<RemoteEditLog> logs = new ArrayList<>();
    while (true) {
      List<RemoteEditLog> logGroup =
          logsByStartTxId.getOrDefault(curStartTxId, Collections.emptyList());
      if (logGroup.isEmpty()) {
        // we have a gap in logs - for example because we recovered some old
        // storage directory with ancient logs. Clear out any logs we've
        // accumulated so far, and then skip to the next segment of logs
        // after the gap.
        SortedSet<Long> startTxIds = Sets.newTreeSet(logsByStartTxId.keySet());
        startTxIds = startTxIds.tailSet(curStartTxId);
        if (startTxIds.isEmpty()) {
          break;
        } else {
          if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""Found gap in logs at "" + curStartTxId + "": "" + ""not returning previous logs in manifest."")
---------------Reference log end----------------
          }
          logs.clear();
          curStartTxId = startTxIds.first();
          continue;
        }
      }

      // Find the one that extends the farthest forward
      RemoteEditLog bestLog = Collections.max(logGroup);
      logs.add(bestLog);
      // And then start looking from after that point
      curStartTxId = bestLog.getEndTxId() + 1;
    }
    RemoteEditLogManifest ret = new RemoteEditLogManifest(logs,
        curStartTxId - 1);
    
    if (LOG.isDebugEnabled()) {
      LOG.debug(""Generated manifest for logs since "" + fromTxId + "":""
          + ret);      
    }
    return ret;
  }",,
hadoop,3923,LOG.error(errMsg),error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/InMemoryPlan.java/#L447,"private boolean removeReservation(ReservationAllocation reservation) {
    assert (readWriteLock.isWriteLockedByCurrentThread());
    ReservationInterval searchInterval = new ReservationInterval(
        reservation.getStartTime(), reservation.getEndTime());
    Set<InMemoryReservationAllocation> reservations =
        currentReservations.get(searchInterval);
    if (reservations != null) {
      if (rmStateStore != null) {
        rmStateStore.removeReservation(getQueueName(),
            reservation.getReservationId().toString());
      }
      if (!reservations.remove(reservation)) {
        LOG.error(""Unable to remove reservation: {} from plan."",
            reservation.getReservationId());
        return false;
      }
      if (reservations.isEmpty()) {
        currentReservations.remove(searchInterval);
      }
    } else {
      String errMsg = ""The specified Reservation with ID ""
          + reservation.getReservationId() + "" does not exist in the plan"";
      
---------------Reference log start----------------
LOG.error(errMsg)
---------------Reference log end----------------
      throw new IllegalArgumentException(errMsg);
    }
    reservationTable.remove(reservation.getReservationId());
    decrementAllocation(reservation);
    LOG.info(""Sucessfully deleted reservation: {} in plan."",
        reservation.getReservationId());
    return true;
  }",,
hadoop,598,"LOG.error(""Error in RMCallbackHandler: "", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/ApplicationMaster.java/#L1280,"@Override
    public void onError(Throwable e) {
      
---------------Reference log start----------------
LOG.error(""Error in RMCallbackHandler: "", e)
---------------Reference log end----------------
      done = true;
    }",,
hadoop,141,"LOG.info(""Loading service definition from local FS: "" + filePath)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/ApiServiceClient.java/#L349,"public Service loadAppJsonFromLocalFS(String fileName, String serviceName,
      Long lifetime, String queue) throws IOException, YarnException {
    File file = new File(fileName);
    if (!file.exists() && fileName.equals(file.getName())) {
      String examplesDirStr = System.getenv(""YARN_SERVICE_EXAMPLES_DIR"");
      String[] examplesDirs;
      if (examplesDirStr == null) {
        String yarnHome = System
            .getenv(ApplicationConstants.Environment.HADOOP_YARN_HOME.key());
        examplesDirs = new String[]{
            yarnHome + ""/share/hadoop/yarn/yarn-service-examples"",
            yarnHome + ""/yarn-service-examples""
        };
      } else {
        examplesDirs = StringUtils.split(examplesDirStr, "":"");
      }
      for (String dir : examplesDirs) {
        file = new File(MessageFormat.format(""{0}/{1}/{2}.json"",
            dir, fileName, fileName));
        if (file.exists()) {
          break;
        }
        // Then look for secondary location.
        file = new File(MessageFormat.format(""{0}/{1}.json"",
            dir, fileName));
        if (file.exists()) {
          break;
        }
      }
    }
    if (!file.exists()) {
      throw new YarnException(""File or example could not be found: "" +
          fileName);
    }
    Path filePath = new Path(file.getAbsolutePath());
    
---------------Reference log start----------------
LOG.info(""Loading service definition from local FS: "" + filePath)
---------------Reference log end----------------
    Service service = jsonSerDeser
        .load(FileSystem.getLocal(getConfig()), filePath);
    if (!StringUtils.isEmpty(serviceName)) {
      service.setName(serviceName);
    }
    if (lifetime != null && lifetime > 0) {
      service.setLifetime(lifetime);
    }
    if (!StringUtils.isEmpty(queue)) {
      service.setQueue(queue);
    }
    return service;
  }",,
hadoop,2186,"LOG.info(""Sending finish application request to {} sub-cluster RMs"", subClusterIds.size())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/amrmproxy/FederationInterceptor.java/#L749,"@Override
  public FinishApplicationMasterResponse finishApplicationMaster(
      FinishApplicationMasterRequest request)
      throws YarnException, IOException {

    this.finishAMCalled = true;

    // TODO: consider adding batchFinishApplicationMaster in UAMPoolManager
    boolean failedToUnRegister = false;
    ExecutorCompletionService<FinishApplicationMasterResponseInfo> compSvc =
        null;

    // Application master is completing operation. Send the finish
    // application master request to all the registered sub-cluster resource
    // managers in parallel, wait for the responses and aggregate the results.
    Set<String> subClusterIds = this.uamPool.getAllUAMIds();
    if (subClusterIds.size() > 0) {
      final FinishApplicationMasterRequest finishRequest = request;
      compSvc =
          new ExecutorCompletionService<FinishApplicationMasterResponseInfo>(
              this.threadpool);

      
---------------Reference log start----------------
LOG.info(""Sending finish application request to {} sub-cluster RMs"", subClusterIds.size())
---------------Reference log end----------------
      for (final String subClusterId : subClusterIds) {
        compSvc.submit(new Callable<FinishApplicationMasterResponseInfo>() {
          @Override
          public FinishApplicationMasterResponseInfo call() throws Exception {
            LOG.info(""Sending finish application request to RM {}"",
                subClusterId);
            FinishApplicationMasterResponse uamResponse = null;
            try {
              uamResponse =
                  uamPool.finishApplicationMaster(subClusterId, finishRequest);

              if (uamResponse.getIsUnregistered()) {
                secondaryRelayers.remove(subClusterId);
                if (getNMStateStore() != null) {
                  getNMStateStore().removeAMRMProxyAppContextEntry(attemptId,
                      NMSS_SECONDARY_SC_PREFIX + subClusterId);
                }
              }
            } catch (Throwable e) {
              LOG.warn(""Failed to finish unmanaged application master: ""
                  + ""RM address: "" + subClusterId + "" ApplicationId: ""
                  + attemptId, e);
            }
            return new FinishApplicationMasterResponseInfo(uamResponse,
                subClusterId);
          }
        });
      }
    }

    // While the finish application request is being processed
    // asynchronously by other sub-cluster resource managers, send the same
    // request to the home resource manager on this thread.
    FinishApplicationMasterResponse homeResponse =
        this.homeRMRelayer.finishApplicationMaster(request);

    // Stop the home heartbeat thread
    this.homeHeartbeartHandler.shutdown();

    if (subClusterIds.size() > 0) {
      // Wait for other sub-cluster resource managers to return the
      // response and merge it with the home response
      LOG.info(
          ""Waiting for finish application response from {} sub-cluster RMs"",
          subClusterIds.size());
      for (int i = 0; i < subClusterIds.size(); ++i) {
        try {
          Future<FinishApplicationMasterResponseInfo> future = compSvc.take();
          FinishApplicationMasterResponseInfo uamResponse = future.get();
          LOG.debug(""Received finish application response from RM: {}"",
              uamResponse.getSubClusterId());
          if (uamResponse.getResponse() == null
              || !uamResponse.getResponse().getIsUnregistered()) {
            failedToUnRegister = true;
          }
        } catch (Throwable e) {
          failedToUnRegister = true;
          LOG.warn(""Failed to finish unmanaged application master: ""
              + "" ApplicationId: "" + this.attemptId, e);
        }
      }
    }

    if (failedToUnRegister) {
      homeResponse.setIsUnregistered(false);
    } else {
      // Clean up UAMs only when the app finishes successfully, so that no more
      // attempt will be launched.
      this.uamPool.stop();
      if (this.registryClient != null) {
        this.registryClient
            .removeAppFromRegistry(this.attemptId.getApplicationId());
      }
    }
    return homeResponse;
  }",,
hadoop,1201,"LOG.info(""Registering the Unmanaged application master {}"", this.applicationId)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/uam/UnmanagedApplicationManager.java/#L221,"public RegisterApplicationMasterResponse registerApplicationMaster(
      RegisterApplicationMasterRequest request)
      throws YarnException, IOException {
    // Save the register request for re-register later
    this.registerRequest = request;

    
---------------Reference log start----------------
LOG.info(""Registering the Unmanaged application master {}"", this.applicationId)
---------------Reference log end----------------
    RegisterApplicationMasterResponse response =
        this.rmProxyRelayer.registerApplicationMaster(this.registerRequest);
    this.heartbeatHandler.resetLastResponseId();

    for (Container container : response.getContainersFromPreviousAttempts()) {
      LOG.debug(""RegisterUAM returned existing running container {}"",
          container.getId());
    }
    for (NMToken nmToken : response.getNMTokensFromPreviousAttempts()) {
      LOG.debug(""RegisterUAM returned existing NM token for node {}"",
          nmToken.getNodeId());
    }
    LOG.info(
        ""RegisterUAM returned {} existing running container and {} NM tokens"",
        response.getContainersFromPreviousAttempts().size(),
        response.getNMTokensFromPreviousAttempts().size());

    // Only when register succeed that we start the heartbeat thread
    this.heartbeatHandler.setDaemon(true);
    this.heartbeatHandler.start();

    return response;
  }",,
hadoop,6348,"LOG.info(""Connects to Namenode [{}]"", get().get(FileSystemAccess.class).getFileSystemConfiguration().getTrimmed(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY))",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/fs/http/server/HttpFSServerWebApp.java/#L107,"@Override
  public void init() throws ServerException {
    if (SERVER != null) {
      throw new RuntimeException(""HttpFSServer server already initialized"");
    }
    SERVER = this;
    super.init();
    adminGroup = getConfig().get(getPrefixedName(CONF_ADMIN_GROUP), ""admin"");
    
---------------Reference log start----------------
LOG.info(""Connects to Namenode [{}]"", get().get(FileSystemAccess.class).getFileSystemConfiguration().getTrimmed(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY))
---------------Reference log end----------------
    setMetrics(getConfig());
  }",,
hadoop,322,LOG.error(message),error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ServiceClient.java/#L696,"private Map<String, Long> flexComponents(String serviceName,
      Map<String, Long> componentCounts, Service persistedService)
      throws YarnException, IOException {
    ServiceApiUtil.validateNameFormat(serviceName, getConfig());

    Map<String, Long> original = new HashMap<>(componentCounts.size());

    ComponentCountProto.Builder countBuilder = ComponentCountProto.newBuilder();
    FlexComponentsRequestProto.Builder requestBuilder =
        FlexComponentsRequestProto.newBuilder();

    for (Component persistedComp : persistedService.getComponents()) {
      String name = persistedComp.getName();
      if (componentCounts.containsKey(persistedComp.getName())) {
        original.put(name, persistedComp.getNumberOfContainers());
        persistedComp.setNumberOfContainers(componentCounts.get(name));

        // build the request
        countBuilder.setName(persistedComp.getName())
            .setNumberOfContainers(persistedComp.getNumberOfContainers());
        requestBuilder.addComponents(countBuilder.build());
      }
    }
    if (original.size() < componentCounts.size()) {
      componentCounts.keySet().removeAll(original.keySet());
      throw new YarnException(""Components "" + componentCounts.keySet()
          + "" do not exist in app definition."");
    }
    ServiceApiUtil.writeAppDefinition(fs, persistedService);

    ApplicationId appId = getAppId(serviceName);
    if (appId == null) {
      String message = ""Application ID doesn't exist for "" + serviceName;
      LOG.error(message);
      throw new YarnException(message);
    }
    ApplicationReport appReport =
        yarnClient.getApplicationReport(appId);
    if (appReport.getYarnApplicationState() != RUNNING) {
      String message =
          serviceName + "" is at "" + appReport.getYarnApplicationState()
              + "" state, flex can only be invoked when service is running"";
      LOG.error(message);
      throw new YarnException(message);
    }

    Service liveService = getStatus(serviceName);
    if (liveService.getState().equals(ServiceState.UPGRADING) ||
        liveService.getState().equals(ServiceState.UPGRADING_AUTO_FINALIZE)) {
      String message = serviceName + "" is at "" +
          liveService.getState()
          + "" state, flex can not be invoked when service is upgrading. "";
      
---------------Reference log start----------------
LOG.error(message)
---------------Reference log end----------------
      throw new YarnException(message);
    }

    if (StringUtils.isEmpty(appReport.getHost())) {
      throw new YarnException(serviceName + "" AM hostname is empty"");
    }
    ClientAMProtocol proxy =
        createAMProxy(serviceName, appReport);
    proxy.flexComponents(requestBuilder.build());
    for (Map.Entry<String, Long> entry : original.entrySet()) {
      LOG.info(""[COMPONENT {}]: number of containers changed from {} to {}"",
          entry.getKey(), entry.getValue(),
          componentCounts.get(entry.getKey()));
    }
    return original;
  }",,
hadoop,11704,"LOG.debug(""Using CIDR match for '"" + host + ""' and "" + privilege)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-nfs/src/main/java/org/apache/hadoop/nfs/NfsExports.java/#L384,"private static Match getMatch(String line) {
    String[] parts = line.split(""\\s+"");
    final String host;
    AccessPrivilege privilege = AccessPrivilege.READ_ONLY;
    switch (parts.length) {
    case 1:
      host = StringUtils.toLowerCase(parts[0]).trim();
      break;
    case 2:
      host = StringUtils.toLowerCase(parts[0]).trim();
      String option = parts[1].trim();
      if (""rw"".equalsIgnoreCase(option)) {
        privilege = AccessPrivilege.READ_WRITE;
      }
      break;
    default:
      throw new IllegalArgumentException(""Incorrectly formatted line '"" + line
          + ""'"");
    }
    if (host.equals(""*"")) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using match all for '"" + host + ""' and "" + privilege);
      }
      return new AnonymousMatch(privilege);
    } else if (CIDR_FORMAT_SHORT.matcher(host).matches()) {
      if (LOG.isDebugEnabled()) {
        
---------------Reference log start----------------
LOG.debug(""Using CIDR match for '"" + host + ""' and "" + privilege)
---------------Reference log end----------------
      }
      return new CIDRMatch(privilege, new SubnetUtils(host).getInfo());
    } else if (CIDR_FORMAT_LONG.matcher(host).matches()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using CIDR match for '"" + host + ""' and "" + privilege);
      }
      String[] pair = host.split(""/"");
      return new CIDRMatch(privilege,
          new SubnetUtils(pair[0], pair[1]).getInfo());
    } else if (host.contains(""*"") || host.contains(""?"") || host.contains(""["")
        || host.contains(""]"") || host.contains(""("") || host.contains("")"")) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using Regex match for '"" + host + ""' and "" + privilege);
      }
      return new RegexMatch(privilege, host);
    } else if (HOSTNAME_FORMAT.matcher(host).matches()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""Using exact match for '"" + host + ""' and "" + privilege);
      }
      return new ExactMatch(privilege, host);
    } else {
      throw new IllegalArgumentException(""Invalid hostname provided '"" + host
          + ""'"");
    }
  }",,
hadoop,10757,"LOG.debug(""Reinstate summary {}"", key)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/InconsistentAmazonS3Client.java/#L282,"private void addSummaryIfNotPresent(List<S3ObjectSummary> list,
      S3ObjectSummary item) {
    // Behavior of S3ObjectSummary
    String key = item.getKey();
    if (list.stream().noneMatch((member) -> member.getKey().equals(key))) {
      
---------------Reference log start----------------
LOG.debug(""Reinstate summary {}"", key)
---------------Reference log end----------------
      list.add(item);
    }",,
hadoop,921,"LOG.info(""Instantiating AHSWebApp at "" + getPort())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/ApplicationHistoryServer.java/#L318,"@SuppressWarnings(""unchecked"")
  private void startWebApp() {
    Configuration conf = getConfig();
    // Always load pseudo authentication filter to parse ""user.name"" in an URL
    // to identify a HTTP request's user in insecure mode.
    // When Kerberos authentication type is set (i.e., secure mode is turned on),
    // the customized filter will be loaded by the timeline server to do Kerberos
    // + DT authentication.
    String initializers = conf.get(""hadoop.http.filter.initializers"", """");
    Set<String> defaultInitializers = new LinkedHashSet<String>();
    // Add CORS filter
    if (!initializers.contains(CrossOriginFilterInitializer.class.getName())) {
      if(conf.getBoolean(YarnConfiguration.
          TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED,
          YarnConfiguration.
          TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED_DEFAULT)) {
        if (initializers.contains(
            HttpCrossOriginFilterInitializer.class.getName())) {
          initializers = initializers.replaceAll(
              HttpCrossOriginFilterInitializer.class.getName(),
              CrossOriginFilterInitializer.class.getName());
        } else {
          defaultInitializers.add(CrossOriginFilterInitializer.class.getName());
        }
      }
    }
    TimelineServerUtils.addTimelineAuthFilter(
        initializers, defaultInitializers, secretManagerService);
    TimelineServerUtils.setTimelineFilters(
        conf, initializers, defaultInitializers);
    String bindAddress = WebAppUtils.getWebAppBindURL(conf,
                          YarnConfiguration.TIMELINE_SERVICE_BIND_HOST,
                          WebAppUtils.getAHSWebAppURLWithoutScheme(conf));
    try {
      AHSWebApp ahsWebApp =
          new AHSWebApp(timelineDataManager, ahsClientService);
      webApp =
          WebApps
            .$for(""applicationhistory"", ApplicationHistoryClientService.class,
                ahsClientService, ""ws"")
             .with(conf)
              .withAttribute(YarnConfiguration.TIMELINE_SERVICE_WEBAPP_ADDRESS,
                 conf.get(YarnConfiguration.TIMELINE_SERVICE_WEBAPP_ADDRESS))
              .withCSRFProtection(YarnConfiguration.TIMELINE_CSRF_PREFIX)
              .withXFSProtection(YarnConfiguration.TIMELINE_XFS_PREFIX)
              .at(bindAddress).build(ahsWebApp);
       HttpServer2 httpServer = webApp.httpServer();

       String[] names = conf.getTrimmedStrings(
           YarnConfiguration.TIMELINE_SERVICE_UI_NAMES);
       WebAppContext webAppContext = httpServer.getWebAppContext();

      for (String name : names) {
        String webPath = conf.get(
            YarnConfiguration.TIMELINE_SERVICE_UI_WEB_PATH_PREFIX + name);
        String onDiskPath = conf.get(
            YarnConfiguration.TIMELINE_SERVICE_UI_ON_DISK_PATH_PREFIX + name);
        WebAppContext uiWebAppContext = new WebAppContext();
        uiWebAppContext.setContextPath(webPath);
        if (onDiskPath.endsWith("".war"")) {
          uiWebAppContext.setWar(onDiskPath);
        } else {
          uiWebAppContext.setResourceBase(onDiskPath);
        }
        final String[] ALL_URLS = {""/*""};
        FilterHolder[] filterHolders =
            webAppContext.getServletHandler().getFilters();
        for (FilterHolder filterHolder : filterHolders) {
          if (!""guice"".equals(filterHolder.getName())) {
            HttpServer2.defineFilter(uiWebAppContext, filterHolder.getName(),
                filterHolder.getClassName(), filterHolder.getInitParameters(),
                ALL_URLS);
          }
        }
        LOG.info(""Hosting "" + name + "" from "" + onDiskPath + "" at "" + webPath);
        httpServer.addHandlerAtFront(uiWebAppContext);
      }
       httpServer.start();
       conf.updateConnectAddr(YarnConfiguration.TIMELINE_SERVICE_BIND_HOST,
        YarnConfiguration.TIMELINE_SERVICE_WEBAPP_ADDRESS,
        YarnConfiguration.DEFAULT_TIMELINE_SERVICE_WEBAPP_ADDRESS,
        this.getListenerAddress());
       
---------------Reference log start----------------
LOG.info(""Instantiating AHSWebApp at "" + getPort())
---------------Reference log end----------------
    } catch (Exception e) {
      String msg = ""AHSWebApp failed to start."";
      LOG.error(msg, e);
      throw new YarnRuntimeException(msg, e);
    }
  }",,
hadoop,2077,"LOG.debug(""Did not load local image to hash file, "" + ""file is unmodified"")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/runc/ImageTagToManifestPlugin.java/#L151,"protected BufferedReader getLocalImageToHashReader() throws IOException {
    if (localImageTagToHashFile == null) {
      LOG.debug(""Did not load local image to hash file, "" +
          ""file is null"");
      return null;
    }

    File imageTagToHashFile = new File(localImageTagToHashFile);
    if(!imageTagToHashFile.exists()) {
      LOG.debug(""Did not load local image to hash file, "" +
          ""file doesn't exist"");
      return null;
    }

    long newLocalModTime = imageTagToHashFile.lastModified();
    if (newLocalModTime == localModTime) {
      
---------------Reference log start----------------
LOG.debug(""Did not load local image to hash file, "" + ""file is unmodified"")
---------------Reference log end----------------
      return null;
    }
    localModTime = newLocalModTime;

    return new BufferedReader(new InputStreamReader(
        new FileInputStream(imageTagToHashFile), StandardCharsets.UTF_8));
  }",,
hadoop,11532,"LOG.info(""mv  "" + srcObject + "" "" + targetPath)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-openstack/src/main/java/org/apache/hadoop/fs/swift/snative/SwiftNativeFileSystemStore.java/#L665,"public void rename(Path src, Path dst)
    throws FileNotFoundException, SwiftOperationFailedException, IOException {
    if (LOG.isDebugEnabled()) {
      LOG.debug(""mv "" + src + "" "" + dst);
    }
    boolean renamingOnToSelf = src.equals(dst);

    SwiftObjectPath srcObject = toObjectPath(src);
    SwiftObjectPath destObject = toObjectPath(dst);

    if (SwiftUtils.isRootDir(srcObject)) {
      throw new SwiftOperationFailedException(""cannot rename root dir"");
    }

    final SwiftFileStatus srcMetadata;
    srcMetadata = getObjectMetadata(src);
    SwiftFileStatus dstMetadata;
    try {
      dstMetadata = getObjectMetadata(dst);
    } catch (FileNotFoundException e) {
      //destination does not exist.
      LOG.debug(""Destination does not exist"");
      dstMetadata = null;
    }

    //check to see if the destination parent directory exists
    Path srcParent = src.getParent();
    Path dstParent = dst.getParent();
    //skip the overhead of a HEAD call if the src and dest share the same
    //parent dir (in which case the dest dir exists), or the destination
    //directory is root, in which case it must also exist
    if (dstParent != null && !dstParent.equals(srcParent)) {
      SwiftFileStatus fileStatus;
      try {
        fileStatus = getObjectMetadata(dstParent);
      } catch (FileNotFoundException e) {
        //destination parent doesn't exist; bail out
        LOG.debug(""destination parent directory "" + dstParent + "" doesn't exist"");
        throw e;
      }
      if (!fileStatus.isDir()) {
        throw new ParentNotDirectoryException(dstParent.toString());
      }
    }

    boolean destExists = dstMetadata != null;
    boolean destIsDir = destExists && SwiftUtils.isDirectory(dstMetadata);
    //calculate the destination
    SwiftObjectPath destPath;

    //enum the child entries and everything underneath
    List<FileStatus> childStats = listDirectory(srcObject, true, true);
    boolean srcIsFile = !srcMetadata.isDirectory();
    if (srcIsFile) {

      //source is a simple file OR a partitioned file
      // outcomes:
      // #1 dest exists and is file: fail
      // #2 dest exists and is dir: destination path becomes under dest dir
      // #3 dest does not exist: use dest as name
      if (destExists) {

        if (destIsDir) {
          //outcome #2 -move to subdir of dest
          destPath = toObjectPath(new Path(dst, src.getName()));
        } else {
          //outcome #1 dest it's a file: fail if different
          if (!renamingOnToSelf) {
            throw new FileAlreadyExistsException(
                    ""cannot rename a file over one that already exists"");
          } else {
            //is mv self self where self is a file. this becomes a no-op
            LOG.debug(""Renaming file onto self: no-op => success"");
            return;
          }
        }
      } else {
        //outcome #3 -new entry
        destPath = toObjectPath(dst);
      }
      int childCount = childStats.size();
      //here there is one of:
      // - a single object ==> standard file
      // ->
      if (childCount == 0) {
        copyThenDeleteObject(srcObject, destPath);
      } else {
        //do the copy
        SwiftUtils.debug(LOG, ""Source file appears to be partitioned."" +
                              "" copying file and deleting children"");

        copyObject(srcObject, destPath);
        for (FileStatus stat : childStats) {
          SwiftUtils.debug(LOG, ""Deleting partitioned file %s "", stat);
          deleteObject(stat.getPath());
        }

        swiftRestClient.delete(srcObject);
      }
    } else {

      //here the source exists and is a directory
      // outcomes (given we know the parent dir exists if we get this far)
      // #1 destination is a file: fail
      // #2 destination is a directory: create a new dir under that one
      // #3 destination doesn't exist: create a new dir with that name
      // #3 and #4 are only allowed if the dest path is not == or under src


      if (destExists && !destIsDir) {
        // #1 destination is a file: fail
        throw new FileAlreadyExistsException(
                ""the source is a directory, but not the destination"");
      }
      Path targetPath;
      if (destExists) {
        // #2 destination is a directory: create a new dir under that one
        targetPath = new Path(dst, src.getName());
      } else {
        // #3 destination doesn't exist: create a new dir with that name
        targetPath = dst;
      }
      SwiftObjectPath targetObjectPath = toObjectPath(targetPath);
      //final check for any recursive operations
      if (srcObject.isEqualToOrParentOf(targetObjectPath)) {
        //you can't rename a directory onto itself
        throw new SwiftOperationFailedException(
          ""cannot move a directory under itself"");
      }


      
---------------Reference log start----------------
LOG.info(""mv  "" + srcObject + "" "" + targetPath)
---------------Reference log end----------------

      logDirectory(""Directory to copy "", srcObject, childStats);

      // iterative copy of everything under the directory.
      // by listing all children this can be done iteratively
      // rather than recursively -everything in this list is either a file
      // or a 0-byte-len file pretending to be a directory.
      String srcURI = src.toUri().toString();
      int prefixStripCount = srcURI.length() + 1;
      for (FileStatus fileStatus : childStats) {
        Path copySourcePath = fileStatus.getPath();
        String copySourceURI = copySourcePath.toUri().toString();

        String copyDestSubPath = copySourceURI.substring(prefixStripCount);

        Path copyDestPath = new Path(targetPath, copyDestSubPath);
        if (LOG.isTraceEnabled()) {
          //trace to debug some low-level rename path problems; retained
          //in case they ever come back.
          LOG.trace(""srcURI="" + srcURI
                  + ""; copySourceURI="" + copySourceURI
                  + ""; copyDestSubPath="" + copyDestSubPath
                  + ""; copyDestPath="" + copyDestPath);
        }
        SwiftObjectPath copyDestination = toObjectPath(copyDestPath);

        try {
          copyThenDeleteObject(toObjectPath(copySourcePath),
                  copyDestination);
        } catch (FileNotFoundException e) {
          LOG.info(""Skipping rename of "" + copySourcePath);
        }
        //add a throttle delay
        throttle();
      }
      //now rename self. If missing, create the dest directory and warn
      if (!SwiftUtils.isRootDir(srcObject)) {
        try {
          copyThenDeleteObject(srcObject,
                  targetObjectPath);
        } catch (FileNotFoundException e) {
          //create the destination directory
          LOG.warn(""Source directory deleted during rename"", e);
          innerCreateDirectory(destObject);
        }
      }
    }
  }",,
hadoop,1729,"LOG.error(""Unknown resource reported: "" + req)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/ResourceLocalizationService.java/#L1163,"LocalizerHeartbeatResponse processHeartbeat(
        List<LocalResourceStatus> remoteResourceStatuses) {
      LocalizerHeartbeatResponse response =
        recordFactory.newRecordInstance(LocalizerHeartbeatResponse.class);
      String user = context.getUser();
      ApplicationId applicationId =
          context.getContainerId().getApplicationAttemptId().getApplicationId();

      boolean fetchFailed = false;
      // Update resource statuses.
      for (LocalResourceStatus stat : remoteResourceStatuses) {
        LocalResource rsrc = stat.getResource();
        LocalResourceRequest req = null;
        try {
          req = new LocalResourceRequest(rsrc);
        } catch (URISyntaxException e) {
          LOG.error(
              ""Got exception in parsing URL of LocalResource:""
                  + rsrc.getResource(), e);
          continue;
        }
        LocalizerResourceRequestEvent assoc = scheduled.get(req);
        if (assoc == null) {
          // internal error
          
---------------Reference log start----------------
LOG.error(""Unknown resource reported: "" + req)
---------------Reference log end----------------
          continue;
        }
        LocalResourcesTracker tracker =
            getLocalResourcesTracker(req.getVisibility(), user, applicationId);
        if (tracker == null) {
          // This is likely due to a race between heartbeat and
          // app cleaning up.
          continue;
        }
        switch (stat.getStatus()) {
          case FETCH_SUCCESS:
            // notify resource
            try {
              tracker.handle(new ResourceLocalizedEvent(req,
                  stat.getLocalPath().toPath(), stat.getLocalSize()));
            } catch (URISyntaxException e) { }

            // unlocking the resource and removing it from scheduled resource
            // list
            assoc.getResource().unlock();
            scheduled.remove(req);
            break;
          case FETCH_PENDING:
            break;
          case FETCH_FAILURE:
            final String diagnostics = stat.getException().toString();
            LOG.warn(""{} failed for {} : {}"", req, localizerId, diagnostics);
            fetchFailed = true;
            tracker.handle(new ResourceFailedLocalizationEvent(req,
                diagnostics));

            // unlocking the resource and removing it from scheduled resource
            // list
            assoc.getResource().unlock();
            scheduled.remove(req);
            break;
          default:
            LOG.info(""Unknown status: "" + stat.getStatus());
            fetchFailed = true;
            tracker.handle(new ResourceFailedLocalizationEvent(req,
                stat.getException().getMessage()));
            break;
        }
      }
      if (fetchFailed || killContainerLocalizer.get()) {
        response.setLocalizerAction(LocalizerAction.DIE);
        return response;
      }

      // Give the localizer resources for remote-fetching.
      List<ResourceLocalizationSpec> rsrcs =
          new ArrayList<ResourceLocalizationSpec>();

      /*
       * TODO : It doesn't support multiple downloads per ContainerLocalizer
       * at the same time. We need to think whether we should support this.
       */
      ResourceLocalizationSpec next = findNextResource(user, applicationId);
      if (next != null) {
        rsrcs.add(next);
      }

      response.setLocalizerAction(LocalizerAction.LIVE);
      response.setResourceSpecs(rsrcs);
      return response;
    }",,
hadoop,7835,"LOG.error(""Disk Balancer - "" + errorString)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java/#L435,"private void verifyTimeStamp(NodePlan plan) throws DiskBalancerException {
    long now = Time.now();
    long planTime = plan.getTimeStamp();

    if ((planTime + planValidityInterval) < now) {
      String planValidity = config.get(
          DFSConfigKeys.DFS_DISK_BALANCER_PLAN_VALID_INTERVAL,
          DFSConfigKeys.DFS_DISK_BALANCER_PLAN_VALID_INTERVAL_DEFAULT);
      if (planValidity.matches(""[0-9]$"")) {
        planValidity += ""ms"";
      }
      String errorString = ""Plan was generated more than "" + planValidity
          + "" ago"";
      
---------------Reference log start----------------
LOG.error(""Disk Balancer - "" + errorString)
---------------Reference log end----------------
      throw new DiskBalancerException(errorString,
          DiskBalancerException.Result.OLD_PLAN_SUBMITTED);
    }
  }",,
hadoop,988,"LOG.debug(""NoOpTimelineWriter is configured. Not storing "" + ""TimelineEntities."")",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/NoOpTimelineWriterImpl.java/#L62,"@Override
  public TimelineWriteResponse write(TimelineCollectorContext context,
                                     TimelineDomain domain) throws IOException {
    
---------------Reference log start----------------
LOG.debug(""NoOpTimelineWriter is configured. Not storing "" + ""TimelineEntities."")
---------------Reference log end----------------
    return new TimelineWriteResponse();
  }",,
hadoop,4996,"LOG.info("" Using ResourceCalculatorProcessTree : "" + pTree)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java/#L626,"public void initialize(JobConf job, JobID id, 
                         Reporter reporter,
                         boolean useNewApi) throws IOException, 
                                                   ClassNotFoundException,
                                                   InterruptedException {
    jobContext = new JobContextImpl(job, id, reporter);
    taskContext = new TaskAttemptContextImpl(job, taskId, reporter);
    if (getState() == TaskStatus.State.UNASSIGNED) {
      setState(TaskStatus.State.RUNNING);
    }
    if (useNewApi) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""using new api for output committer"");
      }
      outputFormat =
        ReflectionUtils.newInstance(taskContext.getOutputFormatClass(), job);
      committer = outputFormat.getOutputCommitter(taskContext);
    } else {
      committer = conf.getOutputCommitter();
    }
    Path outputPath = FileOutputFormat.getOutputPath(conf);
    if (outputPath != null) {
      if ((committer instanceof FileOutputCommitter)) {
        FileOutputFormat.setWorkOutputPath(conf, 
          ((FileOutputCommitter)committer).getTaskAttemptPath(taskContext));
      } else {
        FileOutputFormat.setWorkOutputPath(conf, outputPath);
      }
    }
    committer.setupTask(taskContext);
    Class<? extends ResourceCalculatorProcessTree> clazz =
        conf.getClass(MRConfig.RESOURCE_CALCULATOR_PROCESS_TREE,
            null, ResourceCalculatorProcessTree.class);
    pTree = ResourceCalculatorProcessTree
            .getResourceCalculatorProcessTree(System.getenv().get(""JVM_PID""), clazz, conf);
    
---------------Reference log start----------------
LOG.info("" Using ResourceCalculatorProcessTree : "" + pTree)
---------------Reference log end----------------
    if (pTree != null) {
      pTree.updateProcessTree();
      initCpuCumulativeTime = pTree.getCumulativeCpuTime();
    }
  }",,
hadoop,4953,"LOG.info(""task-diagnostic-info for task "" + taskid + "" : "" + diagnosticInfo)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/TaskStatus.java/#L134,"public void setDiagnosticInfo(String info) {
    // if the diag-info has already reached its max then log and return
    if (diagnosticInfo != null 
        && diagnosticInfo.length() == getMaxStringSize()) {
      LOG.info(""task-diagnostic-info for task "" + taskid + "" : "" + info);
      return;
    }
    diagnosticInfo = 
      ((diagnosticInfo == null) ? info : diagnosticInfo.concat(info)); 
    // trim the string to MAX_STRING_SIZE if needed
    if (diagnosticInfo != null 
        && diagnosticInfo.length() > getMaxStringSize()) {
      
---------------Reference log start----------------
LOG.info(""task-diagnostic-info for task "" + taskid + "" : "" + diagnosticInfo)
---------------Reference log end----------------
      diagnosticInfo = diagnosticInfo.substring(0, getMaxStringSize());
    }
  }",,
hadoop,348,"LOG.debug(""{}"", builder)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ServiceClient.java/#L1221,"private void printLocalResources(Map<String, LocalResource> map) {
    LOG.debug(""Added LocalResource for localization: "");
    StringBuilder builder = new StringBuilder();
    for (Map.Entry<String, LocalResource> entry : map.entrySet()) {
      builder.append(entry.getKey()).append("" -> "")
          .append(entry.getValue().getResource().getFile())
          .append(System.lineSeparator());
    }
    
---------------Reference log start----------------
LOG.debug(""{}"", builder)
---------------Reference log end----------------
  }
  }",,
hadoop,7209,"LOG.error(""Unexpected safe mode action"")",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java/#L5035,"boolean setSafeMode(SafeModeAction action) throws IOException {
    String operationName = action.toString().toLowerCase();
    boolean error = false;
    if (action != SafeModeAction.SAFEMODE_GET) {
      checkSuperuserPrivilege(operationName);
      switch(action) {
      case SAFEMODE_LEAVE: // leave safe mode
        leaveSafeMode(false);
        break;
      case SAFEMODE_ENTER: // enter safe mode
        enterSafeMode(false);
        break;
      case SAFEMODE_FORCE_EXIT:
        leaveSafeMode(true);
        break;
      default:
        
---------------Reference log start----------------
LOG.error(""Unexpected safe mode action"")
---------------Reference log end----------------
        error = true;
      }
    }
    if (!error) {
      logAuditEvent(true, operationName, null);
    }
    return isInSafeMode();
  }",,
hadoop,8143,"LOG.error(""Failed to initialize handler {}"", classes[i].toString())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/DatanodeHttpServer.java/#L292,"private ChannelHandler[] getFilterHandlers(Configuration configuration) {
    if (configuration == null) {
      return null;
    }
    // If the hdfs-site.xml has the proper configs for filter classes, use them.
    Class<?>[] classes =
        configuration.getClasses(
            DFSConfigKeys.DFS_DATANODE_HTTPSERVER_FILTER_HANDLERS);

    // else use the hard coded class from the default configuration.
    if (classes == null) {
      classes =
          configuration.getClasses(
              DFSConfigKeys.DFS_DATANODE_HTTPSERVER_FILTER_HANDLERS_DEFAULT);
    }

    // if we are not able to find any handlers, let us fail since running
    // with Csrf will is a security hole. Let us abort the startup.
    if(classes == null)  {
      return null;
    }

    ChannelHandler[] handlers = new ChannelHandler[classes.length];
    for (int i = 0; i < classes.length; i++) {
      LOG.debug(""Loading filter handler {}"", classes[i].getName());
      try {
        Method initializeState = classes[i].getDeclaredMethod(""initializeState"",
            Configuration.class);
        Constructor constructor =
            classes[i].getDeclaredConstructor(initializeState.getReturnType());
        handlers[i] = (ChannelHandler) constructor.newInstance(
            HANDLER_STATE.getOrDefault(classes[i],
            initializeState.invoke(null, configuration)));
      } catch (NoSuchMethodException | InvocationTargetException
          | IllegalAccessException | InstantiationException
          | IllegalArgumentException e) {
        
---------------Reference log start----------------
LOG.error(""Failed to initialize handler {}"", classes[i].toString())
---------------Reference log end----------------
        throw new RuntimeException(e);
      }
    }
    return (handlers);
  }",,
hadoop,7970,"LOG.info(""Starting DataNode with maxLockedMemory = {}"", dnConf.maxLockedMemory)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java/#L1426,"void startDataNode(List<StorageLocation> dataDirectories,
                     SecureResources resources
                     ) throws IOException {

    // settings global for all BPs in the Data Node
    this.secureResources = resources;
    synchronized (this) {
      this.dataDirs = dataDirectories;
    }
    this.dnConf = new DNConf(this);
    checkSecureConfig(dnConf, getConf(), resources);

    if (dnConf.maxLockedMemory > 0) {
      if (!NativeIO.POSIX.getCacheManipulator().verifyCanMlock()) {
        throw new RuntimeException(String.format(
            ""Cannot start datanode because the configured max locked memory"" +
            "" size (%s) is greater than zero and native code is not available."",
            DFS_DATANODE_MAX_LOCKED_MEMORY_KEY));
      }
      if (Path.WINDOWS) {
        NativeIO.Windows.extendWorkingSetSize(dnConf.maxLockedMemory);
      } else {
        long ulimit = NativeIO.POSIX.getCacheManipulator().getMemlockLimit();
        if (dnConf.maxLockedMemory > ulimit) {
          throw new RuntimeException(String.format(
            ""Cannot start datanode because the configured max locked memory"" +
            "" size (%s) of %d bytes is more than the datanode's available"" +
            "" RLIMIT_MEMLOCK ulimit of %d bytes."",
            DFS_DATANODE_MAX_LOCKED_MEMORY_KEY,
            dnConf.maxLockedMemory,
            ulimit));
        }
      }
    }
    
---------------Reference log start----------------
LOG.info(""Starting DataNode with maxLockedMemory = {}"", dnConf.maxLockedMemory)
---------------Reference log end----------------

    int volFailuresTolerated = dnConf.getVolFailuresTolerated();
    int volsConfigured = dnConf.getVolsConfigured();
    if (volFailuresTolerated < MAX_VOLUME_FAILURE_TOLERATED_LIMIT
        || volFailuresTolerated >= volsConfigured) {
      throw new HadoopIllegalArgumentException(""Invalid value configured for ""
          + ""dfs.datanode.failed.volumes.tolerated - "" + volFailuresTolerated
          + "". Value configured is either less than -1 or >= ""
          + ""to the number of configured volumes ("" + volsConfigured + "")."");
    }

    storage = new DataStorage();
    
    // global DN settings
    registerMXBean();
    initDataXceiver();
    startInfoServer();
    pauseMonitor = new JvmPauseMonitor();
    pauseMonitor.init(getConf());
    pauseMonitor.start();
  
    // BlockPoolTokenSecretManager is required to create ipc server.
    this.blockPoolTokenSecretManager = new BlockPoolTokenSecretManager();

    // Login is done by now. Set the DN user name.
    dnUserName = UserGroupInformation.getCurrentUser().getUserName();
    LOG.info(""dnUserName = {}"", dnUserName);
    LOG.info(""supergroup = {}"", supergroup);
    initIpcServer();

    metrics = DataNodeMetrics.create(getConf(), getDisplayName());
    peerMetrics = dnConf.peerStatsEnabled ?
        DataNodePeerMetrics.create(getDisplayName(), getConf()) : null;
    metrics.getJvmMetrics().setPauseMonitor(pauseMonitor);

    ecWorker = new ErasureCodingWorker(getConf(), this);
    blockRecoveryWorker = new BlockRecoveryWorker(this);

    blockPoolManager = new BlockPoolManager(this);
    blockPoolManager.refreshNamenodes(getConf());

    // Create the ReadaheadPool from the DataNode context so we can
    // exit without having to explicitly shutdown its thread pool.
    readaheadPool = ReadaheadPool.getInstance();
    saslClient = new SaslDataTransferClient(dnConf.getConf(),
        dnConf.saslPropsResolver, dnConf.trustedChannelResolver);
    saslServer = new SaslDataTransferServer(dnConf, blockPoolTokenSecretManager);
    startMetricsLogger();

    if (dnConf.diskStatsEnabled) {
      diskMetrics = new DataNodeDiskMetrics(this,
          dnConf.outliersReportIntervalMs, getConf());
    }
  }",,
hadoop,9165,"LOG.error(msg, e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java/#L222,"@Override
  public <T extends BaseRecord> QueryResult<T> get(Class<T> clazz)
      throws IOException {
    verifyDriverReady();
    long start = monotonicNow();
    StateStoreMetrics metrics = getMetrics();
    List<T> ret = new ArrayList<>();
    try {
      String path = getPathForClass(clazz);
      List<String> children = getChildren(path);
      for (String child : children) {
        String pathRecord = path + ""/"" + child;
        if (child.endsWith(TMP_MARK)) {
          LOG.debug(""There is a temporary file {} in {}"", child, path);
          if (isOldTempRecord(child)) {
            LOG.warn(""Removing {} as it's an old temporary record"", child);
            remove(pathRecord);
          }
        } else {
          T record = getRecord(pathRecord, clazz);
          ret.add(record);
        }
      }
    } catch (Exception e) {
      if (metrics != null) {
        metrics.addFailure(monotonicNow() - start);
      }
      String msg = ""Cannot fetch records for "" + clazz.getSimpleName();
      
---------------Reference log start----------------
LOG.error(msg, e)
---------------Reference log end----------------
      throw new IOException(msg, e);
    }

    if (metrics != null) {
      metrics.addRead(monotonicNow() - start);
    }
    return new QueryResult<T>(ret, getTime());
  }",,
hadoop,27,"LOG.debug(""Interrupted while waiting for queue"", ex)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/async/impl/AMRMClientAsyncImpl.java/#L355,"public void run() {
      while (true) {
        if (!keepRunning) {
          return;
        }
        try {
          Object object;
          try {
            object = responseQueue.take();
          } catch (InterruptedException ex) {
            
---------------Reference log start----------------
LOG.debug(""Interrupted while waiting for queue"", ex)
---------------Reference log end----------------
            Thread.currentThread().interrupt();
            continue;
          }
          if (object instanceof Throwable) {
            progress = handler.getProgress();
            handler.onError((Throwable) object);
            continue;
          }

          AllocateResponse response = (AllocateResponse) object;
          String collectorAddress = null;
          if (response.getCollectorInfo() != null) {
            collectorAddress = response.getCollectorInfo().getCollectorAddr();
          }

          TimelineV2Client timelineClient =
              client.getRegisteredTimelineV2Client();
          if (timelineClient != null && response.getCollectorInfo() != null) {
            timelineClient.
                setTimelineCollectorInfo(response.getCollectorInfo());
          }

          List<NodeReport> updatedNodes = response.getUpdatedNodes();
          if (!updatedNodes.isEmpty()) {
            handler.onNodesUpdated(updatedNodes);
          }

          List<ContainerStatus> completed =
              response.getCompletedContainersStatuses();
          if (!completed.isEmpty()) {
            handler.onContainersCompleted(completed);
          }

          if (handler instanceof AMRMClientAsync.AbstractCallbackHandler) {
            // RM side of the implementation guarantees that there are
            // no duplications between increased and decreased containers
            List<UpdatedContainer> changed = new ArrayList<>();
            changed.addAll(response.getUpdatedContainers());
            if (!changed.isEmpty()) {
              ((AMRMClientAsync.AbstractCallbackHandler) handler)
                  .onContainersUpdated(changed);
            }
          }

          List<Container> allocated = response.getAllocatedContainers();
          if (!allocated.isEmpty()) {
            handler.onContainersAllocated(allocated);
          }

          PreemptionMessage preemptionMessage = response.getPreemptionMessage();
          if (preemptionMessage != null) {
            if (handler instanceof AMRMClientAsync.AbstractCallbackHandler) {
              ((AMRMClientAsync.AbstractCallbackHandler) handler)
                  .onPreemptionMessageReceived(preemptionMessage);
            }
          }

          if (!response.getContainersFromPreviousAttempts().isEmpty()) {
            if (handler instanceof AMRMClientAsync.AbstractCallbackHandler) {
              ((AMRMClientAsync.AbstractCallbackHandler) handler)
                  .onContainersReceivedFromPreviousAttempts(
                      response.getContainersFromPreviousAttempts());
            }
          }
          List<RejectedSchedulingRequest> rejectedSchedulingRequests =
              response.getRejectedSchedulingRequests();
          if (!rejectedSchedulingRequests.isEmpty()) {
            if (handler instanceof AMRMClientAsync.AbstractCallbackHandler) {
              ((AMRMClientAsync.AbstractCallbackHandler) handler)
                  .onRequestsRejected(rejectedSchedulingRequests);
            }
          }
          progress = handler.getProgress();
        } catch (Throwable ex) {
          handler.onError(ex);
          // re-throw exception to end the thread
          throw new YarnRuntimeException(ex);
        }
      }
    }",,
hadoop,5862,DFSClient.LOG.warn(errMsg),warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java/#L1625,"@Override
  public synchronized void seek(long targetPos) throws IOException {
    if (targetPos > getFileLength()) {
      throw new EOFException(""Cannot seek after EOF"");
    }
    if (targetPos < 0) {
      throw new EOFException(""Cannot seek to negative offset"");
    }
    if (closed.get()) {
      throw new IOException(""Stream is closed!"");
    }
    boolean done = false;
    if (pos <= targetPos && targetPos <= blockEnd) {
      //
      // If this seek is to a positive position in the current
      // block, and this piece of data might already be lying in
      // the TCP buffer, then just eat up the intervening data.
      //
      int diff = (int)(targetPos - pos);
      if (diff <= blockReader.available()) {
        try {
          pos += blockReader.skip(diff);
          if (pos == targetPos) {
            done = true;
          } else {
            // The range was already checked. If the block reader returns
            // something unexpected instead of throwing an exception, it is
            // most likely a bug.
            String errMsg = ""BlockReader failed to seek to "" +
                targetPos + "". Instead, it seeked to "" + pos + ""."";
            
---------------Reference log start----------------
DFSClient.LOG.warn(errMsg)
---------------Reference log end----------------
            throw new IOException(errMsg);
          }
        } catch (IOException e) {//make following read to retry
          DFSClient.LOG.debug(""Exception while seek to {} from {} of {} from ""
              + ""{}"", targetPos, getCurrentBlock(), src, currentNode, e);
          checkInterrupted(e);
        }
      }
    }
    if (!done) {
      pos = targetPos;
      blockEnd = -1;
    }
  }",,
hadoop,4139,"LOG.info(""After major compaction for qualifier="" + Bytes.toString(CellUtil.cloneQualifier(sumCell)) + "" with currentColumnCells.size="" + currentColumnCells.size() + "" returning finalCells.size="" + finalCells.size() + "" with sum="" + sum.longValue() + "" with cell timestamp "" + sumCell.getTimestamp())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-server/hadoop-yarn-server-timelineservice-hbase-server-2/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/flow/FlowScanner.java/#L510,"@VisibleForTesting
  List<Cell> processSummationMajorCompaction(
      SortedSet<Cell> currentColumnCells, NumericValueConverter converter,
      long currentTimestamp)
      throws IOException {
    Number sum = 0;
    Number currentValue = 0;
    long ts = 0L;
    boolean summationDone = false;
    List<Cell> finalCells = new ArrayList<Cell>();
    if (currentColumnCells == null) {
      return finalCells;
    }

    LOG.debug(""In processSummationMajorCompaction, will drop cells older""
        + "" than {} CurrentColumnCells size={}"", currentTimestamp,
        currentColumnCells.size());

    for (Cell cell : currentColumnCells) {
      AggregationOperation cellAggOp = getCurrentAggOp(cell);
      // if this is the existing flow sum cell
      List<Tag> tags = HBaseTimelineServerUtils.convertCellAsTagList(cell);
      String appId = HBaseTimelineServerUtils
          .getAggregationCompactionDimension(tags);
      if (appId == FLOW_APP_ID) {
        sum = converter.add(sum, currentValue);
        summationDone = true;
        if (LOG.isTraceEnabled()) {
          LOG.trace(""reading flow app id sum="" + sum);
        }
      } else {
        currentValue = (Number) converter.decodeValue(CellUtil
            .cloneValue(cell));
        // read the timestamp truncated by the generator
        ts =  TimestampGenerator.getTruncatedTimestamp(cell.getTimestamp());
        if ((cellAggOp == AggregationOperation.SUM_FINAL)
            && ((ts + this.appFinalValueRetentionThreshold)
                < currentTimestamp)) {
          sum = converter.add(sum, currentValue);
          summationDone = true;
          if (LOG.isTraceEnabled()) {
            LOG.trace(""MAJOR COMPACTION loop sum= "" + sum
                + "" discarding now: "" + "" qualifier=""
                + Bytes.toString(CellUtil.cloneQualifier(cell)) + "" value=""
                + converter.decodeValue(CellUtil.cloneValue(cell))
                + "" timestamp="" + cell.getTimestamp() + "" "" + this.action);
          }
        } else {
          // not a final value but it's the latest cell for this app
          // so include this cell in the list of cells to write back
          finalCells.add(cell);
        }
      }
    }
    if (summationDone) {
      Cell anyCell = currentColumnCells.first();
      List<Tag> tags = new ArrayList<Tag>();
      Tag t = HBaseTimelineServerUtils.createTag(
          AggregationOperation.SUM_FINAL.getTagType(),
          Bytes.toBytes(FLOW_APP_ID));
      tags.add(t);
      t = HBaseTimelineServerUtils.createTag(
          AggregationCompactionDimension.APPLICATION_ID.getTagType(),
          Bytes.toBytes(FLOW_APP_ID));
      tags.add(t);
      byte[] tagByteArray =
          HBaseTimelineServerUtils.convertTagListToByteArray(tags);
      Cell sumCell = HBaseTimelineServerUtils.createNewCell(
          CellUtil.cloneRow(anyCell),
          CellUtil.cloneFamily(anyCell),
          CellUtil.cloneQualifier(anyCell),
          TimestampGenerator.getSupplementedTimestamp(
              System.currentTimeMillis(), FLOW_APP_ID),
              converter.encodeValue(sum), tagByteArray);
      finalCells.add(sumCell);
      if (LOG.isTraceEnabled()) {
        LOG.trace(""MAJOR COMPACTION final sum= "" + sum + "" for ""
            + Bytes.toString(CellUtil.cloneQualifier(sumCell))
            + "" "" + this.action);
      }
      
---------------Reference log start----------------
LOG.info(""After major compaction for qualifier="" + Bytes.toString(CellUtil.cloneQualifier(sumCell)) + "" with currentColumnCells.size="" + currentColumnCells.size() + "" returning finalCells.size="" + finalCells.size() + "" with sum="" + sum.longValue() + "" with cell timestamp "" + sumCell.getTimestamp())
---------------Reference log end----------------
    } else {
      String qualifier = """";
      LOG.info(""After major compaction for qualifier="" + qualifier
          + "" with currentColumnCells.size=""
          + currentColumnCells.size()
          + "" returning finalCells.size="" + finalCells.size()
          + "" with zero sum=""
          + sum.longValue());
    }
    return finalCells;
  }",,
hadoop,12779,"LOG.info(""Using pure-Java version of bzip2 library"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/bzip2/Bzip2Factory.java/#L54,"public static synchronized boolean isNativeBzip2Loaded(Configuration conf) {
    String libname = conf.get(""io.compression.codec.bzip2.library"", 
                              ""system-native"");
    if (!bzip2LibraryName.equals(libname)) {
      nativeBzip2Loaded = false;
      bzip2LibraryName = libname;
      if (libname.equals(""java-builtin"")) {
        
---------------Reference log start----------------
LOG.info(""Using pure-Java version of bzip2 library"")
---------------Reference log end----------------
      } else if (NativeCodeLoader.isNativeCodeLoaded()) {
        try {
          // Initialize the native library.
          Bzip2Compressor.initSymbols(libname);
          Bzip2Decompressor.initSymbols(libname);
          nativeBzip2Loaded = true;
          LOG.info(""Successfully loaded & initialized native-bzip2 library "" +
                   libname);
        } catch (Throwable t) {
          LOG.warn(""Failed to load/initialize native-bzip2 library "" + 
                   libname + "", will use pure-Java version"");
        }
      }
    }
    return nativeBzip2Loaded;
  }",,
hadoop,6116,"LOG.debug(""SASL encryption trust check: localHostTrusted = {}, "" + ""remoteHostTrusted = {}"", localTrusted, remoteTrusted)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/SaslDataTransferClient.java/#L230,"private IOStreamPair checkTrustAndSend(
      InetAddress addr, OutputStream underlyingOut, InputStream underlyingIn,
      DataEncryptionKeyFactory encryptionKeyFactory,
      Token<BlockTokenIdentifier> accessToken, DatanodeID datanodeId,
      SecretKey secretKey)
      throws IOException {
    boolean localTrusted = trustedChannelResolver.isTrusted();
    boolean remoteTrusted = trustedChannelResolver.isTrusted(addr);
    
---------------Reference log start----------------
LOG.debug(""SASL encryption trust check: localHostTrusted = {}, "" + ""remoteHostTrusted = {}"", localTrusted, remoteTrusted)
---------------Reference log end----------------
    if (!localTrusted || !remoteTrusted) {
      // The encryption key factory only returns a key if encryption is enabled.
      DataEncryptionKey encryptionKey =
          encryptionKeyFactory.newDataEncryptionKey();
      return send(addr, underlyingOut, underlyingIn, encryptionKey, accessToken,
          datanodeId, secretKey);
    } else {
      LOG.debug(
          ""SASL client skipping handshake on trusted connection for addr = {}, ""
              + ""datanodeId = {}"", addr, datanodeId);
      return null;
    }
  }",,
hadoop,2258,"LOG.info(""No interceptor pipeline for application {},"" + "" likely because its AM is not run in this node."", applicationId)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/amrmproxy/AMRMProxyService.java/#L566,"protected void stopApplication(ApplicationId applicationId) {
    Preconditions.checkArgument(applicationId != null,
        ""applicationId is null"");
    RequestInterceptorChainWrapper pipeline =
        this.applPipelineMap.remove(applicationId);

    if (pipeline == null) {
      
---------------Reference log start----------------
LOG.info(""No interceptor pipeline for application {},"" + "" likely because its AM is not run in this node."", applicationId)
---------------Reference log end----------------
    } else {
      // Remove the appAttempt in AMRMTokenSecretManager
      this.secretManager
          .applicationMasterFinished(pipeline.getApplicationAttemptId());

      LOG.info(""Stopping the request processing pipeline for application: ""
          + applicationId);
      try {
        pipeline.getRootInterceptor().shutdown();
      } catch (Throwable ex) {
        LOG.warn(
            ""Failed to shutdown the request processing pipeline for app:""
                + applicationId, ex);
      }

      // Remove the app context from NMSS after the interceptors are shutdown
      if (this.nmContext.getNMStateStore() != null) {
        try {
          this.nmContext.getNMStateStore()
              .removeAMRMProxyAppContext(pipeline.getApplicationAttemptId());
        } catch (IOException e) {
          LOG.error(""Error removing AMRMProxy application context for ""
              + applicationId, e);
        }
      }
    }
  }",,
hadoop,9009,"LOG.error(""Failed to start router"", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/DFSRouter.java/#L72,"public static void main(String[] argv) {
    if (DFSUtil.parseHelpArgument(argv, USAGE, System.out, true)) {
      System.exit(0);
    }

    try {
      StringUtils.startupShutdownMessage(Router.class, argv, LOG);

      Router router = new Router();

      ShutdownHookManager.get().addShutdownHook(
          new CompositeServiceShutdownHook(router), SHUTDOWN_HOOK_PRIORITY);

      Configuration conf = new HdfsConfiguration();
      router.init(conf);
      router.start();
    } catch (Throwable e) {
      
---------------Reference log start----------------
LOG.error(""Failed to start router"", e)
---------------Reference log end----------------
      terminate(1, e);
    }
  }",,
hadoop,4739,"LOG.info(""Killing map task "" + task.getID())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl.java/#L2106,"private void checkReadyForCompletionWhenAllReducersDone(JobImpl job) {
      if (job.finishJobWhenReducersDone) {
        int totalReduces = job.getTotalReduces();
        int completedReduces = job.getCompletedReduces();

        if (totalReduces > 0 && totalReduces == completedReduces
            && !job.completingJob) {

          for (TaskId mapTaskId : job.mapTasks) {
            MapTaskImpl task = (MapTaskImpl) job.tasks.get(mapTaskId);
            if (!task.isFinished()) {
              
---------------Reference log start----------------
LOG.info(""Killing map task "" + task.getID())
---------------Reference log end----------------
              job.eventHandler.handle(
                  new TaskEvent(task.getID(), TaskEventType.T_KILL));
            }
          }

          job.completingJob = true;
        }
      }
    }",,
hadoop,5808,"LOG.debug(""Change nextOffset (after trim) to {}"", nextOffset.get())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java/#L1005,"private synchronized WriteCtx offerNextToWrite() {
    if (pendingWrites.isEmpty()) {
      LOG.debug(""The async write task has no pending writes, fileId: {}"",
          latestAttr.getFileId());
      // process pending commit again to handle this race: a commit is added
      // to pendingCommits map just after the last doSingleWrite returns.
      // There is no pending write and the commit should be handled by the
      // last doSingleWrite. Due to the race, the commit is left along and
      // can't be processed until cleanup. Therefore, we should do another
      // processCommits to fix the race issue.
      processCommits(nextOffset.get()); // nextOffset has same value as
                                        // flushedOffset
      this.asyncStatus = false;
      return null;
    } 

    Entry<OffsetRange, WriteCtx> lastEntry = pendingWrites.lastEntry();
    OffsetRange range = lastEntry.getKey();
    WriteCtx toWrite = lastEntry.getValue();

    LOG.trace(""range.getMin()={} nextOffset={}"",
        range.getMin(), nextOffset);

    long offset = nextOffset.get();
    if (range.getMin() > offset) {
      LOG.debug(""The next sequential write has not arrived yet"");
      processCommits(nextOffset.get()); // handle race
      this.asyncStatus = false;
    } else if (range.getMax() <= offset) {
      LOG.debug(""Remove write {} which is already written from the list"",
          range);
      // remove the WriteCtx from cache
      pendingWrites.remove(range);
    } else if (range.getMin() < offset && range.getMax() > offset) {
      LOG.warn(""Got an overlapping write {}, nextOffset={}. "" +
          ""Remove and trim it"", range, offset);
      pendingWrites.remove(range);
      trimWriteRequest(toWrite, offset);
      // update nextOffset
      nextOffset.addAndGet(toWrite.getCount());
      
---------------Reference log start----------------
LOG.debug(""Change nextOffset (after trim) to {}"", nextOffset.get())
---------------Reference log end----------------
      return toWrite;
    } else {
      LOG.debug(""Remove write {} from the list"", range);
      // after writing, remove the WriteCtx from cache
      pendingWrites.remove(range);
      // update nextOffset
      nextOffset.addAndGet(toWrite.getCount());
      LOG.debug(""Change nextOffset to {}"", nextOffset.get());
      return toWrite;
    }
    return null;
  }",,
hadoop,12800,LOG.trace(t.getMessage()),trace,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/FastByteComparisons.java/#L97,"static Comparer<byte[]> getBestComparer() {
      if (System.getProperty(""os.arch"").toLowerCase().startsWith(""sparc"")) {
        if (LOG.isTraceEnabled()) {
          LOG.trace(""Lexicographical comparer selected for ""
              + ""byte aligned system architecture"");
        }
        return lexicographicalComparerJavaImpl();
      }
      try {
        Class<?> theClass = Class.forName(UNSAFE_COMPARER_NAME);

        // yes, UnsafeComparer does implement Comparer<byte[]>
        @SuppressWarnings(""unchecked"")
        Comparer<byte[]> comparer =
          (Comparer<byte[]>) theClass.getEnumConstants()[0];
        if (LOG.isTraceEnabled()) {
          LOG.trace(""Unsafe comparer selected for ""
              + ""byte unaligned system architecture"");
        }
        return comparer;
      } catch (Throwable t) { // ensure we really catch *everything*
        if (LOG.isTraceEnabled()) {
          
---------------Reference log start----------------
LOG.trace(t.getMessage())
---------------Reference log end----------------
          LOG.trace(""Lexicographical comparer selected"");
        }
        return lexicographicalComparerJavaImpl();
      }
    }",,
hadoop,915,"LOG.error(""Error when writing finish information of container "" + containerFinish.getContainerId(), e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/applicationhistoryservice/FileSystemApplicationHistoryStore.java/#L549,"@Override
  public void containerFinished(ContainerFinishData containerFinish)
      throws IOException {
    HistoryFileWriter hfWriter =
        getHistoryFileWriter(containerFinish.getContainerId()
          .getApplicationAttemptId().getApplicationId());
    assert containerFinish instanceof ContainerFinishDataPBImpl;
    try {
      hfWriter.writeHistoryData(new HistoryDataKey(containerFinish
        .getContainerId().toString(), FINISH_DATA_SUFFIX),
        ((ContainerFinishDataPBImpl) containerFinish).getProto().toByteArray());
      LOG.info(""Finish information of container ""
          + containerFinish.getContainerId() + "" is written"");
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.error(""Error when writing finish information of container "" + containerFinish.getContainerId(), e)
---------------Reference log end----------------
    }
  }",,
hadoop,7848,"LOG.error(""No movable source blocks found. {}"", item.toJson())",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java/#L973,"ExtendedBlock getNextBlock(List<FsVolumeSpi.BlockIterator> poolIters,
                               DiskBalancerWorkItem item) {
      Preconditions.checkNotNull(poolIters);
      int currentCount = 0;
      ExtendedBlock block = null;
      while (block == null && currentCount < poolIters.size()) {
        currentCount++;
        int index = poolIndex++ % poolIters.size();
        FsVolumeSpi.BlockIterator currentPoolIter = poolIters.get(index);
        block = getBlockToCopy(currentPoolIter, item);
      }

      if (block == null) {
        try {
          item.setErrMsg(""No source blocks found to move."");
          
---------------Reference log start----------------
LOG.error(""No movable source blocks found. {}"", item.toJson())
---------------Reference log end----------------
        } catch (IOException e) {
          LOG.error(""Unable to get json from Item."");
        }
      }
      return block;
    }",,
hadoop,1070,"LOG.debug(""Got the information about the specified SubCluster {}"", subClusterInfo)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java/org/apache/hadoop/yarn/server/federation/store/impl/SQLFederationStateStore.java/#L442,"@Override
  public GetSubClusterInfoResponse getSubCluster(
      GetSubClusterInfoRequest subClusterRequest) throws YarnException {

    // Input validator
    FederationMembershipStateStoreInputValidator.validate(subClusterRequest);

    CallableStatement cstmt = null;

    SubClusterInfo subClusterInfo = null;
    SubClusterId subClusterId = subClusterRequest.getSubClusterId();

    try {
      cstmt = getCallableStatement(CALL_SP_GET_SUBCLUSTER);
      cstmt.setString(1, subClusterId.getId());

      // Set the parameters for the stored procedure
      cstmt.registerOutParameter(2, java.sql.Types.VARCHAR);
      cstmt.registerOutParameter(3, java.sql.Types.VARCHAR);
      cstmt.registerOutParameter(4, java.sql.Types.VARCHAR);
      cstmt.registerOutParameter(5, java.sql.Types.VARCHAR);
      cstmt.registerOutParameter(6, java.sql.Types.TIMESTAMP);
      cstmt.registerOutParameter(7, java.sql.Types.VARCHAR);
      cstmt.registerOutParameter(8, java.sql.Types.BIGINT);
      cstmt.registerOutParameter(9, java.sql.Types.VARCHAR);

      // Execute the query
      long startTime = clock.getTime();
      cstmt.execute();
      long stopTime = clock.getTime();

      String amRMAddress = cstmt.getString(2);
      String clientRMAddress = cstmt.getString(3);
      String rmAdminAddress = cstmt.getString(4);
      String webAppAddress = cstmt.getString(5);

      // first check if the subCluster exists
      if((amRMAddress == null) || (clientRMAddress == null)) {
        LOG.warn(""The queried SubCluster: {} does not exist."", subClusterId);
        return null;
      }

      Timestamp heartBeatTimeStamp = cstmt.getTimestamp(6, utcCalendar);
      long lastHeartBeat =
          heartBeatTimeStamp != null ? heartBeatTimeStamp.getTime() : 0;

      SubClusterState state = SubClusterState.fromString(cstmt.getString(7));
      long lastStartTime = cstmt.getLong(8);
      String capability = cstmt.getString(9);

      subClusterInfo = SubClusterInfo.newInstance(subClusterId, amRMAddress,
          clientRMAddress, rmAdminAddress, webAppAddress, lastHeartBeat, state,
          lastStartTime, capability);

      FederationStateStoreClientMetrics
          .succeededStateStoreCall(stopTime - startTime);

      // Check if the output it is a valid subcluster
      try {
        FederationMembershipStateStoreInputValidator
            .checkSubClusterInfo(subClusterInfo);
      } catch (FederationStateStoreInvalidInputException e) {
        String errMsg =
            ""SubCluster "" + subClusterId.toString() + "" does not exist"";
        FederationStateStoreUtils.logAndThrowStoreException(LOG, errMsg);
      }
      
---------------Reference log start----------------
LOG.debug(""Got the information about the specified SubCluster {}"", subClusterInfo)
---------------Reference log end----------------
    } catch (SQLException e) {
      FederationStateStoreClientMetrics.failedStateStoreCall();
      FederationStateStoreUtils.logAndThrowRetriableException(LOG,
          ""Unable to obtain the SubCluster information for "" + subClusterId, e);
    } finally {
      // Return to the pool the CallableStatement
      FederationStateStoreUtils.returnToPool(LOG, cstmt);
    }
    return GetSubClusterInfoResponse.newInstance(subClusterInfo);
  }",,
hadoop,2071,"LOG.warn(""Unable to write docker command to "" + cmdDir)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/linux/runtime/docker/DockerClient.java/#L126,"public String writeCommandToTempFile(DockerCommand cmd,
      ContainerId containerId, Context nmContext)
      throws ContainerExecutionException {
    String filePrefix = containerId.toString();
    ApplicationId appId = containerId.getApplicationAttemptId()
        .getApplicationId();
    File dockerCommandFile;
    File cmdDir = null;

    if(nmContext == null || nmContext.getLocalDirsHandler() == null) {
      throw new ContainerExecutionException(
          ""Unable to write temporary docker command"");
    }

    try {
      String cmdDirPath = nmContext.getLocalDirsHandler().getLocalPathForWrite(
          ResourceLocalizationService.NM_PRIVATE_DIR + Path.SEPARATOR +
          appId + Path.SEPARATOR + filePrefix + Path.SEPARATOR).toString();
      cmdDir = new File(cmdDirPath);
      if (!cmdDir.mkdirs() && !cmdDir.exists()) {
        throw new IOException(""Cannot create container private directory ""
            + cmdDir);
      }
      dockerCommandFile = File.createTempFile(TMP_FILE_PREFIX + filePrefix,
          TMP_FILE_SUFFIX, cmdDir);
      try (
        Writer writer = new OutputStreamWriter(
            new FileOutputStream(dockerCommandFile.toString()), ""UTF-8"");
        PrintWriter printWriter = new PrintWriter(writer);
      ) {
        printWriter.println(""[docker-command-execution]"");
        for (Map.Entry<String, List<String>> entry :
            cmd.getDockerCommandWithArguments().entrySet()) {
          if (entry.getKey().contains(""="")) {
            throw new ContainerExecutionException(
                ""'=' found in entry for docker command file, key = "" + entry
                    .getKey() + ""; value = "" + entry.getValue());
          }
          String value = StringUtils.join("","", entry.getValue());
          if (value.contains(""\n"")) {
            throw new ContainerExecutionException(
                ""'\\n' found in entry for docker command file, key = "" + entry
                    .getKey() + ""; value = "" + value);
          }
          printWriter.println(""  "" + entry.getKey() + ""="" + value);
        }
        if (cmd instanceof DockerRunCommand) {
          DockerRunCommand runCommand = (DockerRunCommand) cmd;
          if (runCommand.containsEnv()) {
            String path = writeEnvFile(runCommand, filePrefix, cmdDir);
            printWriter.println(""  environ="" + path);
          }
        }
        return dockerCommandFile.toString();
      }
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.warn(""Unable to write docker command to "" + cmdDir)
---------------Reference log end----------------
      throw new ContainerExecutionException(e);
    }
  }",,
hadoop,3600,"LOG.info(""Transitioning RM to Standby mode"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceManager.java/#L1210,"@Override
    public void run() {
      // Run this only once, even if multiple threads end up triggering
      // this simultaneously.
      if (hasAlreadyRun.getAndSet(true)) {
        return;
      }

      if (rmContext.isHAEnabled()) {
        try {
          // Transition to standby and reinit active services
          
---------------Reference log start----------------
LOG.info(""Transitioning RM to Standby mode"")
---------------Reference log end----------------
          transitionToStandby(true);
          EmbeddedElector elector = rmContext.getLeaderElectorService();
          if (elector != null) {
            elector.rejoinElection();
          }
        } catch (Exception e) {
          LOG.error(FATAL, ""Failed to transition RM to Standby mode."", e);
          ExitUtil.terminate(1, e);
        }
      }
    }",,
hadoop,4066,"LOG.error(""Error in creating hbase tables: "", e)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-timelineservice-hbase/hadoop-yarn-server-timelineservice-hbase-client/src/main/java/org/apache/hadoop/yarn/server/timelineservice/storage/HBaseTimelineSchemaCreator.java/#L282,"private static void createAllSchemas(Configuration hbaseConf,
      boolean skipExisting) {
    List<Exception> exceptions = new ArrayList<>();
    try {
      if (skipExisting) {
        LOG.info(""Will skip existing tables and continue on htable creation ""
            + ""exceptions!"");
      }
      createAllTables(hbaseConf, skipExisting);
      LOG.info(""Successfully created HBase schema. "");
    } catch (IOException e) {
      
---------------Reference log start----------------
LOG.error(""Error in creating hbase tables: "", e)
---------------Reference log end----------------
      exceptions.add(e);
    }

    if (exceptions.size() > 0) {
      LOG.warn(""Schema creation finished with the following exceptions"");
      for (Exception e : exceptions) {
        LOG.warn(e.getMessage());
      }
      System.exit(-1);
    } else {
      LOG.info(""Schema creation finished successfully"");
    }
  }",,
hadoop,784,"LOG.error(""Error putting related entity "" + relatedEntity.getId() + "" of type "" + relatedEntity.getType() + "" for entity "" + entity.getEntityId() + "" of type "" + entity.getEntityType(), de)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice/src/main/java/org/apache/hadoop/yarn/server/timeline/LeveldbTimelineStore.java/#L954,"private void put(TimelineEntity entity, TimelinePutResponse response,
      boolean allowEmptyDomainId) {
    LockMap.CountingReentrantLock<EntityIdentifier> lock =
        writeLocks.getLock(new EntityIdentifier(entity.getEntityId(),
            entity.getEntityType()));
    lock.lock();
    WriteBatch writeBatch = null;
    List<EntityIdentifier> relatedEntitiesWithoutStartTimes =
        new ArrayList<EntityIdentifier>();
    byte[] revStartTime = null;
    Map<String, Set<Object>> primaryFilters = null;
    try {
      writeBatch = db.createWriteBatch();
      List<TimelineEvent> events = entity.getEvents();
      // look up the start time for the entity
      StartAndInsertTime startAndInsertTime = getAndSetStartTime(
          entity.getEntityId(), entity.getEntityType(),
          entity.getStartTime(), events);
      if (startAndInsertTime == null) {
        // if no start time is found, add an error and return
        handleError(entity, response, TimelinePutError.NO_START_TIME);   
        return;
      }
      revStartTime = writeReverseOrderedLong(startAndInsertTime
          .startTime);

      primaryFilters = entity.getPrimaryFilters();

      // write entity marker
      byte[] markerKey = createEntityMarkerKey(entity.getEntityId(),
          entity.getEntityType(), revStartTime);
      byte[] markerValue = writeReverseOrderedLong(startAndInsertTime
          .insertTime);
      writeBatch.put(markerKey, markerValue);
      writePrimaryFilterEntries(writeBatch, primaryFilters, markerKey,
          markerValue);

      // write event entries
      if (events != null && !events.isEmpty()) {
        for (TimelineEvent event : events) {
          byte[] revts = writeReverseOrderedLong(event.getTimestamp());
          byte[] key = createEntityEventKey(entity.getEntityId(),
              entity.getEntityType(), revStartTime, revts,
              event.getEventType());
          byte[] value = GenericObjectMapper.write(event.getEventInfo());
          writeBatch.put(key, value);
          writePrimaryFilterEntries(writeBatch, primaryFilters, key, value);
        }
      }

      // write related entity entries
      Map<String, Set<String>> relatedEntities =
          entity.getRelatedEntities();
      if (relatedEntities != null && !relatedEntities.isEmpty()) {
        for (Entry<String, Set<String>> relatedEntityList :
            relatedEntities.entrySet()) {
          String relatedEntityType = relatedEntityList.getKey();
          for (String relatedEntityId : relatedEntityList.getValue()) {
            // invisible ""reverse"" entries (entity -> related entity)
            byte[] key = createReverseRelatedEntityKey(entity.getEntityId(),
                entity.getEntityType(), revStartTime, relatedEntityId,
                relatedEntityType);
            writeBatch.put(key, EMPTY_BYTES);
            // look up start time of related entity
            byte[] relatedEntityStartTime = getStartTime(relatedEntityId,
                relatedEntityType);
            // delay writing the related entity if no start time is found
            if (relatedEntityStartTime == null) {
              relatedEntitiesWithoutStartTimes.add(
                  new EntityIdentifier(relatedEntityId, relatedEntityType));
              continue;
            } else {
              // This is the existing entity
              byte[] domainIdBytes = db.get(createDomainIdKey(
                  relatedEntityId, relatedEntityType, relatedEntityStartTime));
              // The timeline data created by the server before 2.6 won't have
              // the domain field. We assume this timeline data is in the
              // default timeline domain.
              String domainId = null;
              if (domainIdBytes == null) {
                domainId = TimelineDataManager.DEFAULT_DOMAIN_ID;
              } else {
                domainId = new String(domainIdBytes, Charset.forName(""UTF-8""));
              }
              if (!domainId.equals(entity.getDomainId())) {
                // in this case the entity will be put, but the relation will be
                // ignored
                handleError(entity, response, TimelinePutError.FORBIDDEN_RELATION);
                continue;
              }
            }
            // write ""forward"" entry (related entity -> entity)
            key = createRelatedEntityKey(relatedEntityId,
                relatedEntityType, relatedEntityStartTime,
                entity.getEntityId(), entity.getEntityType());
            writeBatch.put(key, EMPTY_BYTES);
          }
        }
      }

      // write primary filter entries
      if (primaryFilters != null && !primaryFilters.isEmpty()) {
        for (Entry<String, Set<Object>> primaryFilter :
            primaryFilters.entrySet()) {
          for (Object primaryFilterValue : primaryFilter.getValue()) {
            byte[] key = createPrimaryFilterKey(entity.getEntityId(),
                entity.getEntityType(), revStartTime,
                primaryFilter.getKey(), primaryFilterValue);
            writeBatch.put(key, EMPTY_BYTES);
            writePrimaryFilterEntries(writeBatch, primaryFilters, key,
                EMPTY_BYTES);
          }
        }
      }

      // write other info entries
      Map<String, Object> otherInfo = entity.getOtherInfo();
      if (otherInfo != null && !otherInfo.isEmpty()) {
        for (Entry<String, Object> i : otherInfo.entrySet()) {
          byte[] key = createOtherInfoKey(entity.getEntityId(),
              entity.getEntityType(), revStartTime, i.getKey());
          byte[] value = GenericObjectMapper.write(i.getValue());
          writeBatch.put(key, value);
          writePrimaryFilterEntries(writeBatch, primaryFilters, key, value);
        }
      }

      // write domain id entry
      byte[] key = createDomainIdKey(entity.getEntityId(),
          entity.getEntityType(), revStartTime);
      if (entity.getDomainId() == null ||
          entity.getDomainId().length() == 0) {
        if (!allowEmptyDomainId) {
          handleError(entity, response, TimelinePutError.NO_DOMAIN);
          return;
        }
      } else {
        writeBatch.put(key, entity.getDomainId().getBytes(Charset.forName(""UTF-8"")));
        writePrimaryFilterEntries(writeBatch, primaryFilters, key,
            entity.getDomainId().getBytes(Charset.forName(""UTF-8"")));
      }
      db.write(writeBatch);
    } catch (DBException de) {
      LOG.error(""Error putting entity "" + entity.getEntityId() +
                "" of type "" + entity.getEntityType(), de);
      handleError(entity, response, TimelinePutError.IO_EXCEPTION);
    } catch (IOException e) {
      LOG.error(""Error putting entity "" + entity.getEntityId() +
          "" of type "" + entity.getEntityType(), e);
      handleError(entity, response, TimelinePutError.IO_EXCEPTION);
    } finally {
      lock.unlock();
      writeLocks.returnLock(lock);
      IOUtils.cleanupWithLogger(LOG, writeBatch);
    }

    for (EntityIdentifier relatedEntity : relatedEntitiesWithoutStartTimes) {
      lock = writeLocks.getLock(relatedEntity);
      lock.lock();
      try {
        StartAndInsertTime relatedEntityStartAndInsertTime =
            getAndSetStartTime(relatedEntity.getId(), relatedEntity.getType(),
            readReverseOrderedLong(revStartTime, 0), null);
        if (relatedEntityStartAndInsertTime == null) {
          throw new IOException(""Error setting start time for related entity"");
        }
        byte[] relatedEntityStartTime = writeReverseOrderedLong(
            relatedEntityStartAndInsertTime.startTime);
          // This is the new entity, the domain should be the same
        byte[] key = createDomainIdKey(relatedEntity.getId(),
            relatedEntity.getType(), relatedEntityStartTime);
        db.put(key, entity.getDomainId().getBytes(Charset.forName(""UTF-8"")));
        db.put(createRelatedEntityKey(relatedEntity.getId(),
            relatedEntity.getType(), relatedEntityStartTime,
            entity.getEntityId(), entity.getEntityType()), EMPTY_BYTES);
        db.put(createEntityMarkerKey(relatedEntity.getId(),
            relatedEntity.getType(), relatedEntityStartTime),
            writeReverseOrderedLong(relatedEntityStartAndInsertTime
                .insertTime));
      } catch (DBException de) {
        
---------------Reference log start----------------
LOG.error(""Error putting related entity "" + relatedEntity.getId() + "" of type "" + relatedEntity.getType() + "" for entity "" + entity.getEntityId() + "" of type "" + entity.getEntityType(), de)
---------------Reference log end----------------
        handleError(entity, response, TimelinePutError.IO_EXCEPTION);
      } catch (IOException e) {
        LOG.error(""Error putting related entity "" + relatedEntity.getId() +
            "" of type "" + relatedEntity.getType() + "" for entity "" +
            entity.getEntityId() + "" of type "" + entity.getEntityType(), e);
        handleError(entity, response, TimelinePutError.IO_EXCEPTION);
      } finally {
        lock.unlock();
        writeLocks.returnLock(lock);
      }
    }
  }",,
hadoop,8675,"LOG.info(""Provided storage {} transitioning to state {}"", this, State.FAILED)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java/#L483,"@Override
    void setState(DatanodeStorage.State state) {
      if (state == State.FAILED) {
        // The state should change to FAILED only when there are no active
        // datanodes with PROVIDED storage.
        ProvidedDescriptor dn = (ProvidedDescriptor) getDatanodeDescriptor();
        if (dn.activeProvidedDatanodes() == 0) {
          
---------------Reference log start----------------
LOG.info(""Provided storage {} transitioning to state {}"", this, State.FAILED)
---------------Reference log end----------------
          super.setState(state);
        }
      } else {
        super.setState(state);
      }
    }",,
hadoop,7243,"LOG.info(""Disabled the erasure coding policy "" + name)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/ErasureCodingPolicyManager.java/#L418,"public synchronized boolean disablePolicy(String name) {
    ErasureCodingPolicyInfo info = policiesByName.get(name);
    if (info == null) {
      throw new HadoopIllegalArgumentException(""The policy name "" +
          name + "" does not exist"");
    }

    if (enabledPoliciesByName.containsKey(name)) {
      enabledPoliciesByName.remove(name);
      enabledPolicies =
          enabledPoliciesByName.values().toArray(new ErasureCodingPolicy[0]);
      info.setState(ErasureCodingPolicyState.DISABLED);
      
---------------Reference log start----------------
LOG.info(""Disabled the erasure coding policy "" + name)
---------------Reference log end----------------
      allPersistedPolicies.put(info.getPolicy().getId(),
          createPolicyInfo(info.getPolicy(),
              ErasureCodingPolicyState.DISABLED));
      return true;
    }
    return false;
  }",,
hadoop,9204,"LOG.debug(""Writing file: {}"", filename)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileImpl.java/#L131,"@Override
  protected <T extends BaseRecord> BufferedWriter getWriter(String filename) {
    BufferedWriter writer = null;
    try {
      
---------------Reference log start----------------
LOG.debug(""Writing file: {}"", filename)
---------------Reference log end----------------
      File file = new File(filename);
      FileOutputStream fos = new FileOutputStream(file, false);
      OutputStreamWriter osw =
          new OutputStreamWriter(fos, StandardCharsets.UTF_8);
      writer = new BufferedWriter(osw);
    } catch (IOException e) {
      LOG.error(""Cannot open write stream for record {}"", filename, e);
    }
    return writer;
  }",,
hadoop,11977,"LOG.warn(""Can't find user name for uid "" + uid + "". Use default user name "" + unknown)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/ShellBasedIdMapping.java/#L662,"synchronized public String getUserName(int uid, String unknown) {
    checkAndUpdateMaps();
    String uname = uidNameMap.get(uid);
    if (uname == null) {
      try {
        updateMapIncr(uid, false);
      } catch (Exception e) {        
      }
      uname = uidNameMap.get(uid);
      if (uname == null) {     
        
---------------Reference log start----------------
LOG.warn(""Can't find user name for uid "" + uid + "". Use default user name "" + unknown)
---------------Reference log end----------------
        uname = unknown;
      }
    }
    return uname;
  }",,
hadoop,12515,"LOG.info(""Adding a new node: "" + NodeBase.getPath(node))",info,https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/NetworkTopology.java/#L149,"public void add(Node node) {
    if (node==null) return;
    int newDepth = NodeBase.locationToDepth(node.getNetworkLocation()) + 1;
    netlock.writeLock().lock();
    try {
      if( node instanceof InnerNode ) {
        throw new IllegalArgumentException(
          ""Not allow to add an inner node: ""+NodeBase.getPath(node));
      }
      if ((depthOfAllLeaves != -1) && (depthOfAllLeaves != newDepth)) {
        LOG.error(""Error: can't add leaf node {} at depth {} to topology:{}\n"",
            NodeBase.getPath(node), newDepth, this);
        throw new InvalidTopologyException(""Failed to add "" + NodeBase.getPath(node) +
            "": You cannot have a rack and a non-rack node at the same "" +
            ""level of the network topology."");
      }
      Node rack = getNodeForNetworkLocation(node);
      if (rack != null && !(rack instanceof InnerNode)) {
        throw new IllegalArgumentException(""Unexpected data node "" 
                                           + node.toString() 
                                           + "" at an illegal network location"");
      }
      if (clusterMap.add(node)) {
        
---------------Reference log start----------------
LOG.info(""Adding a new node: "" + NodeBase.getPath(node))
---------------Reference log end----------------
        if (rack == null) {
          incrementRacks();
        }
        if (depthOfAllLeaves == -1) {
          depthOfAllLeaves = node.getLevel();
        }
      }
      LOG.debug(""NetworkTopology became:\n{}"", this);
    } finally {
      netlock.writeLock().unlock();
    }
  }",,
hadoop,9242,"LOG.error(""Cannot locate eligible NNs for {}"", bpId)",error,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/resolver/MembershipNamenodeResolver.java/#L240,"@Override
  public List<? extends FederationNamenodeContext> getNamenodesForBlockPoolId(
      final String bpId) throws IOException {

    List<? extends FederationNamenodeContext> ret = cacheBP.get(bpId);
    if (ret == null) {
      try {
        MembershipState partial = MembershipState.newInstance();
        partial.setBlockPoolId(bpId);
        GetNamenodeRegistrationsRequest request =
            GetNamenodeRegistrationsRequest.newInstance(partial);

        final List<MembershipState> result =
            getRecentRegistrationForQuery(request, true, false);
        if (result == null || result.isEmpty()) {
          
---------------Reference log start----------------
LOG.error(""Cannot locate eligible NNs for {}"", bpId)
---------------Reference log end----------------
        } else {
          cacheBP.put(bpId, result);
          ret = result;
        }
      } catch (StateStoreUnavailableException e) {
        LOG.error(""Cannot get active NN for {}, State Store unavailable"", bpId);
        return null;
      }
    }
    if (ret == null) {
      return null;
    }
    return Collections.unmodifiableList(ret);
  }",,
hadoop,10267,"LOG.info(""Initializing ApplicationMaster"")",info,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/ApplicationMaster.java/#L178,"public static void main(String[] args) {
    boolean result = false;
    try {
      ApplicationMaster appMaster = new ApplicationMaster();
      
---------------Reference log start----------------
LOG.info(""Initializing ApplicationMaster"")
---------------Reference log end----------------
      boolean doRun = appMaster.init(args);
      if (!doRun) {
        System.exit(0);
      }
      result = appMaster.run();
    } catch (Throwable t) {
      LOG.error(""Error running ApplicationMaster"", t);
      System.exit(1);
    }
    if (result) {
      LOG.info(""Application Master completed successfully. exiting"");
      System.exit(0);
    } else {
      LOG.info(""Application Master failed. exiting"");
      System.exit(2);
    }
  }",,
hadoop,2898,"LOG.info(""Killing container "" + container)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fifo/FifoScheduler.java/#L992,"@VisibleForTesting
  @Override
  public void killContainer(RMContainer container) {
    ContainerStatus status = SchedulerUtils.createKilledContainerStatus(
        container.getContainerId(),
        ""Killed by RM to simulate an AM container failure"");
    
---------------Reference log start----------------
LOG.info(""Killing container "" + container)
---------------Reference log end----------------
    completedContainer(container, status, RMContainerEventType.KILL);
  }",,
hadoop,3166,"LOG.info(""Application '"" + applicationId + ""' is submitted without priority "" + ""hence considering default queue/cluster priority: "" + appPriority.getPriority())",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java/#L2871,"@Override
  public Priority checkAndGetApplicationPriority(
          Priority priorityRequestedByApp, UserGroupInformation user,
          String queuePath, ApplicationId applicationId) throws YarnException {
    readLock.lock();
    try {
      Priority appPriority = priorityRequestedByApp;

      // Verify the scenario where priority is null from submissionContext.
      if (null == appPriority) {
        // Verify whether submitted user has any default priority set. If so,
        // user's default priority will get precedence over queue default.
        // for updateApplicationPriority call flow, this check is done in
        // CientRMService itself.
        appPriority = this.appPriorityACLManager.getDefaultPriority(
            normalizeQueueName(queuePath),
            user);

        // Get the default priority for the Queue. If Queue is non-existent,
        // then
        // use default priority. Do it only if user doesn't have any default.
        if (null == appPriority) {
          appPriority = this.queueManager.getDefaultPriorityForQueue(
              normalizeQueueName(queuePath));
        }

        
---------------Reference log start----------------
LOG.info(""Application '"" + applicationId + ""' is submitted without priority "" + ""hence considering default queue/cluster priority: "" + appPriority.getPriority())
---------------Reference log end----------------
      }

      // Verify whether submitted priority is lesser than max priority
      // in the cluster. If it is out of found, defining a max cap.
      if (appPriority.getPriority() > getMaxClusterLevelAppPriority()
          .getPriority()) {
        appPriority = Priority
            .newInstance(getMaxClusterLevelAppPriority().getPriority());
      }

      // Lets check for ACLs here.
      if (!appPriorityACLManager.checkAccess(user, normalizeQueueName(queuePath), appPriority)) {
        throw new YarnException(new AccessControlException(
                ""User "" + user + "" does not have permission to submit/update ""
                        + applicationId + "" for "" + appPriority));
      }

      LOG.info(""Priority '"" + appPriority.getPriority()
          + ""' is acceptable in queue : "" + queuePath + "" for application: ""
          + applicationId);

      return appPriority;
    } finally {
      readLock.unlock();
    }
  }",,
hadoop,4042,"LOG.debug(""getNewApplication try #{} on SubCluster {}"", i, subClusterId)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationInterceptorREST.java/#L296,"@Override
  public Response createNewApplication(HttpServletRequest hsr)
      throws AuthorizationException, IOException, InterruptedException {

    long startTime = clock.getTime();

    Map<SubClusterId, SubClusterInfo> subClustersActive;
    try {
      subClustersActive = federationFacade.getSubClusters(true);
    } catch (YarnException e) {
      routerMetrics.incrAppsFailedCreated();
      return Response.status(Status.INTERNAL_SERVER_ERROR)
          .entity(e.getLocalizedMessage()).build();
    }

    List<SubClusterId> blacklist = new ArrayList<SubClusterId>();

    for (int i = 0; i < numSubmitRetries; ++i) {

      SubClusterId subClusterId;
      try {
        subClusterId = getRandomActiveSubCluster(subClustersActive, blacklist);
      } catch (YarnException e) {
        routerMetrics.incrAppsFailedCreated();
        return Response.status(Status.SERVICE_UNAVAILABLE)
            .entity(e.getLocalizedMessage()).build();
      }

      
---------------Reference log start----------------
LOG.debug(""getNewApplication try #{} on SubCluster {}"", i, subClusterId)
---------------Reference log end----------------

      DefaultRequestInterceptorREST interceptor =
          getOrCreateInterceptorForSubCluster(subClusterId,
              subClustersActive.get(subClusterId).getRMWebServiceAddress());
      Response response = null;
      try {
        response = interceptor.createNewApplication(hsr);
      } catch (Exception e) {
        LOG.warn(""Unable to create a new ApplicationId in SubCluster {}"",
            subClusterId.getId(), e);
      }

      if (response != null &&
          response.getStatus() == HttpServletResponse.SC_OK) {

        long stopTime = clock.getTime();
        routerMetrics.succeededAppsCreated(stopTime - startTime);

        return response;
      } else {
        // Empty response from the ResourceManager.
        // Blacklist this subcluster for this request.
        blacklist.add(subClusterId);
      }
    }

    String errMsg = ""Fail to create a new application."";
    LOG.error(errMsg);
    routerMetrics.incrAppsFailedCreated();
    return Response
        .status(Status.INTERNAL_SERVER_ERROR)
        .entity(errMsg)
        .build();
  }",,
hadoop,9899,"LOG.warn(""Unable to get key from credential providers. {}"", ioe)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SimpleKeyProvider.java/#L53,"@Override
  public String getStorageAccountKey(String accountName, Configuration rawConfig)
      throws KeyProviderException {
    String key = null;

    try {
      AbfsConfiguration abfsConfig = new AbfsConfiguration(rawConfig, accountName);
      key = abfsConfig.getPasswordString(ConfigurationKeys.FS_AZURE_ACCOUNT_KEY_PROPERTY_NAME);

      // Validating the key.
      validateStorageAccountKey(key);
    } catch (IllegalAccessException | InvalidConfigurationValueException e) {
      throw new KeyProviderException(""Failure to initialize configuration"", e);
    } catch(IOException ioe) {
      
---------------Reference log start----------------
LOG.warn(""Unable to get key from credential providers. {}"", ioe)
---------------Reference log end----------------
    }

    return key;
  }",,
hadoop,11004,"LOG.debug(""Requesting role {} with duration {}; policy = {}"", roleARN, duration, policy)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/auth/STSClientFactory.java/#L228,"@Retries.RetryTranslated
    public Credentials requestRole(
        final String roleARN,
        final String sessionName,
        final String policy,
        final long duration,
        final TimeUnit timeUnit) throws IOException {
      
---------------Reference log start----------------
LOG.debug(""Requesting role {} with duration {}; policy = {}"", roleARN, duration, policy)
---------------Reference log end----------------
      AssumeRoleRequest request = new AssumeRoleRequest();
      request.setDurationSeconds((int) timeUnit.toSeconds(duration));
      request.setRoleArn(roleARN);
      request.setRoleSessionName(sessionName);
      if (isNotEmpty(policy)) {
        request.setPolicy(policy);
      }
      return invoker.retry(""request role credentials"", """", true,
          () -> tokenService.assumeRole(request).getCredentials());
    }",,
hadoop,91,"LOG.warn(""Failed to fetch application attempt report from "" + ""ATS v2"", ex)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/api/impl/YarnClientImpl.java/#L831,"@Override
  public ApplicationAttemptReport getApplicationAttemptReport(
      ApplicationAttemptId appAttemptId) throws YarnException, IOException {
    try {
      GetApplicationAttemptReportRequest request = Records
          .newRecord(GetApplicationAttemptReportRequest.class);
      request.setApplicationAttemptId(appAttemptId);
      GetApplicationAttemptReportResponse response = rmClient
          .getApplicationAttemptReport(request);
      return response.getApplicationAttemptReport();
    } catch (YarnException e) {

      // Even if history-service is enabled, treat all exceptions still the same
      // except the following
      if (e.getClass() != ApplicationNotFoundException.class) {
        throw e;
      }
      if (timelineV2ServiceEnabled) {
        try {
          return ahsV2Client.getApplicationAttemptReport(appAttemptId);
        } catch (Exception ex) {
          
---------------Reference log start----------------
LOG.warn(""Failed to fetch application attempt report from "" + ""ATS v2"", ex)
---------------Reference log end----------------
        }
      }
      if (!historyServiceEnabled) {
        // Just throw it as usual if historyService is not enabled.
        throw e;
      }
      return historyClient.getApplicationAttemptReport(appAttemptId);
    }
  }",,
hadoop,11256,"LOG.debug(""Setting isAuthoritativeDir==false on {}"", ddbPathMetadata)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/s3guard/DynamoDBMetadataStore.java/#L1761,"private void removeAuthoritativeDirFlag(
      final Set<Path> pathSet,
      final AncestorState state) throws IOException {

    AtomicReference<IOException> rIOException = new AtomicReference<>();

    Set<DDBPathMetadata> metas = pathSet.stream().map(path -> {
      try {
        if (path.isRoot()) {
          LOG.debug(""ignoring root path"");
          return null;
        }
        if (state != null && state.get(path) != null) {
          // there's already an entry for this path
          LOG.debug(""Ignoring update of entry already in the state map"");
          return null;
        }
        DDBPathMetadata ddbPathMetadata = get(path);
        if (ddbPathMetadata == null) {
          // there is no entry.
          LOG.debug(""No parent {}; skipping"", path);
          return null;
        }
        if (ddbPathMetadata.isDeleted()) {
          // the parent itself is deleted
          LOG.debug(""Parent has been deleted {}; skipping"", path);
          return null;
        }
        if (!ddbPathMetadata.getFileStatus().isDirectory()) {
          // the parent itself is deleted
          LOG.debug(""Parent is not a directory {}; skipping"", path);
          return null;
        }
        
---------------Reference log start----------------
LOG.debug(""Setting isAuthoritativeDir==false on {}"", ddbPathMetadata)
---------------Reference log end----------------
        ddbPathMetadata.setAuthoritativeDir(false);
        ddbPathMetadata.setLastUpdated(ttlTimeProvider.getNow());
        return ddbPathMetadata;
      } catch (IOException e) {
        String msg = String.format(""IOException while getting PathMetadata ""
            + ""on path: %s."", path);
        LOG.error(msg, e);
        rIOException.set(e);
        return null;
      }
    }).filter(Objects::nonNull).collect(Collectors.toSet());

    try {
      LOG.debug(""innerPut on metas: {}"", metas);
      if (!metas.isEmpty()) {
        innerPut(metas, state);
      }
    } catch (IOException e) {
      String msg = String.format(""IOException while setting false ""
          + ""authoritative directory flag on: %s."", metas);
      LOG.error(msg, e);
      rIOException.set(e);
    }

    if (rIOException.get() != null) {
      throw rIOException.get();
    }
  }",,
hadoop,5035,"LOG.debug(""previousRange "" + previousRange)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/SortedRanges.java/#L144,"synchronized void remove(Range range) {
    if(range.isEmpty()) {
      return;
    }
    long startIndex = range.getStartIndex();
    long endIndex = range.getEndIndex();
    //make sure that there are no overlapping ranges
    SortedSet<Range> headSet = ranges.headSet(range);
    if(headSet.size()>0) {
      Range previousRange = headSet.last();
      
---------------Reference log start----------------
LOG.debug(""previousRange "" + previousRange)
---------------Reference log end----------------
      if(startIndex<previousRange.getEndIndex()) {
        //previousRange overlaps this range
        //narrow down the previousRange
        if(ranges.remove(previousRange)) {
          indicesCount-=previousRange.getLength();
          LOG.debug(""removed previousRange ""+previousRange);
        }
        add(previousRange.getStartIndex(), startIndex);
        if(endIndex<=previousRange.getEndIndex()) {
          add(endIndex, previousRange.getEndIndex());
        }
      }
    }
    
    Iterator<Range> tailSetIt = ranges.tailSet(range).iterator();
    while(tailSetIt.hasNext()) {
      Range nextRange = tailSetIt.next();
      LOG.debug(""nextRange ""+nextRange +""   startIndex:""+startIndex+
          ""  endIndex:""+endIndex);
      if(endIndex>nextRange.getStartIndex()) {
        //nextRange overlaps this range
        //narrow down the nextRange
        tailSetIt.remove();
        indicesCount-=nextRange.getLength();
        if(endIndex<nextRange.getEndIndex()) {
          add(endIndex, nextRange.getEndIndex());
          break;
        }
      } else {
        break;
      }
    }
  }",,
hadoop,397,"log.debug(""mkdir {} with perms {}"", dir, clusterPerms)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/CoreFileSystem.java/#L220,"@SuppressWarnings(""deprecation"")
  public void createWithPermissions(Path dir, FsPermission clusterPerms) throws
          IOException,
          BadClusterStateException {
    if (fileSystem.isFile(dir)) {
      // HADOOP-9361 shows some filesystems don't correctly fail here
      throw new BadClusterStateException(
              ""Cannot create a directory over a file %s"", dir);
    }
    
---------------Reference log start----------------
log.debug(""mkdir {} with perms {}"", dir, clusterPerms)
---------------Reference log end----------------
    //no mask whatoever
    fileSystem.getConf().set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY, ""000"");
    fileSystem.mkdirs(dir, clusterPerms);
    //and force set it anyway just to make sure
    fileSystem.setPermission(dir, clusterPerms);
  }",,
hadoop,4942,"LOG.warn(""Further groups got skipped."")",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/ReduceTask.java/#L275,"private void mayBeSkip() throws IOException {
       hasNext = skipIt.hasNext();
       if(!hasNext) {
         
---------------Reference log start----------------
LOG.warn(""Further groups got skipped."")
---------------Reference log end----------------
         return;
       }
       grpIndex++;
       long nextGrpIndex = skipIt.next();
       long skip = 0;
       long skipRec = 0;
       while(grpIndex<nextGrpIndex && super.more()) {
         while (hasNext()) {
           VALUE value = moveToNext();
           if(toWriteSkipRecs) {
             writeSkippedRec(getKey(), value);
           }
           skipRec++;
         }
         super.nextKey();
         grpIndex++;
         skip++;
       }
       
       //close the skip writer once all the ranges are skipped
       if(skip>0 && skipIt.skippedAllRanges() && skipWriter!=null) {
         skipWriter.close();
       }
       skipGroupCounter.increment(skip);
       skipRecCounter.increment(skipRec);
       reportNextRecordRange(umbilical, grpIndex);
     }",,
hadoop,6995,"LOG.warn(""Error during write properties to the VERSION file to {}"", sd, e)",warn,https://github.com/apache/hadoop/blob/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NNStorage.java/#L1171,"@Override
  public void writeAll() throws IOException {
    this.layoutVersion = getServiceLayoutVersion();
    for (StorageDirectory sd : getStorageDirs()) {
      try {
        writeProperties(sd);
      } catch (Exception e) {
        
---------------Reference log start----------------
LOG.warn(""Error during write properties to the VERSION file to {}"", sd, e)
---------------Reference log end----------------
        reportErrorsOnDirectory(sd);
        if (getStorageDirs().isEmpty()) {
          throw new IOException(""All the storage failed while writing "" +
              ""properties to VERSION file"");
        }
      }
    }
  }",,
hadoop,9480,"LOG.debug(""Summary: {} {}"", obj.getObjectKey(), obj.getMetadata().getContentLength())",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-cloud-storage-project/hadoop-huaweicloud/src/main/java/org/apache/hadoop/fs/obs/OBSObjectBucketUtils.java/#L842,"static ContentSummary getDirectoryContentSummary(final OBSFileSystem owner,
      final String key) throws IOException {
    String newKey = key;
    newKey = OBSCommonUtils.maybeAddTrailingSlash(newKey);
    long[] summary = {0, 0, 1};
    LOG.debug(""Summary key {}"", newKey);
    ListObjectsRequest request = new ListObjectsRequest();
    request.setBucketName(owner.getBucket());
    request.setPrefix(newKey);
    Set<String> directories = new TreeSet<>();
    request.setMaxKeys(owner.getMaxKeys());
    ObjectListing objects = OBSCommonUtils.listObjects(owner, request);
    while (true) {
      if (!objects.getCommonPrefixes().isEmpty() || !objects.getObjects()
          .isEmpty()) {
        if (LOG.isDebugEnabled()) {
          LOG.debug(""Found path as directory (with /): {}/{}"",
              objects.getCommonPrefixes().size(),
              objects.getObjects().size());
        }
        for (String prefix : objects.getCommonPrefixes()) {
          LOG.debug(""Objects in folder ["" + prefix + ""]:"");
          getDirectories(prefix, newKey, directories);
        }

        for (ObsObject obj : objects.getObjects()) {
          
---------------Reference log start----------------
LOG.debug(""Summary: {} {}"", obj.getObjectKey(), obj.getMetadata().getContentLength())
---------------Reference log end----------------
          if (!obj.getObjectKey().endsWith(""/"")) {
            summary[0] += obj.getMetadata().getContentLength();
            summary[1] += 1;
          }
          getDirectories(obj.getObjectKey(), newKey, directories);
        }
      }
      if (!objects.isTruncated()) {
        break;
      }
      objects = OBSCommonUtils.continueListObjects(owner, objects);
    }
    summary[2] += directories.size();
    LOG.debug(String.format(
        ""file size [%d] - file count [%d] - directory count [%d] - ""
            + ""file path [%s]"",
        summary[0],
        summary[1], summary[2], newKey));
    return new ContentSummary.Builder().length(summary[0])
        .fileCount(summary[1]).directoryCount(summary[2])
        .spaceConsumed(summary[0]).build();
  }",,
hadoop,3578,"LOG.info(""Using Scheduler: "" + schedulerClassName)",info,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceManager.java/#L521,"protected ResourceScheduler createScheduler() {
    String schedulerClassName = conf.get(YarnConfiguration.RM_SCHEDULER,
        YarnConfiguration.DEFAULT_RM_SCHEDULER);
    
---------------Reference log start----------------
LOG.info(""Using Scheduler: "" + schedulerClassName)
---------------Reference log end----------------
    try {
      Class<?> schedulerClazz = Class.forName(schedulerClassName);
      if (ResourceScheduler.class.isAssignableFrom(schedulerClazz)) {
        return (ResourceScheduler) ReflectionUtils.newInstance(schedulerClazz,
            this.conf);
      } else {
        throw new YarnRuntimeException(""Class: "" + schedulerClassName
            + "" not instance of "" + ResourceScheduler.class.getCanonicalName());
      }
    } catch (ClassNotFoundException e) {
      throw new YarnRuntimeException(""Could not instantiate Scheduler: ""
          + schedulerClassName, e);
    }
  }",,
hadoop,696,"LOG.debug(""Adding resource type - name = {}, units = {}, type = {}"", VCORES, ResourceInformation.VCORES.getUnits(), ResourceTypes.COUNTABLE)",debug,https://github.com/apache/hadoop/blob/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/util/resource/ResourceUtils.java/#L171,"private static void addMandatoryResources(
      Map<String, ResourceInformation> res) {
    ResourceInformation ri;
    if (!res.containsKey(MEMORY)) {
      LOG.debug(""Adding resource type - name = {}, units = {}, type = {}"",
          MEMORY, ResourceInformation.MEMORY_MB.getUnits(),
          ResourceTypes.COUNTABLE);
      ri = ResourceInformation.newInstance(MEMORY,
          ResourceInformation.MEMORY_MB.getUnits());
      res.put(MEMORY, ri);
    }
    if (!res.containsKey(VCORES)) {
      
---------------Reference log start----------------
LOG.debug(""Adding resource type - name = {}, units = {}, type = {}"", VCORES, ResourceInformation.VCORES.getUnits(), ResourceTypes.COUNTABLE)
---------------Reference log end----------------
      ri = ResourceInformation.newInstance(VCORES);
      res.put(VCORES, ri);
    }
  }",,
jmeter,13816,"log.debug(""Waiting infinitely for message"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/sampler/FixedQueueExecutor.java/#L97,"@Override
    public Message sendAndReceive(Message request,
            int deliveryMode,
            int priority,
            long expiration) throws JMSException {
        String id = request.getJMSCorrelationID();
        if(id == null && !useReqMsgIdAsCorrelId){
            throw new IllegalArgumentException(""Correlation id is null. Set the JMSCorrelationID header."");
        }
        final CountDownLatch countDownLatch = new CountDownLatch(1);
        final MessageAdmin admin = MessageAdmin.getAdmin();
        if(useReqMsgIdAsCorrelId) {// msgId not available until after send() is called
            // Note: there is only one admin object which is shared between all threads
            synchronized (admin) {// interlock with Receiver
                producer.send(request, deliveryMode, priority, expiration);
                id=request.getJMSMessageID();
                admin.putRequest(id, request, countDownLatch);
            }
        } else {
            admin.putRequest(id, request, countDownLatch);
            producer.send(request, deliveryMode, priority, expiration);
        }

        try {
            log.debug(""{} will wait for reply {} started on {}"",
                    Thread.currentThread().getName(), id, System.currentTimeMillis());

            // This used to be request.wait(timeout_ms), where 0 means forever
            // However 0 means return immediately for the latch
            if (timeout == 0){
                
---------------Reference log start----------------
log.debug(""Waiting infinitely for message"")
---------------Reference log end----------------
                countDownLatch.await(); //
            } else {
                if(!countDownLatch.await(timeout, TimeUnit.MILLISECONDS)) {
                    log.debug(""Timeout {} ms reached before getting a reply message"", timeout);
                }
            }
            log.debug(""{} done waiting for {} on {} ended on {}"",
                    Thread.currentThread().getName(),
                    id, request, System.currentTimeMillis());
        } catch (InterruptedException e) {
            log.warn(""Interrupt exception caught"", e);
            Thread.currentThread().interrupt();
        }
        return admin.get(id);
    }",,
jmeter,14261,"log.debug(""{} Running up named: {}"", Thread.currentThread().getName(), getName())",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/modifiers/UserParameters.java/#L149,"@SuppressWarnings(""SynchronizeOnNonFinalField"")
    private void setValues() {
        synchronized (lock) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""{} Running up named: {}"", Thread.currentThread().getName(), getName())
---------------Reference log end----------------
            }
            PropertyIterator namesIter = getNames().iterator();
            PropertyIterator valueIter = getValues().iterator();
            JMeterVariables jmvars = getThreadContext().getVariables();
            while (namesIter.hasNext() && valueIter.hasNext()) {
                String name = namesIter.next().getStringValue();
                String value = valueIter.next().getStringValue();
                if (log.isDebugEnabled()) {
                    log.debug(""{} saving variable: {}={}"", Thread.currentThread().getName(), name, value);//$NON-NLS-1$
                }
                jmvars.put(name, value);
            }
        }
    }",,
jmeter,13688,"log.debug(""Arg: {}"", arg)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L1217,"public void parseArguments(String queryString, String contentEncoding) {
        String[] args = JOrphanUtils.split(queryString, QRY_SEP);
        for (String arg : args) {
            
---------------Reference log start----------------
log.debug(""Arg: {}"", arg)
---------------Reference log end----------------
            // need to handle four cases:
            // - string contains name=value
            // - string contains name=
            // - string contains name
            // - empty string

            String metaData; // records the existence of an equal sign
            String name;
            String value;
            int length = arg.length();
            int endOfNameIndex = arg.indexOf(ARG_VAL_SEP);
            if (endOfNameIndex != -1) {// is there a separator?
                // case of name=value, name=
                metaData = ARG_VAL_SEP;
                name = arg.substring(0, endOfNameIndex);
                value = arg.substring(endOfNameIndex + 1, length);
            } else {
                metaData = """";
                name = arg;
                value = """";
            }
            if (name.length() > 0) {
                log.debug(""Name: {} Value: {} Metadata: {}"", name, value, metaData);
                // If we know the encoding, we can decode the argument value,
                // to make it easier to read for the user
                if (!StringUtils.isEmpty(contentEncoding)) {
                    addEncodedArgument(name, value, metaData, contentEncoding);
                } else {
                    // If we do not know the encoding, we just use the encoded value
                    // The browser has already done the encoding, so save the values as is
                    addNonEncodedArgument(name, value, metaData);
                }
            }
        }
    }",,
jmeter,13328,"log.debug(""Start : getDOM1"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/parser/HtmlParsingUtils.java/#L227,"public static Node getDOM(String text) {
        
---------------Reference log start----------------
log.debug(""Start : getDOM1"")
---------------Reference log end----------------

        Node node = getParser()
                .parseDOM(
                        new ByteArrayInputStream(
                                text.getBytes(StandardCharsets.UTF_8)), null);

        if (log.isDebugEnabled()) {
            log.debug(""node : {}"", node);
        }

        log.debug(""End : getDOM1"");

        return node;

    }",,
jmeter,14944,"log.warn(""Valid ciphers are: {}"", join(sock.getSupportedCipherSuites()))",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/HttpSSLProtocolSocketFactory.java/#L92,"private void configureSocket(Socket socket){
        if (!(socket instanceof SSLSocket)) {
            throw new IllegalArgumentException(""Expected SSLSocket"");
        }
        SSLSocket sock = (SSLSocket) socket;
        if (!PROTOCOL_LIST.isEmpty()) {
            try {
                sock.setEnabledProtocols(protocols);
            } catch (IllegalArgumentException e) { // NOSONAR
                if (log.isWarnEnabled()) {
                    log.warn(""Could not set protocol list: {}."", PROTOCOL_LIST);
                    log.warn(""Valid protocols are: {}"", join(sock.getSupportedProtocols()));
                }
            }
        }

        if (!CIPHER_LIST.isEmpty()) {
            try {
                sock.setEnabledCipherSuites(ciphers);
            } catch (IllegalArgumentException e) { // NOSONAR
                if (log.isWarnEnabled()) {
                    log.warn(""Could not set cipher list: {}."", CIPHER_LIST);
                    
---------------Reference log start----------------
log.warn(""Valid ciphers are: {}"", join(sock.getSupportedCipherSuites()))
---------------Reference log end----------------
                }
            }
        }
    }",,
jmeter,14667,"log.error(""Failed to create output Stream"", e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/DiskStoreSampleSender.java/#L159,"@SuppressWarnings(""FutureReturnValueIgnored"")
    private Object readResolve() throws ObjectStreamException{
        log.info(""Using DiskStoreSampleSender for this test run""); // server log file
        singleExecutor = Executors.newSingleThreadExecutor();
        try {
            temporaryFile = File.createTempFile(""SerialisedSampleSender"", "".ser"");
            temporaryFile.deleteOnExit();
            singleExecutor.submit(() -> {
                OutputStream anOutputStream;
                try {
                    anOutputStream = new FileOutputStream(temporaryFile);
                    oos = new ObjectOutputStream(anOutputStream);
                } catch (IOException e) {
                    
---------------Reference log start----------------
log.error(""Failed to create output Stream"", e)
---------------Reference log end----------------
                }
            });
        } catch (IOException e) {
            log.error(""Failed to create output file"", e);
        }
        return this;
    }",,
jmeter,13636,"log.debug(""RuntimeException"", e)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPHC4Impl.java/#L755,"@Override
    protected HTTPSampleResult sample(URL url, String method,
            boolean areFollowingRedirect, int frameDepth) {

        if (log.isDebugEnabled()) {
            log.debug(""Start : sample {} method {} followingRedirect {} depth {}"",
                    url, method, areFollowingRedirect, frameDepth);
        }
        JMeterVariables jMeterVariables = JMeterContextService.getContext().getVariables();

        HTTPSampleResult res = createSampleResult(url, method);

        CloseableHttpClient httpClient = null;
        HttpRequestBase httpRequest = null;
        HttpContext localContext = new BasicHttpContext();
        HttpClientContext clientContext = HttpClientContext.adapt(localContext);
        clientContext.setAttribute(CONTEXT_ATTRIBUTE_AUTH_MANAGER, getAuthManager());
        HttpClientKey key = createHttpClientKey(url);
        MutableTriple<CloseableHttpClient, AuthState, PoolingHttpClientConnectionManager> triple;
        try {
            triple = setupClient(key, jMeterVariables, clientContext);
            httpClient = triple.getLeft();
            URI uri = url.toURI();
            httpRequest = createHttpRequest(uri, method, areFollowingRedirect);
            setupRequest(url, httpRequest, res); // can throw IOException
        } catch (Exception e) {
            res.sampleStart();
            res.sampleEnd();
            errorResult(e, res);
            return res;
        }

        setupClientContextBeforeSample(jMeterVariables, localContext);

        res.sampleStart();

        final CacheManager cacheManager = getCacheManager();
        if (cacheManager != null && HTTPConstants.GET.equalsIgnoreCase(method) && cacheManager.inCache(url, httpRequest.getAllHeaders())) {
            return updateSampleResultForResourceInCache(res);
        }
        CloseableHttpResponse httpResponse = null;
        try {
            currentRequest = httpRequest;
            handleMethod(method, res, httpRequest, localContext);
            // store the SampleResult in LocalContext to compute connect time
            localContext.setAttribute(CONTEXT_ATTRIBUTE_SAMPLER_RESULT, res);
            // perform the sample
            httpResponse =
                    executeRequest(httpClient, httpRequest, localContext, url);
            saveProxyAuth(triple, localContext);
            if (log.isDebugEnabled()) {
                log.debug(""Headers in request before:{}"", Arrays.asList(httpRequest.getAllHeaders()));
            }
            // Needs to be done after execute to pick up all the headers
            final HttpRequest request = (HttpRequest) localContext.getAttribute(HttpCoreContext.HTTP_REQUEST);
            if (log.isDebugEnabled()) {
                log.debug(""Headers in request after:{}, in localContext#request:{}"",
                        Arrays.asList(httpRequest.getAllHeaders()),
                        Arrays.asList(request.getAllHeaders()));
            }
            extractClientContextAfterSample(jMeterVariables, localContext);
            // We've finished with the request, so we can add the LocalAddress to it for display
            if (localAddress != null) {
                request.addHeader(HEADER_LOCAL_ADDRESS, localAddress.toString());
            }
            res.setRequestHeaders(getAllHeadersExceptCookie(request));

            Header contentType = httpResponse.getLastHeader(HTTPConstants.HEADER_CONTENT_TYPE);
            if (contentType != null){
                String ct = contentType.getValue();
                res.setContentType(ct);
                res.setEncodingAndType(ct);
            }
            HttpEntity entity = httpResponse.getEntity();
            if (entity != null) {
                res.setResponseData(readResponse(res, entity.getContent(), entity.getContentLength()));
            }

            res.sampleEnd(); // Done with the sampling proper.
            currentRequest = null;

            // Now collect the results into the HTTPSampleResult:
            StatusLine statusLine = httpResponse.getStatusLine();
            int statusCode = statusLine.getStatusCode();
            res.setResponseCode(Integer.toString(statusCode));
            res.setResponseMessage(statusLine.getReasonPhrase());
            res.setSuccessful(isSuccessCode(statusCode));
            res.setResponseHeaders(getResponseHeaders(httpResponse));
            if (res.isRedirect()) {
                final Header headerLocation = httpResponse.getLastHeader(HTTPConstants.HEADER_LOCATION);
                if (headerLocation == null) { // HTTP protocol violation, but avoids NPE
                    throw new IllegalArgumentException(""Missing location header in redirect for "" + httpRequest.getRequestLine());
                }
                String redirectLocation = headerLocation.getValue();
                res.setRedirectLocation(redirectLocation);
            }

            // record some sizes to allow HTTPSampleResult.getBytes() with different options
            long headerBytes =
                (long)res.getResponseHeaders().length()   // condensed length (without \r)
              + (long) httpResponse.getAllHeaders().length // Add \r for each header
              + 1L // Add \r for initial header
              + 2L; // final \r\n before data
            HttpConnectionMetrics metrics = (HttpConnectionMetrics) localContext.getAttribute(CONTEXT_ATTRIBUTE_METRICS);
            long totalBytes = metrics.getReceivedBytesCount();
            res.setHeadersSize((int)headerBytes);
            res.setBodySize(totalBytes - headerBytes);
            res.setSentBytes((Long) localContext.getAttribute(CONTEXT_ATTRIBUTE_SENT_BYTES));
            if (log.isDebugEnabled()) {
                long total = res.getHeadersSize() + res.getBodySizeAsLong();
                log.debug(""ResponseHeadersSize={} Content-Length={} Total={}"",
                        res.getHeadersSize(), res.getBodySizeAsLong(), total);
            }

            // If we redirected automatically, the URL may have changed
            if (getAutoRedirects()) {
                HttpUriRequest req = (HttpUriRequest) localContext.getAttribute(HttpCoreContext.HTTP_REQUEST);
                HttpHost target = (HttpHost) localContext.getAttribute(HttpCoreContext.HTTP_TARGET_HOST);
                URI redirectURI = req.getURI();
                if (redirectURI.isAbsolute()) {
                    res.setURL(redirectURI.toURL());
                } else {
                    res.setURL(new URL(new URL(target.toURI()),redirectURI.toString()));
                }
            }

            // Store any cookies received in the cookie manager:
            saveConnectionCookies(httpResponse, res.getURL(), getCookieManager());

            // Save cache information
            if (cacheManager != null){
                cacheManager.saveDetails(httpResponse, res);
            }

            // Follow redirects and download page resources if appropriate:
            res = resultProcessing(areFollowingRedirect, frameDepth, res);
            if(!isSuccessCode(statusCode)) {
                EntityUtils.consumeQuietly(httpResponse.getEntity());
            }

        } catch (IOException e) {
            log.debug(""IOException"", e);
            if (res.getEndTime() == 0) {
                res.sampleEnd();
            }
           // pick up headers if failed to execute the request
            if (res.getRequestHeaders() != null) {
                log.debug(""Overwriting request old headers: {}"", res.getRequestHeaders());
            }
            res.setRequestHeaders(getAllHeadersExceptCookie((HttpRequest) localContext.getAttribute(HttpCoreContext.HTTP_REQUEST)));
            errorResult(e, res);
            return res;
        } catch (RuntimeException e) {
            
---------------Reference log start----------------
log.debug(""RuntimeException"", e)
---------------Reference log end----------------
            if (res.getEndTime() == 0) {
                res.sampleEnd();
            }
            errorResult(e, res);
            return res;
        } finally {
            JOrphanUtils.closeQuietly(httpResponse);
            currentRequest = null;
            JMeterContextService.getContext().getSamplerContext().remove(CONTEXT_ATTRIBUTE_PARENT_SAMPLE_CLIENT_STATE);
        }
        return res;
    }",,
jmeter,14883,"log.debug(""Setting {}={}"", jprop.getName(), value)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/testbeans/TestBeanHelper.java/#L87,"public static void prepare(TestElement el) {
        if (!(el instanceof TestBean)) {
            return;
        }
        try {
            BeanInfo beanInfo = Introspector.getBeanInfo(el.getClass());
            PropertyDescriptor[] descs = beanInfo.getPropertyDescriptors();

            if (log.isDebugEnabled()) {
                log.debug(""Preparing {}"", el.getClass());
            }

            for (PropertyDescriptor desc : descs) {
                if (isDescriptorIgnored(desc)) {
                    if (log.isDebugEnabled()) {
                        log.debug(""Ignoring property '{}' in {}"", desc.getName(), el.getClass().getCanonicalName());
                    }
                    continue;
                }
                // Obtain a value of the appropriate type for this property.
                JMeterProperty jprop = el.getProperty(desc.getName());
                Class<?> type = desc.getPropertyType();
                Object value = unwrapProperty(desc, jprop, type);

                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""Setting {}={}"", jprop.getName(), value)
---------------Reference log end----------------
                }

                // Set the bean's property to the value we just obtained:
                if (value != null || !type.isPrimitive())
                // We can't assign null to primitive types.
                {
                    Method writeMethod = desc.getWriteMethod();
                    if (writeMethod!=null) {
                        invokeOrBailOut(el, writeMethod, new Object[] {value});
                    }
                }
            }
        } catch (IntrospectionException e) {
            log.error(""Couldn't set properties for {}"", el.getClass(), e);
        } catch (UnsatisfiedLinkError ule) { // Can occur running headless on Jenkins
            log.error(""Couldn't set properties for {}"", el.getClass());
            throw ule;
        }
    }",,
jmeter,14897,"log.error(""Tried to parse a non-number string to an integer"", e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/testelement/property/AbstractProperty.java/#L146,"@Override
    public double getDoubleValue() {
        String val = getStringValue();
        if (val == null || val.length()==0) {
            return 0;
        }
        try {
            return Double.parseDouble(val);
        } catch (NumberFormatException e) {
            
---------------Reference log start----------------
log.error(""Tried to parse a non-number string to an integer"", e)
---------------Reference log end----------------
            return 0;
        }
    }",,
jmeter,14099,"LOGGER.error(""Error inserting text"", ex)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/SamplerResultTab.java/#L693,"protected void setTextOptimized(String data) {
        Document document = results.getDocument();
        Document blank = new DefaultStyledDocument();
        results.setDocument(blank);
        try {
            document.insertString(0, data == null ? """" : data, null);
        } catch (BadLocationException ex) {
            
---------------Reference log start----------------
LOGGER.error(""Error inserting text"", ex)
---------------Reference log end----------------
        }
        results.setDocument(document);
    }",,
jmeter,13724,"log.debug(""line was not filtered"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/util/accesslog/TCLogParser.java/#L288,"protected int parseLine(String line, TestElement el) {
        int count = 0;
        // we clean the line to get
        // rid of extra stuff
        String cleanedLine = this.cleanURL(line);
        log.debug(""parsing line: {}"", line);
        // now we set request method
        el.setProperty(HTTPSamplerBase.METHOD, RMETHOD);
        if (FILTER != null) {
            log.debug(""filter is not null"");
            if (!FILTER.isFiltered(line,el)) {
                
---------------Reference log start----------------
log.debug(""line was not filtered"")
---------------Reference log end----------------
                // increment the current count
                count++;
                // we filter the line first, before we try
                // to separate the URL into file and
                // parameters.
                line = FILTER.filter(cleanedLine);
                if (line != null) {
                    createUrl(line, el);
                }
            } else {
                log.debug(""Line was filtered"");
            }
        } else {
            log.debug(""filter was null"");
            // increment the current count
            count++;
            // in the case when the filter is not set, we
            // parse all the lines
            createUrl(cleanedLine, el);
        }
        return count;
    }",,
jmeter,13553,"log.debug(""Parsing html of: {}"", html)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/FormCharSetFinder.java/#L53,"public void addFormActionsAndCharSet(String html, Map<String, String> formEncodings, String pageEncoding)
            throws HTMLParseException {
        
---------------Reference log start----------------
log.debug(""Parsing html of: {}"", html)
---------------Reference log end----------------

        Document document = Jsoup.parse(html);
        Elements forms = document.select(""form"");
        for (Element element : forms) {
            String action = element.attr(""action"");
            if (!StringUtils.isEmpty(action)) {
                // We use the page encoding where the form resides, as the
                // default encoding for the form
                String formCharSet = pageEncoding;
                String acceptCharSet = element.attr(""accept-charset"");
                // Check if we found an accept-charset attribute on the form
                if(acceptCharSet != null) {
                    String[] charSets = JOrphanUtils.split(acceptCharSet, "","");
                    // Just use the first one of the possible many charsets
                    if(charSets.length > 0) {
                        formCharSet = charSets[0].trim();
                        if(formCharSet.length() == 0) {
                            formCharSet = null;
                        }
                    }
                }
                if(formCharSet != null) {
                    formEncodings.put(action, formCharSet);
                }
            }
        }
    }",,
jmeter,14093,"log.warn(""Chart property exception occurred."", e)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/AxisGraph.java/#L408,"private void drawSample(String _title, int _maxLength, String[] _xAxisLabels,
            String _yAxisTitle, String[] _legendLabels, double[][] _data,
            int _width, int _height, Color[] _color,
            Font legendFont, Graphics g) {
        double max = maxYAxisScale > 0 ? maxYAxisScale : findMax(_data); // define max scale y axis
        try {
            // Width and Height are already set in StatGraphVisualizer

            if (_maxLength < 3) {
                _maxLength = 3;
            }
            // if the ""Title of Graph"" is empty, we can assume some default
            if (_title.length() == 0 ) {
                _title = JMeterUtils.getResString(""aggregate_graph_title""); //$NON-NLS-1$
            }
            // if the labels are too long, they'll be ""squeezed"" to make the chart viewable.
            for (int i = 0; i < _xAxisLabels.length; i++) {
                String label = _xAxisLabels[i];
                _xAxisLabels[i]=squeeze(label, _maxLength);
            }
            this.setPreferredSize(new Dimension(_width,_height));
            // _xAxisTitle to null (don't display x axis title)
            DataSeries dataSeries = new DataSeries( _xAxisLabels, null, _yAxisTitle, _title );

            ClusteredBarChartProperties clusteredBarChartProperties= new ClusteredBarChartProperties();
            clusteredBarChartProperties.setShowOutlinesFlag(outlinesBarFlag);
            ValueLabelRenderer valueLabelRenderer = new ValueLabelRenderer(false, false, showGrouping, 0);
            valueLabelRenderer.setValueLabelPosition(ValueLabelPosition.AT_TOP);

            valueLabelRenderer.setValueChartFont(new ChartFont(valueFont, foreColor));
            valueLabelRenderer.useVerticalLabels(valueOrientation);

            clusteredBarChartProperties.addPostRenderEventListener(valueLabelRenderer);

            Paint[] paints = new Paint[_color.length];
            System.arraycopy(_color, 0, paints, 0, paints.length);

            AxisChartDataSet axisChartDataSet =
                new AxisChartDataSet(
                        _data, _legendLabels, paints, ChartType.BAR_CLUSTERED, clusteredBarChartProperties );
            dataSeries.addIAxisPlotDataSet( axisChartDataSet );

            ChartProperties chartProperties= new ChartProperties();
            LabelAxisProperties xaxis = new LabelAxisProperties();
            DataAxisProperties yaxis = new DataAxisProperties();
            yaxis.setUseCommas(showGrouping);

            if (legendFont != null) {
                yaxis.setAxisTitleChartFont(new ChartFont(legendFont, new Color(20)));
                yaxis.setScaleChartFont(new ChartFont(legendFont, new Color(20)));
                xaxis.setAxisTitleChartFont(new ChartFont(legendFont, new Color(20)));
                xaxis.setScaleChartFont(new ChartFont(legendFont, new Color(20)));
            }
            if (titleFont != null) {
                chartProperties.setTitleFont(new ChartFont(titleFont, new Color(0)));
            }

            // Y Axis
            try {
                BigDecimal round = BigDecimal.valueOf(max / 1000d);
                round = round.setScale(0, RoundingMode.HALF_EVEN);
                double topValue = round.doubleValue() * 1000;
                yaxis.setUserDefinedScale(0, 500);
                yaxis.setNumItems((int) (topValue / 500)+1);
                yaxis.setShowGridLines(1);
            } catch (PropertyException e) {
                
---------------Reference log start----------------
log.warn(""Chart property exception occurred."", e)
---------------Reference log end----------------
            }

            AxisProperties axisProperties= new AxisProperties(xaxis, yaxis);
            axisProperties.setXAxisLabelsAreVertical(true);
            LegendProperties legendProperties= new LegendProperties();
            legendProperties.setBorderStroke(null);
            legendProperties.setPlacement(legendPlacement);
            legendProperties.setIconBorderPaint(Color.WHITE);
            if (legendPlacement == LegendAreaProperties.RIGHT || legendPlacement == LegendAreaProperties.LEFT) {
                legendProperties.setNumColumns(1);
            }
            if (legendFont != null) {
                legendProperties.setFont(legendFont); //new Font(""SansSerif"", Font.PLAIN, 10)
            }
            AxisChart axisChart = new AxisChart(
                    dataSeries, chartProperties, axisProperties,
                    legendProperties, _width, _height );
            axisChart.setGraphics2D((Graphics2D) g);
            axisChart.render();
        } catch (ChartDataException | PropertyException e) {
            log.warn(""Exception occurred while rendering chart."", e);
        }
    }",,
jmeter,13362,"log.debug(""setHeaders HTTP Method{}(Java) url:{} entry:{}"", conn.getRequestMethod(), url.toString(), entry)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/CacheManager.java/#L435,"public void setHeaders(HttpURLConnection conn,
            org.apache.jmeter.protocol.http.control.Header[] headers, URL url) {
        CacheEntry entry = getEntry(url.toString(),
                headers != null ? asHeaders(headers) : new Header[0]);
        if (log.isDebugEnabled()){
            
---------------Reference log start----------------
log.debug(""setHeaders HTTP Method{}(Java) url:{} entry:{}"", conn.getRequestMethod(), url.toString(), entry)
---------------Reference log end----------------
        }
        if (entry != null){
            final String lastModified = entry.getLastModified();
            if (lastModified != null){
                conn.addRequestProperty(HTTPConstants.IF_MODIFIED_SINCE, lastModified);
            }
            final String etag = entry.getEtag();
            if (etag != null){
                conn.addRequestProperty(HTTPConstants.IF_NONE_MATCH, etag);
            }
        }
    }",,
jmeter,14383,"log.warn(""Failed to perform quick component add: {}"", comp, err)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/MainFrame.java/#L762,"@Override
        public void actionPerformed(ActionEvent actionEvent) {
            String propname = ""gui.quick_"" + getCurrentKey(actionEvent);
            String comp = JMeterUtils.getProperty(propname);
            log.debug(""Event {}: {}"", propname, comp);

            if (comp == null) {
                log.warn(""No component set through property: {}"", propname);
                return;
            }

            GuiPackage guiPackage = GuiPackage.getInstance();
            try {
                guiPackage.updateCurrentNode();
                TestElement testElement = guiPackage.createTestElement(SaveService.aliasToClass(comp));
                JMeterTreeNode parentNode = guiPackage.getCurrentNode();
                while (!MenuFactory.canAddTo(parentNode, testElement)) {
                    parentNode = (JMeterTreeNode) parentNode.getParent();
                }
                if (parentNode.getParent() == null) {
                    log.debug(""Cannot add element on very top level"");
                } else {
                    JMeterTreeNode node = guiPackage.getTreeModel().addComponent(testElement, parentNode);
                    guiPackage.getMainFrame().getTree().setSelectionPath(new TreePath(node.getPath()));
                }
            } catch (Exception err) {
                
---------------Reference log start----------------
log.warn(""Failed to perform quick component add: {}"", comp, err)
---------------Reference log end----------------
            }
        }",,
jmeter,13803,"log.debug(""Adding property [{}={}]"", name, value)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/Utils.java/#L231,"public static void addJMSProperties(Message msg, Map<String, Object> map) throws JMSException {
        if (map == null) {
            return;
        }
        for (Map.Entry<String, Object> me : map.entrySet()) {
            String name = me.getKey();
            Object value = me.getValue();
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Adding property [{}={}]"", name, value)
---------------Reference log end----------------
            }

            // Some JMS implemenations do not allow certain header fields to be set using properties
            // e.g.: WebsphereMQ does not allow corr. id. to be set using setStringProperty()
            if (""JMSCorrelationID"".equalsIgnoreCase(name)) { // $NON-NLS-1$
                msg.setJMSCorrelationID((String)value);
            } else if (""JMSType"".equalsIgnoreCase(name)) { // $NON-NLS-1$
                msg.setJMSType((String)value);
            } else {
                msg.setObjectProperty(name, value);
            }
        }
    }",,
jmeter,14156,"log.debug(""Getting message number: {}"", msgPos)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/SMIMEAssertion.java/#L92,"public static AssertionResult getResult(SMIMEAssertionTestElement testElement, SampleResult response, String name) {
        checkForBouncycastle();
        AssertionResult res = new AssertionResult(name);
        try {
            MimeMessage msg;
            final int msgPos = testElement.getSpecificMessagePositionAsInt();
            if (msgPos < 0){ // means counting from end
                SampleResult[] subResults = response.getSubResults();
                final int pos = subResults.length + msgPos;
                log.debug(""Getting message number: {} of {}"", pos, subResults.length);
                msg = getMessageFromResponse(response,pos);
            } else {
                
---------------Reference log start----------------
log.debug(""Getting message number: {}"", msgPos)
---------------Reference log end----------------
                msg = getMessageFromResponse(response, msgPos);
            }

            SMIMESignedParser signedParser = null;
            if(log.isDebugEnabled()) {
                log.debug(""Content-type: {}"", msg.getContentType());
            }
            if (msg.isMimeType(""multipart/signed"")) { // $NON-NLS-1$
                MimeMultipart multipart = (MimeMultipart) msg.getContent();
                signedParser = new SMIMESignedParser(new BcDigestCalculatorProvider(), multipart);
            } else if (msg.isMimeType(""application/pkcs7-mime"") // $NON-NLS-1$
                    || msg.isMimeType(""application/x-pkcs7-mime"")) { // $NON-NLS-1$
                signedParser = new SMIMESignedParser(new BcDigestCalculatorProvider(), msg);
            }

            if (null != signedParser) {
                log.debug(""Found signature"");

                if (testElement.isNotSigned()) {
                    res.setFailure(true);
                    res.setFailureMessage(""Mime message is signed"");
                } else if (testElement.isVerifySignature() || !testElement.isSignerNoCheck()) {
                    res = verifySignature(testElement, signedParser, name);
                }

            } else {
                log.debug(""Did not find signature"");
                if (!testElement.isNotSigned()) {
                    res.setFailure(true);
                    res.setFailureMessage(""Mime message is not signed"");
                }
            }

        } catch (MessagingException e) {
            String msg = ""Cannot parse mime msg: "" + e.getMessage();
            log.warn(msg, e);
            res.setFailure(true);
            res.setFailureMessage(msg);
        } catch (CMSException e) {
            res.setFailure(true);
            res.setFailureMessage(""Error reading the signature: ""
                    + e.getMessage());
        } catch (SMIMEException e) {
            res.setFailure(true);
            res.setFailureMessage(""Cannot extract signed body part from signature: ""
                    + e.getMessage());
        } catch (IOException e) { // should never happen
            log.error(""Cannot read mime message content: {}"", e.getMessage(), e);
            res.setError(true);
            res.setFailureMessage(e.getMessage());
        }

        return res;
    }",,
jmeter,13694,"log.debug(""allowPattern: {}, excludePattern: {}, localMatcher: {}, url: {}"", allowPattern, excludePattern, localMatcher, url)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L1426,"protected HTTPSampleResult downloadPageResources(final HTTPSampleResult pRes, final HTTPSampleResult container, final int frameDepth) {
        HTTPSampleResult res = pRes;
        Iterator<URL> urls = null;
        try {
            final byte[] responseData = res.getResponseData();
            if (responseData.length > 0) {  // Bug 39205
                final LinkExtractorParser parser = getParser(res);
                if (parser != null) {
                    String userAgent = getUserAgent(res);
                    urls = parser.getEmbeddedResourceURLs(userAgent, responseData, res.getURL(), res.getDataEncodingWithDefault());
                }
            }
        } catch (LinkExtractorParseException e) {
            // Don't break the world just because this failed:
            res.addSubResult(errorResult(e, new HTTPSampleResult(res)));
            setParentSampleSuccess(res, false);
        }
        HTTPSampleResult lContainer = container;
        // Iterate through the URLs and download each image:
        if (urls != null && urls.hasNext()) {
            if (lContainer == null) {
                lContainer = new HTTPSampleResult(res);
                lContainer.addRawSubResult(res);
            }
            res = lContainer;

            // Get the URL matcher
            String allowRegex = getEmbeddedUrlRE();
            Perl5Matcher localMatcher = null;
            Pattern allowPattern = null;
            if (allowRegex.length() > 0) {
                try {
                    allowPattern = JMeterUtils.getPattern(allowRegex);
                    localMatcher = JMeterUtils.getMatcher();// don't fetch unless pattern compiles
                } catch (MalformedCachePatternException e) { // NOSONAR
                    log.warn(""Ignoring embedded URL match string: {}"", e.getMessage());
                }
            }
            Pattern excludePattern = null;
            String excludeRegex = getEmbededUrlExcludeRE();
            if (excludeRegex.length() > 0) {
                try {
                    excludePattern = JMeterUtils.getPattern(excludeRegex);
                    if (localMatcher == null) {
                        localMatcher = JMeterUtils.getMatcher();// don't fetch unless pattern compiles
                    }
                } catch (MalformedCachePatternException e) { // NOSONAR
                    log.warn(""Ignoring embedded URL exclude string: {}"", e.getMessage());
                }
            }

            // For concurrent get resources
            final List<Callable<AsynSamplerResultHolder>> list = new ArrayList<>();

            int maxConcurrentDownloads = CONCURRENT_POOL_SIZE; // init with default value
            boolean isConcurrentDwn = isConcurrentDwn();
            if (isConcurrentDwn) {
                try {
                    maxConcurrentDownloads = Integer.parseInt(getConcurrentPool());
                } catch (NumberFormatException nfe) {
                    log.warn(""Concurrent download resources selected, ""// $NON-NLS-1$
                            + ""but pool size value is bad. Use default value"");// $NON-NLS-1$
                }

                // if the user choose a number of parallel downloads of 1
                // no need to use another thread, do the sample on the current thread
                if (maxConcurrentDownloads == 1) {
                    log.warn(""Number of parallel downloads set to 1, (sampler name={})"", getName());
                    isConcurrentDwn = false;
                }
            }

            while (urls.hasNext()) {
                Object binURL = urls.next(); // See catch clause below
                try {
                    URL url = (URL) binURL;
                    if (url == null) {
                        log.warn(""Null URL detected (should not happen)"");
                    } else {
                        try {
                            url = escapeIllegalURLCharacters(url);
                        } catch (Exception e) { // NOSONAR
                            res.addSubResult(errorResult(new Exception(url.toString() + "" is not a correct URI"", e), new HTTPSampleResult(res)));
                            setParentSampleSuccess(res, false);
                            continue;
                        }
                        
---------------Reference log start----------------
log.debug(""allowPattern: {}, excludePattern: {}, localMatcher: {}, url: {}"", allowPattern, excludePattern, localMatcher, url)
---------------Reference log end----------------
                        // I don't think localMatcher can be null here, but check just in case
                        if (allowPattern != null && localMatcher != null && !localMatcher.matches(url.toString(), allowPattern)) {
                            continue; // we have a pattern and the URL does not match, so skip it
                        }
                        if (excludePattern != null && localMatcher != null && localMatcher.matches(url.toString(), excludePattern)) {
                            continue; // we have a pattern and the URL does not match, so skip it
                        }
                        try {
                            url = url.toURI().normalize().toURL();
                        } catch (MalformedURLException | URISyntaxException e) {
                            res.addSubResult(errorResult(new Exception(url.toString() + "" URI can not be normalized"", e), new HTTPSampleResult(res)));
                            setParentSampleSuccess(res, false);
                            continue;
                        }

                        if (isConcurrentDwn) {
                            // if concurrent download emb. resources, add to a list for async gets later
                            list.add(new ASyncSample(url, HTTPConstants.GET, false, frameDepth + 1, getCookieManager(), this));
                        } else {
                            // default: serial download embedded resources
                            HTTPSampleResult binRes = sample(url, HTTPConstants.GET, false, frameDepth + 1);
                            res.addSubResult(binRes);
                            setParentSampleSuccess(res, res.isSuccessful() && (binRes == null || binRes.isSuccessful()));
                        }
                    }
                } catch (ClassCastException e) { // NOSONAR
                    res.addSubResult(errorResult(new Exception(binURL + "" is not a correct URI"", e), new HTTPSampleResult(res)));
                    setParentSampleSuccess(res, false);
                }
            }

            // IF for download concurrent embedded resources
            if (isConcurrentDwn && !list.isEmpty()) {

                ResourcesDownloader resourcesDownloader = ResourcesDownloader.getInstance();

                try {
                    // sample all resources
                    final List<Future<AsynSamplerResultHolder>> retExec =
                            resourcesDownloader.invokeAllAndAwaitTermination(maxConcurrentDownloads, list);
                    CookieManager cookieManager = getCookieManager();
                    // add result to main sampleResult
                    for (Future<AsynSamplerResultHolder> future : retExec) {
                        // this call will not block as the futures return by invokeAllAndAwaitTermination
                        //   are either done or cancelled
                        AsynSamplerResultHolder binRes = future.get();
                        if (cookieManager != null) {
                            CollectionProperty cookies = binRes.getCookies();
                            for (JMeterProperty jMeterProperty : cookies) {
                                Cookie cookie = (Cookie) jMeterProperty.getObjectValue();
                                cookieManager.add(cookie);
                            }
                        }
                        res.addSubResult(binRes.getResult());
                        setParentSampleSuccess(res, res.isSuccessful() && (binRes.getResult() != null ? binRes.getResult().isSuccessful():true));
                    }
                } catch (InterruptedException ie) {
                    log.warn(""Interrupted fetching embedded resources"", ie); // $NON-NLS-1$
                    Thread.currentThread().interrupt();
                } catch (ExecutionException ee) {
                    log.warn(""Execution issue when fetching embedded resources"", ee); // $NON-NLS-1$
                }
            }
        }
        return res;
    }",,
jmeter,15001,"log.debug(""{} : {}"", getClass().getName(), e.getLocalizedMessage())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/BeanShellTestElement.java/#L215,"private void tryEval(String code) {
        if (bshInterpreter == null || !hasInitFile) {
            return;
        }
        try {
            bshInterpreter.eval(code);
        } catch (JMeterException e) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""{} : {}"", getClass().getName(), e.getLocalizedMessage())
---------------Reference log end----------------
            }
        }
    }",,
jmeter,14036,"log.debug(""Canceled state: {}"", cancelState)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/influxdb/InfluxdbBackendListenerClient.java/#L405,"@Override
    public void teardownTest(BackendListenerContext context) throws Exception {
        boolean cancelState = timerHandle.cancel(false);
        
---------------Reference log start----------------
log.debug(""Canceled state: {}"", cancelState)
---------------Reference log end----------------
        scheduler.shutdown();
        try {
            scheduler.awaitTermination(30, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            log.error(""Error waiting for end of scheduler"");
            Thread.currentThread().interrupt();
        }

        addAnnotation(false);

        // Send last set of data before ending
        log.info(""Sending last metrics to InfluxDB"");
        sendMetrics();

        influxdbMetricsManager.destroy();
        super.teardownTest(context);
    }",,
jmeter,13322,"LOG.info(""Created {}"", parserClassName)",info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/parser/BaseParser.java/#L74,"public static LinkExtractorParser getParser(String parserClassName)
            throws LinkExtractorParseException {

        // Is there a cached parser?
        LinkExtractorParser parser = PARSERS.get(parserClassName);
        if (parser != null) {
            LOG.debug(""Fetched {}"", parserClassName);
            return parser;
        }

        try {
            Object clazz = Class.forName(parserClassName).getDeclaredConstructor().newInstance();
            if (clazz instanceof LinkExtractorParser) {
                parser = (LinkExtractorParser) clazz;
            } else {
                throw new LinkExtractorParseException(new ClassCastException(parserClassName));
            }
        } catch (IllegalArgumentException | ReflectiveOperationException | SecurityException e) {
            throw new LinkExtractorParseException(e);
        }
        
---------------Reference log start----------------
LOG.info(""Created {}"", parserClassName)
---------------Reference log end----------------
        if (parser.isReusable()) {
            LinkExtractorParser currentParser = PARSERS.putIfAbsent(
                    parserClassName, parser);// cache the parser if not already
                                             // done by another thread
            if (currentParser != null) {
                return currentParser;
            }
        }

        return parser;
    }",,
jmeter,15043,"log.warn(""Unknown error"", new Throwable(""errorMsg == null""))",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JMeterUtils.java/#L861,"public static void reportErrorToUser(String errorMsg, String titleMsg, Exception exception) {
        if (errorMsg == null) {
            errorMsg = ""Unknown error - see log file"";
            
---------------Reference log start----------------
log.warn(""Unknown error"", new Throwable(""errorMsg == null""))
---------------Reference log end----------------
        }
        if (exception != null) {
            log.error(errorMsg, exception);
        } else {
            log.error(errorMsg);
        }
        GuiPackage instance = GuiPackage.getInstance();
        if (instance == null) {
            System.out.println(errorMsg); // NOSONAR intentional
            return; // Done
        }
        try {
            JOptionPane.showMessageDialog(instance.getMainFrame(),
                    formatMessage(errorMsg),
                    titleMsg,
                    JOptionPane.ERROR_MESSAGE);
        } catch (HeadlessException e) {
            log.warn(""reportErrorToUser(\""{}\"") caused"", errorMsg, e);
        }
    }",,
jmeter,14270,"log.debug(""Scheduled timer: @{} {}"", System.identityHashCode(future), getInfo(samp))",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/modifiers/SampleTimeout.java/#L142,"private void createTask(final Sampler samp) {
        long timeout = getPropertyAsLong(TIMEOUT); // refetch each time so it can be a variable
        if (timeout <= 0) {
            return;
        }
        if (!(samp instanceof Interruptible)) { // may be applied to a whole test
            return; // Cannot time out in this case
        }
        final Interruptible sampler = (Interruptible) samp;

        Callable<Object> call = () -> {
            long start = System.nanoTime();
            boolean interrupted = sampler.interrupt();
            String elapsed = Double.toString((double)(System.nanoTime()-start)/ 1000000000)+"" secs"";
            if (interrupted) {
                if (log.isWarnEnabled()) {
                    log.warn(""Call Done interrupting {} took {}"", getInfo(samp), elapsed);
                }
            } else {
                if (log.isDebugEnabled()) {
                    log.debug(""Call Didn't interrupt: {} took {}"", getInfo(samp), elapsed);
                }
            }
            return null;
        };
        // schedule the interrupt to occur and save for possible cancellation
        future = execService.schedule(call, timeout, TimeUnit.MILLISECONDS);
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Scheduled timer: @{} {}"", System.identityHashCode(future), getInfo(samp))
---------------Reference log end----------------
        }
    }",,
jmeter,14773,"log.debug(""Ignoring timer node: {}"", node)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/TreeClonerNoTimer.java/#L45,"@Override
    protected Object addNodeToTree(Object node) {
        if(node instanceof Timer) {
            
---------------Reference log start----------------
log.debug(""Ignoring timer node: {}"", node)
---------------Reference log end----------------
            return node; // don't add the timer
        } else {
            return super.addNodeToTree(node);
        }
    }",,
jmeter,14164,"log.debug(""Could not read cert file {}"", testElement.getSignerCertFile(), e)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/SMIMEAssertion.java/#L237,"private static void checkSignerByFile(SMIMEAssertionTestElement testElement, AssertionResult res,
            X509CertificateHolder cert) throws CertificateException {
        CertificateFactory cf = CertificateFactory
                .getInstance(""X.509"");
        try (InputStream fis = new FileInputStream(testElement.getSignerCertFile());
                InputStream bis = new BufferedInputStream(fis)){
            X509CertificateHolder certFromFile = new JcaX509CertificateHolder((X509Certificate) cf.generateCertificate(bis));
            if (!certFromFile.equals(cert)) {
                res.setFailure(true);
                res.setFailureMessage(""Signer certificate does not match certificate ""
                                + testElement.getSignerCertFile());
            }
        } catch (IOException e) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Could not read cert file {}"", testElement.getSignerCertFile(), e)
---------------Reference log end----------------
            }
            res.setFailure(true);
            res.setFailureMessage(""Could not read certificate file "" + testElement.getSignerCertFile());
        }
    }",,
jmeter,15036,"log.warn(""Exception '{}' occurred when fetching int property:'{}', defaulting to: {}"", e.getMessage(), propName, defaultVal)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JMeterUtils.java/#L686,"public static int getPropDefault(String propName, int defaultVal) {
        try {
            return Integer.parseInt(appProperties.getProperty(propName, Integer.toString(defaultVal)).trim());
        } catch (Exception e) {
            
---------------Reference log start----------------
log.warn(""Exception '{}' occurred when fetching int property:'{}', defaulting to: {}"", e.getMessage(), propName, defaultVal)
---------------Reference log end----------------
        }
        return defaultVal;
    }",,
jmeter,13624,"log.debug(""Store creds {} for {}"", credentials, authscope)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPHC4Impl.java/#L224,"@Override
        public void setCredentials(AuthScope authscope, Credentials credentials) {
            
---------------Reference log start----------------
log.debug(""Store creds {} for {}"", credentials, authscope)
---------------Reference log end----------------
        }
        }",,
jmeter,13354,"log.debug(""Found vary value {} for {} in response"", header, headerName)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/CacheManager.java/#L220,"private Pair<String, String> getVaryHeader(String headerName, Header[] reqHeaders) {
        if (headerName == null) {
            return null;
        }
        final Set<String> names = new HashSet<>(Arrays.asList(headerName.split("",\\s*"")));
        final Map<String, List<String>> values = new HashMap<>();
        for (final String name: names) {
            values.put(name, new ArrayList<String>());
        }
        for (Header header: reqHeaders) {
            if (names.contains(header.getName())) {
                
---------------Reference log start----------------
log.debug(""Found vary value {} for {} in response"", header, headerName)
---------------Reference log end----------------
                values.get(header.getName()).add(header.getValue());
            }
        }
        return new ImmutablePair<>(headerName, values.toString());
    }",,
jmeter,14537,"log.warn(""Can't escape commata in input string: {}"", arg, e)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/functions/gui/FunctionHelper.java/#L329,"private String escapeCommata(String arg) {
        int level = 0;
        StringBuilder result = new StringBuilder(arg.length());
        try (Reader r = new StringReader(arg)) {
            int c;
            char lastChar = ANY_NORMAL_CHAR;
            while ((c = r.read()) != -1) {
                char nextChar = (char) c;
                if (lastChar == '\\') {
                    lastChar = ANY_NORMAL_CHAR;
                } else if (lastChar == '$' && nextChar == '{') {
                    level++;
                    lastChar = ANY_NORMAL_CHAR;
                } else if (nextChar == '}') {
                    level--;
                    lastChar = ANY_NORMAL_CHAR;
                } else if (nextChar == ',' && level == 0) {
                    result.append('\\');
                    lastChar = ANY_NORMAL_CHAR;
                } else {
                    lastChar = nextChar;
                }
                result.append(nextChar);
            }
        } catch (IOException e) {
            
---------------Reference log start----------------
log.warn(""Can't escape commata in input string: {}"", arg, e)
---------------Reference log end----------------
            return arg;
        }
        return result.toString();
    }",,
jmeter,14540,"log.debug(""Start of transaction {}"", getName())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/control/TransactionController.java/#L155,"private Sampler nextWithTransactionSampler() {
        // Check if transaction is done
        if(transactionSampler != null && transactionSampler.isTransactionDone()) {
            if (log.isDebugEnabled()) {
                log.debug(""End of transaction {}"", getName());
            }
            // This transaction is done
            transactionSampler = null;
            return null;
        }

        // Check if it is the start of a new transaction
        if (isFirst()) // must be the start of the subtree
        {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Start of transaction {}"", getName())
---------------Reference log end----------------
            }
            transactionSampler = new TransactionSampler(this, getName());
        }

        // Sample the children of the transaction
        Sampler subSampler = super.next();
        transactionSampler.setSubSampler(subSampler);
        // If we do not get any sub samplers, the transaction is done
        if (subSampler == null) {
            transactionSampler.setTransactionDone();
        }
        return transactionSampler;
    }",,
jmeter,13426,"log.debug(""Checking match against auth'n entry: {}"", uRL)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/AuthManager.java/#L264,"public Authorization getAuthForURL(URL url) {
        if (!isSupportedProtocol(url)) {
            return null;
        }

        // TODO: replace all this url2 mess with a proper method
        // ""areEquivalent(url1, url2)"" that
        // would also ignore case in protocol and host names, etc. -- use that
        // method in the CookieManager too.

        URL url2 = null;

        try {
            if (url.getPort() == -1) {
                // Obtain another URL with an explicit port:
                int port = url.getProtocol().equalsIgnoreCase(HTTPConstants.PROTOCOL_HTTP) ? HTTPConstants.DEFAULT_HTTP_PORT : HTTPConstants.DEFAULT_HTTPS_PORT;
                // only http and https are supported
                url2 = new URL(url.getProtocol(), url.getHost(), port, url.getPath());
            } else if ((url.getPort() == HTTPConstants.DEFAULT_HTTP_PORT && url.getProtocol().equalsIgnoreCase(HTTPConstants.PROTOCOL_HTTP))
                    || (url.getPort() == HTTPConstants.DEFAULT_HTTPS_PORT && url.getProtocol().equalsIgnoreCase(HTTPConstants.PROTOCOL_HTTPS))) {
                url2 = new URL(url.getProtocol(), url.getHost(), url.getPath());
            }
        } catch (MalformedURLException e) {
            log.error(""Internal error!"", e); // this should never happen
            // anyway, we'll continue with url2 set to null.
        }

        String s1 = url.toString();
        String s2 = null;
        if (url2 != null) {
            s2 = url2.toString();
        }

        log.debug(""Target URL strings to match against: {} and {}"", s1, s2);
        // TODO should really return most specific (i.e. longest) match.
        for (JMeterProperty jMeterProperty : getAuthObjects()) {
            Authorization auth = (Authorization) jMeterProperty.getObjectValue();

            String uRL = auth.getURL();
            
---------------Reference log start----------------
log.debug(""Checking match against auth'n entry: {}"", uRL)
---------------Reference log end----------------
            if (s1.startsWith(uRL) || s2 != null && s2.startsWith(uRL)) {
                log.debug(""Matched against auth'n entry: {}"", uRL);
                return auth;
            }
            log.debug(""Did not match against auth'n entry: {}"", uRL);
        }
        return null;
    }",,
jmeter,13706,"log.debug(""Big response, truncating it to {} bytes"", MAX_BYTES_TO_STORE_PER_REQUEST)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L1957,"public byte[] readResponse(SampleResult sampleResult, InputStream in, long length) throws IOException {

        OutputStream w = null;
        try (Closeable ignore = in) { // NOSONAR No try with resource as performance is critical here
            byte[] readBuffer = new byte[8192]; // 8kB is the (max) size to have the latency ('the first packet')
            int bufferSize = 32;// Enough for MD5

            MessageDigest md = null;
            boolean knownResponseLength = length > 0;// may also happen if long value > int.max
            if (useMD5()) {
                try {
                    md = MessageDigest.getInstance(""MD5""); //$NON-NLS-1$
                } catch (NoSuchAlgorithmException e) {
                    log.error(""Should not happen - could not find MD5 digest"", e);
                }
            } else {
                if (!knownResponseLength) {
                    bufferSize = 4 * 1024;
                } else {
                    bufferSize = (int) Math.min(MAX_BUFFER_SIZE, length);
                }
            }


            int bytesReadInBuffer = 0;
            long totalBytes = 0;
            boolean first = true;
            boolean storeInBOS = true;
            while ((bytesReadInBuffer = in.read(readBuffer)) > -1) {
                if (first) {
                    sampleResult.latencyEnd();
                    first = false;
                    if(md == null) {
                        if(!knownResponseLength) {
                            w = new org.apache.commons.io.output.ByteArrayOutputStream(bufferSize);
                        }
                        else {
                            w = new DirectAccessByteArrayOutputStream(bufferSize);
                        }
                    }
                }

                if (md == null) {
                    if(storeInBOS) {
                        if(MAX_BYTES_TO_STORE_PER_REQUEST <= 0 ||
                                (totalBytes+bytesReadInBuffer<=MAX_BYTES_TO_STORE_PER_REQUEST) ||
                                JMeterContextService.getContext().isRecording()) {
                            w.write(readBuffer, 0, bytesReadInBuffer);
                        } else {
                            
---------------Reference log start----------------
log.debug(""Big response, truncating it to {} bytes"", MAX_BYTES_TO_STORE_PER_REQUEST)
---------------Reference log end----------------
                            w.write(readBuffer, 0, (int)(MAX_BYTES_TO_STORE_PER_REQUEST-totalBytes));
                            storeInBOS = false;
                        }
                    }
                } else {
                    md.update(readBuffer, 0, bytesReadInBuffer);
                }
                totalBytes += bytesReadInBuffer;
            }

            if (first) { // Bug 46838 - if there was no data, still need to set latency
                sampleResult.latencyEnd();
                return new byte[0];
            }

            if (md == null) {
                return toByteArray(w);
            } else {
                byte[] md5Result = md.digest();
                sampleResult.setBytes(totalBytes);
                return JOrphanUtils.baToHexBytes(md5Result);
            }

        } finally {
            IOUtils.closeQuietly(w, null);
        }
    }",,
jmeter,14622,"LOGGER.info(""Writing statistics JSON to {}"", outputFile)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/JsonExporter.java/#L82,"@Override
    public void export(SampleContext context, File file, ReportGeneratorConfiguration reportGeneratorConfiguration)
            throws ExportException {
        Object data = context.getData().get(ReportGenerator.STATISTICS_SUMMARY_CONSUMER_NAME);
        if (data instanceof MapResultData) {
            LOGGER.info(""Found data for consumer {}in context"", ReportGenerator.STATISTICS_SUMMARY_CONSUMER_NAME);
            MapResultData result = (MapResultData) data;
            Map<String, SamplingStatistic> statistics = new HashMap<>();
            MapResultData overallData = (MapResultData) result.getResult(""overall"");
            LOGGER.info(""Creating statistics for overall"");
            createStatistic(statistics, overallData);

            ListResultData itemsData = (ListResultData) result.getResult(""items"");
            LOGGER.info(""Creating statistics for other transactions"");
            itemsData.forEach(r -> createStatistic(statistics, (MapResultData)r));

            LOGGER.info(""Checking output folder"");
            File outputDir = checkAndGetOutputFolder(reportGeneratorConfiguration);

            File outputFile = new File(outputDir, OUTPUT_FILENAME);
            
---------------Reference log start----------------
LOGGER.info(""Writing statistics JSON to {}"", outputFile)
---------------Reference log end----------------
            try (Writer fileWriter = Files.newBufferedWriter(outputFile.toPath())) {
                OBJECT_WRITER.writeValue(fileWriter, statistics);
            } catch (IOException e) {
                throw new ExportException(""Error generating JSON statistics file to "" + outputFile +"" for ""+statistics, e);
            }
        }
    }",,
jmeter,13409,log.warn(e.getMessage()),warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/HttpMirrorThread.java/#L130,"@Override
    public void run() {
        log.debug(""Starting thread"");
        BufferedInputStream in = null;
        BufferedOutputStream out = null;

        try {
            in = new BufferedInputStream(clientSocket.getInputStream());

            // Read the header part, we will be looking for a content-length
            // header, so we know how much we should read.
            // We assume headers are in ISO_8859_1
            // If we do not find such a header, we will just have to read until
            // we have to block to read more, until we support chunked transfer
            int contentLength = -1;
            boolean isChunked = false;
            byte[] buffer = new byte[1024];
            StringBuilder headers = new StringBuilder();
            int length = 0;
            int positionOfBody = 0;
            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            while(positionOfBody <= 0 && ((length = in.read(buffer)) != -1)) {
                log.debug(""Write body"");
                baos.write(buffer, 0, length); // echo back
                headers.append(new String(buffer, 0, length, ISO_8859_1));
                // Check if we have read all the headers
                positionOfBody = getPositionOfBody(headers.toString());
            }

            baos.close();
            final String headerString = headers.toString();
            if(headerString.length() == 0 || headerString.indexOf('\r') < 0) {
                log.error(""Invalid request received:'{}'"", headerString);
                return;
            }
            log.debug(""Received => '{}'"", headerString);
            final String firstLine = headerString.substring(0, headerString.indexOf('\r'));
            final String[] requestParts = firstLine.split(""\\s+"");
            final String requestMethod = requestParts[0];
            final String requestPath = requestParts[1];
            final HashMap<String, String> parameters = new HashMap<>();
            if (HTTPConstants.GET.equals(requestMethod)) {
                int querypos = requestPath.indexOf('?');
                if (querypos >= 0) {
                    String query;
                    try {
                        URI uri = new URI(requestPath); // Use URI because it will decode the query
                        query = uri.getQuery();
                    } catch (URISyntaxException e) {
                        
---------------Reference log start----------------
log.warn(e.getMessage())
---------------Reference log end----------------
                        query=requestPath.substring(querypos+1);
                    }
                    if (query != null) {
                        String[] params = query.split(""&"");
                        for(String param : params) {
                            String[] parts = param.split(""="",2);
                            if (parts.length==2) {
                                parameters.put(parts[0], parts[1]);
                            } else { // allow for parameter name only
                                parameters.put(parts[0], """");
                            }
                        }
                    }
                }
            }

            final boolean verbose = parameters.containsKey(VERBOSE);

            if (verbose) {
                System.out.println(firstLine); // NOSONAR
                log.info(firstLine);
            }

            // Look for special Response Length header
            String responseStatusValue = getRequestHeaderValue(headerString, ""X-ResponseStatus""); //$NON-NLS-1$
            if(responseStatusValue == null) {
                responseStatusValue = ""200 OK"";
            }
            // Do this before the status check so can override the status, e.g. with a different redirect type
            if (parameters.containsKey(REDIRECT)) {
                responseStatusValue = ""302 Temporary Redirect"";
            }
            if (parameters.containsKey(STATUS)) {
                responseStatusValue = parameters.get(STATUS);
            }

            log.debug(""Write headers"");
            out = new BufferedOutputStream(clientSocket.getOutputStream());
            // The headers are written using ISO_8859_1 encoding
            out.write((""HTTP/1.0 ""+responseStatusValue).getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);
            out.write(""Content-Type: text/plain"".getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);

            if (parameters.containsKey(REDIRECT)) {
                final String redirectLocation =
                        HTTPConstants.HEADER_LOCATION + "": "" + parameters.get(REDIRECT);
                if (verbose) {
                    System.out.println(redirectLocation); // NOSONAR
                    log.info(redirectLocation);
                }
                out.write(redirectLocation.getBytes(ISO_8859_1));
                out.write(CRLF);
            }

            // Look for special Header request
            String headersValue = getRequestHeaderValue(headerString, ""X-SetHeaders""); //$NON-NLS-1$
            if (headersValue != null) {
                String[] headersToSet = headersValue.split(""\\|"");
                for (String string : headersToSet) {
                    out.write(string.getBytes(ISO_8859_1));
                    out.write(CRLF);
                }
            }

            // Look for special Response Length header
            String responseLengthValue = getRequestHeaderValue(headerString, ""X-ResponseLength""); //$NON-NLS-1$
            int responseLength=-1;
            if(responseLengthValue != null) {
                responseLength = Integer.parseInt(responseLengthValue);
            }

            // Look for special Cookie request
            String cookieHeaderValue = getRequestHeaderValue(headerString, ""X-SetCookie""); //$NON-NLS-1$
            if (cookieHeaderValue != null) {
                out.write(""Set-Cookie: "".getBytes(ISO_8859_1));
                out.write(cookieHeaderValue.getBytes(ISO_8859_1));
                out.write(CRLF);
            }
            out.write(CRLF);
            out.flush();

            if(responseLength>=0) {
                out.write(baos.toByteArray(), 0, Math.min(baos.toByteArray().length, responseLength));
            } else {
                out.write(baos.toByteArray());
            }
            // Check if we have found a content-length header
            String contentLengthHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.HEADER_CONTENT_LENGTH);
            if(contentLengthHeaderValue != null) {
                contentLength = Integer.parseInt(contentLengthHeaderValue);
            }
            // Look for special Sleep request
            String sleepHeaderValue = getRequestHeaderValue(headerString, ""X-Sleep""); //$NON-NLS-1$
            if(sleepHeaderValue != null) {
                TimeUnit.MILLISECONDS.sleep(Integer.parseInt(sleepHeaderValue));
            }
            String transferEncodingHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.TRANSFER_ENCODING);
            if(transferEncodingHeaderValue != null) {
                isChunked = transferEncodingHeaderValue.equalsIgnoreCase(""chunked""); //$NON-NLS-1$
                // We only support chunked transfer encoding
                if(!isChunked) {
                    log.error(""Transfer-Encoding header set, the value is not supported : {}"", transferEncodingHeaderValue);
                }
            }

            // If we know the content length, we can allow the reading of
            // the request to block until more data arrives.
            // If it is chunked transfer, we cannot allow the reading to
            // block, because we do not know when to stop reading, because
            // the chunked transfer is not properly supported yet
            length = 0;
            if(contentLength > 0) {
                // Check how much of the body we have already read as part of reading
                // the headers
                // We subtract two bytes for the crlf divider between header and body
                int totalReadBytes = headerString.length() - positionOfBody - 2;

                // We know when to stop reading, so we can allow the read method to block
                log.debug(""Reading, {} < {}"", totalReadBytes, contentLength);
                while((totalReadBytes < contentLength) && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);

                    totalReadBytes += length;
                    log.debug(""totalReadBytes: {}"", totalReadBytes);
                }
            }
            else if (isChunked) {
                // It is chunked transfer encoding, which we do not really support yet.
                // So we just read without blocking, because we do not know when to
                // stop reading, so we cannot block
                // TODO properly implement support for chunked transfer, i.e. to
                // know when we have read the whole request, and therefore allow
                // the reading to block
                log.debug(""Chunked"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    out.write(buffer, 0, length);
                }
            }
            else {
                // The request has no body, or it has a transfer encoding we do not support.
                // In either case, we read any data available
                log.debug(""Other"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);
                }
            }
            log.debug(""Flush"");
            out.flush();
        } catch (IOException | InterruptedException e) {
            log.error("""", e);
        } finally {
            JOrphanUtils.closeQuietly(out);
            JOrphanUtils.closeQuietly(in);
            JOrphanUtils.closeQuietly(clientSocket);
        }
        log.debug(""End of Thread"");
    }",,
jmeter,14121,"log.debug(""XMLSchemaAssertionGui.modifyTestElement() called"")",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/gui/XMLSchemaAssertionGUI.java/#L84,"@Override
    public void modifyTestElement(TestElement inElement) {

        
---------------Reference log start----------------
log.debug(""XMLSchemaAssertionGui.modifyTestElement() called"")
---------------Reference log end----------------
        configureTestElement(inElement);
        ((XMLSchemaAssertion) inElement).setXsdFileName(xmlSchema.getText());
    }",,
jmeter,14746,"log.info(""Starting setUp ThreadGroup: {} : {} "", groupCount, groupName)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/StandardJMeterEngine.java/#L414,"@Override
    public void run() {
        log.info(""Running the test!"");
        running = true;

        /*
         * Ensure that the sample variables are correctly initialised for each run.
         */
        SampleEvent.initSampleVariables();

        JMeterContextService.startTest();
        try {
            PreCompiler compiler = new PreCompiler();
            test.traverse(compiler);
        } catch (RuntimeException e) {
            log.error(""Error occurred compiling the tree:"",e);
            JMeterUtils.reportErrorToUser(""Error occurred compiling the tree: - see log file"", e);
            return; // no point continuing
        }
        /**
         * Notification of test listeners needs to happen after function
         * replacement, but before setting RunningVersion to true.
         */
        SearchByClass<TestStateListener> testListeners = new SearchByClass<>(TestStateListener.class); // TL - S&E
        test.traverse(testListeners);

        // Merge in any additional test listeners
        // currently only used by the function parser
        testListeners.getSearchResults().addAll(testList);
        testList.clear(); // no longer needed

        test.traverse(new TurnElementsOn());
        notifyTestListenersOfStart(testListeners);

        List<?> testLevelElements = new ArrayList<>(test.list(test.getArray()[0]));
        removeThreadGroups(testLevelElements);

        SearchByClass<SetupThreadGroup> setupSearcher = new SearchByClass<>(SetupThreadGroup.class);
        SearchByClass<AbstractThreadGroup> searcher = new SearchByClass<>(AbstractThreadGroup.class);
        SearchByClass<PostThreadGroup> postSearcher = new SearchByClass<>(PostThreadGroup.class);

        test.traverse(setupSearcher);
        test.traverse(searcher);
        test.traverse(postSearcher);

        TestCompiler.initialize();
        // for each thread group, generate threads
        // hand each thread the sampler controller
        // and the listeners, and the timer
        Iterator<SetupThreadGroup> setupIter = setupSearcher.getSearchResults().iterator();
        Iterator<AbstractThreadGroup> iter = searcher.getSearchResults().iterator();
        Iterator<PostThreadGroup> postIter = postSearcher.getSearchResults().iterator();

        ListenerNotifier notifier = new ListenerNotifier();

        int groupCount = 0;
        JMeterContextService.clearTotalThreads();

        if (setupIter.hasNext()) {
            log.info(""Starting setUp thread groups"");
            while (running && setupIter.hasNext()) {//for each setup thread group
                AbstractThreadGroup group = setupIter.next();
                groupCount++;
                String groupName = group.getName();
                
---------------Reference log start----------------
log.info(""Starting setUp ThreadGroup: {} : {} "", groupCount, groupName)
---------------Reference log end----------------
                startThreadGroup(group, groupCount, setupSearcher, testLevelElements, notifier);
                if (serialized && setupIter.hasNext()) {
                    log.info(""Waiting for setup thread group: {} to finish before starting next setup group"",
                            groupName);
                    group.waitThreadsStopped();
                }
            }
            log.info(""Waiting for all setup thread groups to exit"");
            //wait for all Setup Threads To Exit
            waitThreadsStopped();
            log.info(""All Setup Threads have ended"");
            groupCount=0;
            JMeterContextService.clearTotalThreads();
        }

        groups.clear(); // The groups have all completed now

        /*
         * Here's where the test really starts. Run a Full GC now: it's no harm
         * at all (just delays test start by a tiny amount) and hitting one too
         * early in the test can impair results for short tests.
         */
        JMeterUtils.helpGC();

        JMeterContextService.getContext().setSamplingStarted(true);
        boolean mainGroups = running; // still running at this point, i.e. setUp was not cancelled
        while (running && iter.hasNext()) {// for each thread group
            AbstractThreadGroup group = iter.next();
            //ignore Setup and Post here.  We could have filtered the searcher. but then
            //future Thread Group objects wouldn't execute.
            if (group instanceof SetupThreadGroup ||
                    group instanceof PostThreadGroup) {
                continue;
            }
            groupCount++;
            String groupName = group.getName();
            log.info(""Starting ThreadGroup: {} : {}"", groupCount, groupName);
            startThreadGroup(group, groupCount, searcher, testLevelElements, notifier);
            if (serialized && iter.hasNext()) {
                log.info(""Waiting for thread group: {} to finish before starting next group"", groupName);
                group.waitThreadsStopped();
            }
        } // end of thread groups
        if (groupCount == 0){ // No TGs found
            log.info(""No enabled thread groups found"");
        } else {
            if (running) {
                log.info(""All thread groups have been started"");
            } else {
                log.info(""Test stopped - no more thread groups will be started"");
            }
        }

        //wait for all Test Threads To Exit
        waitThreadsStopped();
        groups.clear(); // The groups have all completed now

        if (postIter.hasNext()){
            groupCount = 0;
            JMeterContextService.clearTotalThreads();
            log.info(""Starting tearDown thread groups"");
            if (mainGroups && !running) { // i.e. shutdown/stopped during main thread groups
                running = tearDownOnShutdown; // re-enable for tearDown if necessary
            }
            while (running && postIter.hasNext()) {//for each setup thread group
                AbstractThreadGroup group = postIter.next();
                groupCount++;
                String groupName = group.getName();
                log.info(""Starting tearDown ThreadGroup: {} : {}"", groupCount, groupName);
                startThreadGroup(group, groupCount, postSearcher, testLevelElements, notifier);
                if (serialized && postIter.hasNext()) {
                    log.info(""Waiting for post thread group: {} to finish before starting next post group"", groupName);
                    group.waitThreadsStopped();
                }
            }
            waitThreadsStopped(); // wait for Post threads to stop
        }

        notifyTestListenersOfEnd(testListeners);
        JMeterContextService.endTest();
        if (JMeter.isNonGUI() && SYSTEM_EXIT_FORCED) {
            log.info(""Forced JVM shutdown requested at end of test"");
            System.exit(0); // NOSONAR Intentional
        }
    }",,
jmeter,15085,"log.info(""Stopping because end time detected by thread: {}"", threadName)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/threads/JMeterThread.java/#L231,"private void stopSchedulerIfNeeded() {
        long now = System.currentTimeMillis();
        if (now >= endTime) {
            running = false;
            
---------------Reference log start----------------
log.info(""Stopping because end time detected by thread: {}"", threadName)
---------------Reference log end----------------
        }
    }",,
jmeter,13291,"log.debug(""execute ({} {})"", fileName, xpathString)",debug,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/XPath.java/#L72,"@Override
    public synchronized String execute(SampleResult previousResult, Sampler currentSampler)
            throws InvalidVariableException {
        String fileName = ((CompoundVariable) values[0]).execute();
        String xpathString = ((CompoundVariable) values[1]).execute();

        
---------------Reference log start----------------
log.debug(""execute ({} {})"", fileName, xpathString)
---------------Reference log end----------------

        String myValue = XPathWrapper.getXPathString(fileName, xpathString);

        log.debug(""execute value: {}"", myValue);

        return myValue;
    }",,
jmeter,14758,"log.info(""Forced JVM shutdown requested at end of test"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/StandardJMeterEngine.java/#L496,"@Override
    public void run() {
        log.info(""Running the test!"");
        running = true;

        /*
         * Ensure that the sample variables are correctly initialised for each run.
         */
        SampleEvent.initSampleVariables();

        JMeterContextService.startTest();
        try {
            PreCompiler compiler = new PreCompiler();
            test.traverse(compiler);
        } catch (RuntimeException e) {
            log.error(""Error occurred compiling the tree:"",e);
            JMeterUtils.reportErrorToUser(""Error occurred compiling the tree: - see log file"", e);
            return; // no point continuing
        }
        /**
         * Notification of test listeners needs to happen after function
         * replacement, but before setting RunningVersion to true.
         */
        SearchByClass<TestStateListener> testListeners = new SearchByClass<>(TestStateListener.class); // TL - S&E
        test.traverse(testListeners);

        // Merge in any additional test listeners
        // currently only used by the function parser
        testListeners.getSearchResults().addAll(testList);
        testList.clear(); // no longer needed

        test.traverse(new TurnElementsOn());
        notifyTestListenersOfStart(testListeners);

        List<?> testLevelElements = new ArrayList<>(test.list(test.getArray()[0]));
        removeThreadGroups(testLevelElements);

        SearchByClass<SetupThreadGroup> setupSearcher = new SearchByClass<>(SetupThreadGroup.class);
        SearchByClass<AbstractThreadGroup> searcher = new SearchByClass<>(AbstractThreadGroup.class);
        SearchByClass<PostThreadGroup> postSearcher = new SearchByClass<>(PostThreadGroup.class);

        test.traverse(setupSearcher);
        test.traverse(searcher);
        test.traverse(postSearcher);

        TestCompiler.initialize();
        // for each thread group, generate threads
        // hand each thread the sampler controller
        // and the listeners, and the timer
        Iterator<SetupThreadGroup> setupIter = setupSearcher.getSearchResults().iterator();
        Iterator<AbstractThreadGroup> iter = searcher.getSearchResults().iterator();
        Iterator<PostThreadGroup> postIter = postSearcher.getSearchResults().iterator();

        ListenerNotifier notifier = new ListenerNotifier();

        int groupCount = 0;
        JMeterContextService.clearTotalThreads();

        if (setupIter.hasNext()) {
            log.info(""Starting setUp thread groups"");
            while (running && setupIter.hasNext()) {//for each setup thread group
                AbstractThreadGroup group = setupIter.next();
                groupCount++;
                String groupName = group.getName();
                log.info(""Starting setUp ThreadGroup: {} : {} "", groupCount, groupName);
                startThreadGroup(group, groupCount, setupSearcher, testLevelElements, notifier);
                if (serialized && setupIter.hasNext()) {
                    log.info(""Waiting for setup thread group: {} to finish before starting next setup group"",
                            groupName);
                    group.waitThreadsStopped();
                }
            }
            log.info(""Waiting for all setup thread groups to exit"");
            //wait for all Setup Threads To Exit
            waitThreadsStopped();
            log.info(""All Setup Threads have ended"");
            groupCount=0;
            JMeterContextService.clearTotalThreads();
        }

        groups.clear(); // The groups have all completed now

        /*
         * Here's where the test really starts. Run a Full GC now: it's no harm
         * at all (just delays test start by a tiny amount) and hitting one too
         * early in the test can impair results for short tests.
         */
        JMeterUtils.helpGC();

        JMeterContextService.getContext().setSamplingStarted(true);
        boolean mainGroups = running; // still running at this point, i.e. setUp was not cancelled
        while (running && iter.hasNext()) {// for each thread group
            AbstractThreadGroup group = iter.next();
            //ignore Setup and Post here.  We could have filtered the searcher. but then
            //future Thread Group objects wouldn't execute.
            if (group instanceof SetupThreadGroup ||
                    group instanceof PostThreadGroup) {
                continue;
            }
            groupCount++;
            String groupName = group.getName();
            log.info(""Starting ThreadGroup: {} : {}"", groupCount, groupName);
            startThreadGroup(group, groupCount, searcher, testLevelElements, notifier);
            if (serialized && iter.hasNext()) {
                log.info(""Waiting for thread group: {} to finish before starting next group"", groupName);
                group.waitThreadsStopped();
            }
        } // end of thread groups
        if (groupCount == 0){ // No TGs found
            log.info(""No enabled thread groups found"");
        } else {
            if (running) {
                log.info(""All thread groups have been started"");
            } else {
                log.info(""Test stopped - no more thread groups will be started"");
            }
        }

        //wait for all Test Threads To Exit
        waitThreadsStopped();
        groups.clear(); // The groups have all completed now

        if (postIter.hasNext()){
            groupCount = 0;
            JMeterContextService.clearTotalThreads();
            log.info(""Starting tearDown thread groups"");
            if (mainGroups && !running) { // i.e. shutdown/stopped during main thread groups
                running = tearDownOnShutdown; // re-enable for tearDown if necessary
            }
            while (running && postIter.hasNext()) {//for each setup thread group
                AbstractThreadGroup group = postIter.next();
                groupCount++;
                String groupName = group.getName();
                log.info(""Starting tearDown ThreadGroup: {} : {}"", groupCount, groupName);
                startThreadGroup(group, groupCount, postSearcher, testLevelElements, notifier);
                if (serialized && postIter.hasNext()) {
                    log.info(""Waiting for post thread group: {} to finish before starting next post group"", groupName);
                    group.waitThreadsStopped();
                }
            }
            waitThreadsStopped(); // wait for Post threads to stop
        }

        notifyTestListenersOfEnd(testListeners);
        JMeterContextService.endTest();
        if (JMeter.isNonGUI() && SYSTEM_EXIT_FORCED) {
            
---------------Reference log start----------------
log.info(""Forced JVM shutdown requested at end of test"")
---------------Reference log end----------------
            System.exit(0); // NOSONAR Intentional
        }
    }",,
jmeter,14299,slf4jLogger.debug(message),debug,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/logging/Slf4jLogkitLogger.java/#L153,"@Override
    public void log(org.apache.log.Priority priority, String message) {
        if (priority == org.apache.log.Priority.FATAL_ERROR) {
            slf4jLogger.error(message);
        } else if (priority == org.apache.log.Priority.ERROR) {
            slf4jLogger.error(message);
        } else if (priority == org.apache.log.Priority.WARN) {
            slf4jLogger.warn(message);
        } else if (priority == org.apache.log.Priority.INFO) {
            slf4jLogger.info(message);
        } else if (priority == org.apache.log.Priority.DEBUG) {
            
---------------Reference log start----------------
slf4jLogger.debug(message)
---------------Reference log end----------------
        }
    }",,
jmeter,14333,"log.debug(""listClasses : {}"", clazz)",debug,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/reflect/ClassFinder.java/#L332,"public static List<String> findClasses(String[] searchPathsOrJars, ClassFilter filter) throws IOException {
        if (log.isDebugEnabled()) {
            log.debug(""findClasses with searchPathsOrJars : {} and classFilter : {}"",
                    Arrays.toString(searchPathsOrJars), filter);
        }

        // Find all jars in the search path
        Collection<File> strPathsOrJars = addJarsInPath(searchPathsOrJars);

        // Some of the jars might be out of classpath, however java.class.path does not represent
        // the actual ClassLoader in use. For instance, NewDriver builds its own classpath

        Set<String> listClasses = new TreeSet<>();
        // first get all the classes
        for (File path : strPathsOrJars) {
            findClassesInOnePath(path, listClasses, filter);
        }

        if (log.isDebugEnabled()) {
            log.debug(""listClasses.size()={}"", listClasses.size());
            for (String clazz : listClasses) {
                
---------------Reference log start----------------
log.debug(""listClasses : {}"", clazz)
---------------Reference log end----------------
            }
        }

        return new ArrayList<>(listClasses);
    }",,
jmeter,14319,"log.debug(""Exception is: "", ioe)",debug,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/exec/KeyToolUtils.java/#L486,"private static boolean checkKeytool(String keytoolPath) {
        final SystemCommand nativeCommand = new SystemCommand(null, null);
        final List<String> arguments = new ArrayList<>();
        arguments.add(keytoolPath);
        arguments.add(""-help""); // $NON-NLS-1$
        try {
            int status = nativeCommand.run(arguments);
            if (log.isDebugEnabled()) {
                log.debug(""checkKeyTool:status="" + status);
                log.debug(nativeCommand.getOutResult());
            }
            /*
             * Some implementations of keytool return status 1 for -help
             * MacOS/Java 7 returns 2 if it cannot find keytool
             */
            return status == 0 || status == 1; // TODO this is rather fragile
        } catch (IOException ioe) {
            log.info(""Exception checking for keytool existence, will return false, try another way."");
            
---------------Reference log start----------------
log.debug(""Exception is: "", ioe)
---------------Reference log end----------------
            return false;
        } catch (InterruptedException e) { // NOSONAR
            log.error(""Command was interrupted\n"" + nativeCommand.getOutResult(), e);
            Thread.currentThread().interrupt();
            return false;
        } catch (TimeoutException e) { // NOSONAR
            log.info(""Timeout reached while checking for keytool existence, will return false, try another way."", e);
            return false;
        }
    }",,
jmeter,14389,"LOGGER.error(""No name provided for GuiLogEventAppender"")",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/logging/GuiLogEventAppender.java/#L71,"@PluginFactory
    public static GuiLogEventAppender createAppender(@PluginAttribute(""name"") String name,
            @PluginAttribute(""ignoreExceptions"") boolean ignoreExceptions,
            @PluginElement(""Layout"") Layout<? extends Serializable> layout, @PluginElement(""Filters"") Filter filter) {
        if (name == null) {
            
---------------Reference log start----------------
LOGGER.error(""No name provided for GuiLogEventAppender"")
---------------Reference log end----------------
            return null;
        }

        if (layout == null) {
            layout = PatternLayout.createDefaultLayout();
        }

        return new GuiLogEventAppender(name, filter, layout, ignoreExceptions);
    }",,
jmeter,14072,"log.error(""No listener client data found for BackendListener {}"", myName)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/BackendListener.java/#L359,"@Override
    public void testEnded(String host) {
        synchronized (LOCK) {
            ListenerClientData listenerClientDataForName = queuesByTestElementName.get(myName);
            if (log.isDebugEnabled()) {
                log.debug(""testEnded called on instance {}#{}"", myName, listenerClientDataForName.instanceCount);
            }
            if (listenerClientDataForName != null) {
                listenerClientDataForName.instanceCount--;
                if (listenerClientDataForName.instanceCount > 0) {
                    // Not the last instance of myName
                    return;
                } else {
                    queuesByTestElementName.remove(myName);
                }
            } else {
                
---------------Reference log start----------------
log.error(""No listener client data found for BackendListener {}"", myName)
---------------Reference log end----------------
            }
        }
        try {
            listenerClientData.queue.put(FINAL_SAMPLE_RESULT);
        } catch (Exception ex) {
            log.warn(""testEnded() with exception: {}"", ex.getMessage(), ex);
        }
        if (listenerClientData.queueWaits.longValue() > 0) {
            log.warn(
                    ""QueueWaits: {}; QueueWaitTime: {} (nanoseconds), you may need to increase queue capacity, see property 'backend_queue_capacity'"",
                    listenerClientData.queueWaits, listenerClientData.queueWaitTime);
        }
        try {
            listenerClientData.latch.await();
            BackendListenerContext context = new BackendListenerContext(getArguments());
            listenerClientData.client.teardownTest(context);
        } catch (Exception e) {
            throw new IllegalStateException(""Failed calling teardownTest"", e);
        }
    }",,
jmeter,13420,"log.debug(""Flush"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/HttpMirrorThread.java/#L280,"@Override
    public void run() {
        log.debug(""Starting thread"");
        BufferedInputStream in = null;
        BufferedOutputStream out = null;

        try {
            in = new BufferedInputStream(clientSocket.getInputStream());

            // Read the header part, we will be looking for a content-length
            // header, so we know how much we should read.
            // We assume headers are in ISO_8859_1
            // If we do not find such a header, we will just have to read until
            // we have to block to read more, until we support chunked transfer
            int contentLength = -1;
            boolean isChunked = false;
            byte[] buffer = new byte[1024];
            StringBuilder headers = new StringBuilder();
            int length = 0;
            int positionOfBody = 0;
            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            while(positionOfBody <= 0 && ((length = in.read(buffer)) != -1)) {
                log.debug(""Write body"");
                baos.write(buffer, 0, length); // echo back
                headers.append(new String(buffer, 0, length, ISO_8859_1));
                // Check if we have read all the headers
                positionOfBody = getPositionOfBody(headers.toString());
            }

            baos.close();
            final String headerString = headers.toString();
            if(headerString.length() == 0 || headerString.indexOf('\r') < 0) {
                log.error(""Invalid request received:'{}'"", headerString);
                return;
            }
            log.debug(""Received => '{}'"", headerString);
            final String firstLine = headerString.substring(0, headerString.indexOf('\r'));
            final String[] requestParts = firstLine.split(""\\s+"");
            final String requestMethod = requestParts[0];
            final String requestPath = requestParts[1];
            final HashMap<String, String> parameters = new HashMap<>();
            if (HTTPConstants.GET.equals(requestMethod)) {
                int querypos = requestPath.indexOf('?');
                if (querypos >= 0) {
                    String query;
                    try {
                        URI uri = new URI(requestPath); // Use URI because it will decode the query
                        query = uri.getQuery();
                    } catch (URISyntaxException e) {
                        log.warn(e.getMessage());
                        query=requestPath.substring(querypos+1);
                    }
                    if (query != null) {
                        String[] params = query.split(""&"");
                        for(String param : params) {
                            String[] parts = param.split(""="",2);
                            if (parts.length==2) {
                                parameters.put(parts[0], parts[1]);
                            } else { // allow for parameter name only
                                parameters.put(parts[0], """");
                            }
                        }
                    }
                }
            }

            final boolean verbose = parameters.containsKey(VERBOSE);

            if (verbose) {
                System.out.println(firstLine); // NOSONAR
                log.info(firstLine);
            }

            // Look for special Response Length header
            String responseStatusValue = getRequestHeaderValue(headerString, ""X-ResponseStatus""); //$NON-NLS-1$
            if(responseStatusValue == null) {
                responseStatusValue = ""200 OK"";
            }
            // Do this before the status check so can override the status, e.g. with a different redirect type
            if (parameters.containsKey(REDIRECT)) {
                responseStatusValue = ""302 Temporary Redirect"";
            }
            if (parameters.containsKey(STATUS)) {
                responseStatusValue = parameters.get(STATUS);
            }

            log.debug(""Write headers"");
            out = new BufferedOutputStream(clientSocket.getOutputStream());
            // The headers are written using ISO_8859_1 encoding
            out.write((""HTTP/1.0 ""+responseStatusValue).getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);
            out.write(""Content-Type: text/plain"".getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);

            if (parameters.containsKey(REDIRECT)) {
                final String redirectLocation =
                        HTTPConstants.HEADER_LOCATION + "": "" + parameters.get(REDIRECT);
                if (verbose) {
                    System.out.println(redirectLocation); // NOSONAR
                    log.info(redirectLocation);
                }
                out.write(redirectLocation.getBytes(ISO_8859_1));
                out.write(CRLF);
            }

            // Look for special Header request
            String headersValue = getRequestHeaderValue(headerString, ""X-SetHeaders""); //$NON-NLS-1$
            if (headersValue != null) {
                String[] headersToSet = headersValue.split(""\\|"");
                for (String string : headersToSet) {
                    out.write(string.getBytes(ISO_8859_1));
                    out.write(CRLF);
                }
            }

            // Look for special Response Length header
            String responseLengthValue = getRequestHeaderValue(headerString, ""X-ResponseLength""); //$NON-NLS-1$
            int responseLength=-1;
            if(responseLengthValue != null) {
                responseLength = Integer.parseInt(responseLengthValue);
            }

            // Look for special Cookie request
            String cookieHeaderValue = getRequestHeaderValue(headerString, ""X-SetCookie""); //$NON-NLS-1$
            if (cookieHeaderValue != null) {
                out.write(""Set-Cookie: "".getBytes(ISO_8859_1));
                out.write(cookieHeaderValue.getBytes(ISO_8859_1));
                out.write(CRLF);
            }
            out.write(CRLF);
            out.flush();

            if(responseLength>=0) {
                out.write(baos.toByteArray(), 0, Math.min(baos.toByteArray().length, responseLength));
            } else {
                out.write(baos.toByteArray());
            }
            // Check if we have found a content-length header
            String contentLengthHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.HEADER_CONTENT_LENGTH);
            if(contentLengthHeaderValue != null) {
                contentLength = Integer.parseInt(contentLengthHeaderValue);
            }
            // Look for special Sleep request
            String sleepHeaderValue = getRequestHeaderValue(headerString, ""X-Sleep""); //$NON-NLS-1$
            if(sleepHeaderValue != null) {
                TimeUnit.MILLISECONDS.sleep(Integer.parseInt(sleepHeaderValue));
            }
            String transferEncodingHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.TRANSFER_ENCODING);
            if(transferEncodingHeaderValue != null) {
                isChunked = transferEncodingHeaderValue.equalsIgnoreCase(""chunked""); //$NON-NLS-1$
                // We only support chunked transfer encoding
                if(!isChunked) {
                    log.error(""Transfer-Encoding header set, the value is not supported : {}"", transferEncodingHeaderValue);
                }
            }

            // If we know the content length, we can allow the reading of
            // the request to block until more data arrives.
            // If it is chunked transfer, we cannot allow the reading to
            // block, because we do not know when to stop reading, because
            // the chunked transfer is not properly supported yet
            length = 0;
            if(contentLength > 0) {
                // Check how much of the body we have already read as part of reading
                // the headers
                // We subtract two bytes for the crlf divider between header and body
                int totalReadBytes = headerString.length() - positionOfBody - 2;

                // We know when to stop reading, so we can allow the read method to block
                log.debug(""Reading, {} < {}"", totalReadBytes, contentLength);
                while((totalReadBytes < contentLength) && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);

                    totalReadBytes += length;
                    log.debug(""totalReadBytes: {}"", totalReadBytes);
                }
            }
            else if (isChunked) {
                // It is chunked transfer encoding, which we do not really support yet.
                // So we just read without blocking, because we do not know when to
                // stop reading, so we cannot block
                // TODO properly implement support for chunked transfer, i.e. to
                // know when we have read the whole request, and therefore allow
                // the reading to block
                log.debug(""Chunked"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    out.write(buffer, 0, length);
                }
            }
            else {
                // The request has no body, or it has a transfer encoding we do not support.
                // In either case, we read any data available
                log.debug(""Other"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);
                }
            }
            
---------------Reference log start----------------
log.debug(""Flush"")
---------------Reference log end----------------
            out.flush();
        } catch (IOException | InterruptedException e) {
            log.error("""", e);
        } finally {
            JOrphanUtils.closeQuietly(out);
            JOrphanUtils.closeQuietly(in);
            JOrphanUtils.closeQuietly(clientSocket);
        }
        log.debug(""End of Thread"");
    }",,
jmeter,13526,"log.error(""Program error: test script recording target not found."")",error,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/ProxyControl.java/#L1086,"public JMeterTreeNode findTargetControllerNode() {
        JMeterTreeNode myTarget = getTarget();
        if (myTarget != null) {
            return myTarget;
        }
        myTarget = findFirstNodeOfType(RecordingController.class);
        if (myTarget != null) {
            return myTarget;
        }
        myTarget = findFirstNodeOfType(AbstractThreadGroup.class);
        if (myTarget != null) {
            return myTarget;
        }
        
---------------Reference log start----------------
log.error(""Program error: test script recording target not found."")
---------------Reference log end----------------
        return null;
    }",,
jmeter,14116,"log.error(""BeanShell Jar missing?"", ex)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/BeanShellAssertion.java/#L114,"@Override
    public AssertionResult getResult(SampleResult response) {
        AssertionResult result = new AssertionResult(getName());

        final BeanShellInterpreter bshInterpreter = getBeanShellInterpreter();
        if (bshInterpreter == null) {
            result.setFailure(true);
            result.setError(true);
            result.setFailureMessage(""BeanShell Interpreter not found"");
            return result;
        }
        try {

            // Add SamplerData for consistency with BeanShell Sampler
            bshInterpreter.set(""SampleResult"", response); //$NON-NLS-1$
            bshInterpreter.set(""Response"", response); //$NON-NLS-1$
            bshInterpreter.set(""ResponseData"", response.getResponseData());//$NON-NLS-1$
            bshInterpreter.set(""ResponseCode"", response.getResponseCode());//$NON-NLS-1$
            bshInterpreter.set(""ResponseMessage"", response.getResponseMessage());//$NON-NLS-1$
            bshInterpreter.set(""ResponseHeaders"", response.getResponseHeaders());//$NON-NLS-1$
            bshInterpreter.set(""RequestHeaders"", response.getRequestHeaders());//$NON-NLS-1$
            bshInterpreter.set(""SampleLabel"", response.getSampleLabel());//$NON-NLS-1$
            bshInterpreter.set(""SamplerData"", response.getSamplerData());//$NON-NLS-1$
            bshInterpreter.set(""Successful"", response.isSuccessful());//$NON-NLS-1$

            // The following are used to set the Result details on return from
            // the script:
            bshInterpreter.set(""FailureMessage"", """");//$NON-NLS-1$ //$NON-NLS-2$
            bshInterpreter.set(""Failure"", false);//$NON-NLS-1$

            processFileOrScript(bshInterpreter);

            result.setFailureMessage(bshInterpreter.get(""FailureMessage"").toString());//$NON-NLS-1$
            result.setFailure(Boolean.parseBoolean(bshInterpreter.get(""Failure"") //$NON-NLS-1$
                    .toString()));
            result.setError(false);
        }
        catch (NoClassDefFoundError ex) { // NOSONAR explicitly trap this error to make tests work better
            
---------------Reference log start----------------
log.error(""BeanShell Jar missing?"", ex)
---------------Reference log end----------------
            result.setError(true);
            result.setFailureMessage(""BeanShell Jar missing? "" + ex.toString());
            response.setStopThread(true); // No point continuing
        } catch (Exception ex) // Mainly for bsh.EvalError
        {
            result.setError(true);
            result.setFailureMessage(ex.toString());
            log.warn(""Error in BeanShellAssertion"", ex);
        }

        return result;
    }",,
jmeter,14938,"log.warn(""Truststore file not found, loading empty truststore"")",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/SSLManager.java/#L274,"protected KeyStore getTrustStore() {
        if (!truststoreLoaded) {

            truststoreLoaded=true;// we've tried ...

            String fileName = System.getProperty(SSL_TRUST_STORE);
            if (fileName == null) {
                return null;
            }
            log.info(""TrustStore Location: {}"", fileName);

            try {
                this.trustStore = KeyStore.getInstance(""JKS"");
                log.info(""TrustStore created OK, Type: JKS"");
            } catch (Exception e) {
                this.trustStore = null;
                throw new RuntimeException(""Problem creating truststore: ""+e.getMessage(), e);
            }

            try {
                File initStore = new File(fileName);

                if (initStore.exists()) {
                    try (InputStream fis = new FileInputStream(initStore)) {
                        this.trustStore.load(fis, null);
                        log.info(""Truststore loaded OK from file"");
                    }
                } else {
                    
---------------Reference log start----------------
log.warn(""Truststore file not found, loading empty truststore"")
---------------Reference log end----------------
                    this.trustStore.load(null, null);
                }
            } catch (Exception e) {
                throw new RuntimeException(""Can't load TrustStore: "" + e.getMessage(), e);
            }
        }

        return this.trustStore;
    }",,
jmeter,14548,"log.error(""{}: error while processing [{}]"", testElementName, condition, ex)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/control/IfController.java/#L120,"@Override
        public boolean evaluate(String testElementName, String condition) {
            try {
                ScriptContext newContext = new SimpleScriptContext();
                newContext.setBindings(NASHORN_ENGINE.get().createBindings(), ScriptContext.ENGINE_SCOPE);
                Object o = NASHORN_ENGINE.get().eval(condition, newContext);
                return computeResultFromString(condition, o.toString());
            } catch (Exception ex) {
                
---------------Reference log start----------------
log.error(""{}: error while processing [{}]"", testElementName, condition, ex)
---------------Reference log end----------------
            }
            return false;
        }",,
jmeter,13942,"log.error("""", ex)",error,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/TCPSampler.java/#L402,"@Override
    public SampleResult sample(Entry e)// Entry tends to be ignored ...
    {
        if (firstSample) { // Do stuff we cannot do as part of threadStarted()
            initSampling();
            firstSample=false;
        }
        final boolean reUseConnection = isReUseConnection();
        final boolean closeConnection = isCloseConnection();
        String socketKey = getSocketKey();
        if (log.isDebugEnabled()){
            log.debug(getLabel() + "" "" + getFilename() + "" "" + getUsername() + "" "" + getPassword());
        }
        SampleResult res = new SampleResult();
        boolean isSuccessful = false;
        res.setSampleLabel(getName());// Use the test element name for the label
        String sb = ""Host: "" + getServer() +
                "" Port: "" + getPort() + ""\n"" +
                ""Reuse: "" + reUseConnection +
                "" Close: "" + closeConnection + ""\n["" +
                ""SOLINGER: "" + getSoLinger() +
                "" EOL: "" + getEolByte() +
                "" noDelay: "" + getNoDelay() +
                ""]"";
        res.setSamplerData(sb);
        res.sampleStart();
        try {
            Socket sock;
            try {
                sock = getSocket(socketKey);
            } finally {
                res.connectEnd();
            }
            if (sock == null) {
                res.setResponseCode(""500""); //$NON-NLS-1$
                res.setResponseMessage(getError());
            } else if (protocolHandler == null){
                res.setResponseCode(""500""); //$NON-NLS-1$
                res.setResponseMessage(""Protocol handler not found"");
            } else {
                currentSocket = sock;
                InputStream is = sock.getInputStream();
                OutputStream os = sock.getOutputStream();
                String req = getRequestData();
                // TODO handle filenames
                res.setSamplerData(req);
                protocolHandler.write(os, req);
                String in = protocolHandler.read(is, res);
                isSuccessful = setupSampleResult(res, in, null, protocolHandler);
            }
        } catch (ReadException ex) {
            
---------------Reference log start----------------
log.error("""", ex)
---------------Reference log end----------------
            isSuccessful=setupSampleResult(res, ex.getPartialResponse(), ex,protocolHandler);
            closeSocket(socketKey);
        } catch (Exception ex) {
            log.error("""", ex);
            isSuccessful=setupSampleResult(res, """", ex, protocolHandler);
            closeSocket(socketKey);
        } finally {
            currentSocket = null;
            // Calculate response time
            res.sampleEnd();

            // Set if we were successful or not
            res.setSuccessful(isSuccessful);

            if (!reUseConnection || closeConnection) {
                closeSocket(socketKey);
            }
        }
        return res;
    }",,
jmeter,14336,"log.error(""Error filtering class {}, it will be ignored"", className, e)",error,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/reflect/ClassFinder.java/#L408,"private static void applyFiltering(Set<String> classesSet, ClassFilter filter, String className) {
        try {
            if (filter.accept(className)) {
                classesSet.add(className);
            }
        } catch (Throwable e) { // NOSONAR : We need to trap also Errors
            
---------------Reference log start----------------
log.error(""Error filtering class {}, it will be ignored"", className, e)
---------------Reference log end----------------
        }
    }",,
jmeter,14744,"log.error(""Error occurred compiling the tree:"", e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/StandardJMeterEngine.java/#L365,"@Override
    public void run() {
        log.info(""Running the test!"");
        running = true;

        /*
         * Ensure that the sample variables are correctly initialised for each run.
         */
        SampleEvent.initSampleVariables();

        JMeterContextService.startTest();
        try {
            PreCompiler compiler = new PreCompiler();
            test.traverse(compiler);
        } catch (RuntimeException e) {
            
---------------Reference log start----------------
log.error(""Error occurred compiling the tree:"", e)
---------------Reference log end----------------
            JMeterUtils.reportErrorToUser(""Error occurred compiling the tree: - see log file"", e);
            return; // no point continuing
        }
        /**
         * Notification of test listeners needs to happen after function
         * replacement, but before setting RunningVersion to true.
         */
        SearchByClass<TestStateListener> testListeners = new SearchByClass<>(TestStateListener.class); // TL - S&E
        test.traverse(testListeners);

        // Merge in any additional test listeners
        // currently only used by the function parser
        testListeners.getSearchResults().addAll(testList);
        testList.clear(); // no longer needed

        test.traverse(new TurnElementsOn());
        notifyTestListenersOfStart(testListeners);

        List<?> testLevelElements = new ArrayList<>(test.list(test.getArray()[0]));
        removeThreadGroups(testLevelElements);

        SearchByClass<SetupThreadGroup> setupSearcher = new SearchByClass<>(SetupThreadGroup.class);
        SearchByClass<AbstractThreadGroup> searcher = new SearchByClass<>(AbstractThreadGroup.class);
        SearchByClass<PostThreadGroup> postSearcher = new SearchByClass<>(PostThreadGroup.class);

        test.traverse(setupSearcher);
        test.traverse(searcher);
        test.traverse(postSearcher);

        TestCompiler.initialize();
        // for each thread group, generate threads
        // hand each thread the sampler controller
        // and the listeners, and the timer
        Iterator<SetupThreadGroup> setupIter = setupSearcher.getSearchResults().iterator();
        Iterator<AbstractThreadGroup> iter = searcher.getSearchResults().iterator();
        Iterator<PostThreadGroup> postIter = postSearcher.getSearchResults().iterator();

        ListenerNotifier notifier = new ListenerNotifier();

        int groupCount = 0;
        JMeterContextService.clearTotalThreads();

        if (setupIter.hasNext()) {
            log.info(""Starting setUp thread groups"");
            while (running && setupIter.hasNext()) {//for each setup thread group
                AbstractThreadGroup group = setupIter.next();
                groupCount++;
                String groupName = group.getName();
                log.info(""Starting setUp ThreadGroup: {} : {} "", groupCount, groupName);
                startThreadGroup(group, groupCount, setupSearcher, testLevelElements, notifier);
                if (serialized && setupIter.hasNext()) {
                    log.info(""Waiting for setup thread group: {} to finish before starting next setup group"",
                            groupName);
                    group.waitThreadsStopped();
                }
            }
            log.info(""Waiting for all setup thread groups to exit"");
            //wait for all Setup Threads To Exit
            waitThreadsStopped();
            log.info(""All Setup Threads have ended"");
            groupCount=0;
            JMeterContextService.clearTotalThreads();
        }

        groups.clear(); // The groups have all completed now

        /*
         * Here's where the test really starts. Run a Full GC now: it's no harm
         * at all (just delays test start by a tiny amount) and hitting one too
         * early in the test can impair results for short tests.
         */
        JMeterUtils.helpGC();

        JMeterContextService.getContext().setSamplingStarted(true);
        boolean mainGroups = running; // still running at this point, i.e. setUp was not cancelled
        while (running && iter.hasNext()) {// for each thread group
            AbstractThreadGroup group = iter.next();
            //ignore Setup and Post here.  We could have filtered the searcher. but then
            //future Thread Group objects wouldn't execute.
            if (group instanceof SetupThreadGroup ||
                    group instanceof PostThreadGroup) {
                continue;
            }
            groupCount++;
            String groupName = group.getName();
            log.info(""Starting ThreadGroup: {} : {}"", groupCount, groupName);
            startThreadGroup(group, groupCount, searcher, testLevelElements, notifier);
            if (serialized && iter.hasNext()) {
                log.info(""Waiting for thread group: {} to finish before starting next group"", groupName);
                group.waitThreadsStopped();
            }
        } // end of thread groups
        if (groupCount == 0){ // No TGs found
            log.info(""No enabled thread groups found"");
        } else {
            if (running) {
                log.info(""All thread groups have been started"");
            } else {
                log.info(""Test stopped - no more thread groups will be started"");
            }
        }

        //wait for all Test Threads To Exit
        waitThreadsStopped();
        groups.clear(); // The groups have all completed now

        if (postIter.hasNext()){
            groupCount = 0;
            JMeterContextService.clearTotalThreads();
            log.info(""Starting tearDown thread groups"");
            if (mainGroups && !running) { // i.e. shutdown/stopped during main thread groups
                running = tearDownOnShutdown; // re-enable for tearDown if necessary
            }
            while (running && postIter.hasNext()) {//for each setup thread group
                AbstractThreadGroup group = postIter.next();
                groupCount++;
                String groupName = group.getName();
                log.info(""Starting tearDown ThreadGroup: {} : {}"", groupCount, groupName);
                startThreadGroup(group, groupCount, postSearcher, testLevelElements, notifier);
                if (serialized && postIter.hasNext()) {
                    log.info(""Waiting for post thread group: {} to finish before starting next post group"", groupName);
                    group.waitThreadsStopped();
                }
            }
            waitThreadsStopped(); // wait for Post threads to stop
        }

        notifyTestListenersOfEnd(testListeners);
        JMeterContextService.endTest();
        if (JMeter.isNonGUI() && SYSTEM_EXIT_FORCED) {
            log.info(""Forced JVM shutdown requested at end of test"");
            System.exit(0); // NOSONAR Intentional
        }
    }",,
jmeter,13916,"log.debug(""Read: {}\n{}"", w.size(), w.toString())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/TCPClientImpl.java/#L118,"@Override
    public String read(InputStream is, SampleResult sampleResult) throws ReadException{
        ByteArrayOutputStream w = new ByteArrayOutputStream();
        try {
            byte[] buffer = new byte[4096];
            int x;
            boolean first = true;
            while ((x = is.read(buffer)) > -1) {
                if (first) {
                    sampleResult.latencyEnd();
                    first = false;
                }
                w.write(buffer, 0, x);
                if (useEolByte && (buffer[x - 1] == eolByte)) {
                    break;
                }
            }

            // do we need to close byte array (or flush it?)
            if(log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Read: {}\n{}"", w.size(), w.toString())
---------------Reference log end----------------
            }
            return w.toString(CHARSET);
        } catch (IOException e) {
            throw new ReadException(""Error reading from server, bytes read: "" + w.size(), e, w.toString());
        }
    }",,
jmeter,13771,"logger.debug(""Message partially delivered"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/mail/src/main/java/org/apache/jmeter/protocol/smtp/sampler/protocol/SynchronousTransportListener.java/#L69,"@Override
    public void messagePartiallyDelivered(TransportEvent e) {
        
---------------Reference log start----------------
logger.debug(""Message partially delivered"")
---------------Reference log end----------------
        finish();
    }",,
jmeter,14543,"log.debug(""Condition value: '{}'"", res)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/control/WhileController.java/#L73,"private boolean endOfLoop(boolean loopEnd) {
        if(breakLoop) {
            return true;
        }
        String cnd = getCondition().trim();
        log.debug(""Condition string: '{}'"", cnd);
        boolean res;
        // If blank, only check previous sample when at end of loop
        if ((loopEnd && cnd.isEmpty()) || ""LAST"".equalsIgnoreCase(cnd)) {// $NON-NLS-1$
            JMeterVariables threadVars = JMeterContextService.getContext().getVariables();
            res = ""false"".equalsIgnoreCase(threadVars.get(JMeterThread.LAST_SAMPLE_OK));// $NON-NLS-1$
        } else {
            // cnd may be null if next() called us
            res = ""false"".equalsIgnoreCase(cnd);// $NON-NLS-1$
        }
        
---------------Reference log start----------------
log.debug(""Condition value: '{}'"", res)
---------------Reference log end----------------
        return res;
    }",,
jmeter,14988,"log.debug(""Default Cipher: {}"", dCiphers[i])",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JsseSSLManager.java/#L252,"private SSLContext createContext() throws GeneralSecurityException {
        SSLContext context;
        if (pro != null) {
            context = SSLContext.getInstance(DEFAULT_SSL_PROTOCOL, pro); // $NON-NLS-1$
        } else {
            context = SSLContext.getInstance(DEFAULT_SSL_PROTOCOL); // $NON-NLS-1$
        }
        KeyManagerFactory managerFactory =
            KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
        JmeterKeyStore keys = this.getKeyStore();
        managerFactory.init(null, defaultpw == null ? new char[]{} : defaultpw.toCharArray());
        KeyManager[] managers = managerFactory.getKeyManagers();
        KeyManager[] newManagers = new KeyManager[managers.length];

        if (log.isDebugEnabled()) {
            log.debug(""JmeterKeyStore type: {}"", keys.getClass());
        }

        // Now wrap the default managers with our key manager
        for (int i = 0; i < managers.length; i++) {
            if (managers[i] instanceof X509KeyManager) {
                X509KeyManager manager = (X509KeyManager) managers[i];
                newManagers[i] = new WrappedX509KeyManager(manager, keys);
            } else {
                newManagers[i] = managers[i];
            }
        }

        // Get the default trust managers
        TrustManagerFactory tmfactory = TrustManagerFactory.getInstance(
                TrustManagerFactory.getDefaultAlgorithm());
        tmfactory.init(this.getTrustStore());

        // Wrap the defaults in our custom trust manager
        TrustManager[] trustmanagers = tmfactory.getTrustManagers();
        for (int i = 0; i < trustmanagers.length; i++) {
            if (trustmanagers[i] instanceof X509TrustManager) {
                trustmanagers[i] = new CustomX509TrustManager(
                    (X509TrustManager)trustmanagers[i]);
            }
        }
        context.init(newManagers, trustmanagers, this.rand);
        if (log.isDebugEnabled()){
            String[] dCiphers = context.getSocketFactory().getDefaultCipherSuites();
            String[] sCiphers = context.getSocketFactory().getSupportedCipherSuites();
            int len = (dCiphers.length > sCiphers.length) ? dCiphers.length : sCiphers.length;
            for (int i = 0; i < len; i++) {
                if (i < dCiphers.length) {
                    
---------------Reference log start----------------
log.debug(""Default Cipher: {}"", dCiphers[i])
---------------Reference log end----------------
                }
                if (i < sCiphers.length) {
                    log.debug(""Supported Cipher: {}"", sCiphers[i]);
                }
            }
        }
        return context;
    }",,
jmeter,15070,"log.info(""Loading file: {}"", file)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/save/SaveService.java/#L428,"public static HashTree loadTree(File file) throws IOException {
        
---------------Reference log start----------------
log.info(""Loading file: {}"", file)
---------------Reference log end----------------
        try (InputStream inputStream = new FileInputStream(file);
                BufferedInputStream bufferedInputStream =
                    new BufferedInputStream(inputStream)){
            return readTree(bufferedInputStream, file);
        }
    }",,
jmeter,14635,"log.debug(""Worker ended"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/AsynchSampleSender.java/#L169,"@Override
        public void run() {
            try {
                boolean eof = false;
                while (!eof) {
                    List<SampleEvent> l = new ArrayList<>();
                    SampleEvent e = queue.take();
                    // try to process as many as possible
                    // The == comparison is not an error
                    while (!(eof = e == FINAL_EVENT) && e != null) {
                        l.add(e);
                        e = queue.poll(); // returns null if nothing on queue currently
                    }
                    int size = l.size();
                    if (size > 0) {
                        try {
                            listener.processBatch(l);
                        } catch (RemoteException err) {
                            if (err.getCause() instanceof java.net.ConnectException){
                                throw new JMeterError(""Could not return sample"",err);
                            }
                            log.error(""Failed to return sample"", err);
                        }
                    }
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
            
---------------Reference log start----------------
log.debug(""Worker ended"")
---------------Reference log end----------------
        }
        }",,
jmeter,13887,"log.error(""Error getting argument list for {}"", className, e)",error,https://github.com/apache/jmeter/blob/master/src/protocol/java/src/main/java/org/apache/jmeter/protocol/java/config/gui/JavaConfigGui.java/#L232,"private void configureClassName() {
        String className = classNameLabeledChoice.getText().trim();
        try {
            JavaSamplerClient client = Class.forName(className, true,
                    Thread.currentThread().getContextClassLoader())
                    .asSubclass(JavaSamplerClient.class)
                    .getDeclaredConstructor().newInstance();

            Arguments currArgs = new Arguments();
            argsPanel.modifyTestElement(currArgs);
            Map<String, String> currArgsMap = currArgs.getArgumentsAsMap();

            Arguments newArgs = new Arguments();
            Arguments testParams = null;
            try {
                testParams = client.getDefaultParameters();
            } catch (AbstractMethodError e) {
                log.warn(""JavaSamplerClient doesn't implement ""
                        + ""getDefaultParameters.  Default parameters won't ""
                        + ""be shown.  Please update your client class: {}"", className);
            }

            if (testParams != null) {
                for (JMeterProperty jMeterProperty : testParams.getArguments()) {
                    Argument arg = (Argument) jMeterProperty.getObjectValue();
                    String name = arg.getName();
                    String value = arg.getValue();

                    // If a user has set parameters in one test, and then
                    // selects a different test which supports the same
                    // parameters, those parameters should have the same
                    // values that they did in the original test.
                    if (currArgsMap.containsKey(name)) {
                        String newVal = currArgsMap.get(name);
                        if (newVal != null && newVal.length() > 0) {
                            value = newVal;
                        }
                    }
                    newArgs.addArgument(name, value);
                }
            }

            argsPanel.configure(newArgs);
            warningLabel.setVisible(false);
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(""Error getting argument list for {}"", className, e)
---------------Reference log end----------------
            warningLabel.setVisible(true);
        }
    }",,
jmeter,13754,"log.debug(""ddn and newDn= {}@@@@{}"", ddn, newdn)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/ldap/src/main/java/org/apache/jmeter/protocol/ldap/sampler/LdapExtClient.java/#L231,"public static void moddnOp(DirContext dirContext, String ddn, String newdn) throws NamingException {
        
---------------Reference log start----------------
log.debug(""ddn and newDn= {}@@@@{}"", ddn, newdn)
---------------Reference log end----------------
        if (dirContext == null) {
            throw new NamingException(CONTEXT_IS_NULL);
        }
        dirContext.rename(ddn, newdn);
    }",,
jmeter,13777,"logger.info(""Using ssl/tls protocols for mail: {}"", tlsProtocolsToUse)",info,https://github.com/apache/jmeter/blob/master/src/protocol/mail/src/main/java/org/apache/jmeter/protocol/smtp/sampler/protocol/SendMailCommand.java/#L293,"void configureTLSProtocols(Properties props, String protocol) {
        String tlsProtocolsToUse = getTlsProtocolsToUse();
        if (useStartTLS || useSSL) {
            if (StringUtils.isEmpty(tlsProtocolsToUse)) {
                try {
                    tlsProtocolsToUse = StringUtils.join(
                        SSLContext.getDefault().getSupportedSSLParameters().getProtocols(), "" "");
                } catch (Exception e) {
                    logger.error(""Problem setting ssl/tls protocols for mail"", e);
                }
            }
            
---------------Reference log start----------------
logger.info(""Using ssl/tls protocols for mail: {}"", tlsProtocolsToUse)
---------------Reference log end----------------
            props.setProperty(MAIL_PROPERTY_PREFIX + protocol + "".ssl.protocols"", tlsProtocolsToUse);
        }
    }",,
jmeter,13845,"LOGGER.debug(""isClearQueue"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/sampler/JMSSampler.java/#L231,"private void handleClearQueue(SampleResult res) throws JMSException {
        
---------------Reference log start----------------
LOGGER.debug(""isClearQueue"")
---------------Reference log end----------------
        StringBuilder sb = new StringBuilder(75);
        res.setSuccessful(true);
        sb.append(""Clear messages on Send Queue "").append(sendQueue.getQueueName())
                .append("": "")
                .append(clearQueue(sendQueue, res));
        res.setResponseData(sb.toString(), res.getDataEncodingWithDefault());
        res.setResponseCodeOK();
    }",,
jmeter,13897,"log.debug(""{}\tCreating Java Client"", whoAmI())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/java/src/main/java/org/apache/jmeter/protocol/java/sampler/JavaSampler.java/#L191,"@Override
    public SampleResult sample(Entry entry) {
        Arguments args = getArguments();
        args.addArgument(TestElement.NAME, getName()); // Allow Sampler access
                                                        // to test element name
        context = new JavaSamplerContext(args);
        if (javaClient == null) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""{}\tCreating Java Client"", whoAmI())
---------------Reference log end----------------
            }
            javaClient = createJavaClient();
            javaClient.setupTest(context);
        }

        SampleResult result = javaClient.runTest(context);

        // Only set the default label if it has not been set
        if (result != null && result.getSampleLabel().length() == 0) {
            result.setSampleLabel(getName());
        }

        return result;
    }",,
jmeter,13958,"log.debug(""PoolConfiguration:{}"", this.dataSource)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jdbc/src/main/java/org/apache/jmeter/protocol/jdbc/config/DataSourceElement.java/#L319,"private BasicDataSource initPool(String maxPool) {
        BasicDataSource dataSource = new BasicDataSource();

        if (log.isDebugEnabled()) {
            StringBuilder sb = new StringBuilder(40);
            sb.append(""MaxPool: "");
            sb.append(maxPool);
            sb.append("" Timeout: "");
            sb.append(getTimeout());
            sb.append("" TrimInt: "");
            sb.append(getTrimInterval());
            sb.append("" Auto-Commit: "");
            sb.append(isAutocommit());
            sb.append("" Preinit: "");
            sb.append(isPreinit());
            log.debug(sb.toString());
        }
        int poolSize = Integer.parseInt(maxPool);
        dataSource.setMinIdle(0);
        dataSource.setInitialSize(poolSize);
        dataSource.setAutoCommitOnReturn(false);
        if(StringUtils.isNotEmpty(initQuery)) {
            String[] sqls = initQuery.split(""\n"");
            dataSource.setConnectionInitSqls(Arrays.asList(sqls));
        } else {
            dataSource.setConnectionInitSqls(Collections.emptyList());
        }
        if(StringUtils.isNotEmpty(connectionProperties)) {
            dataSource.setConnectionProperties(connectionProperties);
        }
        dataSource.setRollbackOnReturn(false);
        dataSource.setMaxIdle(poolSize);
        dataSource.setMaxTotal(poolSize);
        dataSource.setMaxWaitMillis(Long.parseLong(getTimeout()));

        dataSource.setDefaultAutoCommit(isAutocommit());

        if (log.isDebugEnabled()) {
            StringBuilder sb = new StringBuilder(40);
            sb.append(""KeepAlive: "");
            sb.append(isKeepAlive());
            sb.append("" Age: "");
            sb.append(getConnectionAge());
            sb.append("" CheckQuery: "");
            sb.append(getCheckQuery());
            log.debug(sb.toString());
        }
        dataSource.setTestOnBorrow(false);
        dataSource.setTestOnReturn(false);
        dataSource.setTestOnCreate(false);
        dataSource.setTestWhileIdle(false);

        if(isKeepAlive()) {
            dataSource.setTestWhileIdle(true);
            String validationQuery = getCheckQuery();
            if (StringUtils.isBlank(validationQuery)) {
                dataSource.setValidationQuery(null);
            } else {
                dataSource.setValidationQuery(validationQuery);
            }
            dataSource.setSoftMinEvictableIdleTimeMillis(Long.parseLong(getConnectionAge()));
            dataSource.setTimeBetweenEvictionRunsMillis(Integer.parseInt(getTrimInterval()));
        }

        int transactionIsolation = DataSourceElementBeanInfo.getTransactionIsolationMode(getTransactionIsolation());
        if (transactionIsolation >= 0) {
            dataSource.setDefaultTransactionIsolation(transactionIsolation);
        }

        String _username = getUsername();
        if (log.isDebugEnabled()) {
            StringBuilder sb = new StringBuilder(40);
            sb.append(""Driver: "");
            sb.append(getDriver());
            sb.append("" DbUrl: "");
            sb.append(getDbUrl());
            sb.append("" User: "");
            sb.append(_username);
            log.debug(sb.toString());
        }
        dataSource.setDriverClassName(getDriver());
        dataSource.setUrl(getDbUrl());

        if (_username.length() > 0){
            dataSource.setUsername(_username);
            dataSource.setPassword(getPassword());
        }

        if(isPreinit()) {
            // side effect - connection pool init - that is what we want
            // see also https://commons.apache.org/proper/commons-dbcp/apidocs/org/apache/commons/dbcp2/BasicDataSource.html#setInitialSize-int-
            // it says: ""The pool is initialized the first time one of the following methods is invoked:
            // getConnection, setLogwriter, setLoginTimeout, getLoginTimeout, getLogWriter.""
            // so we get a connection and close it - which releases it back to the pool (but stays open)
            try {
                dataSource.getConnection().close();
                if (log.isDebugEnabled()) {
                    log.debug(""Preinitializing the connection pool: {}@{}"", getDataSourceName(), System.identityHashCode(dataSource));
                }
            } catch (SQLException ex) {
                if (log.isErrorEnabled()) {
                    log.error(""Error preinitializing the connection pool: {}@{}"", getDataSourceName(), System.identityHashCode(dataSource), ex);
                }
            }
        }

        
---------------Reference log start----------------
log.debug(""PoolConfiguration:{}"", this.dataSource)
---------------Reference log end----------------
        return dataSource;
    }",,
jmeter,14508,"log.error(""OpenLinkAction: User default browser is not found, or it fails to be launched,"" + "" or the default handler application failed to be launched on {}"", url, err)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/OpenLinkAction.java/#L74,"@Override
    public void doAction(ActionEvent e) {
        String url = LINK_MAP.get(e.getActionCommand());
        if(url == null) {
            log.warn(""Action {} not handled by this class"", e.getActionCommand());
            return;
        }
        try {
            if(e.getSource() instanceof String[]) {
                url += ""#""+((String[])e.getSource())[1];
            }
            java.awt.Desktop.getDesktop().browse(java.net.URI.create(url));
        } catch (IOException err) {
            
---------------Reference log start----------------
log.error(""OpenLinkAction: User default browser is not found, or it fails to be launched,"" + "" or the default handler application failed to be launched on {}"", url, err)
---------------Reference log end----------------
        } catch (UnsupportedOperationException err) {
            log.error(""OpenLinkAction: Current platform does not support the Desktop.Action.BROWSE action on {}"", url, err);
            showBrowserWarning(url);
        } catch (SecurityException err) {
            log.error(""OpenLinkAction: Security problem on {}"", url, err);
        } catch (Exception err) {
            log.error(""OpenLinkAction on {}"", url, err);
        }
    }",,
jmeter,14464,"log.error(""Failed to apply naming policy"", err)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/ApplyNamingConvention.java/#L72,"@Override
    public void doAction(ActionEvent e) {
        GuiPackage guiPackage = GuiPackage.getInstance();
        JMeterTreeNode[] currentNodes = guiPackage.getTreeListener().getSelectedNodes();
        List<JMeterTreeNode> filteredNodes = new ArrayList<>();
        for (JMeterTreeNode jMeterTreeNode : currentNodes) {
            if (jMeterTreeNode.getUserObject() instanceof Controller) {
                filteredNodes.add(jMeterTreeNode);
            } else {
                log.warn(""Applying naming policy, selected node {}is not a Controller, will ignore it"", jMeterTreeNode.getName());
            }
        }
        try {
            for (JMeterTreeNode currentNode : filteredNodes) {
                applyNamingPolicyToCurrentNode(guiPackage, currentNode);
            }
            GuiPackage.getInstance().getMainFrame().repaint();
        } catch (Exception err) {
            Toolkit.getDefaultToolkit().beep();
            
---------------Reference log start----------------
log.error(""Failed to apply naming policy"", err)
---------------Reference log end----------------
            JMeterUtils.reportErrorToUser(""Failed to apply naming policy"", err);
        }
    }",,
jmeter,15079,"log.warn(""Setting date format to: {}"", fmt)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/save/CSVSaveService.java/#L224,"@SuppressWarnings(""JdkObsolete"")
    private static SampleEvent makeResultFromDelimitedString(
            final String[] parts,
            final SampleSaveConfiguration saveConfig, // may be updated
            final long lineNumber) {

        SampleResult result = null;
        String hostname = """";// $NON-NLS-1$
        long timeStamp = 0;
        long elapsed = 0;
        String text = null;
        String field = null; // Save the name for error reporting
        int i = 0;
        try {
            if (saveConfig.saveTimestamp()) {
                field = TIME_STAMP;
                text = parts[i++];
                if (saveConfig.printMilliseconds()) {
                    try {
                        timeStamp = Long.parseLong(text); // see if this works
                    } catch (NumberFormatException e) { // it did not, let's try some other formats
                        log.warn(""Cannot parse timestamp: '{}', will try following formats {}"", text,
                                Arrays.asList(DATE_FORMAT_STRINGS));
                        boolean foundMatch = false;
                        for(String fmt : DATE_FORMAT_STRINGS) {
                            SimpleDateFormat dateFormat = new SimpleDateFormat(fmt);
                            dateFormat.setLenient(false);
                            try {
                                Date stamp = dateFormat.parse(text);
                                timeStamp = stamp.getTime();
                                
---------------Reference log start----------------
log.warn(""Setting date format to: {}"", fmt)
---------------Reference log end----------------
                                saveConfig.setDateFormat(fmt);
                                foundMatch = true;
                                break;
                            } catch (ParseException pe) {
                                log.info(""{} did not match {}, trying next date format"", text, fmt);
                            }
                        }
                        if (!foundMatch) {
                            throw new ParseException(""No date-time format found matching ""+text,-1);
                        }
                    }
                } else if (saveConfig.strictDateFormatter() != null) {
                    Date stamp = saveConfig.strictDateFormatter().parse(text);
                    timeStamp = stamp.getTime();
                } else { // can this happen?
                    final String msg = ""Unknown timestamp format"";
                    log.warn(msg);
                    throw new JMeterError(msg);
                }
            }

            if (saveConfig.saveTime()) {
                field = CSV_ELAPSED;
                text = parts[i++];
                elapsed = Long.parseLong(text);
            }

            if (saveConfig.saveSampleCount()) {
                @SuppressWarnings(""deprecation"")
                StatisticalSampleResult sampleResult = new StatisticalSampleResult(timeStamp, elapsed);
                result = sampleResult;
            } else {
                result = new SampleResult(timeStamp, elapsed);
            }

            if (saveConfig.saveLabel()) {
                field = LABEL;
                text = parts[i++];
                result.setSampleLabel(text);
            }
            if (saveConfig.saveCode()) {
                field = RESPONSE_CODE;
                text = parts[i++];
                result.setResponseCode(text);
            }

            if (saveConfig.saveMessage()) {
                field = RESPONSE_MESSAGE;
                text = parts[i++];
                result.setResponseMessage(text);
            }

            if (saveConfig.saveThreadName()) {
                field = THREAD_NAME;
                text = parts[i++];
                result.setThreadName(text);
            }

            if (saveConfig.saveDataType()) {
                field = DATA_TYPE;
                text = parts[i++];
                result.setDataType(text);
            }

            if (saveConfig.saveSuccess()) {
                field = SUCCESSFUL;
                text = parts[i++];
                result.setSuccessful(Boolean.valueOf(text));
            }

            if (saveConfig.saveAssertionResultsFailureMessage()) {
                i++;
                // TODO - should this be restored?
            }

            if (saveConfig.saveBytes()) {
                field = CSV_BYTES;
                text = parts[i++];
                result.setBytes(Long.parseLong(text));
            }

            if (saveConfig.saveSentBytes()) {
                field = CSV_SENT_BYTES;
                text = parts[i++];
                result.setSentBytes(Long.parseLong(text));
            }

            if (saveConfig.saveThreadCounts()) {
                field = CSV_THREAD_COUNT1;
                text = parts[i++];
                result.setGroupThreads(Integer.parseInt(text));

                field = CSV_THREAD_COUNT2;
                text = parts[i++];
                result.setAllThreads(Integer.parseInt(text));
            }

            if (saveConfig.saveUrl()) {
                i++;
                // TODO: should this be restored?
            }

            if (saveConfig.saveFileName()) {
                field = CSV_FILENAME;
                text = parts[i++];
                result.setResultFileName(text);
            }
            if (saveConfig.saveLatency()) {
                field = CSV_LATENCY;
                text = parts[i++];
                result.setLatency(Long.parseLong(text));
            }

            if (saveConfig.saveEncoding()) {
                field = CSV_ENCODING;
                text = parts[i++];
                result.setEncodingAndType(text);
            }

            if (saveConfig.saveSampleCount()) {
                field = CSV_SAMPLE_COUNT;
                text = parts[i++];
                result.setSampleCount(Integer.parseInt(text));
                field = CSV_ERROR_COUNT;
                text = parts[i++];
                result.setErrorCount(Integer.parseInt(text));
            }

            if (saveConfig.saveHostname()) {
                field = CSV_HOSTNAME;
                hostname = parts[i++];
            }

            if (saveConfig.saveIdleTime()) {
                field = CSV_IDLETIME;
                text = parts[i++];
                result.setIdleTime(Long.parseLong(text));
            }
            if (saveConfig.saveConnectTime()) {
                field = CSV_CONNECT_TIME;
                text = parts[i++];
                result.setConnectTime(Long.parseLong(text));
            }

            if (i + saveConfig.getVarCount() < parts.length) {
                log.warn(""Line: {}. Found {} fields, expected {}. Extra fields have been ignored."", lineNumber,
                        parts.length, i);
            }

        } catch (NumberFormatException | ParseException e) {
            if (log.isWarnEnabled()) {
                log.warn(""Error parsing field '{}' at line {}. {}"", field, lineNumber, e.toString());
            }
            throw new JMeterError(e);
        } catch (ArrayIndexOutOfBoundsException e) {
            log.warn(""Insufficient columns to parse field '{}' at line {}"", field, lineNumber);
            throw new JMeterError(e);
        }
        return new SampleEvent(result, """", hostname);
    }",,
jmeter,13550,"log.warn(""Could not delete {}, this could create issues, stop jmeter, ensure file is deleted and restart again"", CERT_PATH.getAbsolutePath())",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/ProxyControl.java/#L1641,"@SuppressWarnings(""JdkObsolete"")
    private void initJMeterKeyStore() throws IOException, GeneralSecurityException {
        if (storePassword != null) { // Assume we have already created the store
            try {
                keyStore = getKeyStore(storePassword.toCharArray());
                X509Certificate caCert = (X509Certificate) keyStore.getCertificate(JMETER_SERVER_ALIAS);
                caCert.checkValidity(new Date(System.currentTimeMillis() + DateUtils.MILLIS_PER_DAY));
            } catch (Exception e) { // store is faulty, we need to recreate it
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Could not open expected file or certificate is not valid {} {}"",
                        CERT_PATH_ABS, e.getMessage(), e);
            }
        }
        if (keyStore == null) { // no existing file or not valid
            storePassword = JOrphanUtils.generateRandomAlphanumericPassword(20); // Alphanum to avoid issues with command-line quoting
            keyPassword = storePassword; // we use same password for both
            setPassword(storePassword);
            log.info(""Generating standard keypair in {}"", CERT_PATH_ABS);
            if (!CERT_PATH.delete()) { // safer to start afresh
                
---------------Reference log start----------------
log.warn(""Could not delete {}, this could create issues, stop jmeter, ensure file is deleted and restart again"", CERT_PATH.getAbsolutePath())
---------------Reference log end----------------
            }
            KeyToolUtils.genkeypair(CERT_PATH, JMETER_SERVER_ALIAS, storePassword, CERT_VALIDITY, null, null);
            keyStore = getKeyStore(storePassword.toCharArray()); // This should now work
        }
    }",,
jmeter,14629,"log.info(""Using batch queue size (asynch.batch.queue.size): {}"", capacity)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/AsynchSampleSender.java/#L85,"protected Object readResolve() throws ObjectStreamException{
        int capacity = getCapacity();
        
---------------Reference log start----------------
log.info(""Using batch queue size (asynch.batch.queue.size): {}"", capacity)
---------------Reference log end----------------
        queue = new ArrayBlockingQueue<>(capacity);
        Worker worker = new Worker(queue, listener);
        worker.setDaemon(true);
        worker.start();
        return this;
    }",,
jmeter,13302,"log.debug(""i: {}"", ((CompoundVariable) values[i]).execute())",debug,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/CSVRead.java/#L151,"@Override
    public void setParameters(Collection<CompoundVariable> parameters) throws InvalidVariableException {
        if (log.isDebugEnabled()) {
            log.debug(""setParameter - Collection.size={}"", parameters.size());
        }

        values = parameters.toArray();

        if (log.isDebugEnabled()) {
            for (int i = 0; i < parameters.size(); i++) {
                
---------------Reference log start----------------
log.debug(""i: {}"", ((CompoundVariable) values[i]).execute())
---------------Reference log end----------------
            }
        }

        checkParameterCount(parameters, 2);

        /*
         * Need to reset the containers for repeated runs; about the only way
         * for functions to detect that a run is starting seems to be the
         * setParameters() call.
         */
        FileWrapper.clearAll();// TODO only clear the relevant entry - if possible...

    }",,
jmeter,14893,"log.warn(""Can't find icon for {} - {}"", icon[0], icon[1])",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/plugin/PluginManager.java/#L59,"private void installPlugin(JMeterPlugin plugin) {
        String[][] icons = plugin.getIconMappings();
        ClassLoader classloader = plugin.getClass().getClassLoader();

        for (String[] icon : icons) {
            URL resource = classloader.getResource(icon[1].trim());

            if (resource == null) {
                
---------------Reference log start----------------
log.warn(""Can't find icon for {} - {}"", icon[0], icon[1])
---------------Reference log end----------------
            } else {
                final ImageIcon regularIcon = new ImageIcon(resource);
                GUIFactory.registerIcon(icon[0], regularIcon);
                ImageIcon disabledIcon = null;
                if (icon.length > 2 && icon[2] != null) {
                    URL resource2 = classloader.getResource(icon[2].trim());
                    if (resource2 == null) {
                        log.info(""Can't find disabled icon for {} - {}"", icon[0], icon[2]);
                    } else {
                        disabledIcon = new ImageIcon(resource2);
                    }
                } else {
                    // Second icon is not specified, create disabled one automatically
                    disabledIcon = new ImageIcon(
                            GrayFilter.createDisabledImage(regularIcon.getImage())
                    );
                }
                if (disabledIcon != null) {
                    GUIFactory.registerDisabledIcon(icon[0], disabledIcon);
                }
            }
        }
    }",,
jmeter,13332,"log.warn(""Some bad HTML {}"", printNode(tempNode), ex)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/parser/HtmlParsingUtils.java/#L335,"@SuppressWarnings(""JdkObsolete"")
    private static boolean recurseForm(Node tempNode, LinkedList<HTTPSamplerBase> urlConfigs, URL context, String selectName,
            boolean inForm) {
        NamedNodeMap nodeAtts = tempNode.getAttributes();
        String tag = tempNode.getNodeName();
        try {
            if (inForm) {
                HTTPSamplerBase url = urlConfigs.getLast();
                if (tag.equalsIgnoreCase(""form"")) { // $NON-NLS-1$
                    try {
                        urlConfigs.add(createFormUrlConfig(tempNode, context));
                    } catch (MalformedURLException e) {
                        inForm = false;
                    }
                } else if (tag.equalsIgnoreCase(""input"")) { // $NON-NLS-1$
                    url.addEncodedArgument(getAttributeValue(nodeAtts, ""name""),  // $NON-NLS-1$
                            getAttributeValue(nodeAtts, ""value"")); // $NON-NLS-1$
                } else if (tag.equalsIgnoreCase(""textarea"")) { // $NON-NLS-1$
                    try {
                        url.addEncodedArgument(getAttributeValue(nodeAtts, ""name""),  // $NON-NLS-1$
                                tempNode.getFirstChild().getNodeValue());
                    } catch (NullPointerException e) {
                        url.addArgument(getAttributeValue(nodeAtts, ""name""), """"); // $NON-NLS-1$
                    }
                } else if (tag.equalsIgnoreCase(""select"")) { // $NON-NLS-1$
                    selectName = getAttributeValue(nodeAtts, ""name""); // $NON-NLS-1$
                } else if (tag.equalsIgnoreCase(""option"")) { // $NON-NLS-1$
                    String value = getAttributeValue(nodeAtts, ""value""); // $NON-NLS-1$
                    if (value == null) {
                        try {
                            value = tempNode.getFirstChild().getNodeValue();
                        } catch (NullPointerException e) {
                            value = """"; // $NON-NLS-1$
                        }
                    }
                    url.addEncodedArgument(selectName, value);
                }
            } else if (tag.equalsIgnoreCase(""form"")) { // $NON-NLS-1$
                try {
                    urlConfigs.add(createFormUrlConfig(tempNode, context));
                    inForm = true;
                } catch (MalformedURLException e) {
                    inForm = false;
                }
            }
        } catch (Exception ex) {
            
---------------Reference log start----------------
log.warn(""Some bad HTML {}"", printNode(tempNode), ex)
---------------Reference log end----------------
        }
        NodeList childNodes = tempNode.getChildNodes();
        for (int x = 0; x < childNodes.getLength(); x++) {
            inForm = recurseForm(childNodes.item(x), urlConfigs, context, selectName, inForm);
        }
        return inForm;
    }",,
jmeter,13767,"log.debug(""file path set to: "" + attachment)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/mail/src/main/java/org/apache/jmeter/protocol/smtp/sampler/SmtpSampler.java/#L225,"private File attachmentToFile(String attachment) { // NOSONAR False positive saying not used
        File file = new File(attachment);
        if (!file.isAbsolute() && !file.exists()) {
            if(log.isDebugEnabled()) {
                log.debug(""loading file with relative path: "" + attachment);
            }
            file = new File(FileServer.getFileServer().getBaseDir(), attachment);
            if(log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""file path set to: "" + attachment)
---------------Reference log end----------------
            }
        }
        return file;
    }",,
jmeter,14482,"log.warn(messageFormat, ex.toString(), ex)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/Load.java/#L242,"private static void reportError(final String messageFormat, final Throwable ex, final boolean stackTrace) {
        if (log.isWarnEnabled()) {
            if (stackTrace) {
                
---------------Reference log start----------------
log.warn(messageFormat, ex.toString(), ex)
---------------Reference log end----------------
            } else {
                log.warn(messageFormat, ex.toString());
            }
        }
        String msg = ex.getMessage();
        if (msg == null) {
            msg = ""Unexpected error - see log for details"";
        }
        JMeterUtils.reportErrorToUser(msg);
    }",,
jmeter,14906,"log.error(""Couldn't clone map"", e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/testelement/property/MapProperty.java/#L128,"private Map<String, JMeterProperty> cloneMap() {
        try {
            @SuppressWarnings(""unchecked"") // value is the correct class
            Map<String, JMeterProperty> newCol = value.getClass().getDeclaredConstructor().newInstance();
            PropertyIterator iter = valueIterator();
            while (iter.hasNext()) {
                JMeterProperty item = iter.next();
                newCol.put(item.getName(), item.clone());
            }
            return newCol;
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(""Couldn't clone map"", e)
---------------Reference log end----------------
            return value;
        }
    }",,
jmeter,14796,"log.info(""Stopping the backing engine"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/RemoteJMeterEngineImpl.java/#L196,"@Override
    public void rexit() throws RemoteException {
        log.info(""Exiting"");
        // Bug 59400 - allow rexit() to return
        Thread et = new Thread(() -> {
            
---------------Reference log start----------------
log.info(""Stopping the backing engine"")
---------------Reference log end----------------
            backingEngine.exit();
        });
        et.setDaemon(false);
        // Tidy up any objects we created
        Registry reg = LocateRegistry.getRegistry(
                RmiUtils.getRmiHost().getHostName(),
                this.rmiRegistryPort,
                RmiUtils.createClientSocketFactory());
        try {
            reg.unbind(JMETER_ENGINE_RMI_NAME);
        } catch (NotBoundException e) {
            log.warn(""{} is not bound"", JMETER_ENGINE_RMI_NAME, e);
        }
        log.info(""Unbound from registry"");
        try {
            UnicastRemoteObject.unexportObject(this, false);
        } catch (NoSuchObjectException e) {
            log.warn(""{} not longer exists"", this, e);
        }
        log.info(""Unexported RemoteJMeterEngineImpl"");
        // Help with garbage control
        JMeterUtils.helpGC();
        et.start();
    }",,
jmeter,13947,"log.debug(""Thread Finished"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/TCPSampler.java/#L517,"@Override
    public void threadFinished() {
        
---------------Reference log start----------------
log.debug(""Thread Finished"")
---------------Reference log end----------------
        tearDown();
        if (protocolHandler != null){
            protocolHandler.teardownTest();
        }
    }",,
jmeter,14168,"log.debug(""DN from assertion: {}"", principal)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/SMIMEAssertion.java/#L269,"private static void checkSubject(SMIMEAssertionTestElement testElement, AssertionResult res,
            X509CertificateHolder cert, StringBuilder failureMessage) {
        String subject = testElement.getSignerDn();
        if (subject.length() > 0) {
            final X500Name certPrincipal = cert.getSubject();
            log.debug(""DN from cert: {}"", certPrincipal);
            X500Name principal = new X500Name(subject);
            
---------------Reference log start----------------
log.debug(""DN from assertion: {}"", principal)
---------------Reference log end----------------
            if (!principal.equals(certPrincipal)) {
                res.setFailure(true);
                failureMessage
                        .append(""Distinguished name of signer certificate does not match \"""")
                        .append(subject).append(""\""\n"");
            }
        }
    }",,
jmeter,14859,"log.debug(""Set {}={}"", name, value)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/testbeans/gui/GenericTestBeanCustomizer.java/#L499,"@SuppressWarnings(""unchecked"")
    @Override
    public void setObject(Object map) {
        propertyMap = (Map<String, Object>) map;

        if (propertyMap.isEmpty()) {
            // Uninitialized -- set it to the defaults:
            for (PropertyDescriptor descriptor : descriptors) {
                Object value = descriptor.getValue(DEFAULT);
                String name = descriptor.getName();
                if (value != null) {
                    propertyMap.put(name, value);
                    
---------------Reference log start----------------
log.debug(""Set {}={}"", name, value)
---------------Reference log end----------------
                }
                firePropertyChange(name, null, value);
            }
        }

        // Now set the editors to the element's values:
        for (int i = 0; i < editors.length; i++) {
            if (editors[i] == null) {
                continue;
            }
            try {
                setEditorValue(i, propertyMap.get(descriptors[i].getName()));
            } catch (IllegalArgumentException e) {
                // I guess this can happen as a result of a bad
                // file read? In this case, it would be better to replace the
                // incorrect value with anything valid, e.g. the default value
                // for the property.
                // But for the time being, I just prefer to be aware of any
                // problems occurring here, most likely programming errors,
                // so I'll bail out.
                // (MS Note) Can't bail out - newly create elements have blank
                // values and must get the defaults.
                // Also, when loading previous versions of JMeter test scripts,
                // some values
                // may not be right, and should get default values - MS
                // TODO: review this and possibly change to:
                setEditorValue(i, descriptors[i].getValue(DEFAULT));
            }
        }
    }",,
jmeter,13592,"log.debug(""{} Running up named: {}"", Thread.currentThread().getName(), getName())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/modifier/RegExUserParameters.java/#L60,"@Override
    public void process() {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""{} Running up named: {}"", Thread.currentThread().getName(), getName())
---------------Reference log end----------------
        }
        Sampler entry = getThreadContext().getCurrentSampler();
        if (!(entry instanceof HTTPSamplerBase)) {
            return;
        }

        Map<String, String> paramMap = buildParamsMap();
        if(paramMap == null || paramMap.isEmpty()){
            log.info(
                    ""RegExUserParameters element: {} => Referenced RegExp was not found, no parameter will be changed"",
                    getName());
            return;
        }

        HTTPSamplerBase sampler = (HTTPSamplerBase) entry;
        for (JMeterProperty jMeterProperty : sampler.getArguments()) {
            Argument arg = (Argument) jMeterProperty.getObjectValue();
            String oldValue = arg.getValue();
            // if parameter name exists in http request
            // then change its value with value obtained with regular expression
            String val = paramMap.get(arg.getName());
            if (val != null) {
                arg.setValue(val);
            }
            if (log.isDebugEnabled()) {
                log.debug(
                        ""RegExUserParameters element: {} => changed parameter: {} = {}, was: {}"",
                        getName(), arg.getName(), arg.getValue(), oldValue);
            }
        }
    }",,
jmeter,14600,"log.debug(""End of report generation"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/ReportGenerator.java/#L264,"public void generate() throws GenerationException {

        if (resultCollector != null) {
            log.info(""Flushing result collector before report Generation"");
            resultCollector.flushFile();
        }
        log.debug(""Start report generation"");

        File tmpDir = configuration.getTempDirectory();
        boolean tmpDirCreated = createTempDir(tmpDir);

        // Build consumers chain
        SampleContext sampleContext = new SampleContext();
        sampleContext.setWorkingDirectory(tmpDir);
        SampleSource source = new CsvFileSampleSource(testFile, CSV_DEFAULT_SEPARATOR);
        source.setSampleContext(sampleContext);

        NormalizerSampleConsumer normalizer = new NormalizerSampleConsumer();
        normalizer.setName(NORMALIZER_CONSUMER_NAME);

        FilterConsumer dateRangeConsumer = createFilterByDateRange();
        dateRangeConsumer.addSampleConsumer(createBeginDateConsumer());
        dateRangeConsumer.addSampleConsumer(createEndDateConsumer());

        FilterConsumer nameFilter = createNameFilter();

        FilterConsumer excludeControllerFilter = createExcludeControllerFilter();

        nameFilter.addSampleConsumer(excludeControllerFilter);

        dateRangeConsumer.addSampleConsumer(nameFilter);

        normalizer.addSampleConsumer(dateRangeConsumer);

        source.addSampleConsumer(normalizer);

        // Get graph configurations
        Map<String, GraphConfiguration> graphConfigurations = configuration
                .getGraphConfigurations();

        // Process configuration to build graph consumers
        for (Map.Entry<String, GraphConfiguration> entryGraphCfg : graphConfigurations.entrySet()) {
            addGraphConsumer(nameFilter, excludeControllerFilter, entryGraphCfg);
        }

        // Generate data
        log.debug(""Start samples processing"");
        try {
            source.run(); // NOSONAR
        } catch (SampleException ex) {
            throw new GenerationException(""Error while processing samples: "" + ex.getMessage(), ex);
        }
        log.debug(""End of samples processing"");

        log.debug(""Start data exporting"");

        // Process configuration to build data exporters
        String key;
        ExporterConfiguration value;
        for (Map.Entry<String, ExporterConfiguration> entry : configuration.getExportConfigurations().entrySet()) {
            key = entry.getKey();
            value = entry.getValue();
            if (log.isInfoEnabled()) {
                log.info(""Exporting data using exporter:'{}' of className:'{}'"", key, value.getClassName());
            }
            exportData(sampleContext, key, value);
        }

        log.debug(""End of data exporting"");

        removeTempDir(tmpDir, tmpDirCreated);

        
---------------Reference log start----------------
log.debug(""End of report generation"")
---------------Reference log end----------------
    }
    }",,
jmeter,14063,"log.debug(""Thread: {} took from queue: {}, isFinal: {}"", Thread.currentThread().getName(), sampleResult, sampleResult == FINAL_SAMPLE_RESULT)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/BackendListener.java/#L216,"@Override
        public void run() {
            final boolean isDebugEnabled = log.isDebugEnabled();
            List<SampleResult> sampleResults = new ArrayList<>(listenerClientData.queue.size());
            try {
                try {

                    boolean endOfLoop = false;
                    while (!endOfLoop) {
                        if (isDebugEnabled) {
                            log.debug(""Thread: {} taking SampleResult from queue: {}"", Thread.currentThread().getName(),
                                    listenerClientData.queue.size());
                        }
                        SampleResult sampleResult = listenerClientData.queue.take();
                        if (isDebugEnabled) {
                            log.debug(""Thread: {} took SampleResult: {}, isFinal: {}"",
                                    Thread.currentThread().getName(),
                                    sampleResult,
                                    sampleResult == FINAL_SAMPLE_RESULT);
                        }
                        // try to process as many as possible
                        // The == comparison is not a mistake
                        while (!(endOfLoop = sampleResult == FINAL_SAMPLE_RESULT) && sampleResult != null) {
                            sampleResults.add(sampleResult);
                            if (isDebugEnabled) {
                                log.debug(""Thread: {} polling from queue: {}"", Thread.currentThread().getName(),
                                        listenerClientData.queue.size());
                            }
                            sampleResult = listenerClientData.queue.poll(); // returns null if nothing on queue currently
                            if (isDebugEnabled) {
                                
---------------Reference log start----------------
log.debug(""Thread: {} took from queue: {}, isFinal: {}"", Thread.currentThread().getName(), sampleResult, sampleResult == FINAL_SAMPLE_RESULT)
---------------Reference log end----------------
                            }
                        }
                        if (isDebugEnabled) {
                            log.debug(""Thread: {} exiting with FINAL EVENT: {}, null: {}"",
                                    Thread.currentThread().getName(), sampleResult == FINAL_SAMPLE_RESULT,
                                    sampleResult == null);
                        }
                        sendToListener(backendListenerClient, context, sampleResults);
                        if (!endOfLoop) {
                            LockSupport.parkNanos(100);
                        }
                    }
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                }
                // We may have been interrupted
                sendToListener(backendListenerClient, context, sampleResults);
                log.info(""Worker ended"");
            } finally {
                listenerClientData.latch.countDown();
            }
        }",,
jmeter,14184,"log.warn(""Could not convert {}={} using Locale: {}"", pn, objectValue, rb.getLocale())",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/timers/ConstantThroughputTimer.java/#L292,"@Override
    public void setProperty(JMeterProperty property) {
        if (property instanceof StringProperty) {
            final String pn = property.getName();
            if (pn.equals(""calcMode"")) {
                final Object objectValue = property.getObjectValue();
                try {
                    final BeanInfo beanInfo = Introspector.getBeanInfo(this.getClass());
                    final ResourceBundle rb = (ResourceBundle) beanInfo.getBeanDescriptor().getValue(GenericTestBeanCustomizer.RESOURCE_BUNDLE);
                    for(Enum<Mode> e : Mode.values()) {
                        final String propName = e.toString();
                        if (objectValue.equals(rb.getObject(propName))) {
                            final int tmpMode = e.ordinal();
                            log.debug(""Converted {}={} to mode={} using Locale: {}"", pn, objectValue, tmpMode,
                                    rb.getLocale());
                            super.setProperty(pn, tmpMode);
                            return;
                        }
                    }
                    
---------------Reference log start----------------
log.warn(""Could not convert {}={} using Locale: {}"", pn, objectValue, rb.getLocale())
---------------Reference log end----------------
                } catch (IntrospectionException e) {
                    log.error(""Could not find BeanInfo"", e);
                }
            }
        }
        super.setProperty(property);
    }",,
jmeter,13666,"log.debug(""Bind exception, try again"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPJavaImpl.java/#L543,"@Override
    protected HTTPSampleResult sample(URL url, String method, boolean areFollowingRedirect, int frameDepth) {
        HttpURLConnection conn = null;

        String urlStr = url.toString();
        if (log.isDebugEnabled()) {
            log.debug(""Start : sample {}, method {}, followingRedirect {}, depth {}"",
                    urlStr, method, areFollowingRedirect, frameDepth);
        }

        HTTPSampleResult res = new HTTPSampleResult();
        configureSampleLabel(res, url);
        res.setURL(url);
        res.setHTTPMethod(method);

        res.sampleStart(); // Count the retries as well in the time

        // Check cache for an entry with an Expires header in the future
        final CacheManager cacheManager = getCacheManager();
        if (cacheManager != null && HTTPConstants.GET.equalsIgnoreCase(method)) {
           if (cacheManager.inCache(url, getHeaders(getHeaderManager()))) {
               return updateSampleResultForResourceInCache(res);
           }
        }

        try {
            // Sampling proper - establish the connection and read the response:
            // Repeatedly try to connect:
            int retry = -1;
            // Start with -1 so tries at least once, and retries at most MAX_CONN_RETRIES times
            for (; retry < MAX_CONN_RETRIES; retry++) {
                try {
                    conn = setupConnection(url, method, res);
                    // Attempt the connection:
                    savedConn = conn;
                    conn.connect();
                    break;
                } catch (BindException e) {
                    if (retry >= MAX_CONN_RETRIES) {
                        log.error(""Can't connect after {} retries, message: {}"", retry, e.toString());
                        throw e;
                    }
                    
---------------Reference log start----------------
log.debug(""Bind exception, try again"")
---------------Reference log end----------------
                    if (conn!=null) {
                        savedConn = null; // we don't want interrupt to try disconnection again
                        conn.disconnect();
                    }
                    setUseKeepAlive(false);
                } catch (IOException e) {
                    log.debug(""Connection failed, giving up"");
                    throw e;
                }
            }
            if (retry > MAX_CONN_RETRIES) {
                // This should never happen, but...
                throw new BindException();
            }
            // Nice, we've got a connection. Finish sending the request:
            if (method.equals(HTTPConstants.POST)) {
                String postBody = sendPostData(conn);
                res.setQueryString(postBody);
            } else if (method.equals(HTTPConstants.PUT)) {
                String putBody = sendPutData(conn);
                res.setQueryString(putBody);
            }
            // Request sent. Now get the response:
            byte[] responseData = readResponse(conn, res);

            res.sampleEnd();
            // Done with the sampling proper.

            // Now collect the results into the HTTPSampleResult:

            res.setResponseData(responseData);

            int errorLevel = conn.getResponseCode();
            String respMsg = conn.getResponseMessage();
            String hdr=conn.getHeaderField(0);
            if (hdr == null) {
                hdr=""(null)"";  // $NON-NLS-1$
            }
            if (errorLevel == -1){// Bug 38902 - sometimes -1 seems to be returned unnecessarily
                if (respMsg != null) {// Bug 41902 - NPE
                    try {
                        errorLevel = Integer.parseInt(respMsg.substring(0, 3));
                        log.warn(""ResponseCode==-1; parsed {} as {}"", respMsg, errorLevel);
                      } catch (NumberFormatException e) {
                        log.warn(""ResponseCode==-1; could not parse {} hdr: {}"", respMsg, hdr);
                      }
                } else {
                    respMsg=hdr; // for result
                    log.warn(""ResponseCode==-1 & null ResponseMessage. Header(0)= {} "", hdr);
                }
            }
            if (errorLevel == -1) {
                res.setResponseCode(""(null)""); // $NON-NLS-1$
            } else {
                res.setResponseCode(Integer.toString(errorLevel));
            }
            res.setSuccessful(isSuccessCode(errorLevel));

            if (respMsg == null) {// has been seen in a redirect
                respMsg=hdr; // use header (if possible) if no message found
            }
            res.setResponseMessage(respMsg);

            String ct = conn.getContentType();
            if (ct != null){
                res.setContentType(ct);// e.g. text/html; charset=ISO-8859-1
                res.setEncodingAndType(ct);
            }

            String responseHeaders = getResponseHeaders(conn);
            res.setResponseHeaders(responseHeaders);
            if (res.isRedirect()) {
                res.setRedirectLocation(conn.getHeaderField(HTTPConstants.HEADER_LOCATION));
            }

            // record headers size to allow HTTPSampleResult.getBytes() with different options
            res.setHeadersSize(responseHeaders.replaceAll(""\n"", ""\r\n"") // $NON-NLS-1$ $NON-NLS-2$
                    .length() + 2); // add 2 for a '\r\n' at end of headers (before data)
            if (log.isDebugEnabled()) {
                log.debug(""Response headersSize={}, bodySize={}, Total={}"",
                        res.getHeadersSize(),  res.getBodySizeAsLong(),
                        res.getHeadersSize() + res.getBodySizeAsLong());
            }

            // If we redirected automatically, the URL may have changed
            if (getAutoRedirects()){
                res.setURL(conn.getURL());
            }

            // Store any cookies received in the cookie manager:
            saveConnectionCookies(conn, url, getCookieManager());

            // Save cache information
            if (cacheManager != null){
                cacheManager.saveDetails(conn, res);
            }

            res = resultProcessing(areFollowingRedirect, frameDepth, res);

            log.debug(""End : sample"");
            return res;
        } catch (IOException e) {
            if (res.getEndTime() == 0) {
                res.sampleEnd();
            }
            savedConn = null; // we don't want interrupt to try disconnection again
            // We don't want to continue using this connection, even if KeepAlive is set
            if (conn != null) { // May not exist
                conn.disconnect();
            }
            conn=null; // Don't process again
            return errorResult(e, res);
        } finally {
            // calling disconnect doesn't close the connection immediately,
            // but indicates we're through with it. The JVM should close
            // it when necessary.
            savedConn = null; // we don't want interrupt to try disconnection again
            disconnect(conn); // Disconnect unless using KeepAlive
        }
    }",,
jmeter,14707,"log.error(""sampleEnd called twice"", new Throwable(INVALID_CALL_SEQUENCE_MSG))",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/SampleResult.java/#L1147,"public void sampleEnd() {
        if (endTime == 0) {
            setEndTime(currentTimeInMillis());
        } else {
            
---------------Reference log start----------------
log.error(""sampleEnd called twice"", new Throwable(INVALID_CALL_SEQUENCE_MSG))
---------------Reference log end----------------
        }
    }",,
jmeter,13886,"log.debug(""Exception getting interfaces."", e)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/java/src/main/java/org/apache/jmeter/protocol/java/config/gui/JavaConfigGui.java/#L152,"private JPanel createClassnamePanel() {
        List<String> possibleClasses = new ArrayList<>();

        try {
            // Find all the classes which implement the JavaSamplerClient
            // interface.
            possibleClasses = ClassFinder.findClassesThatExtend(JMeterUtils.getSearchPaths(),
                    new Class[] { JavaSamplerClient.class });

            // Remove the JavaConfig class from the list since it only
            // implements the interface for error conditions.

            possibleClasses.remove(JavaSampler.class.getName() + ""$ErrorSamplerClient"");
        } catch (Exception e) {
            
---------------Reference log start----------------
log.debug(""Exception getting interfaces."", e)
---------------Reference log end----------------
        }

        classNameLabeledChoice = new JLabeledChoice(
                JMeterUtils.getResString(""protocol_java_classname""),
                possibleClasses.toArray(ArrayUtils.EMPTY_STRING_ARRAY), true,
                false);
        classNameLabeledChoice.addChangeListener(this);

        JFactory.error(warningLabel);
        warningLabel.setVisible(false);

        VerticalPanel panel = new VerticalPanel();
        panel.add(classNameLabeledChoice);
        panel.add(warningLabel);
        return panel;
    }",,
jmeter,13299,"log.warn(""{} - invalid column number: {} at row {} {}"", Thread.currentThread().getName(), columnOrNext, FileWrapper.getCurrentRow(fileName), e.toString())",warn,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/CSVRead.java/#L118,"@Override
    public String execute(SampleResult previousResult, Sampler currentSampler)
            throws InvalidVariableException {
        String myValue = """"; //$NON-NLS-1$

        String fileName = ((org.apache.jmeter.engine.util.CompoundVariable) values[0]).execute();
        String columnOrNext = ((org.apache.jmeter.engine.util.CompoundVariable) values[1]).execute();

        log.debug(""execute ({}, {})   "", fileName, columnOrNext);

        // Process __CSVRead(filename,*ALIAS)
        if (columnOrNext.startsWith(""*"")) { //$NON-NLS-1$
            FileWrapper.open(fileName, columnOrNext);
            /*
             * All done, so return
             */
            return """"; //$NON-NLS-1$
        }

        // if argument is 'next' - go to the next line
        if (columnOrNext.equals(""next()"") || columnOrNext.equals(""next"")) { //$NON-NLS-1$ //$NON-NLS-2$
            FileWrapper.endRow(fileName);

            /*
             * All done now, so return the empty string - this allows the caller
             * to append __CSVRead(file,next) to the last instance of
             * __CSVRead(file,col)
             *
             * N.B. It is important not to read any further lines at this point,
             * otherwise the wrong line can be retrieved when using multiple
             * threads.
             */
            return """"; //$NON-NLS-1$
        }

        try {
            int columnIndex = Integer.parseInt(columnOrNext); // what column
                                                                // is wanted?
            myValue = FileWrapper.getColumn(fileName, columnIndex);
        } catch (NumberFormatException e) {
            log.warn(""{} - can't parse column number: {} {}"",
                    Thread.currentThread().getName(), columnOrNext,
                    e.toString());
        } catch (IndexOutOfBoundsException e) {
            
---------------Reference log start----------------
log.warn(""{} - invalid column number: {} at row {} {}"", Thread.currentThread().getName(), columnOrNext, FileWrapper.getCurrentRow(fileName), e.toString())
---------------Reference log end----------------
        }

        log.debug(""execute value: {}"", myValue);

        return myValue;
    }",,
jmeter,14529,"log.error(""exception finding action handlers"", e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/ActionRouter.java/#L382,"public void populateCommandMap() {
        if (!commands.isEmpty()) {
            return; // already done
        }
        try {
            List<String> listClasses = findClassesThatExtend(""org.apache.jmeter.gui.action.Command"", // $NON-NLS-1$
                    ""org.apache.jmeter.report.gui"", // $NON-NLS-1$
                    JMeterUtils.getSearchPaths());

            if (listClasses.isEmpty()) {
                //fallback
                Optional<String[]> codeSourceSearchPath = getCodeSourceSearchPath();
                if (codeSourceSearchPath.isPresent()) {
                    log.info(""Using fallback search path"");
                    listClasses = findClassesThatExtend(""org.apache.jmeter.gui.action.Command"", // $NON-NLS-1$
                            ""org.apache.jmeter.report.gui"", // $NON-NLS-1$
                            codeSourceSearchPath.get());
                }
            }

            if (listClasses.isEmpty()) {
                log.error(""!!!!!Uh-oh, didn't find any action handlers!!!!!"");
                throw new JMeterError(""No action handlers found - check JMeterHome and libraries"");
            }
            for (String strClassName : listClasses) {
                Class<?> commandClass = Class.forName(strClassName);
                Command command = (Command) commandClass.getDeclaredConstructor().newInstance();
                for (String commandName : command.getActionNames()) {
                    Set<Command> commandObjects = commands.computeIfAbsent(commandName, k -> new HashSet<>());
                    commandObjects.add(command);
                }
            }
        } catch (HeadlessException e) {
            if (log.isWarnEnabled()) {
                log.warn(""AWT headless exception occurred. {}"", e.toString());
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(""exception finding action handlers"", e)
---------------Reference log end----------------
        }
    }",,
jmeter,13708,"LOG.info(""Setting up HTTPS TrustAll Socket Factory"")",info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/hc/LazyLayeredConnectionSocketFactory.java/#L62,"private static LayeredConnectionSocketFactory checkAndInit() throws SSLInitializationException {
            
---------------Reference log start----------------
LOG.info(""Setting up HTTPS TrustAll Socket Factory"")
---------------Reference log end----------------
            return new SSLConnectionSocketFactory(
                    new HttpSSLProtocolSocketFactory(JsseSSLManager.CPS),
                    SUPPORTED_PROTOCOL_LIST,
                    SUPPORTED_CIPHER_LIST,
                    NoopHostnameVerifier.INSTANCE);
        }",,
jmeter,14768,"log.debug(""num threads = {}"", ((AbstractThreadGroup) item).getNumThreads())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/ConvertListeners.java/#L57,"@Override
    public void addNode(Object node, HashTree subTree) {
        for (Object item : subTree.list()) {
            if (item instanceof AbstractThreadGroup && log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""num threads = {}"", ((AbstractThreadGroup) item).getNumThreads())
---------------Reference log end----------------
            }
            if (item instanceof Remoteable) {
                if (item instanceof RemoteThreadsListenerTestElement){
                    // Used for remote notification of threads start/stop,see BUG 54152
                    try {
                        RemoteThreadsListenerWrapper wrapper = new RemoteThreadsListenerWrapper(new RemoteThreadsListenerImpl());
                        subTree.replaceKey(item, wrapper);
                    } catch (RemoteException e) {
                        log.error(""Error replacing {} by wrapper: {}"", RemoteThreadsListenerTestElement.class,
                                RemoteThreadsListenerWrapper.class, e);
                    }
                    continue;
                }
                if (item instanceof ThreadListener){
                    // TODO Document the reason for this
                    log.error(""Cannot handle ThreadListener Remotable item: {}"", item.getClass());
                    continue;
                }
                try {
                    RemoteSampleListener rtl = new RemoteSampleListenerImpl(item);
                    if (item instanceof TestStateListener && item instanceof SampleListener) { // TL - all
                        RemoteListenerWrapper wrap = new RemoteListenerWrapper(rtl);
                        subTree.replaceKey(item, wrap);
                    } else if (item instanceof TestStateListener) {
                        RemoteTestListenerWrapper wrap = new RemoteTestListenerWrapper(rtl);
                        subTree.replaceKey(item, wrap);
                    } else if (item instanceof SampleListener) {
                        RemoteSampleListenerWrapper wrap = new RemoteSampleListenerWrapper(rtl);
                        subTree.replaceKey(item, wrap);
                    } else {
                        if (log.isWarnEnabled()) {
                            log.warn(""Could not replace Remotable item: {}"", item.getClass());
                        }
                    }
                } catch (RemoteException e) {
                    log.error(""RemoteException occurred while replacing Remotable item."", e); // $NON-NLS-1$
                }
            }
        }
    }",,
jmeter,14621,"LOGGER.info(""Checking output folder"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/JsonExporter.java/#L78,"@Override
    public void export(SampleContext context, File file, ReportGeneratorConfiguration reportGeneratorConfiguration)
            throws ExportException {
        Object data = context.getData().get(ReportGenerator.STATISTICS_SUMMARY_CONSUMER_NAME);
        if (data instanceof MapResultData) {
            LOGGER.info(""Found data for consumer {}in context"", ReportGenerator.STATISTICS_SUMMARY_CONSUMER_NAME);
            MapResultData result = (MapResultData) data;
            Map<String, SamplingStatistic> statistics = new HashMap<>();
            MapResultData overallData = (MapResultData) result.getResult(""overall"");
            LOGGER.info(""Creating statistics for overall"");
            createStatistic(statistics, overallData);

            ListResultData itemsData = (ListResultData) result.getResult(""items"");
            LOGGER.info(""Creating statistics for other transactions"");
            itemsData.forEach(r -> createStatistic(statistics, (MapResultData)r));

            
---------------Reference log start----------------
LOGGER.info(""Checking output folder"")
---------------Reference log end----------------
            File outputDir = checkAndGetOutputFolder(reportGeneratorConfiguration);

            File outputFile = new File(outputDir, OUTPUT_FILENAME);
            LOGGER.info(""Writing statistics JSON to {}"", outputFile);
            try (Writer fileWriter = Files.newBufferedWriter(outputFile.toPath())) {
                OBJECT_WRITER.writeValue(fileWriter, statistics);
            } catch (IOException e) {
                throw new ExportException(""Error generating JSON statistics file to "" + outputFile +"" for ""+statistics, e);
            }
        }
    }",,
jmeter,14910,"log.error(""Error adding {} to classpath"", path, e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/testelement/TestPlan.java/#L269,"@Override
    public void testStarted() {
        if (getBasedir() != null && getBasedir().length() > 0) {
            try {
                FileServer.getFileServer().setBasedir(FileServer.getFileServer().getBaseDir() + getBasedir());
            } catch (IllegalStateException e) {
                log.error(""Failed to set file server base dir with {}"", getBasedir(), e);
            }
        }
        // we set the classpath
        String[] paths = this.getTestPlanClasspathArray();
        for (String path : paths) {
            try {
                NewDriver.addURL(path);
                log.info(""added {} to classpath"", path);
            } catch (MalformedURLException e) {
                // TODO Should we continue the test or fail ?
                
---------------Reference log start----------------
log.error(""Error adding {} to classpath"", path, e)
---------------Reference log end----------------
            }
        }
    }",,
jmeter,13637,"log.debug(""Headers in request before:{}"", Arrays.asList(httpRequest.getAllHeaders()))",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPHC4Impl.java/#L653,"@Override
    protected HTTPSampleResult sample(URL url, String method,
            boolean areFollowingRedirect, int frameDepth) {

        if (log.isDebugEnabled()) {
            log.debug(""Start : sample {} method {} followingRedirect {} depth {}"",
                    url, method, areFollowingRedirect, frameDepth);
        }
        JMeterVariables jMeterVariables = JMeterContextService.getContext().getVariables();

        HTTPSampleResult res = createSampleResult(url, method);

        CloseableHttpClient httpClient = null;
        HttpRequestBase httpRequest = null;
        HttpContext localContext = new BasicHttpContext();
        HttpClientContext clientContext = HttpClientContext.adapt(localContext);
        clientContext.setAttribute(CONTEXT_ATTRIBUTE_AUTH_MANAGER, getAuthManager());
        HttpClientKey key = createHttpClientKey(url);
        MutableTriple<CloseableHttpClient, AuthState, PoolingHttpClientConnectionManager> triple;
        try {
            triple = setupClient(key, jMeterVariables, clientContext);
            httpClient = triple.getLeft();
            URI uri = url.toURI();
            httpRequest = createHttpRequest(uri, method, areFollowingRedirect);
            setupRequest(url, httpRequest, res); // can throw IOException
        } catch (Exception e) {
            res.sampleStart();
            res.sampleEnd();
            errorResult(e, res);
            return res;
        }

        setupClientContextBeforeSample(jMeterVariables, localContext);

        res.sampleStart();

        final CacheManager cacheManager = getCacheManager();
        if (cacheManager != null && HTTPConstants.GET.equalsIgnoreCase(method) && cacheManager.inCache(url, httpRequest.getAllHeaders())) {
            return updateSampleResultForResourceInCache(res);
        }
        CloseableHttpResponse httpResponse = null;
        try {
            currentRequest = httpRequest;
            handleMethod(method, res, httpRequest, localContext);
            // store the SampleResult in LocalContext to compute connect time
            localContext.setAttribute(CONTEXT_ATTRIBUTE_SAMPLER_RESULT, res);
            // perform the sample
            httpResponse =
                    executeRequest(httpClient, httpRequest, localContext, url);
            saveProxyAuth(triple, localContext);
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Headers in request before:{}"", Arrays.asList(httpRequest.getAllHeaders()))
---------------Reference log end----------------
            }
            // Needs to be done after execute to pick up all the headers
            final HttpRequest request = (HttpRequest) localContext.getAttribute(HttpCoreContext.HTTP_REQUEST);
            if (log.isDebugEnabled()) {
                log.debug(""Headers in request after:{}, in localContext#request:{}"",
                        Arrays.asList(httpRequest.getAllHeaders()),
                        Arrays.asList(request.getAllHeaders()));
            }
            extractClientContextAfterSample(jMeterVariables, localContext);
            // We've finished with the request, so we can add the LocalAddress to it for display
            if (localAddress != null) {
                request.addHeader(HEADER_LOCAL_ADDRESS, localAddress.toString());
            }
            res.setRequestHeaders(getAllHeadersExceptCookie(request));

            Header contentType = httpResponse.getLastHeader(HTTPConstants.HEADER_CONTENT_TYPE);
            if (contentType != null){
                String ct = contentType.getValue();
                res.setContentType(ct);
                res.setEncodingAndType(ct);
            }
            HttpEntity entity = httpResponse.getEntity();
            if (entity != null) {
                res.setResponseData(readResponse(res, entity.getContent(), entity.getContentLength()));
            }

            res.sampleEnd(); // Done with the sampling proper.
            currentRequest = null;

            // Now collect the results into the HTTPSampleResult:
            StatusLine statusLine = httpResponse.getStatusLine();
            int statusCode = statusLine.getStatusCode();
            res.setResponseCode(Integer.toString(statusCode));
            res.setResponseMessage(statusLine.getReasonPhrase());
            res.setSuccessful(isSuccessCode(statusCode));
            res.setResponseHeaders(getResponseHeaders(httpResponse));
            if (res.isRedirect()) {
                final Header headerLocation = httpResponse.getLastHeader(HTTPConstants.HEADER_LOCATION);
                if (headerLocation == null) { // HTTP protocol violation, but avoids NPE
                    throw new IllegalArgumentException(""Missing location header in redirect for "" + httpRequest.getRequestLine());
                }
                String redirectLocation = headerLocation.getValue();
                res.setRedirectLocation(redirectLocation);
            }

            // record some sizes to allow HTTPSampleResult.getBytes() with different options
            long headerBytes =
                (long)res.getResponseHeaders().length()   // condensed length (without \r)
              + (long) httpResponse.getAllHeaders().length // Add \r for each header
              + 1L // Add \r for initial header
              + 2L; // final \r\n before data
            HttpConnectionMetrics metrics = (HttpConnectionMetrics) localContext.getAttribute(CONTEXT_ATTRIBUTE_METRICS);
            long totalBytes = metrics.getReceivedBytesCount();
            res.setHeadersSize((int)headerBytes);
            res.setBodySize(totalBytes - headerBytes);
            res.setSentBytes((Long) localContext.getAttribute(CONTEXT_ATTRIBUTE_SENT_BYTES));
            if (log.isDebugEnabled()) {
                long total = res.getHeadersSize() + res.getBodySizeAsLong();
                log.debug(""ResponseHeadersSize={} Content-Length={} Total={}"",
                        res.getHeadersSize(), res.getBodySizeAsLong(), total);
            }

            // If we redirected automatically, the URL may have changed
            if (getAutoRedirects()) {
                HttpUriRequest req = (HttpUriRequest) localContext.getAttribute(HttpCoreContext.HTTP_REQUEST);
                HttpHost target = (HttpHost) localContext.getAttribute(HttpCoreContext.HTTP_TARGET_HOST);
                URI redirectURI = req.getURI();
                if (redirectURI.isAbsolute()) {
                    res.setURL(redirectURI.toURL());
                } else {
                    res.setURL(new URL(new URL(target.toURI()),redirectURI.toString()));
                }
            }

            // Store any cookies received in the cookie manager:
            saveConnectionCookies(httpResponse, res.getURL(), getCookieManager());

            // Save cache information
            if (cacheManager != null){
                cacheManager.saveDetails(httpResponse, res);
            }

            // Follow redirects and download page resources if appropriate:
            res = resultProcessing(areFollowingRedirect, frameDepth, res);
            if(!isSuccessCode(statusCode)) {
                EntityUtils.consumeQuietly(httpResponse.getEntity());
            }

        } catch (IOException e) {
            log.debug(""IOException"", e);
            if (res.getEndTime() == 0) {
                res.sampleEnd();
            }
           // pick up headers if failed to execute the request
            if (res.getRequestHeaders() != null) {
                log.debug(""Overwriting request old headers: {}"", res.getRequestHeaders());
            }
            res.setRequestHeaders(getAllHeadersExceptCookie((HttpRequest) localContext.getAttribute(HttpCoreContext.HTTP_REQUEST)));
            errorResult(e, res);
            return res;
        } catch (RuntimeException e) {
            log.debug(""RuntimeException"", e);
            if (res.getEndTime() == 0) {
                res.sampleEnd();
            }
            errorResult(e, res);
            return res;
        } finally {
            JOrphanUtils.closeQuietly(httpResponse);
            currentRequest = null;
            JMeterContextService.getContext().getSamplerContext().remove(CONTEXT_ATTRIBUTE_PARENT_SAMPLE_CLIENT_STATE);
        }
        return res;
    }",,
jmeter,13987,"log.warn(msg, ex)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/control/IncludeController.java/#L158,"protected HashTree loadIncludedElements() {
        // only try to load the JMX test plan if there is one
        final String includePath = getIncludePath();
        HashTree tree = null;
        if (includePath != null && includePath.length() > 0) {
            String fileName=PREFIX+includePath;
            try {
                File file = new File(fileName.trim());
                final String absolutePath = file.getAbsolutePath();
                log.info(""loadIncludedElements -- try to load included module: {}"", absolutePath);
                if(!file.exists() && !file.isAbsolute()){
                    log.info(""loadIncludedElements -failed for: {}"", absolutePath);
                    file = new File(FileServer.getFileServer().getBaseDir(), includePath);
                    if (log.isInfoEnabled()) {
                        log.info(""loadIncludedElements -Attempting to read it from: {}"", file.getAbsolutePath());
                    }
                    if(!file.canRead() || !file.isFile()){
                        log.error(""Include Controller '{}' can't load '{}' - see log for details"", this.getName(),
                                fileName);
                        throw new IOException(""loadIncludedElements -failed for: "" + absolutePath +
                                "" and "" + file.getAbsolutePath());
                    }
                }

                tree = SaveService.loadTree(file);
                // filter the tree for a TestFragment.
                tree = getProperBranch(tree);
                removeDisabledItems(tree);
                return tree;
            } catch (NoClassDefFoundError ex) // Allow for missing optional jars
            {
                String msg = ""Including file \""""+ fileName
                            + ""\"" failed for Include Controller \""""+ this.getName()
                            +""\"", missing jar file"";
                log.warn(msg, ex);
                JMeterUtils.reportErrorToUser(msg+"" - see log for details"");
            } catch (FileNotFoundException ex) {
                String msg = ""File \""""+ fileName
                        + ""\"" not found for Include Controller \""""+ this.getName()+""\"""";
                JMeterUtils.reportErrorToUser(msg+"" - see log for details"");
                
---------------Reference log start----------------
log.warn(msg, ex)
---------------Reference log end----------------
            } catch (Exception ex) {
                String msg = ""Including file \"""" + fileName
                            + ""\"" failed for Include Controller \"""" + this.getName()
                            +""\"", unexpected error"";
                JMeterUtils.reportErrorToUser(msg+"" - see log for details"");
                log.warn(msg, ex);
            }
        }
        return tree;
    }",,
jmeter,14179,"log.error(""Problem in JSR223 script, {}"", getName(), e)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/timers/JSR223Timer.java/#L50,"@Override
    public long delay() {
        long delay = 0;
        try {
            ScriptEngine scriptEngine = getScriptEngine();
            Object o = processFileOrScript(scriptEngine, null);
            if (o == null) {
                log.warn(""Script did not return a value"");
                return 0;
            }
            delay = Long.parseLong(o.toString());
        } catch (NumberFormatException | IOException | ScriptException e) {
            
---------------Reference log start----------------
log.error(""Problem in JSR223 script, {}"", getName(), e)
---------------Reference log end----------------
        }
        return delay;
    }",,
jmeter,13920,"log.debug(""Ignoring SocketTimeoutException, as we are not looking for EOM"", e)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/BinaryTCPClientImpl.java/#L142,"@Override
    public String read(InputStream is, SampleResult sampleResult) throws ReadException {
        ByteArrayOutputStream w = new ByteArrayOutputStream();
        try {
            byte[] buffer = new byte[4096];
            int x = 0;
            boolean first = true;
            while ((x = is.read(buffer)) > -1) {
                if (first) {
                    sampleResult.latencyEnd();
                    first = false;
                }
                w.write(buffer, 0, x);
                if (useEolByte && (buffer[x - 1] == eolByte)) {
                    break;
                }
            }
        } catch (SocketTimeoutException e) {
            if (useEolByte) {
                throw new ReadException(""Socket timed out while looking for EOM"", e,
                        JOrphanUtils.baToHexString(w.toByteArray()));
            }
            
---------------Reference log start----------------
log.debug(""Ignoring SocketTimeoutException, as we are not looking for EOM"", e)
---------------Reference log end----------------
        } catch (IOException e) {
            throw new ReadException(""Problems while trying to read"", e, JOrphanUtils.baToHexString(w.toByteArray()));
        }
        final String hexString = JOrphanUtils.baToHexString(w.toByteArray());
        if(log.isDebugEnabled()) {
            log.debug(""Read: {}\n{}"", w.size(), hexString);
        }
        return hexString;
    }",,
jmeter,14724,"log.info(""Reset base to '{}'"", base)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/services/FileServer.java/#L102,"public synchronized void resetBase() {
        checkForOpenFiles();
        base = new File(DEFAULT_BASE);
        
---------------Reference log start----------------
log.info(""Reset base to '{}'"", base)
---------------Reference log end----------------
    }
    }",,
jmeter,14493,"log.error(""Could not delete existing file {}"", f.getAbsolutePath())",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/AbstractAction.java/#L101,"protected boolean popupCheckExistingFileListener(HashTree tree) {

        SearchByClass<ResultCollector> resultListeners = new SearchByClass<>(ResultCollector.class);
        tree.traverse(resultListeners);
        for (ResultCollector rc : resultListeners.getSearchResults()) {
            File f = new File(rc.getFilename());
            if (f.exists()) {
                switch (actionOnFile) {
                    case APPEND:
                        break;
                    case DELETE:
                        if (f.delete()) {
                            break;
                        } else {
                            
---------------Reference log start----------------
log.error(""Could not delete existing file {}"", f.getAbsolutePath())
---------------Reference log end----------------
                            return false;
                        }
                    case ASK:
                    default:
                        String[] option = new String[]{JMeterUtils.getResString(""concat_result""),
                                JMeterUtils.getResString(""dont_start""), JMeterUtils.getResString(""replace_file"")};
                        String question = MessageFormat.format(
                                JMeterUtils.getResString(""ask_existing_file""), // $NON-NLS-1$
                                rc.getFilename());
                        // Interactive question
                        int response = JOptionPane.showOptionDialog(GuiPackage.getInstance().getMainFrame(),
                                question, JMeterUtils.getResString(""warning""),
                                JOptionPane.YES_NO_CANCEL_OPTION,
                                JOptionPane.WARNING_MESSAGE,
                                null,
                                option,
                                option[0]);

                        switch (response) {
                            case JOptionPane.CANCEL_OPTION:
                                // replace_file so delete the existing one
                                if (f.delete()) {
                                    break;
                                } else {
                                    log.error(""Could not delete existing file {}"", f.getAbsolutePath());
                                    return false;
                                }
                            case JOptionPane.YES_OPTION:
                                // append is the default behaviour, so nothing to do
                                break;
                            case JOptionPane.NO_OPTION:
                            default:
                                // Exit without start the test
                                return false;
                        }
                        break;
                }
            }
        }
        return true;
    }",,
jmeter,15060,"log.error(""Duplicate class detected for {}: {} & {}"", alias, clazz, old)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/save/SaveService.java/#L175,"private static void makeAlias(String aliasList, String clazz) {
        String[] aliases = aliasList.split("",""); // Can have multiple aliases for same target classname
        String alias = aliases[0];
        for (String a : aliases){
            Object old = aliasToClass.setProperty(a,clazz);
            if (old != null){
                
---------------Reference log start----------------
log.error(""Duplicate class detected for {}: {} & {}"", alias, clazz, old)
---------------Reference log end----------------
            }
        }
        Object oldval=classToAlias.setProperty(clazz,alias);
        if (oldval != null) {
            log.error(""Duplicate alias detected for {}: {} & {}"", clazz, alias, oldval);
        }
    }",,
jmeter,13869,"LOGGER.debug(""JMSSampler: [{}], hashCode=[{}]"", Thread.currentThread().getName(), hashCode())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/sampler/JMSSampler.java/#L754,"@SuppressWarnings(""JdkObsolete"")
    private void logThreadStart() {
        if (LOGGER.isDebugEnabled()) {
            LOGGER.debug(""Thread started {}"", new Date());
            
---------------Reference log start----------------
LOGGER.debug(""JMSSampler: [{}], hashCode=[{}]"", Thread.currentThread().getName(), hashCode())
---------------Reference log end----------------
            LOGGER.debug(""QCF: [{}], sendQueue=[{}]"", getQueueConnectionFactory(), getSendQueue());
            LOGGER.debug(""Timeout = [{}]"", getTimeout());
            LOGGER.debug(""Use temporary queue =[{}]"", useTemporyQueue());
            LOGGER.debug(""Reply queue         = [{}]"", getReceiveQueue());
        }
    }",,
jmeter,14175,"log.warn(""Number format exception while decoding number: '{}'"", ret)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/timers/BeanShellTimer.java/#L68,"@Override
    public long delay() {
        String ret=""0"";
        final BeanShellInterpreter bshInterpreter = getBeanShellInterpreter();
        if (bshInterpreter == null) {
            log.error(""BeanShell not found"");
            return 0;
        }
        try {
            Object o = processFileOrScript(bshInterpreter);
            if (o != null) {
                ret=o.toString();
            }
        } catch (JMeterException e) {
            if (log.isWarnEnabled()) {
                log.warn(""Problem in BeanShell script. {}"", e.toString());
            }
        }
        try {
            return Long.decode(ret);
        } catch (NumberFormatException e){
            
---------------Reference log start----------------
log.warn(""Number format exception while decoding number: '{}'"", ret)
---------------Reference log end----------------
            return 0;
        }
    }",,
jmeter,13752,"log.warn(""Ldap client disconnect - "", e)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/ldap/src/main/java/org/apache/jmeter/protocol/ldap/sampler/LdapExtClient.java/#L138,"public static void disconnect(DirContext dirContext) {
        if (dirContext == null) {
            log.info(""Cannot disconnect null context"");
            return;
        }

        try {
            dirContext.close();
        } catch (NamingException e) {
            
---------------Reference log start----------------
log.warn(""Ldap client disconnect - "", e)
---------------Reference log end----------------
        }
    }",,
jmeter,14997,"log.debug("" Server certificate {}:\n"" + ""  Subject DN: {}\n"" + ""  Signature Algorithm: {}\n"" + ""  Valid from: {}\n"" + ""  Valid until: {}\n"" + ""  Issuer: {}"", i + 1, cert.getSubjectX500Principal(), cert.getSigAlgName(), cert.getNotBefore(), cert.getNotAfter(), cert.getIssuerX500Principal())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/CustomX509TrustManager.java/#L85,"@Override
    public void checkServerTrusted(X509Certificate[] certificates,String authType) // NOSONAR JMeter is a pentest and perf testing tool
            throws CertificateException {
        if (log.isDebugEnabled() && certificates != null) {
            for (int i = 0; i < certificates.length; i++) {
                X509Certificate cert = certificates[i];
                
---------------Reference log start----------------
log.debug("" Server certificate {}:\n"" + ""  Subject DN: {}\n"" + ""  Signature Algorithm: {}\n"" + ""  Valid from: {}\n"" + ""  Valid until: {}\n"" + ""  Issuer: {}"", i + 1, cert.getSubjectX500Principal(), cert.getSigAlgName(), cert.getNotBefore(), cert.getNotAfter(), cert.getIssuerX500Principal())
---------------Reference log end----------------
            }
        }
    }",,
jmeter,13921,"log.debug(""Read: {}\n{}"", w.size(), hexString)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/BinaryTCPClientImpl.java/#L148,"@Override
    public String read(InputStream is, SampleResult sampleResult) throws ReadException {
        ByteArrayOutputStream w = new ByteArrayOutputStream();
        try {
            byte[] buffer = new byte[4096];
            int x = 0;
            boolean first = true;
            while ((x = is.read(buffer)) > -1) {
                if (first) {
                    sampleResult.latencyEnd();
                    first = false;
                }
                w.write(buffer, 0, x);
                if (useEolByte && (buffer[x - 1] == eolByte)) {
                    break;
                }
            }
        } catch (SocketTimeoutException e) {
            if (useEolByte) {
                throw new ReadException(""Socket timed out while looking for EOM"", e,
                        JOrphanUtils.baToHexString(w.toByteArray()));
            }
            log.debug(""Ignoring SocketTimeoutException, as we are not looking for EOM"", e);
        } catch (IOException e) {
            throw new ReadException(""Problems while trying to read"", e, JOrphanUtils.baToHexString(w.toByteArray()));
        }
        final String hexString = JOrphanUtils.baToHexString(w.toByteArray());
        if(log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Read: {}\n{}"", w.size(), hexString)
---------------Reference log end----------------
        }
        return hexString;
    }",,
jmeter,14523,"log.error(""performAction({}) {} caused"", actionCommand, e, er)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/ActionRouter.java/#L108,"private void performAction(final ActionEvent e) {
        String actionCommand = e.getActionCommand();
        if(!NO_TRANSACTION_ACTIONS.contains(actionCommand)) {
            GuiPackage.getInstance().beginUndoTransaction();
        }
        try {
            try {
                GuiPackage.getInstance().updateCurrentGui();
            } catch (Exception err){
                log.error(""performAction({}) updateCurrentGui() on{} caused"", actionCommand, e, err);
                JMeterUtils.reportErrorToUser(""Problem updating GUI - see log file for details"");
            }
            for (Command c : commands.get(actionCommand)) {
                try {
                    preActionPerformed(c.getClass(), e);
                    c.doAction(e);
                    postActionPerformed(c.getClass(), e);
                } catch (IllegalUserActionException err) {
                    String msg = err.getMessage();
                    if (msg == null) {
                        msg = err.toString();
                    }
                    Throwable t = err.getCause();
                    if (t != null) {
                        String cause = t.getMessage();
                        if (cause == null) {
                            cause = t.toString();
                        }
                        msg = msg + ""\n"" + cause;
                    }
                    JMeterUtils.reportErrorToUser(msg);
                } catch (Exception err) {
                    log.error(""Error processing {}"", c, err);
                }
            }
        } catch (NullPointerException er) {
            
---------------Reference log start----------------
log.error(""performAction({}) {} caused"", actionCommand, e, er)
---------------Reference log end----------------
            JMeterUtils.reportErrorToUser(""Sorry, this feature ("" + actionCommand + "") not yet implemented"");
        } finally {
            if(!NO_TRANSACTION_ACTIONS.contains(actionCommand)) {
                GuiPackage.getInstance().endUndoTransaction();
            }
        }
    }",,
jmeter,13412,log.info(redirectLocation),info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/HttpMirrorThread.java/#L180,"@Override
    public void run() {
        log.debug(""Starting thread"");
        BufferedInputStream in = null;
        BufferedOutputStream out = null;

        try {
            in = new BufferedInputStream(clientSocket.getInputStream());

            // Read the header part, we will be looking for a content-length
            // header, so we know how much we should read.
            // We assume headers are in ISO_8859_1
            // If we do not find such a header, we will just have to read until
            // we have to block to read more, until we support chunked transfer
            int contentLength = -1;
            boolean isChunked = false;
            byte[] buffer = new byte[1024];
            StringBuilder headers = new StringBuilder();
            int length = 0;
            int positionOfBody = 0;
            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            while(positionOfBody <= 0 && ((length = in.read(buffer)) != -1)) {
                log.debug(""Write body"");
                baos.write(buffer, 0, length); // echo back
                headers.append(new String(buffer, 0, length, ISO_8859_1));
                // Check if we have read all the headers
                positionOfBody = getPositionOfBody(headers.toString());
            }

            baos.close();
            final String headerString = headers.toString();
            if(headerString.length() == 0 || headerString.indexOf('\r') < 0) {
                log.error(""Invalid request received:'{}'"", headerString);
                return;
            }
            log.debug(""Received => '{}'"", headerString);
            final String firstLine = headerString.substring(0, headerString.indexOf('\r'));
            final String[] requestParts = firstLine.split(""\\s+"");
            final String requestMethod = requestParts[0];
            final String requestPath = requestParts[1];
            final HashMap<String, String> parameters = new HashMap<>();
            if (HTTPConstants.GET.equals(requestMethod)) {
                int querypos = requestPath.indexOf('?');
                if (querypos >= 0) {
                    String query;
                    try {
                        URI uri = new URI(requestPath); // Use URI because it will decode the query
                        query = uri.getQuery();
                    } catch (URISyntaxException e) {
                        log.warn(e.getMessage());
                        query=requestPath.substring(querypos+1);
                    }
                    if (query != null) {
                        String[] params = query.split(""&"");
                        for(String param : params) {
                            String[] parts = param.split(""="",2);
                            if (parts.length==2) {
                                parameters.put(parts[0], parts[1]);
                            } else { // allow for parameter name only
                                parameters.put(parts[0], """");
                            }
                        }
                    }
                }
            }

            final boolean verbose = parameters.containsKey(VERBOSE);

            if (verbose) {
                System.out.println(firstLine); // NOSONAR
                log.info(firstLine);
            }

            // Look for special Response Length header
            String responseStatusValue = getRequestHeaderValue(headerString, ""X-ResponseStatus""); //$NON-NLS-1$
            if(responseStatusValue == null) {
                responseStatusValue = ""200 OK"";
            }
            // Do this before the status check so can override the status, e.g. with a different redirect type
            if (parameters.containsKey(REDIRECT)) {
                responseStatusValue = ""302 Temporary Redirect"";
            }
            if (parameters.containsKey(STATUS)) {
                responseStatusValue = parameters.get(STATUS);
            }

            log.debug(""Write headers"");
            out = new BufferedOutputStream(clientSocket.getOutputStream());
            // The headers are written using ISO_8859_1 encoding
            out.write((""HTTP/1.0 ""+responseStatusValue).getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);
            out.write(""Content-Type: text/plain"".getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);

            if (parameters.containsKey(REDIRECT)) {
                final String redirectLocation =
                        HTTPConstants.HEADER_LOCATION + "": "" + parameters.get(REDIRECT);
                if (verbose) {
                    System.out.println(redirectLocation); // NOSONAR
                    
---------------Reference log start----------------
log.info(redirectLocation)
---------------Reference log end----------------
                }
                out.write(redirectLocation.getBytes(ISO_8859_1));
                out.write(CRLF);
            }

            // Look for special Header request
            String headersValue = getRequestHeaderValue(headerString, ""X-SetHeaders""); //$NON-NLS-1$
            if (headersValue != null) {
                String[] headersToSet = headersValue.split(""\\|"");
                for (String string : headersToSet) {
                    out.write(string.getBytes(ISO_8859_1));
                    out.write(CRLF);
                }
            }

            // Look for special Response Length header
            String responseLengthValue = getRequestHeaderValue(headerString, ""X-ResponseLength""); //$NON-NLS-1$
            int responseLength=-1;
            if(responseLengthValue != null) {
                responseLength = Integer.parseInt(responseLengthValue);
            }

            // Look for special Cookie request
            String cookieHeaderValue = getRequestHeaderValue(headerString, ""X-SetCookie""); //$NON-NLS-1$
            if (cookieHeaderValue != null) {
                out.write(""Set-Cookie: "".getBytes(ISO_8859_1));
                out.write(cookieHeaderValue.getBytes(ISO_8859_1));
                out.write(CRLF);
            }
            out.write(CRLF);
            out.flush();

            if(responseLength>=0) {
                out.write(baos.toByteArray(), 0, Math.min(baos.toByteArray().length, responseLength));
            } else {
                out.write(baos.toByteArray());
            }
            // Check if we have found a content-length header
            String contentLengthHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.HEADER_CONTENT_LENGTH);
            if(contentLengthHeaderValue != null) {
                contentLength = Integer.parseInt(contentLengthHeaderValue);
            }
            // Look for special Sleep request
            String sleepHeaderValue = getRequestHeaderValue(headerString, ""X-Sleep""); //$NON-NLS-1$
            if(sleepHeaderValue != null) {
                TimeUnit.MILLISECONDS.sleep(Integer.parseInt(sleepHeaderValue));
            }
            String transferEncodingHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.TRANSFER_ENCODING);
            if(transferEncodingHeaderValue != null) {
                isChunked = transferEncodingHeaderValue.equalsIgnoreCase(""chunked""); //$NON-NLS-1$
                // We only support chunked transfer encoding
                if(!isChunked) {
                    log.error(""Transfer-Encoding header set, the value is not supported : {}"", transferEncodingHeaderValue);
                }
            }

            // If we know the content length, we can allow the reading of
            // the request to block until more data arrives.
            // If it is chunked transfer, we cannot allow the reading to
            // block, because we do not know when to stop reading, because
            // the chunked transfer is not properly supported yet
            length = 0;
            if(contentLength > 0) {
                // Check how much of the body we have already read as part of reading
                // the headers
                // We subtract two bytes for the crlf divider between header and body
                int totalReadBytes = headerString.length() - positionOfBody - 2;

                // We know when to stop reading, so we can allow the read method to block
                log.debug(""Reading, {} < {}"", totalReadBytes, contentLength);
                while((totalReadBytes < contentLength) && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);

                    totalReadBytes += length;
                    log.debug(""totalReadBytes: {}"", totalReadBytes);
                }
            }
            else if (isChunked) {
                // It is chunked transfer encoding, which we do not really support yet.
                // So we just read without blocking, because we do not know when to
                // stop reading, so we cannot block
                // TODO properly implement support for chunked transfer, i.e. to
                // know when we have read the whole request, and therefore allow
                // the reading to block
                log.debug(""Chunked"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    out.write(buffer, 0, length);
                }
            }
            else {
                // The request has no body, or it has a transfer encoding we do not support.
                // In either case, we read any data available
                log.debug(""Other"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);
                }
            }
            log.debug(""Flush"");
            out.flush();
        } catch (IOException | InterruptedException e) {
            log.error("""", e);
        } finally {
            JOrphanUtils.closeQuietly(out);
            JOrphanUtils.closeQuietly(in);
            JOrphanUtils.closeQuietly(clientSocket);
        }
        log.debug(""End of Thread"");
    }",,
jmeter,14264,"log.error(""Problem in JSR223 script, {}"", getName(), e)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/modifiers/JSR223PreProcessor.java/#L47,"@Override
    public void process() {
        try {
            ScriptEngine scriptEngine = getScriptEngine();
            processFileOrScript(scriptEngine, null);
        } catch (ScriptException | IOException e) {
            
---------------Reference log start----------------
log.error(""Problem in JSR223 script, {}"", getName(), e)
---------------Reference log end----------------
        }
    }",,
jmeter,14874,"log.debug(""Did not set DEFAULT for {}"", name)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/testbeans/gui/TestBeanGUI.java/#L240,"@Override
    public void modifyTestElement(TestElement element) {
        // Fetch data from screen fields
        if (customizer instanceof GenericTestBeanCustomizer) {
            GenericTestBeanCustomizer gtbc = (GenericTestBeanCustomizer) customizer;
            gtbc.saveGuiFields();
        }
        configureTestElement(element);

        // Copy all property values from the map into the element:
        for (PropertyDescriptor desc : beanInfo.getPropertyDescriptors()) {
            String name = desc.getName();
            Object value = propertyMap.get(name);
            log.debug(""Modify {} to {}"", name, value);
            if (value == null) {
                if (GenericTestBeanCustomizer.notNull(desc)) { // cannot be null
                    if (GenericTestBeanCustomizer.noSaveDefault(desc)) {
                        
---------------Reference log start----------------
log.debug(""Did not set DEFAULT for {}"", name)
---------------Reference log end----------------
                        element.removeProperty(name);
                    } else {
                        setPropertyInElement(element, name, desc.getValue(GenericTestBeanCustomizer.DEFAULT));
                    }
                } else {
                    element.removeProperty(name);
                }
            } else {
                if (GenericTestBeanCustomizer.noSaveDefault(desc) && value.equals(desc.getValue(GenericTestBeanCustomizer.DEFAULT))) {
                    log.debug(""Did not set {} to the default: {}"", name, value);
                    element.removeProperty(name);
                } else {
                    setPropertyInElement(element, name, value);
                }
            }
        }
    }",,
jmeter,14896,"log.debug(""Running version, executing function"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/testelement/property/FunctionProperty.java/#L93,"@Override
    public String getStringValue() {
        JMeterContext ctx = JMeterContextService.getContext();// Expensive, so
                                                                // do
        // once
        if (!isRunningVersion() /*|| !ctx.isSamplingStarted()*/) {
            log.debug(""Not running version, return raw function string"");
            return function.getRawParameters();
        }
        if(!ctx.isSamplingStarted()) {
            return function.execute();
        }
        
---------------Reference log start----------------
log.debug(""Running version, executing function"")
---------------Reference log end----------------
        int iter = ctx.getVariables() != null ? ctx.getVariables().getIteration() : -1;
        if (iter < testIteration) {
            testIteration = -1;
        }
        if (iter > testIteration || cacheValue == null) {
            testIteration = iter;
            cacheValue = function.execute();
        }
        return cacheValue;

    }",,
jmeter,13670,"log.warn(""ResponseCode==-1; parsed {} as {}"", respMsg, errorLevel)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPJavaImpl.java/#L586,"@Override
    protected HTTPSampleResult sample(URL url, String method, boolean areFollowingRedirect, int frameDepth) {
        HttpURLConnection conn = null;

        String urlStr = url.toString();
        if (log.isDebugEnabled()) {
            log.debug(""Start : sample {}, method {}, followingRedirect {}, depth {}"",
                    urlStr, method, areFollowingRedirect, frameDepth);
        }

        HTTPSampleResult res = new HTTPSampleResult();
        configureSampleLabel(res, url);
        res.setURL(url);
        res.setHTTPMethod(method);

        res.sampleStart(); // Count the retries as well in the time

        // Check cache for an entry with an Expires header in the future
        final CacheManager cacheManager = getCacheManager();
        if (cacheManager != null && HTTPConstants.GET.equalsIgnoreCase(method)) {
           if (cacheManager.inCache(url, getHeaders(getHeaderManager()))) {
               return updateSampleResultForResourceInCache(res);
           }
        }

        try {
            // Sampling proper - establish the connection and read the response:
            // Repeatedly try to connect:
            int retry = -1;
            // Start with -1 so tries at least once, and retries at most MAX_CONN_RETRIES times
            for (; retry < MAX_CONN_RETRIES; retry++) {
                try {
                    conn = setupConnection(url, method, res);
                    // Attempt the connection:
                    savedConn = conn;
                    conn.connect();
                    break;
                } catch (BindException e) {
                    if (retry >= MAX_CONN_RETRIES) {
                        log.error(""Can't connect after {} retries, message: {}"", retry, e.toString());
                        throw e;
                    }
                    log.debug(""Bind exception, try again"");
                    if (conn!=null) {
                        savedConn = null; // we don't want interrupt to try disconnection again
                        conn.disconnect();
                    }
                    setUseKeepAlive(false);
                } catch (IOException e) {
                    log.debug(""Connection failed, giving up"");
                    throw e;
                }
            }
            if (retry > MAX_CONN_RETRIES) {
                // This should never happen, but...
                throw new BindException();
            }
            // Nice, we've got a connection. Finish sending the request:
            if (method.equals(HTTPConstants.POST)) {
                String postBody = sendPostData(conn);
                res.setQueryString(postBody);
            } else if (method.equals(HTTPConstants.PUT)) {
                String putBody = sendPutData(conn);
                res.setQueryString(putBody);
            }
            // Request sent. Now get the response:
            byte[] responseData = readResponse(conn, res);

            res.sampleEnd();
            // Done with the sampling proper.

            // Now collect the results into the HTTPSampleResult:

            res.setResponseData(responseData);

            int errorLevel = conn.getResponseCode();
            String respMsg = conn.getResponseMessage();
            String hdr=conn.getHeaderField(0);
            if (hdr == null) {
                hdr=""(null)"";  // $NON-NLS-1$
            }
            if (errorLevel == -1){// Bug 38902 - sometimes -1 seems to be returned unnecessarily
                if (respMsg != null) {// Bug 41902 - NPE
                    try {
                        errorLevel = Integer.parseInt(respMsg.substring(0, 3));
                        
---------------Reference log start----------------
log.warn(""ResponseCode==-1; parsed {} as {}"", respMsg, errorLevel)
---------------Reference log end----------------
                      } catch (NumberFormatException e) {
                        log.warn(""ResponseCode==-1; could not parse {} hdr: {}"", respMsg, hdr);
                      }
                } else {
                    respMsg=hdr; // for result
                    log.warn(""ResponseCode==-1 & null ResponseMessage. Header(0)= {} "", hdr);
                }
            }
            if (errorLevel == -1) {
                res.setResponseCode(""(null)""); // $NON-NLS-1$
            } else {
                res.setResponseCode(Integer.toString(errorLevel));
            }
            res.setSuccessful(isSuccessCode(errorLevel));

            if (respMsg == null) {// has been seen in a redirect
                respMsg=hdr; // use header (if possible) if no message found
            }
            res.setResponseMessage(respMsg);

            String ct = conn.getContentType();
            if (ct != null){
                res.setContentType(ct);// e.g. text/html; charset=ISO-8859-1
                res.setEncodingAndType(ct);
            }

            String responseHeaders = getResponseHeaders(conn);
            res.setResponseHeaders(responseHeaders);
            if (res.isRedirect()) {
                res.setRedirectLocation(conn.getHeaderField(HTTPConstants.HEADER_LOCATION));
            }

            // record headers size to allow HTTPSampleResult.getBytes() with different options
            res.setHeadersSize(responseHeaders.replaceAll(""\n"", ""\r\n"") // $NON-NLS-1$ $NON-NLS-2$
                    .length() + 2); // add 2 for a '\r\n' at end of headers (before data)
            if (log.isDebugEnabled()) {
                log.debug(""Response headersSize={}, bodySize={}, Total={}"",
                        res.getHeadersSize(),  res.getBodySizeAsLong(),
                        res.getHeadersSize() + res.getBodySizeAsLong());
            }

            // If we redirected automatically, the URL may have changed
            if (getAutoRedirects()){
                res.setURL(conn.getURL());
            }

            // Store any cookies received in the cookie manager:
            saveConnectionCookies(conn, url, getCookieManager());

            // Save cache information
            if (cacheManager != null){
                cacheManager.saveDetails(conn, res);
            }

            res = resultProcessing(areFollowingRedirect, frameDepth, res);

            log.debug(""End : sample"");
            return res;
        } catch (IOException e) {
            if (res.getEndTime() == 0) {
                res.sampleEnd();
            }
            savedConn = null; // we don't want interrupt to try disconnection again
            // We don't want to continue using this connection, even if KeepAlive is set
            if (conn != null) { // May not exist
                conn.disconnect();
            }
            conn=null; // Don't process again
            return errorResult(e, res);
        } finally {
            // calling disconnect doesn't close the connection immediately,
            // but indicates we're through with it. The JVM should close
            // it when necessary.
            savedConn = null; // we don't want interrupt to try disconnection again
            disconnect(conn); // Disconnect unless using KeepAlive
        }
    }",,
jmeter,14816,"log.warn(""Could not perform remote exit: "" + e.toString())",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/ClientJMeterEngine.java/#L210,"@Override
    public void exit() {
        log.info(""about to exit remote server on {}"", hostAndPort);
        try {
            remote.rexit();
        } catch (RemoteException e) {
            
---------------Reference log start----------------
log.warn(""Could not perform remote exit: "" + e.toString())
---------------Reference log end----------------
        }
    }",,
jmeter,14315,"log.warn(""Problem deleting the certificate file '"" + caCertUsr + ""'"")",warn,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/exec/KeyToolUtils.java/#L234,"public static void generateProxyCA(File keystore, String password, int validity) throws IOException {
        File caCertCrt = new File(ROOT_CACERT_CRT);
        File caCertUsr = new File(ROOT_CACERT_USR);
        boolean fileExists = false;
        if (!keystore.delete() && keystore.exists()) {
            log.warn(""Problem deleting the keystore '"" + keystore + ""'"");
            fileExists = true;
        }
        if (!caCertCrt.delete() && caCertCrt.exists()) {
            log.warn(""Problem deleting the certificate file '"" + caCertCrt + ""'"");
            fileExists = true;
        }
        if (!caCertUsr.delete() && caCertUsr.exists()) {
            
---------------Reference log start----------------
log.warn(""Problem deleting the certificate file '"" + caCertUsr + ""'"")
---------------Reference log end----------------
            fileExists = true;
        }
        if (fileExists) {
            log.warn(""If problems occur when recording SSL, delete the files manually and retry."");
        }
        // Create the self-signed keypairs
        KeyToolUtils.genkeypair(keystore, ROOTCA_ALIAS, password, validity, DNAME_ROOT_CA_KEY, ""bc:c"");
        KeyToolUtils.genkeypair(keystore, INTERMEDIATE_CA_ALIAS, password, validity, DNAME_INTERMEDIATE_CA_KEY, ""bc:c"");

        // Create cert for CA using root
        ByteArrayOutputStream certReqOut = new ByteArrayOutputStream();
        // generate the request
        KeyToolUtils.keytool(""-certreq"", keystore, password, INTERMEDIATE_CA_ALIAS, null, certReqOut);

        // generate the certificate and store in output file
        InputStream certReqIn = new ByteArrayInputStream(certReqOut.toByteArray());
        ByteArrayOutputStream genCertOut = new ByteArrayOutputStream();
        KeyToolUtils.keytool(""-gencert"", keystore, password, ROOTCA_ALIAS, certReqIn, genCertOut, ""-ext"", ""BC:0"");

        // import the signed CA cert into the store (root already there) - both are needed to sign the domain certificates
        InputStream genCertIn = new ByteArrayInputStream(genCertOut.toByteArray());
        KeyToolUtils.keytool(""-importcert"", keystore, password, INTERMEDIATE_CA_ALIAS, genCertIn, null);

        // Export the Root CA for Firefox/Chrome/IE
        KeyToolUtils.keytool(""-exportcert"", keystore, password, ROOTCA_ALIAS, null, null, ""-rfc"", ""-file"", ROOT_CACERT_CRT);
        // Copy for Opera
        if(caCertCrt.exists() && caCertCrt.canRead()) {
            FileUtils.copyFile(caCertCrt, caCertUsr);
        } else {
            log.warn(""Failed creating ""+caCertCrt.getAbsolutePath()+"", check 'keytool' utility in path is available and points to a JDK >= 7"");
        }
    }",,
jmeter,14497,"log.info(""Reading templates from: {}"", file.getAbsolutePath())",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/template/TemplateManager.java/#L99,"private Map<String, Template> readTemplates() {
        final Map<String, Template> temps = new TreeMap<>();

        final String[] templateFiles = TEMPLATE_FILES.split("","");
        for (String templateFile : templateFiles) {
            if(!StringUtils.isEmpty(templateFile)) {
                final File file = new File(JMeterUtils.getJMeterHome(), templateFile);
                try {
                    if(file.exists() && file.canRead()) {
                        if (log.isInfoEnabled()) {
                            
---------------Reference log start----------------
log.info(""Reading templates from: {}"", file.getAbsolutePath())
---------------Reference log end----------------
                        }
                        Map<String, Template> templates = parseTemplateFile(file);
                        final File parent = file.getParentFile();
                        for(Template t : templates.values()) {
                            if (!t.getFileName().startsWith(""/"")) {
                                t.setParent(parent);
                            }
                        }
                        temps.putAll(templates);
                    } else {
                        if (log.isWarnEnabled()) {
                            log.warn(""Ignoring template file:'{}' as it does not exist or is not readable"",
                                    file.getAbsolutePath());
                        }
                    }
                } catch(Exception ex) {
                    if (log.isWarnEnabled()) {
                        log.warn(""Ignoring template file:'{}', an error occurred parsing the file"", file.getAbsolutePath(),
                                ex);
                    }
                }
            }
        }
        return temps;
    }",,
jmeter,13832,"log.debug(""GET_ID [{}] for {}"", id, holder)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/sampler/MessageAdmin.java/#L151,"public Message get(String id) {
        PlaceHolder holder = table.remove(id);
        
---------------Reference log start----------------
log.debug(""GET_ID [{}] for {}"", id, holder)
---------------Reference log end----------------
        if (holder == null || !holder.hasReply()) {
            log.debug(""Message with {} not found."", id);
        }
        return holder==null ? null : (Message) holder.getReply();
    }",,
jmeter,14038,"log.info(""Sending last metrics to InfluxDB"")",info,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/influxdb/InfluxdbBackendListenerClient.java/#L417,"@Override
    public void teardownTest(BackendListenerContext context) throws Exception {
        boolean cancelState = timerHandle.cancel(false);
        log.debug(""Canceled state: {}"", cancelState);
        scheduler.shutdown();
        try {
            scheduler.awaitTermination(30, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            log.error(""Error waiting for end of scheduler"");
            Thread.currentThread().interrupt();
        }

        addAnnotation(false);

        // Send last set of data before ending
        
---------------Reference log start----------------
log.info(""Sending last metrics to InfluxDB"")
---------------Reference log end----------------
        sendMetrics();

        influxdbMetricsManager.destroy();
        super.teardownTest(context);
    }",,
jmeter,14442,"log.debug(""Found shut  host: {}"", exit.getText())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/util/JMeterMenuBar.java/#L637,"public void setRunning(boolean running, String host) {
        log.info(""setRunning({}, {})"", running, host);
        if (org.apache.jmeter.gui.MainFrame.LOCAL.equals(host)) {
            return;
        }
        Iterator<JMenuItem> iter = remoteEngineStart.iterator();
        Iterator<JMenuItem> iter2 = remoteEngineStop.iterator();
        Iterator<JMenuItem> iter3 = remoteEngineExit.iterator();
        Iterator<JMenuItem> iter4 = remoteEngineShut.iterator();
        while (iter.hasNext() && iter2.hasNext() && iter3.hasNext() &&iter4.hasNext()) {
            JMenuItem start = iter.next();
            JMenuItem stop = iter2.next();
            JMenuItem exit = iter3.next();
            JMenuItem shut = iter4.next();
            if (start.getText().equals(host)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Found start host: {}"", start.getText());
                }
                start.setEnabled(!running);
            }
            if (stop.getText().equals(host)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Found stop  host: {}"", stop.getText());
                }
                stop.setEnabled(running);
            }
            if (exit.getText().equals(host)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Found exit  host: {}"", exit.getText());
                }
                exit.setEnabled(true);
            }
            if (shut.getText().equals(host)) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""Found shut  host: {}"", exit.getText())
---------------Reference log end----------------
                }
                shut.setEnabled(running);
            }
        }
    }",,
jmeter,14500,"log.error(""Error setting page for url, {}"", url, ioe)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/Help.java/#L93,"@Override
    public void doAction(ActionEvent e) {
        if(USE_LOCAL_HELP) {
            JDialog dialog = initHelpWindow();
            dialog.setVisible(true); // set the window visible immediately

            /*
             * This means that a new page will be shown before rendering is complete,
             * however the correct location will be displayed.
             * Attempts to use a ""page"" PropertyChangeListener to detect when the page
             * has been loaded failed to work any better.
             */
            StringBuilder url=new StringBuilder();
            if (e.getSource() instanceof String[]) {
                String[] source = (String[]) e.getSource();
                url.append(source[0]).append('#').append(source[1]);
            } else {
                url.append(HELP_COMPONENTS).append('#').append(GuiPackage.getInstance().getTreeListener().getCurrentNode().getDocAnchor());
            }
            try {
                helpDoc.setPage(url.toString()); // N.B. this only reloads if necessary (ignores the reference)
            } catch (IOException ioe) {
                
---------------Reference log start----------------
log.error(""Error setting page for url, {}"", url, ioe)
---------------Reference log end----------------
                helpDoc.setText(""<html><head><title>Problem loading help page</title>""
                        + ""<style><!--""
                        + "".note { background-color: #ffeeee; border: 1px solid brown; }""
                        + ""div { padding: 10; margin: 10; }""
                        + ""--></style></head>""
                        + ""<body><div class='note'>""
                        + ""<h1>Problem loading help page</h1>""
                        + ""<div>Can't load url: &quot;<em>""
                        + url.toString() + ""</em>&quot;</div>""
                        + ""<div>See log for more info</div>""
                        + ""</body>"");
            }
        } else {
            if (e.getSource() instanceof String[]) {
                ActionRouter.getInstance().doActionNow(
                        new ActionEvent(e.getSource(), e.getID(),
                                ActionNames.LINK_FUNC_REF));
            } else {
                String[] source = new String[]{ActionNames.LINK_COMP_REF,
                        GuiPackage.getInstance().getTreeListener().getCurrentNode().getDocAnchor()};
                ActionRouter.getInstance().doActionNow(
                        new ActionEvent(source, e.getID(),
                                ActionNames.LINK_COMP_REF));
            }
        }
    }",,
jmeter,15058,"log.warn(""Failed to read result file."", e)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/save/converters/SampleResultConverter.java/#L470,"protected void readFile(String resultFileName, SampleResult res) {
        File in = new File(resultFileName);
        try (FileInputStream fis = new FileInputStream(in);
                BufferedInputStream bis = new BufferedInputStream(fis)){
            ByteArrayOutputStream outstream = new ByteArrayOutputStream(4096);
            byte[] buffer = new byte[4096];
            int len;
            while ((len = bis.read(buffer)) > 0) {
                outstream.write(buffer, 0, len);
            }
            outstream.close();
            res.setResponseData(outstream.toByteArray());
        } catch (IOException e) {
            
---------------Reference log start----------------
log.warn(""Failed to read result file."", e)
---------------Reference log end----------------
        }
    }",,
jmeter,13403,"log.debug(""Use KerberosScheme"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/DynamicKerberosSchemeFactory.java/#L56,"@Override
    public AuthScheme create(final HttpContext context) {
        boolean stripPort = isEnabled(context.getAttribute(CONTEXT_ATTRIBUTE_STRIP_PORT), isStripPort());
        if (isEnabled(context.getAttribute(CONTEXT_ATTRIBUTE_DELEGATE_CRED), DELEGATE_CRED)) {
            log.debug(""Use DelegatingKerberosScheme"");
            return new DelegatingKerberosScheme(stripPort, isStripPort());
        }
        
---------------Reference log start----------------
log.debug(""Use KerberosScheme"")
---------------Reference log end----------------
        return new KerberosScheme(stripPort, isUseCanonicalHostname());
    }",,
jmeter,14438,"log.info(""setRunning({}, {})"", running, host)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/util/JMeterMenuBar.java/#L604,"public void setRunning(boolean running, String host) {
        
---------------Reference log start----------------
log.info(""setRunning({}, {})"", running, host)
---------------Reference log end----------------
        if (org.apache.jmeter.gui.MainFrame.LOCAL.equals(host)) {
            return;
        }
        Iterator<JMenuItem> iter = remoteEngineStart.iterator();
        Iterator<JMenuItem> iter2 = remoteEngineStop.iterator();
        Iterator<JMenuItem> iter3 = remoteEngineExit.iterator();
        Iterator<JMenuItem> iter4 = remoteEngineShut.iterator();
        while (iter.hasNext() && iter2.hasNext() && iter3.hasNext() &&iter4.hasNext()) {
            JMenuItem start = iter.next();
            JMenuItem stop = iter2.next();
            JMenuItem exit = iter3.next();
            JMenuItem shut = iter4.next();
            if (start.getText().equals(host)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Found start host: {}"", start.getText());
                }
                start.setEnabled(!running);
            }
            if (stop.getText().equals(host)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Found stop  host: {}"", stop.getText());
                }
                stop.setEnabled(running);
            }
            if (exit.getText().equals(host)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Found exit  host: {}"", exit.getText());
                }
                exit.setEnabled(true);
            }
            if (shut.getText().equals(host)) {
                if (log.isDebugEnabled()) {
                    log.debug(""Found shut  host: {}"", exit.getText());
                }
                shut.setEnabled(running);
            }
        }
    }",,
jmeter,13511,"log.error(""Could not initialise key store"", e)",error,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/ProxyControl.java/#L525,"public void startProxy() throws IOException {
        try {
            initKeyStore();
        } catch (GeneralSecurityException e) {
            
---------------Reference log start----------------
log.error(""Could not initialise key store"", e)
---------------Reference log end----------------
            throw new IOException(""Could not create keystore"", e);
        } catch (IOException e) { // make sure we log the error
            log.error(""Could not initialise key store"", e);
            throw e;
        }
        sampleWorkerTimer = new javax.swing.Timer(200, this::putSamplesIntoModel);
        sampleWorkerTimer.start();
        notifyTestListenersOfStart();
        try {
            server = new Daemon(getPort(), this);
            if (getProxyPauseHTTPSample().isEmpty()) {
                sampleGap = JMeterUtils.getPropDefault(""proxy.pause"", 5000);
            } else {
                sampleGap = Long.parseLong(getProxyPauseHTTPSample().trim());
            }
            server.start();
            if (GuiPackage.getInstance() != null) {
                GuiPackage.getInstance().register(server);
            }
        } catch (IOException e) {
            log.error(""Could not create HTTP(S) Test Script Recorder Proxy daemon"", e);
            throw e;
        }
    }",,
jmeter,14475,"LOGGER.debug(""SystemCommand ran: {}  returned: {}"", generationCommand, resultCode)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/HtmlReportGenerator.java/#L103,"public List<String> run() {
        List<String> errorMessageList = new ArrayList<>();
        errorMessageList.addAll(checkArguments());
        if (!errorMessageList.isEmpty()) {
            return errorMessageList;
        }

        ByteArrayOutputStream commandExecutionOutput = new ByteArrayOutputStream();
        int resultCode = -1;
        List<String> generationCommand = createGenerationCommand();
        try {
            SystemCommand sc = new SystemCommand(
                    new File(JMeterUtils.getJMeterBinDir()),
                    COMMAND_TIMEOUT,
                    100,
                    null,
                    null,
                    commandExecutionOutput,
                    null);
            LOGGER.debug(""Running report generation"");
            resultCode = sc.run(generationCommand);
            if (resultCode != 0) {
                errorMessageList.add(commandExecutionOutput.toString());
                LOGGER.info(""The HTML report generation failed and returned: {}"", commandExecutionOutput);
                return errorMessageList;
            }
        } catch (TimeoutException e) {
            errorMessageList.add(MessageFormat.format(JMeterUtils.getResString(""generate_report_ui.html_report_timeout_error""),
                    COMMAND_TIMEOUT, e.getMessage(), commandExecutionOutput));
            LOGGER.error(""Report generation took more time than configured timeout (Property {}={}, command output=[{}])"",
                    ""generate_report_ui.generation_timeout"", COMMAND_TIMEOUT, commandExecutionOutput, e);
        } catch (InterruptedException | IOException e) {
            errorMessageList.add(MessageFormat.format(JMeterUtils.getResString(""generate_report_ui.html_report_unknown_error""),
                    e.getMessage(), commandExecutionOutput));
            LOGGER.error(""Error during HTML report generation, executing {}"", commandExecutionOutput, e);
            if (e instanceof InterruptedException) {
                Thread.currentThread().interrupt();
            }
        }
        
---------------Reference log start----------------
LOGGER.debug(""SystemCommand ran: {}  returned: {}"", generationCommand, resultCode)
---------------Reference log end----------------
        return errorMessageList;
    }",,
jmeter,14790,"log.warn(""Backing engine is null, ignoring reset"")",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/RemoteJMeterEngineImpl.java/#L172,"@Override
    public void rreset() throws RemoteException {
        // Mail on userlist reported NPE here - looks like only happens if there are network errors, but check anyway
        if (backingEngine != null) {
            log.info(""Reset"");
            checkOwner(""reset"");
            backingEngine.reset();
        } else {
            
---------------Reference log start----------------
log.warn(""Backing engine is null, ignoring reset"")
---------------Reference log end----------------
        }
    }",,
jmeter,14262,"log.debug(""{} saving variable: {}={}"", Thread.currentThread().getName(), name, value)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/modifiers/UserParameters.java/#L158,"@SuppressWarnings(""SynchronizeOnNonFinalField"")
    private void setValues() {
        synchronized (lock) {
            if (log.isDebugEnabled()) {
                log.debug(""{} Running up named: {}"", Thread.currentThread().getName(), getName());//$NON-NLS-1$
            }
            PropertyIterator namesIter = getNames().iterator();
            PropertyIterator valueIter = getValues().iterator();
            JMeterVariables jmvars = getThreadContext().getVariables();
            while (namesIter.hasNext() && valueIter.hasNext()) {
                String name = namesIter.next().getStringValue();
                String value = valueIter.next().getStringValue();
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""{} saving variable: {}={}"", Thread.currentThread().getName(), name, value)
---------------Reference log end----------------
                }
                jmvars.put(name, value);
            }
        }
    }",,
jmeter,15113,"log.debug(""Applying TIMER_FACTOR:{} on timer:{} for thread:{}"", TIMER_FACTOR, ((TestElement) timer).getName(), getThreadName())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/threads/JMeterThread.java/#L985,"private void delay(List<Timer> timers) {
        long totalDelay = 0;
        for (Timer timer : timers) {
            TestBeanHelper.prepare((TestElement) timer);
            long delay = timer.delay();
            if (APPLY_TIMER_FACTOR && timer.isModifiable()) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""Applying TIMER_FACTOR:{} on timer:{} for thread:{}"", TIMER_FACTOR, ((TestElement) timer).getName(), getThreadName())
---------------Reference log end----------------
                }
                delay = Math.round(delay * TIMER_FACTOR);
            }
            totalDelay += delay;
        }
        if (totalDelay > 0) {
            try {
                if (scheduler) {
                    // We reduce pause to ensure end of test is not delayed by a sleep ending after test scheduled end
                    // See Bug 60049
                    totalDelay = TIMER_SERVICE.adjustDelay(totalDelay, endTime, false);
                    if (totalDelay < 0) {
                        log.debug(""The delay would be longer than the scheduled period, so stop thread now."");
                        running = false;
                        return;
                    }
                }
                TimeUnit.MILLISECONDS.sleep(totalDelay);
            } catch (InterruptedException e) {
                log.warn(""The delay timer was interrupted - probably did not wait as long as intended."");
                Thread.currentThread().interrupt();
            }
        }
    }",,
jmeter,14157,"log.debug(""Getting message number: {} of {}"", pos, subResults.length)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/SMIMEAssertion.java/#L89,"public static AssertionResult getResult(SMIMEAssertionTestElement testElement, SampleResult response, String name) {
        checkForBouncycastle();
        AssertionResult res = new AssertionResult(name);
        try {
            MimeMessage msg;
            final int msgPos = testElement.getSpecificMessagePositionAsInt();
            if (msgPos < 0){ // means counting from end
                SampleResult[] subResults = response.getSubResults();
                final int pos = subResults.length + msgPos;
                
---------------Reference log start----------------
log.debug(""Getting message number: {} of {}"", pos, subResults.length)
---------------Reference log end----------------
                msg = getMessageFromResponse(response,pos);
            } else {
                log.debug(""Getting message number: {}"", msgPos);
                msg = getMessageFromResponse(response, msgPos);
            }

            SMIMESignedParser signedParser = null;
            if(log.isDebugEnabled()) {
                log.debug(""Content-type: {}"", msg.getContentType());
            }
            if (msg.isMimeType(""multipart/signed"")) { // $NON-NLS-1$
                MimeMultipart multipart = (MimeMultipart) msg.getContent();
                signedParser = new SMIMESignedParser(new BcDigestCalculatorProvider(), multipart);
            } else if (msg.isMimeType(""application/pkcs7-mime"") // $NON-NLS-1$
                    || msg.isMimeType(""application/x-pkcs7-mime"")) { // $NON-NLS-1$
                signedParser = new SMIMESignedParser(new BcDigestCalculatorProvider(), msg);
            }

            if (null != signedParser) {
                log.debug(""Found signature"");

                if (testElement.isNotSigned()) {
                    res.setFailure(true);
                    res.setFailureMessage(""Mime message is signed"");
                } else if (testElement.isVerifySignature() || !testElement.isSignerNoCheck()) {
                    res = verifySignature(testElement, signedParser, name);
                }

            } else {
                log.debug(""Did not find signature"");
                if (!testElement.isNotSigned()) {
                    res.setFailure(true);
                    res.setFailureMessage(""Mime message is not signed"");
                }
            }

        } catch (MessagingException e) {
            String msg = ""Cannot parse mime msg: "" + e.getMessage();
            log.warn(msg, e);
            res.setFailure(true);
            res.setFailureMessage(msg);
        } catch (CMSException e) {
            res.setFailure(true);
            res.setFailureMessage(""Error reading the signature: ""
                    + e.getMessage());
        } catch (SMIMEException e) {
            res.setFailure(true);
            res.setFailureMessage(""Cannot extract signed body part from signature: ""
                    + e.getMessage());
        } catch (IOException e) { // should never happen
            log.error(""Cannot read mime message content: {}"", e.getMessage(), e);
            res.setError(true);
            res.setFailureMessage(e.getMessage());
        }

        return res;
    }",,
jmeter,14391,"log.error(""Drop file failed"", e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/tree/JMeterTreeTransferHandler.java/#L210,"@Override
    @SuppressWarnings(""JdkObsolete"")
    public boolean importData(TransferHandler.TransferSupport support) {
        if (!canImport(support)) {
            return false;
        }

        // deal with the jmx files
        GuiPackage guiInstance = GuiPackage.getInstance();
        DataFlavor[] flavors = support.getDataFlavors();
        Transferable t = support.getTransferable();
        for (DataFlavor flavor : flavors) {
            // Check for file lists specifically
            if (flavor.isFlavorJavaFileListType()) {
                try {
                    return guiInstance.getMainFrame().openJmxFilesFromDragAndDrop(t);
                }
                catch (Exception e) {
                    
---------------Reference log start----------------
log.error(""Drop file failed"", e)
---------------Reference log end----------------
                }
                return false;
            }
        }

        // Extract transfer data.
        JMeterTreeNode[] nodes = getDraggedNodes(t);

        if(nodes == null || nodes.length == 0) {
            return false;
        }

        // Get drop location and mode
        JTree.DropLocation dl = (JTree.DropLocation) support.getDropLocation();
        TreePath dest = dl.getPath();
        JMeterTreeNode target = (JMeterTreeNode) dest.getLastPathComponent();

        nodesForRemoval = new ArrayList<>();
        int index = dl.getChildIndex();
        TreePath[] pathsToSelect = new TreePath[nodes.length];
        int pathPosition = 0;
        JMeterTreeModel treeModel = guiInstance.getTreeModel();
        for (JMeterTreeNode node : nodes) {

            if (index == -1) { // drop mode == DropMode.ON
                index = target.getChildCount();
            }

            // Insert a clone of the node, the original one will be removed by the exportDone method
            // the children are not cloned but moved to the cloned node
            // working on the original node would be harder as
            //    you'll have to deal with the insertion index offset if you re-order a node inside a parent
            JMeterTreeNode copy = (JMeterTreeNode) node.clone();

            // first copy the children as the call to copy.add will modify the collection we're iterating on
            Enumeration<?> enumFrom = node.children();
            List<JMeterTreeNode> tmp = new ArrayList<>();
            while (enumFrom.hasMoreElements()) {
                JMeterTreeNode child = (JMeterTreeNode) enumFrom.nextElement();
                tmp.add(child);
            }

            for (JMeterTreeNode jMeterTreeNode : tmp) {
                copy.add(jMeterTreeNode);
            }
            treeModel.insertNodeInto(copy, target, index++);
            nodesForRemoval.add(node);
            pathsToSelect[pathPosition++] = new TreePath(treeModel.getPathToRoot(copy));
        }

        TreePath treePath = new TreePath(target.getPath());
        // expand the destination node
        JTree tree = (JTree) support.getComponent();
        tree.expandPath(treePath);
        tree.setSelectionPaths(pathsToSelect);
        return true;
    }",,
jmeter,13681,"log.debug(""    {}={}"", lValue.getHeader(i).getName(), lValue.getHeader(i).getValue())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L934,"public void setHeaderManager(final HeaderManager value) {
        HeaderManager mgr = getHeaderManager();
        HeaderManager lValue = value;
        if (mgr != null) {
            lValue = mgr.merge(value);
            if (log.isDebugEnabled()) {
                log.debug(""Existing HeaderManager '{}' merged with '{}'"", mgr.getName(), lValue.getName());
                for (int i = 0; i < lValue.getHeaders().size(); i++) {
                    
---------------Reference log start----------------
log.debug(""    {}={}"", lValue.getHeader(i).getName(), lValue.getHeader(i).getValue())
---------------Reference log end----------------
                }
            }
        }
        setProperty(new TestElementProperty(HEADER_MANAGER, lValue));
    }",,
jmeter,14776,"log.info(""Starting backing engine on {}"", this.rmiRegistryPort)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/RemoteJMeterEngineImpl.java/#L82,"private void init() throws RemoteException {
        
---------------Reference log start----------------
log.info(""Starting backing engine on {}"", this.rmiRegistryPort)
---------------Reference log end----------------
        InetAddress localHost = RmiUtils.getRmiHost();
        if (localHost.isSiteLocalAddress()){
            // should perhaps be log.warn, but this causes the client-server test to fail
            log.info(""IP address is a site-local address; this may cause problems with remote access.\n""
                    + ""\tCan be overridden by defining the system property 'java.rmi.server.hostname' - see jmeter-server script file"");
        }
        log.debug(""This = {}"", this);
        Registry reg = null;
        if (CREATE_SERVER){
            log.info(""Creating RMI registry (server.rmi.create=true)"");
            try {
                reg = LocateRegistry.createRegistry(this.rmiRegistryPort,
                        RmiUtils.createClientSocketFactory(),
                        RmiUtils.createServerSocketFactory());
                log.debug(""Created registry: {}"", reg);
            } catch (RemoteException e){
                String msg=""Problem creating registry: ""+e;
                log.warn(msg);
                System.err.println(msg);
                System.err.println(""Continuing..."");
            }
        }
        try {
            if (reg == null) {
                log.debug(""Locating registry"");
                reg = LocateRegistry.getRegistry(
                        RmiUtils.getRmiHost().getHostName(),
                        this.rmiRegistryPort,
                        RmiUtils.createClientSocketFactory());
            }
            log.debug(""About to rebind registry: {}"", reg);
            reg.rebind(JMETER_ENGINE_RMI_NAME, this);
            log.info(""Bound to RMI registry on port {}"", this.rmiRegistryPort);
        } catch (Exception ex) {
            log.error(""rmiregistry needs to be running to start JMeter in server mode. {}"", ex.toString());
            // Throw an Exception to ensure caller knows ...
            throw new RemoteException(""Cannot start. See server log file."", ex);
        }
    }",,
jmeter,14544,"log.debug(""setCondition({})"", string)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/control/WhileController.java/#L132,"public void setCondition(String string) {
        
---------------Reference log start----------------
log.debug(""setCondition({})"", string)
---------------Reference log end----------------
        setProperty(new StringProperty(CONDITION, string));
    }",,
jmeter,14765,"log.warn(""About to run System.exit(0) on {}"", host)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/StandardJMeterEngine.java/#L565,"@Override
    public void exit() {
        ClientJMeterEngine.tidyRMI(log); // This should be enough to allow server to exit.
        if (REMOTE_SYSTEM_EXIT) { // default is false
            
---------------Reference log start----------------
log.warn(""About to run System.exit(0) on {}"", host)
---------------Reference log end----------------
            // Needs to be run in a separate thread to allow RMI call to return OK
            Thread t = new Thread() {
                @Override
                public void run() {
                    pause(1000); // Allow RMI to complete
                    log.info(""Bye from {}"", host);
                    System.out.println(""Bye from ""+host); // NOSONAR Intentional
                    System.exit(0); // NOSONAR Intentional
                }
            };
            t.start();
        }
    }",,
jmeter,13682,"log.warn(""Existing CookieManager {} superseded by {}"", mgr.getName(), value.getName())",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L954,"public void setCookieManager(CookieManager value) {
        CookieManager mgr = getCookieManager();
        if (mgr != null) {
            if(log.isWarnEnabled()) {
                
---------------Reference log start----------------
log.warn(""Existing CookieManager {} superseded by {}"", mgr.getName(), value.getName())
---------------Reference log end----------------
            }
        }
        setCookieManagerProperty(value);
    }",,
jmeter,13672,"log.debug(""End : sample"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPJavaImpl.java/#L643,"@Override
    protected HTTPSampleResult sample(URL url, String method, boolean areFollowingRedirect, int frameDepth) {
        HttpURLConnection conn = null;

        String urlStr = url.toString();
        if (log.isDebugEnabled()) {
            log.debug(""Start : sample {}, method {}, followingRedirect {}, depth {}"",
                    urlStr, method, areFollowingRedirect, frameDepth);
        }

        HTTPSampleResult res = new HTTPSampleResult();
        configureSampleLabel(res, url);
        res.setURL(url);
        res.setHTTPMethod(method);

        res.sampleStart(); // Count the retries as well in the time

        // Check cache for an entry with an Expires header in the future
        final CacheManager cacheManager = getCacheManager();
        if (cacheManager != null && HTTPConstants.GET.equalsIgnoreCase(method)) {
           if (cacheManager.inCache(url, getHeaders(getHeaderManager()))) {
               return updateSampleResultForResourceInCache(res);
           }
        }

        try {
            // Sampling proper - establish the connection and read the response:
            // Repeatedly try to connect:
            int retry = -1;
            // Start with -1 so tries at least once, and retries at most MAX_CONN_RETRIES times
            for (; retry < MAX_CONN_RETRIES; retry++) {
                try {
                    conn = setupConnection(url, method, res);
                    // Attempt the connection:
                    savedConn = conn;
                    conn.connect();
                    break;
                } catch (BindException e) {
                    if (retry >= MAX_CONN_RETRIES) {
                        log.error(""Can't connect after {} retries, message: {}"", retry, e.toString());
                        throw e;
                    }
                    log.debug(""Bind exception, try again"");
                    if (conn!=null) {
                        savedConn = null; // we don't want interrupt to try disconnection again
                        conn.disconnect();
                    }
                    setUseKeepAlive(false);
                } catch (IOException e) {
                    log.debug(""Connection failed, giving up"");
                    throw e;
                }
            }
            if (retry > MAX_CONN_RETRIES) {
                // This should never happen, but...
                throw new BindException();
            }
            // Nice, we've got a connection. Finish sending the request:
            if (method.equals(HTTPConstants.POST)) {
                String postBody = sendPostData(conn);
                res.setQueryString(postBody);
            } else if (method.equals(HTTPConstants.PUT)) {
                String putBody = sendPutData(conn);
                res.setQueryString(putBody);
            }
            // Request sent. Now get the response:
            byte[] responseData = readResponse(conn, res);

            res.sampleEnd();
            // Done with the sampling proper.

            // Now collect the results into the HTTPSampleResult:

            res.setResponseData(responseData);

            int errorLevel = conn.getResponseCode();
            String respMsg = conn.getResponseMessage();
            String hdr=conn.getHeaderField(0);
            if (hdr == null) {
                hdr=""(null)"";  // $NON-NLS-1$
            }
            if (errorLevel == -1){// Bug 38902 - sometimes -1 seems to be returned unnecessarily
                if (respMsg != null) {// Bug 41902 - NPE
                    try {
                        errorLevel = Integer.parseInt(respMsg.substring(0, 3));
                        log.warn(""ResponseCode==-1; parsed {} as {}"", respMsg, errorLevel);
                      } catch (NumberFormatException e) {
                        log.warn(""ResponseCode==-1; could not parse {} hdr: {}"", respMsg, hdr);
                      }
                } else {
                    respMsg=hdr; // for result
                    log.warn(""ResponseCode==-1 & null ResponseMessage. Header(0)= {} "", hdr);
                }
            }
            if (errorLevel == -1) {
                res.setResponseCode(""(null)""); // $NON-NLS-1$
            } else {
                res.setResponseCode(Integer.toString(errorLevel));
            }
            res.setSuccessful(isSuccessCode(errorLevel));

            if (respMsg == null) {// has been seen in a redirect
                respMsg=hdr; // use header (if possible) if no message found
            }
            res.setResponseMessage(respMsg);

            String ct = conn.getContentType();
            if (ct != null){
                res.setContentType(ct);// e.g. text/html; charset=ISO-8859-1
                res.setEncodingAndType(ct);
            }

            String responseHeaders = getResponseHeaders(conn);
            res.setResponseHeaders(responseHeaders);
            if (res.isRedirect()) {
                res.setRedirectLocation(conn.getHeaderField(HTTPConstants.HEADER_LOCATION));
            }

            // record headers size to allow HTTPSampleResult.getBytes() with different options
            res.setHeadersSize(responseHeaders.replaceAll(""\n"", ""\r\n"") // $NON-NLS-1$ $NON-NLS-2$
                    .length() + 2); // add 2 for a '\r\n' at end of headers (before data)
            if (log.isDebugEnabled()) {
                log.debug(""Response headersSize={}, bodySize={}, Total={}"",
                        res.getHeadersSize(),  res.getBodySizeAsLong(),
                        res.getHeadersSize() + res.getBodySizeAsLong());
            }

            // If we redirected automatically, the URL may have changed
            if (getAutoRedirects()){
                res.setURL(conn.getURL());
            }

            // Store any cookies received in the cookie manager:
            saveConnectionCookies(conn, url, getCookieManager());

            // Save cache information
            if (cacheManager != null){
                cacheManager.saveDetails(conn, res);
            }

            res = resultProcessing(areFollowingRedirect, frameDepth, res);

            
---------------Reference log start----------------
log.debug(""End : sample"")
---------------Reference log end----------------
            return res;
        } catch (IOException e) {
            if (res.getEndTime() == 0) {
                res.sampleEnd();
            }
            savedConn = null; // we don't want interrupt to try disconnection again
            // We don't want to continue using this connection, even if KeepAlive is set
            if (conn != null) { // May not exist
                conn.disconnect();
            }
            conn=null; // Don't process again
            return errorResult(e, res);
        } finally {
            // calling disconnect doesn't close the connection immediately,
            // but indicates we're through with it. The JVM should close
            // it when necessary.
            savedConn = null; // we don't want interrupt to try disconnection again
            disconnect(conn); // Disconnect unless using KeepAlive
        }
    }",,
jmeter,14732,"log.info(""Disabling SSL for RMI as server.rmi.ssl.disable is set to 'true'"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/rmi/RmiUtils.java/#L85,"public static RMIClientSocketFactory createClientSocketFactory() {
        if (SSL_DISABLED) {
            
---------------Reference log start----------------
log.info(""Disabling SSL for RMI as server.rmi.ssl.disable is set to 'true'"")
---------------Reference log end----------------
            return null;
        }
        if (StringUtils.isBlank(KEYSTORE_FILE)) {
            Validate.validState(SSL_DISABLED,
                    ""No keystore for RMI over SSL specified. Set 'server.rmi.ssl.disable' to true, if this is intentional,""
                    + ""if not run create-rmi-keystore.bat/create-rmi-keystore.sh to create a keystore and distribute it on client and servers""
                    + ""used for distributed testing."");
            return null;
        }
        final SSLRMIClientSocketFactory factory = new SSLRMIClientSocketFactory();
        factory.setAlias(KEYSTORE_ALIAS);
        factory.setKeystore(KEYSTORE_FILE, KEYSTORE_TYPE, KEYSTORE_PASSWORD);
        factory.setTruststore(TRUSTSTORE_FILE, TRUSTSTORE_TYPE, TRUSTSTORE_PASSWORD);
        return factory;
    }",,
jmeter,13385,"log.debug(""Policy: {} Clear: {}"", getPolicy(), getClearEachIteration())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/CookieManager.java/#L409,"@Override
    public void testStarted() {
        initialCookies = getCookies();
        try {
            cookieHandler = (CookieHandler) ClassTools.construct(getImplementation(), getPolicy());
        } catch (JMeterException e) {
            log.error(""Unable to load or invoke class: {}"", getImplementation(), e);
        }
        if (log.isDebugEnabled()){
            
---------------Reference log start----------------
log.debug(""Policy: {} Clear: {}"", getPolicy(), getClearEachIteration())
---------------Reference log end----------------
        }
    }",,
jmeter,14756,"log.info(""Starting tearDown ThreadGroup: {} : {}"", groupCount, groupName)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/StandardJMeterEngine.java/#L483,"@Override
    public void run() {
        log.info(""Running the test!"");
        running = true;

        /*
         * Ensure that the sample variables are correctly initialised for each run.
         */
        SampleEvent.initSampleVariables();

        JMeterContextService.startTest();
        try {
            PreCompiler compiler = new PreCompiler();
            test.traverse(compiler);
        } catch (RuntimeException e) {
            log.error(""Error occurred compiling the tree:"",e);
            JMeterUtils.reportErrorToUser(""Error occurred compiling the tree: - see log file"", e);
            return; // no point continuing
        }
        /**
         * Notification of test listeners needs to happen after function
         * replacement, but before setting RunningVersion to true.
         */
        SearchByClass<TestStateListener> testListeners = new SearchByClass<>(TestStateListener.class); // TL - S&E
        test.traverse(testListeners);

        // Merge in any additional test listeners
        // currently only used by the function parser
        testListeners.getSearchResults().addAll(testList);
        testList.clear(); // no longer needed

        test.traverse(new TurnElementsOn());
        notifyTestListenersOfStart(testListeners);

        List<?> testLevelElements = new ArrayList<>(test.list(test.getArray()[0]));
        removeThreadGroups(testLevelElements);

        SearchByClass<SetupThreadGroup> setupSearcher = new SearchByClass<>(SetupThreadGroup.class);
        SearchByClass<AbstractThreadGroup> searcher = new SearchByClass<>(AbstractThreadGroup.class);
        SearchByClass<PostThreadGroup> postSearcher = new SearchByClass<>(PostThreadGroup.class);

        test.traverse(setupSearcher);
        test.traverse(searcher);
        test.traverse(postSearcher);

        TestCompiler.initialize();
        // for each thread group, generate threads
        // hand each thread the sampler controller
        // and the listeners, and the timer
        Iterator<SetupThreadGroup> setupIter = setupSearcher.getSearchResults().iterator();
        Iterator<AbstractThreadGroup> iter = searcher.getSearchResults().iterator();
        Iterator<PostThreadGroup> postIter = postSearcher.getSearchResults().iterator();

        ListenerNotifier notifier = new ListenerNotifier();

        int groupCount = 0;
        JMeterContextService.clearTotalThreads();

        if (setupIter.hasNext()) {
            log.info(""Starting setUp thread groups"");
            while (running && setupIter.hasNext()) {//for each setup thread group
                AbstractThreadGroup group = setupIter.next();
                groupCount++;
                String groupName = group.getName();
                log.info(""Starting setUp ThreadGroup: {} : {} "", groupCount, groupName);
                startThreadGroup(group, groupCount, setupSearcher, testLevelElements, notifier);
                if (serialized && setupIter.hasNext()) {
                    log.info(""Waiting for setup thread group: {} to finish before starting next setup group"",
                            groupName);
                    group.waitThreadsStopped();
                }
            }
            log.info(""Waiting for all setup thread groups to exit"");
            //wait for all Setup Threads To Exit
            waitThreadsStopped();
            log.info(""All Setup Threads have ended"");
            groupCount=0;
            JMeterContextService.clearTotalThreads();
        }

        groups.clear(); // The groups have all completed now

        /*
         * Here's where the test really starts. Run a Full GC now: it's no harm
         * at all (just delays test start by a tiny amount) and hitting one too
         * early in the test can impair results for short tests.
         */
        JMeterUtils.helpGC();

        JMeterContextService.getContext().setSamplingStarted(true);
        boolean mainGroups = running; // still running at this point, i.e. setUp was not cancelled
        while (running && iter.hasNext()) {// for each thread group
            AbstractThreadGroup group = iter.next();
            //ignore Setup and Post here.  We could have filtered the searcher. but then
            //future Thread Group objects wouldn't execute.
            if (group instanceof SetupThreadGroup ||
                    group instanceof PostThreadGroup) {
                continue;
            }
            groupCount++;
            String groupName = group.getName();
            log.info(""Starting ThreadGroup: {} : {}"", groupCount, groupName);
            startThreadGroup(group, groupCount, searcher, testLevelElements, notifier);
            if (serialized && iter.hasNext()) {
                log.info(""Waiting for thread group: {} to finish before starting next group"", groupName);
                group.waitThreadsStopped();
            }
        } // end of thread groups
        if (groupCount == 0){ // No TGs found
            log.info(""No enabled thread groups found"");
        } else {
            if (running) {
                log.info(""All thread groups have been started"");
            } else {
                log.info(""Test stopped - no more thread groups will be started"");
            }
        }

        //wait for all Test Threads To Exit
        waitThreadsStopped();
        groups.clear(); // The groups have all completed now

        if (postIter.hasNext()){
            groupCount = 0;
            JMeterContextService.clearTotalThreads();
            log.info(""Starting tearDown thread groups"");
            if (mainGroups && !running) { // i.e. shutdown/stopped during main thread groups
                running = tearDownOnShutdown; // re-enable for tearDown if necessary
            }
            while (running && postIter.hasNext()) {//for each setup thread group
                AbstractThreadGroup group = postIter.next();
                groupCount++;
                String groupName = group.getName();
                
---------------Reference log start----------------
log.info(""Starting tearDown ThreadGroup: {} : {}"", groupCount, groupName)
---------------Reference log end----------------
                startThreadGroup(group, groupCount, postSearcher, testLevelElements, notifier);
                if (serialized && postIter.hasNext()) {
                    log.info(""Waiting for post thread group: {} to finish before starting next post group"", groupName);
                    group.waitThreadsStopped();
                }
            }
            waitThreadsStopped(); // wait for Post threads to stop
        }

        notifyTestListenersOfEnd(testListeners);
        JMeterContextService.endTest();
        if (JMeter.isNonGUI() && SYSTEM_EXIT_FORCED) {
            log.info(""Forced JVM shutdown requested at end of test"");
            System.exit(0); // NOSONAR Intentional
        }
    }",,
jmeter,14388,"log.warn(""Error awt title: {}"", nsfe.toString())",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/MainFrame.java/#L916,"private void setWindowTitle() {
        Class<?> xtoolkit = Toolkit.getDefaultToolkit().getClass();
        if (xtoolkit.getName().equals(""sun.awt.X11.XToolkit"")) { // NOSONAR (we don't want to depend on native LAF) $NON-NLS-1$
            try {
                final Field awtAppClassName = xtoolkit.getDeclaredField(""awtAppClassName""); // $NON-NLS-1$
                awtAppClassName.setAccessible(true);
                awtAppClassName.set(null, DEFAULT_APP_NAME);
            } catch (NoSuchFieldException | IllegalAccessException nsfe) {
                if (log.isWarnEnabled()) {
                    
---------------Reference log start----------------
log.warn(""Error awt title: {}"", nsfe.toString())
---------------Reference log end----------------
                }
            }
        }
    }",,
jmeter,13261,"log.error(""Format date pattern '{}' is invalid (see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html)"", format, // $NON-NLS-1$
ex)",error,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/RandomDate.java/#L159,"@Override
    public String execute(SampleResult previousResult, Sampler currentSampler) throws InvalidVariableException {
        DateTimeFormatter formatter;
        if(values.length>3) {
            String localeAsString = values[3].execute().trim();
            if (!localeAsString.trim().isEmpty()) {
                locale = LocaleUtils.toLocale(localeAsString);
            }
        }

        String format = values[0].execute().trim();
        if (!StringUtils.isEmpty(format)) {
            try {
                LocaleFormatObject lfo = new LocaleFormatObject(format, locale);
                formatter = dateRandomFormatterCache.get(lfo, key -> createFormatter((LocaleFormatObject) key));
            } catch (IllegalArgumentException ex) {
                log.error(
                        ""Format date pattern '{}' is invalid (see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html)"",
                        format, ex); // $NON-NLS-1$
                return """";
            }
        } else {
            try {
                LocaleFormatObject lfo = new LocaleFormatObject(""yyyy-MM-dd"", locale);
                formatter = dateRandomFormatterCache.get(lfo, key -> createFormatter((LocaleFormatObject) key));
            } catch (IllegalArgumentException ex) {
                
---------------Reference log start----------------
log.error(""Format date pattern '{}' is invalid (see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html)"", format, // $NON-NLS-1$
ex)
---------------Reference log end----------------
                return """";
            }
        }

        String dateStart = values[1].execute().trim();
        long localStartDate = 0;
        if (!dateStart.isEmpty()) {
            try {
                localStartDate = LocalDate.parse(dateStart, formatter).toEpochDay();
            } catch (DateTimeParseException | NumberFormatException ex) {
                log.error(""Failed to parse Start Date '{}'"", dateStart, ex); // $NON-NLS-1$
            }
        } else {
            try {
                localStartDate = LocalDate.now(systemDefaultZoneID).toEpochDay();
            } catch (DateTimeParseException | NumberFormatException ex) {
                log.error(""Failed to create current date '{}'"", dateStart, ex); // $NON-NLS-1$
            }
        }
        long localEndDate = 0;
        String dateEnd = values[2].execute().trim();
        try {
            localEndDate = LocalDate.parse(dateEnd, formatter).toEpochDay();
        } catch (DateTimeParseException | NumberFormatException ex) {
            log.error(""Failed to parse End date '{}'"", dateEnd, ex); // $NON-NLS-1$
        }

        // Generate the random date
        String dateString = """";
        if (localEndDate < localStartDate) {
            log.error(""End Date '{}' must be greater than Start Date '{}'"", dateEnd, dateStart); // $NON-NLS-1$
        } else {
            long randomDay = ThreadLocalRandom.current().nextLong(localStartDate, localEndDate);
            try {
                dateString = LocalDate.ofEpochDay(randomDay).format(formatter);
            } catch (DateTimeParseException | NumberFormatException ex) {
                log.error(""Failed to generate random date '{}'"", randomDay, ex); // $NON-NLS-1$
            }
            addVariableValue(dateString, values, 4);
        }
        return dateString;
    }",,
jmeter,15052,"log.error(""Problem starting BeanShell server"", e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/BeanShellServer.java/#L107,"@Override
    public void run() {

        ClassLoader loader = Thread.currentThread().getContextClassLoader();

        try {
            Class<?> interpreter = loader.loadClass(""bsh.Interpreter"");//$NON-NLS-1$
            Object instance = interpreter.getDeclaredConstructor().newInstance();
            Class<String> string = String.class;
            Class<Object> object = Object.class;

            Method eval = interpreter.getMethod(""eval"", string);//$NON-NLS-1$
            Method setObj = interpreter.getMethod(""set"", string, object);//$NON-NLS-1$
            Method setInt = interpreter.getMethod(""set"", string, int.class);//$NON-NLS-1$
            Method source = interpreter.getMethod(""source"", string);//$NON-NLS-1$

            setObj.invoke(instance, ""t"", this );//$NON-NLS-1$
            setInt.invoke(instance, ""portnum"", serverport);//$NON-NLS-1$

            if (serverfile.length() > 0) {
                try {
                    source.invoke(instance, serverfile);
                } catch (InvocationTargetException ite) {
                    Throwable cause = ite.getCause();
                    if (log.isWarnEnabled()) {
                        log.warn(""Could not source, {}. {}"", serverfile,
                                (cause != null) ? cause.toString() : ite.toString());
                    }
                    if (cause instanceof Error) {
                        throw (Error) cause;
                    }
                }
            }
            eval.invoke(instance, ""setAccessibility(true);"");//$NON-NLS-1$
            eval.invoke(instance, ""server(portnum);"");//$NON-NLS-1$

        } catch (ClassNotFoundException e) {
            log.error(""Beanshell Interpreter not found"");
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(""Problem starting BeanShell server"", e)
---------------Reference log end----------------
        }
    }",,
jmeter,14231,"log.debug(""Input = '{}'"", inputString)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/extractor/RegexExtractor.java/#L179,"private String getInputString(SampleResult result) {
        String inputString = useUrl() ? result.getUrlAsString() // Bug 39707
                : useHeaders() ? result.getResponseHeaders()
                : useRequestHeaders() ? result.getRequestHeaders()
                : useCode() ? result.getResponseCode() // Bug 43451
                : useMessage() ? result.getResponseMessage() // Bug 43451
                : useUnescapedBody() ? StringEscapeUtils.unescapeHtml4(result.getResponseDataAsString())
                : useBodyAsDocument() ? Document.getTextFromDocument(result.getResponseData())
                : result.getResponseDataAsString() // Bug 36898
                ;
       
---------------Reference log start----------------
log.debug(""Input = '{}'"", inputString)
---------------Reference log end----------------
       return inputString;
    }",,
jmeter,14717,"log.info(""Using StatisticalSampleSender for this run. {} config: Thresholds: num={}, time={}. Key uses ThreadName: {}"", isClientConfigured() ? ""Client"" : ""Server"", numSamplesThreshold, timeThresholdMs, keyOnThreadName)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/StatisticalSampleSender.java/#L215,"private Object readResolve() throws ObjectStreamException{
        if (isClientConfigured()) {
            numSamplesThreshold = clientConfiguredNumSamplesThreshold;
            timeThresholdMs = clientConfiguredTimeThresholdMs;
            keyOnThreadName = clientConfiguredKeyOnThreadName;
        } else {
            numSamplesThreshold = NUM_SAMPLES_THRESHOLD;
            timeThresholdMs = TIME_THRESHOLD_MS;
            keyOnThreadName = KEY_ON_THREADNAME;
        }
        if (log.isInfoEnabled()) {
            
---------------Reference log start----------------
log.info(""Using StatisticalSampleSender for this run. {} config: Thresholds: num={}, time={}. Key uses ThreadName: {}"", isClientConfigured() ? ""Client"" : ""Server"", numSamplesThreshold, timeThresholdMs, keyOnThreadName)
---------------Reference log end----------------
        }
        return this;
    }",,
jmeter,13247,"log.warn(""Bad file name format "", e)",warn,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/StringFromFile.java/#L205,"private synchronized void openFile() {
        String tn = Thread.currentThread().getName();
        fileName = ((CompoundVariable) values[0]).execute();

        String start = """";
        if (values.length >= PARAM_START) {
            start = ((CompoundVariable) values[PARAM_START - 1]).execute();
            try {
                // Low chances to be non numeric, we parse
                myStart = Integer.parseInt(start);
            } catch(NumberFormatException e) {
                myStart = COUNT_UNUSED;// Don't process invalid numbers
                log.warn(""Exception parsing {} as int, value will not be considered as Start Number sequence"", start);
            }
        }
        // Have we used myCurrent yet?
        // Set to 1 if start number is missing (to allow for end without start)
        if (myCurrent == COUNT_UNUSED) {
            myCurrent = myStart == COUNT_UNUSED ? 1 : myStart;
        }

        if (values.length >= PARAM_END) {
            String tmp = ((CompoundVariable) values[PARAM_END - 1]).execute();
            try {
                // Low chances to be non numeric, we parse
                myEnd = Integer.parseInt(tmp);
            } catch(NumberFormatException e) {
                myEnd = COUNT_UNUSED;// Don't process invalid numbers (including """")
                log.warn(""Exception parsing {} as int, value will not be considered as End Number sequence"", tmp);
            }
        }

        if (values.length >= PARAM_START) {
            if (log.isInfoEnabled()) {
                log.info(""{} Start = {} Current = {} End = {}"", tn, myStart, myCurrent, myEnd);//$NON-NLS-1$
            }
            if (myEnd != COUNT_UNUSED) {
                if (myCurrent > myEnd) {
                    if (log.isInfoEnabled()) {
                        log.info(""{} No more files to process, {} > {}"", tn, myCurrent, myEnd);//$NON-NLS-1$
                    }
                    myBread = null;
                    return;
                }
            }
            /*
             * DecimalFormat adds the number to the end of the format if there
             * are no formatting characters, so we need a way to prevent this
             * from messing up the file name.
             *
             */
            if (myStart != COUNT_UNUSED) // Only try to format if there is a
                                            // number
            {
                log.info(""{} using format {}"", tn, fileName);
                try {
                    DecimalFormat myFormatter = new DecimalFormat(fileName);
                    fileName = myFormatter.format(myCurrent);
                } catch (NumberFormatException e) {
                    
---------------Reference log start----------------
log.warn(""Bad file name format "", e)
---------------Reference log end----------------
                }
            }
            myCurrent++;// for next time
        }

        log.info(""{} opening file {}"", tn, fileName);//$NON-NLS-1$
        try {
            myBread = Files.newBufferedReader(Paths.get(fileName));
        } catch (Exception e) {
            log.error(""openFile() error: {}"", e.toString());//$NON-NLS-1$
            IOUtils.closeQuietly(myBread, null);
            myBread = null;
        }
    }",,
jmeter,14284,"slf4jLogger.debug(message, throwable)",debug,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/logging/Slf4jLogkitLogger.java/#L42,"@Override
    public void debug(String message, Throwable throwable) {
        
---------------Reference log start----------------
slf4jLogger.debug(message, throwable)
---------------Reference log end----------------
    }
    }",,
jmeter,14599,"log.debug(""End of data exporting"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/ReportGenerator.java/#L260,"public void generate() throws GenerationException {

        if (resultCollector != null) {
            log.info(""Flushing result collector before report Generation"");
            resultCollector.flushFile();
        }
        log.debug(""Start report generation"");

        File tmpDir = configuration.getTempDirectory();
        boolean tmpDirCreated = createTempDir(tmpDir);

        // Build consumers chain
        SampleContext sampleContext = new SampleContext();
        sampleContext.setWorkingDirectory(tmpDir);
        SampleSource source = new CsvFileSampleSource(testFile, CSV_DEFAULT_SEPARATOR);
        source.setSampleContext(sampleContext);

        NormalizerSampleConsumer normalizer = new NormalizerSampleConsumer();
        normalizer.setName(NORMALIZER_CONSUMER_NAME);

        FilterConsumer dateRangeConsumer = createFilterByDateRange();
        dateRangeConsumer.addSampleConsumer(createBeginDateConsumer());
        dateRangeConsumer.addSampleConsumer(createEndDateConsumer());

        FilterConsumer nameFilter = createNameFilter();

        FilterConsumer excludeControllerFilter = createExcludeControllerFilter();

        nameFilter.addSampleConsumer(excludeControllerFilter);

        dateRangeConsumer.addSampleConsumer(nameFilter);

        normalizer.addSampleConsumer(dateRangeConsumer);

        source.addSampleConsumer(normalizer);

        // Get graph configurations
        Map<String, GraphConfiguration> graphConfigurations = configuration
                .getGraphConfigurations();

        // Process configuration to build graph consumers
        for (Map.Entry<String, GraphConfiguration> entryGraphCfg : graphConfigurations.entrySet()) {
            addGraphConsumer(nameFilter, excludeControllerFilter, entryGraphCfg);
        }

        // Generate data
        log.debug(""Start samples processing"");
        try {
            source.run(); // NOSONAR
        } catch (SampleException ex) {
            throw new GenerationException(""Error while processing samples: "" + ex.getMessage(), ex);
        }
        log.debug(""End of samples processing"");

        log.debug(""Start data exporting"");

        // Process configuration to build data exporters
        String key;
        ExporterConfiguration value;
        for (Map.Entry<String, ExporterConfiguration> entry : configuration.getExportConfigurations().entrySet()) {
            key = entry.getKey();
            value = entry.getValue();
            if (log.isInfoEnabled()) {
                log.info(""Exporting data using exporter:'{}' of className:'{}'"", key, value.getClassName());
            }
            exportData(sampleContext, key, value);
        }

        
---------------Reference log start----------------
log.debug(""End of data exporting"")
---------------Reference log end----------------

        removeTempDir(tmpDir, tmpDirCreated);

        log.debug(""End of report generation"");
    }",,
jmeter,14221,"log.debug(""HtmlExtractor {}: processing result"", getName())",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/extractor/HtmlExtractor.java/#L79,"@Override
    public void process() {
        JMeterContext context = getThreadContext();
        SampleResult previousResult = context.getPreviousResult();
        if (previousResult == null) {
            return;
        }
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""HtmlExtractor {}: processing result"", getName())
---------------Reference log end----------------
        }
        // Fetch some variables
        JMeterVariables vars = context.getVariables();

        String refName = getRefName();
        String expression = getExpression();
        String attribute = getAttribute();
        int matchNumber = getMatchNumber();
        final String defaultValue = getDefaultValue();

        if (defaultValue.length() > 0  || isEmptyDefaultValue()) {
            // Only replace default if it is provided or empty default value is explicitly requested
            vars.put(refName, defaultValue);
        }

        try {
            List<String> matches =
                    extractMatchingStrings(vars, expression, attribute, matchNumber, previousResult);
            int prevCount = 0;
            String prevString = vars.get(refName + REF_MATCH_NR);
            if (prevString != null) {
                vars.remove(refName + REF_MATCH_NR);// ensure old value is not left defined
                try {
                    prevCount = Integer.parseInt(prevString);
                } catch (NumberFormatException nfe) {
                    if (log.isWarnEnabled()) {
                        log.warn(""{}: Could not parse number: '{}'."", getName(), prevString);
                    }
                }
            }
            int matchCount=0;// Number of refName_n variable sets to keep
            String match;
            if (matchNumber >= 0) {// Original match behaviour
                match = getCorrectMatch(matches, matchNumber);
                if (match != null) {
                    vars.put(refName, match);
                }
            } else // < 0 means we save all the matches
            {
                matchCount = matches.size();
                vars.put(refName + REF_MATCH_NR, Integer.toString(matchCount));// Save the count
                for (int i = 1; i <= matchCount; i++) {
                    match = getCorrectMatch(matches, i);
                    if (match != null) {
                        final String refNameN = refName + UNDERSCORE + i;
                        vars.put(refNameN, match);
                    }
                }
            }
            // Remove any left-over variables
            for (int i = matchCount + 1; i <= prevCount; i++) {
                final String refNameN = refName + UNDERSCORE + i;
                vars.remove(refNameN);
            }
        } catch (RuntimeException e) {
            if (log.isWarnEnabled()) {
                log.warn(""{}: Error while generating result. {}"", getName(), e.toString());
            }
        }
    }",,
jmeter,13311,"log.debug(""new baseUrl: {} - {}"", s, baseUrl)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/parser/RegexpHTMLParser.java/#L155,"@Override
    public Iterator<URL> getEmbeddedResourceURLs(String userAgent, byte[] html, URL baseUrl, URLCollection urls, String encoding) throws HTMLParseException {
        Pattern pattern= null;
        Perl5Matcher matcher = null;
        try {
            matcher = JMeterUtils.getMatcher();
            PatternMatcherInput input = localInput.get();
            // TODO: find a way to avoid the cost of creating a String here --
            // probably a new PatternMatcherInput working on a byte[] would do
            // better.
            input.setInput(new String(html, encoding));
            pattern=JMeterUtils.getPatternCache().getPattern(
                    REGEXP,
                    Perl5Compiler.CASE_INSENSITIVE_MASK
                    | Perl5Compiler.SINGLELINE_MASK
                    | Perl5Compiler.READ_ONLY_MASK);

            while (matcher.contains(input, pattern)) {
                MatchResult match = matcher.getMatch();
                String s;
                if (log.isDebugEnabled()) {
                    log.debug(""match groups {} {}"", match.groups(), match);
                }
                // Check for a BASE HREF:
                for (int g = 1; g <= NUM_BASE_GROUPS && g <= match.groups(); g++) {
                    s = match.group(g);
                    if (s != null) {
                        
---------------Reference log start----------------
log.debug(""new baseUrl: {} - {}"", s, baseUrl)
---------------Reference log end----------------
                        try {
                            baseUrl = ConversionUtils.makeRelativeURL(baseUrl, s);
                        } catch (MalformedURLException e) {
                            // Doesn't even look like a URL?
                            // Maybe it isn't: Ignore the exception.
                            log.debug(""Can't build base URL from URL {} in page {}"", s, baseUrl, e);
                        }
                    }
                }
                for (int g = NUM_BASE_GROUPS + 1; g <= match.groups(); g++) {
                    s = match.group(g);
                    if (s != null) {
                        if (log.isDebugEnabled()) {
                            log.debug(""group {} - {}"", g, match.group(g));
                        }
                        urls.addURL(s, baseUrl);
                    }
                }
            }
            return urls.iterator();
        } catch (UnsupportedEncodingException
                | MalformedCachePatternException e) {
            throw new HTMLParseException(e.getMessage(), e);
        } finally {
            JMeterUtils.clearMatcherMemory(matcher, pattern);
        }
    }",,
jmeter,13591,"log.debug(""Matched!"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/modifier/AnchorModifier.java/#L218,"private void addFramesetUrls(Document html, HTTPSampleResult result,
       HTTPSamplerBase config, List<HTTPSamplerBase> potentialLinks) {
       String base = """";
       NodeList baseList = html.getElementsByTagName(""base""); // $NON-NLS-1$
       if (baseList.getLength() > 0) {
           base = baseList.item(0).getAttributes().getNamedItem(""href"") // $NON-NLS-1$
                   .getNodeValue();
       }
       NodeList nodeList = html.getElementsByTagName(""frame""); // $NON-NLS-1$
       for (int i = 0; i < nodeList.getLength(); i++) {
           Node tempNode = nodeList.item(i);
           NamedNodeMap nnm = tempNode.getAttributes();
           Node namedItem = nnm.getNamedItem(""src""); // $NON-NLS-1$
           if (namedItem == null) {
               continue;
           }
           String hrefStr = namedItem.getNodeValue();
           try {
               HTTPSamplerBase newUrl = HtmlParsingUtils.createUrlFromAnchor(
                       hrefStr, ConversionUtils.makeRelativeURL(result.getURL(), base));
               newUrl.setMethod(HTTPConstants.GET);
               if (log.isDebugEnabled()) {
                   log.debug(""Potential <frame src> match: "" + newUrl);
               }
               if (HtmlParsingUtils.isAnchorMatched(newUrl, config)) {
                   
---------------Reference log start----------------
log.debug(""Matched!"")
---------------Reference log end----------------
                   potentialLinks.add(newUrl);
               }
           } catch (MalformedURLException e) {
               log.warn(""Bad URL ""+e);
           }
       }
   }",,
jmeter,14613,"log.info(""Will generate dashboard in folder: {}"", outputDir.getAbsolutePath())",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/HtmlTemplateExporter.java/#L330,"@Override
    public void export(SampleContext context, File file,
            ReportGeneratorConfiguration configuration) throws ExportException {
        Validate.notNull(context, MUST_NOT_BE_NULL, ""context"");
        Validate.notNull(file, MUST_NOT_BE_NULL, ""file"");
        Validate.notNull(configuration, MUST_NOT_BE_NULL, ""configuration"");

        log.debug(""Start template processing"");

        // Create data context and populate it
        DataContext dataContext = new DataContext();

        // Get the configuration of the current exporter
        final ExporterConfiguration exportCfg =
                configuration.getExportConfigurations().get(getName());

        // Get template directory property value
        File templateDirectory = getPropertyFromConfig(
                exportCfg,
                TEMPLATE_DIR,
                new File(JMeterUtils.getJMeterBinDir(), TEMPLATE_DIR_NAME_DEFAULT),
                File.class);
        if (!templateDirectory.isDirectory()) {
            String message = String.format(
                    ""\""%s\"" is not a valid template directory"",
                    templateDirectory.getAbsolutePath());
            log.error(message);
            throw new ExportException(message);
        }

        // Get output directory property value
        File outputDir = getPropertyFromConfig(exportCfg, OUTPUT_DIR,
                new File(JMeterUtils.getJMeterBinDir(), OUTPUT_DIR_NAME_DEFAULT), File.class);
        String globallyDefinedOutputDir = JMeterUtils.getProperty(JMeter.JMETER_REPORT_OUTPUT_DIR_PROPERTY);
        if(!StringUtils.isEmpty(globallyDefinedOutputDir)) {
            outputDir = new File(globallyDefinedOutputDir);
        }

        JOrphanUtils.canSafelyWriteToFolder(outputDir, this::htmlReportFileFilter);

        if (log.isInfoEnabled()) {
            
---------------Reference log start----------------
log.info(""Will generate dashboard in folder: {}"", outputDir.getAbsolutePath())
---------------Reference log end----------------
        }

        // Add a flag defining if only sample series are filtered to the context
        final boolean filtersOnlySampleSeries = exportCfg.filtersOnlySampleSeries();
        addToContext(
                DATA_CTX_FILTERS_ONLY_SAMPLE_SERIES,
                filtersOnlySampleSeries,
                dataContext);

        // Add the series filter to the context
        final String seriesFilter = exportCfg.getSeriesFilter();
        Pattern filterPattern = null;
        if (StringUtils.isNotBlank(seriesFilter)) {
            try {
                filterPattern = Pattern.compile(seriesFilter);
            } catch (PatternSyntaxException ex) {
                log.error(""Invalid series filter: '{}', {}"", seriesFilter, ex.getDescription());
            }
        }
        addToContext(DATA_CTX_SERIES_FILTER, seriesFilter, dataContext);

        // Add the flag defining whether only controller series are displayed
        final boolean showControllerSeriesOnly = exportCfg.showControllerSeriesOnly();
        addToContext(
                DATA_CTX_SHOW_CONTROLLERS_ONLY,
                showControllerSeriesOnly,
                dataContext);

        JsonizerVisitor jsonizer = new JsonizerVisitor();
        Map<String, Object> storedData = context.getData();

        // Add begin date consumer result to the data context
        addResultToContext(
                ReportGenerator.BEGIN_DATE_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add end date summary consumer result to the data context
        addResultToContext(
                ReportGenerator.END_DATE_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add Apdex summary consumer result to the data context
        addResultToContext(
                ReportGenerator.APDEX_SUMMARY_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add errors summary consumer result to the data context
        addResultToContext(
                ReportGenerator.ERRORS_SUMMARY_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add requests summary consumer result to the data context
        addResultToContext(
                ReportGenerator.REQUESTS_SUMMARY_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add statistics summary consumer result to the data context
        addResultToContext(
                ReportGenerator.STATISTICS_SUMMARY_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add Top 5 errors by sampler consumer result to the data context
        addResultToContext(
                ReportGenerator.TOP5_ERRORS_BY_SAMPLER_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Collect graph results from sample context and transform them into
        // Json strings to inject in the data context
        ExtraOptionsResultCustomizer customizer = new ExtraOptionsResultCustomizer();
        EmptyGraphChecker checker =
                new EmptyGraphChecker(filtersOnlySampleSeries, showControllerSeriesOnly, filterPattern);
        Map<String, GraphConfiguration> mapConfiguration = new HashMap<>();
        DataContext customGraphs = new DataContext();

        for (Map.Entry<String, GraphConfiguration> graphEntry : configuration.getGraphConfigurations().entrySet()) {
            final String graphId = graphEntry.getKey();
            final GraphConfiguration graphConfiguration = graphEntry.getValue();

            // Initialize customizer and checker
            customizer.setExtraOptions(exportCfg.getGraphExtraConfigurations().get(graphId));
            checker.setExcludesControllers(graphConfiguration.excludesControllers());
            checker.setGraphId(graphId);
            mapConfiguration.put(graphId, graphConfiguration);
            if (graphId.startsWith(CUSTOM_GRAPH_PREFIX)) {
                addResultToContext(
                        graphId, storedData, customGraphs, jsonizer, customizer, checker);
            } else {
                // Export graph data
                addResultToContext(
                        graphId, storedData, dataContext, jsonizer, customizer, checker);
            }
        }
        dataContext.put(""graphConfigurations"", mapConfiguration);
        dataContext.put(""customsGraphsData"", customGraphs);

        // Replace the begin date with its formatted string and store the old timestamp
        long oldTimestamp = formatTimestamp(
                ReportGenerator.BEGIN_DATE_CONSUMER_NAME, dataContext);

        // Replace the end date with its formatted string
        formatTimestamp(ReportGenerator.END_DATE_CONSUMER_NAME, dataContext);

        // Add time zone offset (that matches the begin date) to the context
        TimeZone timezone = TimeZone.getDefault();
        addToContext(
                DATA_CTX_TIMEZONE_OFFSET,
                timezone.getOffset(oldTimestamp),
                dataContext);

        // Add report title to the context
        if (StringUtils.isNotEmpty(configuration.getReportTitle())) {
            dataContext.put(DATA_CTX_REPORT_TITLE, StringEscapeUtils.escapeHtml4(configuration.getReportTitle()));
        }

        // Add the test file name to the context
        addToContext(DATA_CTX_TESTFILE, file.getName(), dataContext);

        // Add the overall filter property to the context
        addToContext(DATA_CTX_OVERALL_FILTER, configuration.getSampleFilter(), dataContext);

        // Walk template directory to copy files and process templated ones
        Configuration templateCfg = new Configuration(Configuration.VERSION_2_3_30);
        try {
            templateCfg.setDirectoryForTemplateLoading(templateDirectory);
            templateCfg.setTemplateExceptionHandler(TemplateExceptionHandler.RETHROW_HANDLER);
            if (log.isInfoEnabled()) {
                log.info(""Report will be generated in: {}, creating folder structure"", outputDir.getAbsolutePath());
            }
            FileUtils.forceMkdir(outputDir);
            TemplateVisitor visitor = new TemplateVisitor(
                    templateDirectory.toPath(),
                    outputDir.toPath(),
                    templateCfg,
                    dataContext);
            Files.walkFileTree(templateDirectory.toPath(), visitor);
        } catch (IOException ex) {
            throw new ExportException(""Unable to process template files."", ex);
        }

        log.debug(""End of template processing"");
    }",,
jmeter,14609,"log.debug(""name:{} matches pattern:{}, supportsControllerDiscrimination:{}, "" + ""isController:{}, showControllerSeriesOnly:{}"", name, filterPattern.pattern(), supportsControllerDiscrimination, isController, showControllerSeriesOnly)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/HtmlTemplateExporter.java/#L245,"@Override
        public boolean checkResult(DataContext dataContext, ResultData result) {
            boolean supportsControllerDiscrimination = findValue(Boolean.class,
                    AbstractGraphConsumer.RESULT_SUPPORTS_CONTROLLERS_DISCRIMINATION,
                    result);

            if (supportsControllerDiscrimination
                    && showControllerSeriesOnly
                    && excludesControllers) {
                // Exporter shows controller series only
                // whereas the current graph support controller
                // discrimination and excludes controllers
                log.warn(""{} is set while the graph {} excludes controllers."",
                        ReportGeneratorConfiguration.EXPORTER_KEY_SHOW_CONTROLLERS_ONLY, graphId);
                return false;
            }

            if (filterPattern == null) {
                return true;
            }

            // Detect whether none series matches the series filter.
            ResultData seriesResult = findData(AbstractGraphConsumer.RESULT_SERIES, result);
            if (!(seriesResult instanceof ListResultData)) {
                return true;
            }

            // Try to find at least one pattern matching
            ListResultData seriesList = (ListResultData) seriesResult;
            int count = seriesList.getSize();
            int index = 0;
            boolean matches = false;
            while (index < count && !matches) {
                ResultData currentResult = seriesList.get(index);
                if (currentResult instanceof MapResultData) {
                    MapResultData seriesData = (MapResultData) currentResult;
                    String name = findValue(String.class,
                            AbstractGraphConsumer.RESULT_SERIES_NAME,
                            seriesData);

                    // Is the current series a controller series ?
                    boolean isController = findValue(Boolean.class,
                            AbstractGraphConsumer.RESULT_SERIES_IS_CONTROLLER,
                            seriesData);

                    matches = filterPattern.matcher(name).matches();
                    if (matches) {
                        // If the name matches pattern, other
                        // properties can discard the series
                        matches = !filtersOnlySampleSeries
                                || !supportsControllerDiscrimination
                                || isController
                                || !showControllerSeriesOnly;
                        if(log.isDebugEnabled()) {
                            
---------------Reference log start----------------
log.debug(""name:{} matches pattern:{}, supportsControllerDiscrimination:{}, "" + ""isController:{}, showControllerSeriesOnly:{}"", name, filterPattern.pattern(), supportsControllerDiscrimination, isController, showControllerSeriesOnly)
---------------Reference log end----------------
                        }
                    } else {
                        // If the name does not match the pattern,
                        // other properties can hold the series
                        matches = filtersOnlySampleSeries
                                && !supportsControllerDiscrimination;
                        if (log.isDebugEnabled()) {
                            log.debug(""name:{} does not match pattern:{}, filtersOnlySampleSeries:{},""
                                + "" supportsControllerDiscrimination:{}"",
                                name, filterPattern.pattern(),
                                filtersOnlySampleSeries,
                                supportsControllerDiscrimination);
                        }
                    }
                }
                index++;
            }
            if (!matches) {
                log.warn(""No series matches the series_filter: {} in graph: {}"",
                        ReportGeneratorConfiguration.EXPORTER_KEY_SERIES_FILTER, graphId);
                return false;
            }
            return true;
        }",,
jmeter,13703,"log.debug(""Location as URL: {}"", url)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L1663,"protected HTTPSampleResult followRedirects(HTTPSampleResult res, int frameDepth) {
        HTTPSampleResult totalRes = new HTTPSampleResult(res);
        totalRes.addRawSubResult(res);
        HTTPSampleResult lastRes = res;

        int redirect;
        for (redirect = 0; redirect < MAX_REDIRECTS; redirect++) {
            boolean invalidRedirectUrl = false;
            String location = lastRes.getRedirectLocation();
            log.debug(""Initial location: {}"", location);
            if (REMOVESLASHDOTDOT) {
                location = ConversionUtils.removeSlashDotDot(location);
            }
            // Browsers seem to tolerate Location headers with spaces,
            // replacing them automatically with %20. We want to emulate
            // this behaviour.
            location = encodeSpaces(location);
            log.debug(""Location after /. and space transforms: {}"", location);
            // Change all but HEAD into GET (Bug 55450)
            String method = lastRes.getHTTPMethod();
            method = computeMethodForRedirect(method);

            try {
                URL url = ConversionUtils.makeRelativeURL(lastRes.getURL(), location);
                url = ConversionUtils.sanitizeUrl(url).toURL();
                
---------------Reference log start----------------
log.debug(""Location as URL: {}"", url)
---------------Reference log end----------------
                HTTPSampleResult tempRes = sample(url, method, true, frameDepth);
                if (tempRes != null) {
                    lastRes = tempRes;
                } else {
                    // Last url was in cache so tempRes is null
                    break;
                }
            } catch (MalformedURLException | URISyntaxException e) {
                errorResult(e, lastRes);
                // The redirect URL we got was not a valid URL
                invalidRedirectUrl = true;
            }
            if (lastRes.getSubResults() != null && lastRes.getSubResults().length > 0) {
                SampleResult[] subs = lastRes.getSubResults();
                for (SampleResult sub : subs) {
                    totalRes.addSubResult(sub);
                }
            } else {
                // Only add sample if it is a sample of valid url redirect, i.e. that
                // we have actually sampled the URL
                if (!invalidRedirectUrl) {
                    totalRes.addSubResult(lastRes);
                }
            }

            if (!lastRes.isRedirect()) {
                break;
            }
        }
        if (redirect >= MAX_REDIRECTS) {
            lastRes = errorResult(new IOException(""Exceeded maximum number of redirects: "" + MAX_REDIRECTS), new HTTPSampleResult(lastRes));
            totalRes.addSubResult(lastRes);
        }

        // Now populate the any totalRes fields that need to
        // come from lastRes:
        totalRes.setSampleLabel(totalRes.getSampleLabel() + ""->"" + lastRes.getSampleLabel());
        // The following three can be discussed: should they be from the
        // first request or from the final one? I chose to do it this way
        // because that's what browsers do: they show the final URL of the
        // redirect chain in the location field.
        totalRes.setURL(lastRes.getURL());
        totalRes.setHTTPMethod(lastRes.getHTTPMethod());
        totalRes.setQueryString(lastRes.getQueryString());
        totalRes.setRequestHeaders(lastRes.getRequestHeaders());

        totalRes.setResponseData(lastRes.getResponseData());
        totalRes.setResponseCode(lastRes.getResponseCode());
        totalRes.setSuccessful(lastRes.isSuccessful());
        totalRes.setResponseMessage(lastRes.getResponseMessage());
        totalRes.setDataType(lastRes.getDataType());
        totalRes.setResponseHeaders(lastRes.getResponseHeaders());
        totalRes.setContentType(lastRes.getContentType());
        totalRes.setDataEncoding(lastRes.getDataEncodingNoDefault());
        return totalRes;
    }",,
jmeter,13335,"LOGGER.debug(""Adding entry {}"", hostEntry)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/gui/DNSCachePanel.java/#L342,"private void addHostToTable(StaticHost hostEntry) {
        
---------------Reference log start----------------
LOGGER.debug(""Adding entry {}"", hostEntry)
---------------Reference log end----------------
        dnsHostsTableModel.addRow(new Object[] {
            hostEntry.getName(), hostEntry.getAddress() });
    }",,
jmeter,15051,"log.error(""Beanshell Interpreter not found"")",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/BeanShellServer.java/#L105,"@Override
    public void run() {

        ClassLoader loader = Thread.currentThread().getContextClassLoader();

        try {
            Class<?> interpreter = loader.loadClass(""bsh.Interpreter"");//$NON-NLS-1$
            Object instance = interpreter.getDeclaredConstructor().newInstance();
            Class<String> string = String.class;
            Class<Object> object = Object.class;

            Method eval = interpreter.getMethod(""eval"", string);//$NON-NLS-1$
            Method setObj = interpreter.getMethod(""set"", string, object);//$NON-NLS-1$
            Method setInt = interpreter.getMethod(""set"", string, int.class);//$NON-NLS-1$
            Method source = interpreter.getMethod(""source"", string);//$NON-NLS-1$

            setObj.invoke(instance, ""t"", this );//$NON-NLS-1$
            setInt.invoke(instance, ""portnum"", serverport);//$NON-NLS-1$

            if (serverfile.length() > 0) {
                try {
                    source.invoke(instance, serverfile);
                } catch (InvocationTargetException ite) {
                    Throwable cause = ite.getCause();
                    if (log.isWarnEnabled()) {
                        log.warn(""Could not source, {}. {}"", serverfile,
                                (cause != null) ? cause.toString() : ite.toString());
                    }
                    if (cause instanceof Error) {
                        throw (Error) cause;
                    }
                }
            }
            eval.invoke(instance, ""setAccessibility(true);"");//$NON-NLS-1$
            eval.invoke(instance, ""server(portnum);"");//$NON-NLS-1$

        } catch (ClassNotFoundException e) {
            
---------------Reference log start----------------
log.error(""Beanshell Interpreter not found"")
---------------Reference log end----------------
        } catch (Exception e) {
            log.error(""Problem starting BeanShell server"", e);
        }
    }",,
jmeter,13243,"log.warn(""Exception parsing {} as int, value will not be considered as End Number sequence"", tmp)",warn,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/StringFromFile.java/#L174,"private synchronized void openFile() {
        String tn = Thread.currentThread().getName();
        fileName = ((CompoundVariable) values[0]).execute();

        String start = """";
        if (values.length >= PARAM_START) {
            start = ((CompoundVariable) values[PARAM_START - 1]).execute();
            try {
                // Low chances to be non numeric, we parse
                myStart = Integer.parseInt(start);
            } catch(NumberFormatException e) {
                myStart = COUNT_UNUSED;// Don't process invalid numbers
                log.warn(""Exception parsing {} as int, value will not be considered as Start Number sequence"", start);
            }
        }
        // Have we used myCurrent yet?
        // Set to 1 if start number is missing (to allow for end without start)
        if (myCurrent == COUNT_UNUSED) {
            myCurrent = myStart == COUNT_UNUSED ? 1 : myStart;
        }

        if (values.length >= PARAM_END) {
            String tmp = ((CompoundVariable) values[PARAM_END - 1]).execute();
            try {
                // Low chances to be non numeric, we parse
                myEnd = Integer.parseInt(tmp);
            } catch(NumberFormatException e) {
                myEnd = COUNT_UNUSED;// Don't process invalid numbers (including """")
                
---------------Reference log start----------------
log.warn(""Exception parsing {} as int, value will not be considered as End Number sequence"", tmp)
---------------Reference log end----------------
            }
        }

        if (values.length >= PARAM_START) {
            if (log.isInfoEnabled()) {
                log.info(""{} Start = {} Current = {} End = {}"", tn, myStart, myCurrent, myEnd);//$NON-NLS-1$
            }
            if (myEnd != COUNT_UNUSED) {
                if (myCurrent > myEnd) {
                    if (log.isInfoEnabled()) {
                        log.info(""{} No more files to process, {} > {}"", tn, myCurrent, myEnd);//$NON-NLS-1$
                    }
                    myBread = null;
                    return;
                }
            }
            /*
             * DecimalFormat adds the number to the end of the format if there
             * are no formatting characters, so we need a way to prevent this
             * from messing up the file name.
             *
             */
            if (myStart != COUNT_UNUSED) // Only try to format if there is a
                                            // number
            {
                log.info(""{} using format {}"", tn, fileName);
                try {
                    DecimalFormat myFormatter = new DecimalFormat(fileName);
                    fileName = myFormatter.format(myCurrent);
                } catch (NumberFormatException e) {
                    log.warn(""Bad file name format "", e);
                }
            }
            myCurrent++;// for next time
        }

        log.info(""{} opening file {}"", tn, fileName);//$NON-NLS-1$
        try {
            myBread = Files.newBufferedReader(Paths.get(fileName));
        } catch (Exception e) {
            log.error(""openFile() error: {}"", e.toString());//$NON-NLS-1$
            IOUtils.closeQuietly(myBread, null);
            myBread = null;
        }
    }",,
jmeter,14530,"log.info(""Using fallback search path"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/ActionRouter.java/#L358,"public void populateCommandMap() {
        if (!commands.isEmpty()) {
            return; // already done
        }
        try {
            List<String> listClasses = findClassesThatExtend(""org.apache.jmeter.gui.action.Command"", // $NON-NLS-1$
                    ""org.apache.jmeter.report.gui"", // $NON-NLS-1$
                    JMeterUtils.getSearchPaths());

            if (listClasses.isEmpty()) {
                //fallback
                Optional<String[]> codeSourceSearchPath = getCodeSourceSearchPath();
                if (codeSourceSearchPath.isPresent()) {
                    
---------------Reference log start----------------
log.info(""Using fallback search path"")
---------------Reference log end----------------
                    listClasses = findClassesThatExtend(""org.apache.jmeter.gui.action.Command"", // $NON-NLS-1$
                            ""org.apache.jmeter.report.gui"", // $NON-NLS-1$
                            codeSourceSearchPath.get());
                }
            }

            if (listClasses.isEmpty()) {
                log.error(""!!!!!Uh-oh, didn't find any action handlers!!!!!"");
                throw new JMeterError(""No action handlers found - check JMeterHome and libraries"");
            }
            for (String strClassName : listClasses) {
                Class<?> commandClass = Class.forName(strClassName);
                Command command = (Command) commandClass.getDeclaredConstructor().newInstance();
                for (String commandName : command.getActionNames()) {
                    Set<Command> commandObjects = commands.computeIfAbsent(commandName, k -> new HashSet<>());
                    commandObjects.add(command);
                }
            }
        } catch (HeadlessException e) {
            if (log.isWarnEnabled()) {
                log.warn(""AWT headless exception occurred. {}"", e.toString());
            }
        } catch (Exception e) {
            log.error(""exception finding action handlers"", e);
        }
    }",,
jmeter,13667,"log.debug(""Connection failed, giving up"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPJavaImpl.java/#L550,"@Override
    protected HTTPSampleResult sample(URL url, String method, boolean areFollowingRedirect, int frameDepth) {
        HttpURLConnection conn = null;

        String urlStr = url.toString();
        if (log.isDebugEnabled()) {
            log.debug(""Start : sample {}, method {}, followingRedirect {}, depth {}"",
                    urlStr, method, areFollowingRedirect, frameDepth);
        }

        HTTPSampleResult res = new HTTPSampleResult();
        configureSampleLabel(res, url);
        res.setURL(url);
        res.setHTTPMethod(method);

        res.sampleStart(); // Count the retries as well in the time

        // Check cache for an entry with an Expires header in the future
        final CacheManager cacheManager = getCacheManager();
        if (cacheManager != null && HTTPConstants.GET.equalsIgnoreCase(method)) {
           if (cacheManager.inCache(url, getHeaders(getHeaderManager()))) {
               return updateSampleResultForResourceInCache(res);
           }
        }

        try {
            // Sampling proper - establish the connection and read the response:
            // Repeatedly try to connect:
            int retry = -1;
            // Start with -1 so tries at least once, and retries at most MAX_CONN_RETRIES times
            for (; retry < MAX_CONN_RETRIES; retry++) {
                try {
                    conn = setupConnection(url, method, res);
                    // Attempt the connection:
                    savedConn = conn;
                    conn.connect();
                    break;
                } catch (BindException e) {
                    if (retry >= MAX_CONN_RETRIES) {
                        log.error(""Can't connect after {} retries, message: {}"", retry, e.toString());
                        throw e;
                    }
                    log.debug(""Bind exception, try again"");
                    if (conn!=null) {
                        savedConn = null; // we don't want interrupt to try disconnection again
                        conn.disconnect();
                    }
                    setUseKeepAlive(false);
                } catch (IOException e) {
                    
---------------Reference log start----------------
log.debug(""Connection failed, giving up"")
---------------Reference log end----------------
                    throw e;
                }
            }
            if (retry > MAX_CONN_RETRIES) {
                // This should never happen, but...
                throw new BindException();
            }
            // Nice, we've got a connection. Finish sending the request:
            if (method.equals(HTTPConstants.POST)) {
                String postBody = sendPostData(conn);
                res.setQueryString(postBody);
            } else if (method.equals(HTTPConstants.PUT)) {
                String putBody = sendPutData(conn);
                res.setQueryString(putBody);
            }
            // Request sent. Now get the response:
            byte[] responseData = readResponse(conn, res);

            res.sampleEnd();
            // Done with the sampling proper.

            // Now collect the results into the HTTPSampleResult:

            res.setResponseData(responseData);

            int errorLevel = conn.getResponseCode();
            String respMsg = conn.getResponseMessage();
            String hdr=conn.getHeaderField(0);
            if (hdr == null) {
                hdr=""(null)"";  // $NON-NLS-1$
            }
            if (errorLevel == -1){// Bug 38902 - sometimes -1 seems to be returned unnecessarily
                if (respMsg != null) {// Bug 41902 - NPE
                    try {
                        errorLevel = Integer.parseInt(respMsg.substring(0, 3));
                        log.warn(""ResponseCode==-1; parsed {} as {}"", respMsg, errorLevel);
                      } catch (NumberFormatException e) {
                        log.warn(""ResponseCode==-1; could not parse {} hdr: {}"", respMsg, hdr);
                      }
                } else {
                    respMsg=hdr; // for result
                    log.warn(""ResponseCode==-1 & null ResponseMessage. Header(0)= {} "", hdr);
                }
            }
            if (errorLevel == -1) {
                res.setResponseCode(""(null)""); // $NON-NLS-1$
            } else {
                res.setResponseCode(Integer.toString(errorLevel));
            }
            res.setSuccessful(isSuccessCode(errorLevel));

            if (respMsg == null) {// has been seen in a redirect
                respMsg=hdr; // use header (if possible) if no message found
            }
            res.setResponseMessage(respMsg);

            String ct = conn.getContentType();
            if (ct != null){
                res.setContentType(ct);// e.g. text/html; charset=ISO-8859-1
                res.setEncodingAndType(ct);
            }

            String responseHeaders = getResponseHeaders(conn);
            res.setResponseHeaders(responseHeaders);
            if (res.isRedirect()) {
                res.setRedirectLocation(conn.getHeaderField(HTTPConstants.HEADER_LOCATION));
            }

            // record headers size to allow HTTPSampleResult.getBytes() with different options
            res.setHeadersSize(responseHeaders.replaceAll(""\n"", ""\r\n"") // $NON-NLS-1$ $NON-NLS-2$
                    .length() + 2); // add 2 for a '\r\n' at end of headers (before data)
            if (log.isDebugEnabled()) {
                log.debug(""Response headersSize={}, bodySize={}, Total={}"",
                        res.getHeadersSize(),  res.getBodySizeAsLong(),
                        res.getHeadersSize() + res.getBodySizeAsLong());
            }

            // If we redirected automatically, the URL may have changed
            if (getAutoRedirects()){
                res.setURL(conn.getURL());
            }

            // Store any cookies received in the cookie manager:
            saveConnectionCookies(conn, url, getCookieManager());

            // Save cache information
            if (cacheManager != null){
                cacheManager.saveDetails(conn, res);
            }

            res = resultProcessing(areFollowingRedirect, frameDepth, res);

            log.debug(""End : sample"");
            return res;
        } catch (IOException e) {
            if (res.getEndTime() == 0) {
                res.sampleEnd();
            }
            savedConn = null; // we don't want interrupt to try disconnection again
            // We don't want to continue using this connection, even if KeepAlive is set
            if (conn != null) { // May not exist
                conn.disconnect();
            }
            conn=null; // Don't process again
            return errorResult(e, res);
        } finally {
            // calling disconnect doesn't close the connection immediately,
            // but indicates we're through with it. The JVM should close
            // it when necessary.
            savedConn = null; // we don't want interrupt to try disconnection again
            disconnect(conn); // Disconnect unless using KeepAlive
        }
    }",,
jmeter,13584,"log.debug(""Potential Form match: "" + newUrl.toString())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/modifier/AnchorModifier.java/#L149,"private void addFormUrls(Document html, HTTPSampleResult result, HTTPSamplerBase config,
            List<HTTPSamplerBase> potentialLinks) {
        NodeList rootList = html.getChildNodes();
        List<HTTPSamplerBase> urls = new ArrayList<>();
        for (int x = 0; x < rootList.getLength(); x++) {
            urls.addAll(HtmlParsingUtils.createURLFromForm(rootList.item(x), result.getURL()));
        }
        for (HTTPSamplerBase newUrl : urls) {
            newUrl.setMethod(HTTPConstants.POST);
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Potential Form match: "" + newUrl.toString())
---------------Reference log end----------------
            }
            if (HtmlParsingUtils.isAnchorMatched(newUrl, config)) {
                log.debug(""Matched!"");
                potentialLinks.add(newUrl);
            }
        }
    }",,
jmeter,14943,"log.warn(""Could not set cipher list: {}."", CIPHER_LIST)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/HttpSSLProtocolSocketFactory.java/#L91,"private void configureSocket(Socket socket){
        if (!(socket instanceof SSLSocket)) {
            throw new IllegalArgumentException(""Expected SSLSocket"");
        }
        SSLSocket sock = (SSLSocket) socket;
        if (!PROTOCOL_LIST.isEmpty()) {
            try {
                sock.setEnabledProtocols(protocols);
            } catch (IllegalArgumentException e) { // NOSONAR
                if (log.isWarnEnabled()) {
                    log.warn(""Could not set protocol list: {}."", PROTOCOL_LIST);
                    log.warn(""Valid protocols are: {}"", join(sock.getSupportedProtocols()));
                }
            }
        }

        if (!CIPHER_LIST.isEmpty()) {
            try {
                sock.setEnabledCipherSuites(ciphers);
            } catch (IllegalArgumentException e) { // NOSONAR
                if (log.isWarnEnabled()) {
                    
---------------Reference log start----------------
log.warn(""Could not set cipher list: {}."", CIPHER_LIST)
---------------Reference log end----------------
                    log.warn(""Valid ciphers are: {}"", join(sock.getSupportedCipherSuites()));
                }
            }
        }
    }",,
jmeter,14964,"log.info(""Type={}. {}"", type, ex.toString())",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/XPathUtil.java/#L280,"@Override
        public void warning(SAXParseException ex) throws SAXException {
            if (log.isInfoEnabled()) {
                
---------------Reference log start----------------
log.info(""Type={}. {}"", type, ex.toString())
---------------Reference log end----------------
            }
            if (val && !tol){
                throw new SAXException(ex);
            }
        }",,
jmeter,14173,"log.error(""BeanShell not found"")",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/timers/BeanShellTimer.java/#L52,"@Override
    public long delay() {
        String ret=""0"";
        final BeanShellInterpreter bshInterpreter = getBeanShellInterpreter();
        if (bshInterpreter == null) {
            
---------------Reference log start----------------
log.error(""BeanShell not found"")
---------------Reference log end----------------
            return 0;
        }
        try {
            Object o = processFileOrScript(bshInterpreter);
            if (o != null) {
                ret=o.toString();
            }
        } catch (JMeterException e) {
            if (log.isWarnEnabled()) {
                log.warn(""Problem in BeanShell script. {}"", e.toString());
            }
        }
        try {
            return Long.decode(ret);
        } catch (NumberFormatException e){
            log.warn(""Number format exception while decoding number: '{}'"", ret);
            return 0;
        }
    }",,
jmeter,13495,"log.error(""{} Problem with keystore"", port, e)",error,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/Proxy.java/#L382,"private SSLSocketFactory getSSLSocketFactory(String host) {
        if (keyStore == null) {
            log.error(""{} No keystore available, cannot record SSL"", port);
            return null;
        }
        final String hashAlias;
        final String keyAlias;
        switch(ProxyControl.KEYSTORE_MODE) {
        case DYNAMIC_KEYSTORE:
            try {
                keyStore = target.getKeyStore(); // pick up any recent changes from other threads
                String alias = getDomainMatch(keyStore, host);
                if (alias == null) {
                    hashAlias = host;
                    keyAlias = host;
                    keyStore = target.updateKeyStore(port, keyAlias);
                } else if (alias.equals(host)) { // the host has a key already
                    hashAlias = host;
                    keyAlias = host;
                } else { // the host matches a domain; use its key
                    hashAlias = alias;
                    keyAlias = alias;
                }
            } catch (IOException | GeneralSecurityException e) {
                log.error(""{} Problem with keystore"", port, e);
                return null;
            }
            break;
        case JMETER_KEYSTORE:
            hashAlias = keyAlias = ProxyControl.JMETER_SERVER_ALIAS;
            break;
        case USER_KEYSTORE:
            hashAlias = keyAlias = ProxyControl.CERT_ALIAS;
            break;
        default:
            throw new IllegalStateException(""Impossible case: "" + ProxyControl.KEYSTORE_MODE);
        }
        synchronized (HOST2SSL_SOCK_FAC) {
            final SSLSocketFactory sslSocketFactory = HOST2SSL_SOCK_FAC.get(hashAlias);
            if (sslSocketFactory != null) {
                log.debug(""{} Good, already in map, host={} using alias {}"", port, host, hashAlias);
                return sslSocketFactory;
            }
            try {
                SSLContext sslcontext = SSLContext.getInstance(SSLCONTEXT_PROTOCOL);
                sslcontext.init(getWrappedKeyManagers(keyAlias), null, null);
                SSLSocketFactory sslFactory = sslcontext.getSocketFactory();
                HOST2SSL_SOCK_FAC.put(hashAlias, sslFactory);
                log.info(""{} KeyStore for SSL loaded OK and put host '{}' in map with key ({})"", port, host, hashAlias);
                return sslFactory;
            } catch (GeneralSecurityException e) {
                log.error(""{} Problem with SSL certificate"", port, e);
            } catch (IOException e) {
                
---------------Reference log start----------------
log.error(""{} Problem with keystore"", port, e)
---------------Reference log end----------------
            }
            return null;
        }
    }",,
jmeter,14835,"log.warn(""Probably an invalid function string: {}"", buffer)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/util/FunctionParser.java/#L246,"ArrayList<CompoundVariable> parseParams(StringReader reader) throws InvalidVariableException {
        ArrayList<CompoundVariable> result = new ArrayList<>();
        StringBuilder buffer = new StringBuilder();
        char[] current = new char[1];
        char previous = ' ';
        int functionRecursion = 0;
        int parenRecursion = 0;
        try {
            while (reader.read(current) == 1) {
                if (current[0] == '\\') { // Process escaped characters
                    buffer.append(current[0]); // Store the \
                    if (reader.read(current) == 0) {
                        break; // end of buffer
                    }
                    previous = ' ';
                    buffer.append(current[0]); // store the following character
                } else if (current[0] == ',' && functionRecursion == 0) {
                    CompoundVariable param = new CompoundVariable();
                    param.setParameters(buffer.toString());
                    buffer.setLength(0);
                    result.add(param);
                } else if (current[0] == ')' && functionRecursion == 0 && parenRecursion == 0) {
                    // Detect functionName() so this does not generate empty string as the parameter
                    if (buffer.length() == 0 && result.isEmpty()){
                        return result;
                    }
                    // Normal exit occurs here
                    CompoundVariable param = new CompoundVariable();
                    param.setParameters(buffer.toString());
                    buffer.setLength(0);
                    result.add(param);
                    return result;
                } else if (current[0] == '{' && previous == '$') {
                    buffer.append(current[0]);
                    previous = current[0];
                    functionRecursion++;
                } else if (current[0] == '}' && functionRecursion > 0) {
                    buffer.append(current[0]);
                    previous = current[0];
                    functionRecursion--;
                } else if (current[0] == ')' && functionRecursion == 0 && parenRecursion > 0) {
                    buffer.append(current[0]);
                    previous = current[0];
                    parenRecursion--;
                } else if (current[0] == '(' && functionRecursion == 0) {
                    buffer.append(current[0]);
                    previous = current[0];
                    parenRecursion++;
                } else {
                    buffer.append(current[0]);
                    previous = current[0];
                }
            }
        } catch (IOException e) {// Should not happen with StringReader
            log.error(""Error parsing function: {}"", buffer, e);
        }
        // Dropped out, i.e. did not find closing ')'
        
---------------Reference log start----------------
log.warn(""Probably an invalid function string: {}"", buffer)
---------------Reference log end----------------
        CompoundVariable var = new CompoundVariable();
        var.setParameters(buffer.toString());
        result.add(var);
        return result;
    }",,
jmeter,13228,"log.info(""Attaching {}"", file)",info,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/FileWrapper.java/#L149,"public static String getColumn(String file, int col) {
        Map<String, FileWrapper> my = filePacks.get();
        FileWrapper fw = my.get(file);
        if (fw == null) // First call
        {
            if (file.startsWith(""*"")) { //$NON-NLS-1$
                log.warn(""Cannot perform initial open using alias {}"", file);
            } else {
                file = checkDefault(file);
                
---------------Reference log start----------------
log.info(""Attaching {}"", file)
---------------Reference log end----------------
                open(file, file);
                fw = my.get(file);
            }
            // TODO improve the error handling
            if (fw == null) {
                return """";  //$NON-NLS-1$
            }
        }
        return fw.getColumn(col);
    }",,
jmeter,13360,"log.warn(""Failed computing expiration date with following info:"" + lastModified + "","" + cacheControl + "","" + expires + "","" + etag + "","" + url + "","" + date)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/CacheManager.java/#L345,"@SuppressWarnings(""JdkObsolete"")
    private Date calcExpiresDate(String lastModified, String cacheControl,
            String expires, String etag, String url, String date) {
        if(!StringUtils.isEmpty(lastModified) && !StringUtils.isEmpty(date)) {
            try {
                Date responseDate = DateUtils.parseDate(date);
                Date lastModifiedAsDate = DateUtils.parseDate(lastModified);
                // see https://developer.mozilla.org/en/HTTP_Caching_FAQ
                // see http://www.ietf.org/rfc/rfc2616.txt#13.2.4
                return new Date(System.currentTimeMillis() + Math.round(
                        (responseDate.getTime() - lastModifiedAsDate.getTime())
                                * 0.1));
            } catch(IllegalArgumentException e) {
                // date or lastModified may be null or in bad format
                if(log.isWarnEnabled()) {
                    
---------------Reference log start----------------
log.warn(""Failed computing expiration date with following info:"" + lastModified + "","" + cacheControl + "","" + expires + "","" + etag + "","" + url + "","" + date)
---------------Reference log end----------------
                }
                // TODO Can't see anything in SPEC
                return new Date(System.currentTimeMillis() + ONE_YEAR_MS);
            }
        } else {
            // TODO Can't see anything in SPEC
            return new Date(System.currentTimeMillis() + ONE_YEAR_MS);
        }
    }",,
jmeter,13863,"LOGGER.debug(""Empty JNDI properties"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/sampler/JMSSampler.java/#L715,"@SuppressWarnings(""JdkObsolete"")
    private Context getInitialContext() throws NamingException {
        Hashtable<String, String> table = new Hashtable<>();

        if (getInitialContextFactory() != null && getInitialContextFactory().trim().length() > 0) {
            LOGGER.debug(""Using InitialContext [{}]"", getInitialContextFactory());
            table.put(Context.INITIAL_CONTEXT_FACTORY, getInitialContextFactory());
        }
        if (getContextProvider() != null && getContextProvider().trim().length() > 0) {
            LOGGER.debug(""Using Provider [{}]"", getContextProvider());
            table.put(Context.PROVIDER_URL, getContextProvider());
        }
        Map<String, String> map = getArguments(JMSSampler.JNDI_PROPERTIES).getArgumentsAsMap();
        if (LOGGER.isDebugEnabled()) {
            if (map.isEmpty()) {
                
---------------Reference log start----------------
LOGGER.debug(""Empty JNDI properties"")
---------------Reference log end----------------
            } else {
                LOGGER.debug(""Number of JNDI properties: {}"", map.size());
            }
        }
        for (Map.Entry<String, String> me : map.entrySet()) {
            table.put(me.getKey(), me.getValue());
        }

        Context initialContext = new InitialContext(table);
        if (LOGGER.isDebugEnabled()) {
            printEnvironment(initialContext);
        }
        return initialContext;
    }",,
jmeter,13304,"log.error(""Failed to parse the date '{}' to shift with formatter '{}'"", dateToShift, formatter, // $NON-NLS-1$
ex)",error,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/TimeShift.java/#L167,"@Override
    public String execute(SampleResult previousResult, Sampler currentSampler) throws InvalidVariableException {
        String amountToShift = amountToShiftCompound.execute().trim();
        String dateToShift = dateToShiftCompound.execute().trim();
        ZonedDateTime zonedDateTimeToShift = ZonedDateTime.now(systemDefaultZoneID);

        DateTimeFormatter formatter = null;
        if (!StringUtils.isEmpty(format)) {
            try {
                LocaleFormatObject lfo = new LocaleFormatObject(format, locale);
                formatter = dateTimeFormatterCache.get(lfo, this::createFormatter);
            } catch (IllegalArgumentException ex) {
                log.error(""Format date pattern '{}' is invalid ""
                        + ""(see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html)"",
                        format, ex); // $NON-NLS-1$
                return """";
            }
        }

        if (!dateToShift.isEmpty()) {
            try {
                if (formatter != null) {
                    zonedDateTimeToShift = ZonedDateTime.parse(dateToShift, formatter);
                } else {
                    zonedDateTimeToShift = ZonedDateTime.ofInstant(Instant.ofEpochMilli(Long.parseLong(dateToShift)),
                            systemDefaultZoneID);
                }
            } catch (DateTimeParseException | NumberFormatException ex) {
                
---------------Reference log start----------------
log.error(""Failed to parse the date '{}' to shift with formatter '{}'"", dateToShift, formatter, // $NON-NLS-1$
ex)
---------------Reference log end----------------
            }
        }

        // Check amount value to shift
        if (!StringUtils.isEmpty(amountToShift)) {
            try {
                Duration duration = Duration.parse(amountToShift);
                zonedDateTimeToShift = zonedDateTimeToShift.plus(duration);
            } catch (DateTimeParseException ex) {
                log.error(
                        ""Failed to parse the amount duration '{}' to shift ""
                        + ""(see https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html#parse-java.lang.CharSequence-) "",
                        amountToShift, ex); // $NON-NLS-1$
            }
        }
        String dateString;
        if (formatter != null) {
            dateString = zonedDateTimeToShift.format(formatter);
        } else {
            dateString = String.valueOf(zonedDateTimeToShift.toInstant().toEpochMilli());
        }

        if (!StringUtils.isEmpty(variableName)) {
            JMeterVariables vars = getVariables();
            if (vars != null) {// vars will be null on TestPlan
                vars.put(variableName, dateString);
            }
        }
        return dateString;
    }",,
jmeter,14554,"log.debug(""Load configuration for graph '{}'"", graphId)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/config/ReportGeneratorConfiguration.java/#L231,"@Override
        public void initialize(String graphId,
                GraphConfiguration graphConfiguration)
                throws ConfigurationException {
            
---------------Reference log start----------------
log.debug(""Load configuration for graph '{}'"", graphId)
---------------Reference log end----------------

            // Get the property defining whether the graph have to
            // filter controller samples
            boolean excludeControllers = getRequiredProperty(
                    props,
                    getGraphPropertyKey(graphId,
                            GRAPH_KEY_EXCLUDE_CONTROLLERS),
                    GRAPH_KEY_EXCLUDE_CONTROLLERS_DEFAULT,
                    Boolean.class);
            graphConfiguration
                    .setExcludeControllers(excludeControllers);

            // Get the property defining the title of the graph
            String title = getRequiredProperty(props,
                    getGraphPropertyKey(graphId, GRAPH_KEY_TITLE),
                    GRAPH_KEY_TITLE_DEFAULT, String.class);
            graphConfiguration.setTitle(title);

            // Get the property defining the class name
            String className = getRequiredProperty(
                    props,
                    getGraphPropertyKey(graphId,
                            SUBCONF_KEY_CLASSNAME), """",
                    String.class);
            log.debug(""Using class:'{}' for graph:'{}' with id:'{}'"", className, title, graphId);
            graphConfiguration.setClassName(className);

        }",,
jmeter,14570,"LOG.debug(""sort(): "" + inputSampleCount.longValue() + "" samples read from input, "" + chunkedSampleCount.longValue() + "" samples written to chunk files"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/processor/ExternalSampleSorter.java/#L305,"@Override
    public void stopConsuming() {
        if (!samples.isEmpty()) {
            chunks.add(sortAndDump(samples, sampleMetadata));
        }
        if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""sort(): "" + inputSampleCount.longValue() + "" samples read from input, "" + chunkedSampleCount.longValue() + "" samples written to chunk files"")
---------------Reference log end----------------
            if (inputSampleCount.get() != chunkedSampleCount.get()) {
                LOG.error(""Failure! Number of samples read from input and written to chunk files differ"");
            } else {
                LOG.info(""dumping of samples chunk succeeded."");
            }
        }
        super.setProducedMetadata(sampleMetadata, 0);
        super.startProducing();
        sortFilesParallel(chunks, sampleMetadata, this);
        super.stopProducing();
        if (this.pool != null) {
            this.pool.shutdown();
        }
        if (!getWorkingDirectory().delete()) {
            LOG.warn(""Was not able to delete folder {}"", getWorkingDirectory());
        }
    }",,
jmeter,14029,"log.warn(""Exception invalidating socketOutputStream connected to graphite server {}:{}"", socketConnectionInfos.getHost(), socketConnectionInfos.getPort(), e1)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/graphite/TextGraphiteMetricsSender.java/#L131,"private void writeMetrics(List<MetricTuple> currentMetrics) {
        SocketOutputStream out = null;
        try {
            out = socketOutputStreamPool.borrowObject(socketConnectionInfos);
            // pw is not closed as it would close the underlying pooled out
            PrintWriter pw = new PrintWriter(new OutputStreamWriter(out, CHARSET_NAME), false);
            for (MetricTuple metric : currentMetrics) {
                pw.printf(""%s %s %d%n"", metric.name, metric.value, metric.timestamp);
            }
            pw.flush();
            if (log.isDebugEnabled()) {
                log.debug(""Wrote {} metrics"", currentMetrics.size());
            }
            if (pw.checkError()) {
                socketOutputStreamPool.invalidateObject(socketConnectionInfos, out);
                log.error(""IO Errors writing to Graphite, some data will be lost"");
            } else {
                socketOutputStreamPool.returnObject(socketConnectionInfos, out);
            }
        } catch (Exception e) {
            // if there was an error, we might miss some data. for now, drop those try to keep going.
            if (out != null) {
                try {
                    socketOutputStreamPool.invalidateObject(socketConnectionInfos, out);
                } catch (Exception e1) {
                    
---------------Reference log start----------------
log.warn(""Exception invalidating socketOutputStream connected to graphite server {}:{}"", socketConnectionInfos.getHost(), socketConnectionInfos.getPort(), e1)
---------------Reference log end----------------
                }
            }
            log.error(""Error writing to Graphite: {}"", e.getMessage(), e);
        }
    }",,
jmeter,13503,"log.warn(""{} Exception while writing error"", port, e)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/Proxy.java/#L583,"private void writeErrorToClient(String message) {
        try {
            OutputStream sockOut = clientSocket.getOutputStream();
            DataOutputStream out = new DataOutputStream(sockOut);
            out.writeBytes(message);
            out.flush();
        } catch (Exception e) {
            
---------------Reference log start----------------
log.warn(""{} Exception while writing error"", port, e)
---------------Reference log end----------------
        }
    }",,
jmeter,14350,"log.warn(""Error trying to find XML terminator. {}"", e.toString())",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/reporters/ResultCollector.java/#L518,"private static boolean trimLastLine(String filename) {
        try (RandomAccessFile raf = new RandomAccessFile(filename, ""rw"")){ // $NON-NLS-1$
            long len = raf.length();
            if (len < MIN_XML_FILE_LEN) {
                return false;
            }
            raf.seek(len - TESTRESULTS_END.length() - 10);
            String line;
            long pos = raf.getFilePointer();
            int end = 0;
            while ((line = raf.readLine()) != null)// reads to end of line OR end of file
            {
                end = line.indexOf(TESTRESULTS_END);
                if (end >= 0) // found the string
                {
                    break;
                }
                pos = raf.getFilePointer();
            }
            if (line == null) {
                log.warn(""Unexpected EOF trying to find XML end marker in {}"", filename);
                return false;
            }
            raf.setLength(pos + end);// Truncate the file
        } catch (FileNotFoundException e) {
            return false;
        } catch (IOException e) {
            if (log.isWarnEnabled()) {
                
---------------Reference log start----------------
log.warn(""Error trying to find XML terminator. {}"", e.toString())
---------------Reference log end----------------
            }
            return false;
        }
        return true;
    }",,
jmeter,14708,"log.error(""samplePause called twice"", new Throwable(INVALID_CALL_SEQUENCE_MSG))",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/SampleResult.java/#L1157,"public void samplePause() {
        if (pauseTime != 0) {
            
---------------Reference log start----------------
log.error(""samplePause called twice"", new Throwable(INVALID_CALL_SEQUENCE_MSG))
---------------Reference log end----------------
        }
        pauseTime = currentTimeInMillis();
    }",,
jmeter,15077,"log.warn(""Cannot parse timestamp: '{}', will try following formats {}"", text, Arrays.asList(DATE_FORMAT_STRINGS))",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/save/CSVSaveService.java/#L215,"@SuppressWarnings(""JdkObsolete"")
    private static SampleEvent makeResultFromDelimitedString(
            final String[] parts,
            final SampleSaveConfiguration saveConfig, // may be updated
            final long lineNumber) {

        SampleResult result = null;
        String hostname = """";// $NON-NLS-1$
        long timeStamp = 0;
        long elapsed = 0;
        String text = null;
        String field = null; // Save the name for error reporting
        int i = 0;
        try {
            if (saveConfig.saveTimestamp()) {
                field = TIME_STAMP;
                text = parts[i++];
                if (saveConfig.printMilliseconds()) {
                    try {
                        timeStamp = Long.parseLong(text); // see if this works
                    } catch (NumberFormatException e) { // it did not, let's try some other formats
                        
---------------Reference log start----------------
log.warn(""Cannot parse timestamp: '{}', will try following formats {}"", text, Arrays.asList(DATE_FORMAT_STRINGS))
---------------Reference log end----------------
                        boolean foundMatch = false;
                        for(String fmt : DATE_FORMAT_STRINGS) {
                            SimpleDateFormat dateFormat = new SimpleDateFormat(fmt);
                            dateFormat.setLenient(false);
                            try {
                                Date stamp = dateFormat.parse(text);
                                timeStamp = stamp.getTime();
                                log.warn(""Setting date format to: {}"", fmt);
                                saveConfig.setDateFormat(fmt);
                                foundMatch = true;
                                break;
                            } catch (ParseException pe) {
                                log.info(""{} did not match {}, trying next date format"", text, fmt);
                            }
                        }
                        if (!foundMatch) {
                            throw new ParseException(""No date-time format found matching ""+text,-1);
                        }
                    }
                } else if (saveConfig.strictDateFormatter() != null) {
                    Date stamp = saveConfig.strictDateFormatter().parse(text);
                    timeStamp = stamp.getTime();
                } else { // can this happen?
                    final String msg = ""Unknown timestamp format"";
                    log.warn(msg);
                    throw new JMeterError(msg);
                }
            }

            if (saveConfig.saveTime()) {
                field = CSV_ELAPSED;
                text = parts[i++];
                elapsed = Long.parseLong(text);
            }

            if (saveConfig.saveSampleCount()) {
                @SuppressWarnings(""deprecation"")
                StatisticalSampleResult sampleResult = new StatisticalSampleResult(timeStamp, elapsed);
                result = sampleResult;
            } else {
                result = new SampleResult(timeStamp, elapsed);
            }

            if (saveConfig.saveLabel()) {
                field = LABEL;
                text = parts[i++];
                result.setSampleLabel(text);
            }
            if (saveConfig.saveCode()) {
                field = RESPONSE_CODE;
                text = parts[i++];
                result.setResponseCode(text);
            }

            if (saveConfig.saveMessage()) {
                field = RESPONSE_MESSAGE;
                text = parts[i++];
                result.setResponseMessage(text);
            }

            if (saveConfig.saveThreadName()) {
                field = THREAD_NAME;
                text = parts[i++];
                result.setThreadName(text);
            }

            if (saveConfig.saveDataType()) {
                field = DATA_TYPE;
                text = parts[i++];
                result.setDataType(text);
            }

            if (saveConfig.saveSuccess()) {
                field = SUCCESSFUL;
                text = parts[i++];
                result.setSuccessful(Boolean.valueOf(text));
            }

            if (saveConfig.saveAssertionResultsFailureMessage()) {
                i++;
                // TODO - should this be restored?
            }

            if (saveConfig.saveBytes()) {
                field = CSV_BYTES;
                text = parts[i++];
                result.setBytes(Long.parseLong(text));
            }

            if (saveConfig.saveSentBytes()) {
                field = CSV_SENT_BYTES;
                text = parts[i++];
                result.setSentBytes(Long.parseLong(text));
            }

            if (saveConfig.saveThreadCounts()) {
                field = CSV_THREAD_COUNT1;
                text = parts[i++];
                result.setGroupThreads(Integer.parseInt(text));

                field = CSV_THREAD_COUNT2;
                text = parts[i++];
                result.setAllThreads(Integer.parseInt(text));
            }

            if (saveConfig.saveUrl()) {
                i++;
                // TODO: should this be restored?
            }

            if (saveConfig.saveFileName()) {
                field = CSV_FILENAME;
                text = parts[i++];
                result.setResultFileName(text);
            }
            if (saveConfig.saveLatency()) {
                field = CSV_LATENCY;
                text = parts[i++];
                result.setLatency(Long.parseLong(text));
            }

            if (saveConfig.saveEncoding()) {
                field = CSV_ENCODING;
                text = parts[i++];
                result.setEncodingAndType(text);
            }

            if (saveConfig.saveSampleCount()) {
                field = CSV_SAMPLE_COUNT;
                text = parts[i++];
                result.setSampleCount(Integer.parseInt(text));
                field = CSV_ERROR_COUNT;
                text = parts[i++];
                result.setErrorCount(Integer.parseInt(text));
            }

            if (saveConfig.saveHostname()) {
                field = CSV_HOSTNAME;
                hostname = parts[i++];
            }

            if (saveConfig.saveIdleTime()) {
                field = CSV_IDLETIME;
                text = parts[i++];
                result.setIdleTime(Long.parseLong(text));
            }
            if (saveConfig.saveConnectTime()) {
                field = CSV_CONNECT_TIME;
                text = parts[i++];
                result.setConnectTime(Long.parseLong(text));
            }

            if (i + saveConfig.getVarCount() < parts.length) {
                log.warn(""Line: {}. Found {} fields, expected {}. Extra fields have been ignored."", lineNumber,
                        parts.length, i);
            }

        } catch (NumberFormatException | ParseException e) {
            if (log.isWarnEnabled()) {
                log.warn(""Error parsing field '{}' at line {}. {}"", field, lineNumber, e.toString());
            }
            throw new JMeterError(e);
        } catch (ArrayIndexOutOfBoundsException e) {
            log.warn(""Insufficient columns to parse field '{}' at line {}"", field, lineNumber);
            throw new JMeterError(e);
        }
        return new SampleEvent(result, """", hostname);
    }",,
jmeter,13679,"log.warn(""Existing AuthManager {} superseded by {}"", mgr.getName(), value.getName())",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L916,"public void setAuthManager(AuthManager value) {
        AuthManager mgr = getAuthManager();
        if (mgr != null) {
            if(log.isWarnEnabled()) {
                
---------------Reference log start----------------
log.warn(""Existing AuthManager {} superseded by {}"", mgr.getName(), value.getName())
---------------Reference log end----------------
            }
        }
        setProperty(new TestElementProperty(AUTH_MANAGER, value));
    }",,
jmeter,14630,"log.debug(""Test Ended on {}"", host)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/AsynchSampleSender.java/#L103,"@Override
    public void testEnded(String host) {
        
---------------Reference log start----------------
log.debug(""Test Ended on {}"", host)
---------------Reference log end----------------
        try {
            listener.testEnded(host);
            queue.put(FINAL_EVENT);
        } catch (Exception ex) {
            log.warn(""testEnded(host)"", ex);
        }
        if (queueWaits > 0) {
            log.info(""QueueWaits: {}; QueueWaitTime: {} (nanoseconds)"", queueWaits, queueWaitTime);
        }
    }",,
jmeter,13918,"log.debug(""Wrote: "" + hexEncodedBinary)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/BinaryTCPClientImpl.java/#L93,"@Override
    public void write(OutputStream os, String hexEncodedBinary) throws IOException{
        os.write(hexStringToByteArray(hexEncodedBinary));
        os.flush();
        if(log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Wrote: "" + hexEncodedBinary)
---------------Reference log end----------------
        }
    }",,
jmeter,13337,"LOGGER.error(""File {} doesn't exist"", pathfileCookie)",error,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/gui/action/ParseCurlCommandAction.java/#L407,"private void createCookieManager(CookieManager cookieManager, Request request) {
        cookieManager.setProperty(TestElement.GUI_CLASS, CookiePanel.class.getName());
        cookieManager.setProperty(TestElement.NAME, ""HTTP CookieManager"");
        cookieManager.setProperty(TestElement.COMMENTS, getDefaultComment());
        if (!request.getCookies(request.getUrl()).isEmpty()) {
            for (Cookie c : request.getCookies(request.getUrl())) {
                cookieManager.getCookies().addItem(c);
            }
        }
        if (!request.getCookieInHeaders(request.getUrl()).isEmpty() && uploadCookiesCheckBox.isSelected()) {
            for (Cookie c : request.getCookieInHeaders(request.getUrl())) {
                cookieManager.getCookies().addItem(c);
            }
        }
        if (!request.getFilepathCookie().isEmpty()) {
            String pathfileCookie=request.getFilepathCookie();
            File file = new File(pathfileCookie);
            if (file.isFile() && file.exists()) {
                try {
                    cookieManager.addFile(pathfileCookie);
                } catch (IOException e) {
                    LOGGER.error(""Failed to read from File {}"", pathfileCookie, e);
                    throw new IllegalArgumentException(""Failed to read from File "" + pathfileCookie);
                }
            } else {
                
---------------Reference log start----------------
LOGGER.error(""File {} doesn't exist"", pathfileCookie)
---------------Reference log end----------------
                throw new IllegalArgumentException(""File "" + pathfileCookie + "" doesn't exist"");
            }
        }
    }",,
jmeter,14403,"LOGGER.error(""Error during html report generation: {}"", exception.getMessage(), exception)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/HtmlReportUI.java/#L215,"@Override
    public void actionPerformed(ActionEvent e) {
        switch (e.getActionCommand()) {
        case CREATE_REQUEST:
            try {
                reportArea.setText(GENERATING_REPORT_LABEL + ""\n"");
                reportLaunchButton.setIcon(runningIcon);
                new ReportGenerationWorker(reportLaunchButton).execute();
            } catch (Exception exception) {
                if (LOGGER.isErrorEnabled()) {
                    
---------------Reference log start----------------
LOGGER.error(""Error during html report generation: {}"", exception.getMessage(), exception)
---------------Reference log end----------------
                }
            }
            if (LOGGER.isDebugEnabled()) {
                LOGGER.debug(""CSV file path {}\nuser.properties file path: {}\nOutput directory file path: {}"",
                        csvFilePathTextField.getText(), userPropertiesFilePathTextField.getText(),
                        outputDirectoryPathTextField.getText());
            }
            break;
        case BROWSE_USER_PROPERTIES:
            userPropertiesFilePathTextField.setText(showFileChooser(userPropertiesFileButton.getParent(),
                    userPropertiesFilePathTextField, false, new String[] { "".properties"" }));
            break;
        case BROWSE_CSV:
            csvFilePathTextField.setText(showFileChooser(csvFileButton.getParent(), csvFilePathTextField, false,
                    new String[] { "".jtl"", "".csv"" }));
            break;
        case BROWSE_OUTPUT:
            outputDirectoryPathTextField.setText(
                    showFileChooser(outputDirectoryButton.getParent(), outputDirectoryPathTextField, true, null));
            break;
        default:
            break;
        }
    }",,
jmeter,15121,"log.error(""Exception invoking listener on threadFinished."", err)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/threads/RemoteThreadsListenerWrapper.java/#L62,"@Override
    public void threadFinished() {
        try {
            listener.threadFinished();
        } catch (RemoteException err) {
            
---------------Reference log start----------------
log.error(""Exception invoking listener on threadFinished."", err)
---------------Reference log end----------------
        }
    }",,
jmeter,14939,"log.info(""Truststore loaded OK from file"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/SSLManager.java/#L271,"protected KeyStore getTrustStore() {
        if (!truststoreLoaded) {

            truststoreLoaded=true;// we've tried ...

            String fileName = System.getProperty(SSL_TRUST_STORE);
            if (fileName == null) {
                return null;
            }
            log.info(""TrustStore Location: {}"", fileName);

            try {
                this.trustStore = KeyStore.getInstance(""JKS"");
                log.info(""TrustStore created OK, Type: JKS"");
            } catch (Exception e) {
                this.trustStore = null;
                throw new RuntimeException(""Problem creating truststore: ""+e.getMessage(), e);
            }

            try {
                File initStore = new File(fileName);

                if (initStore.exists()) {
                    try (InputStream fis = new FileInputStream(initStore)) {
                        this.trustStore.load(fis, null);
                        
---------------Reference log start----------------
log.info(""Truststore loaded OK from file"")
---------------Reference log end----------------
                    }
                } else {
                    log.warn(""Truststore file not found, loading empty truststore"");
                    this.trustStore.load(null, null);
                }
            } catch (Exception e) {
                throw new RuntimeException(""Can't load TrustStore: "" + e.getMessage(), e);
            }
        }

        return this.trustStore;
    }",,
jmeter,14575,"LOG.debug(""sortAndDump(): in "" + (System.currentTimeMillis() - start) / 1000f + "" s. Sorted  "" + samples.size() + "" samples."")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/processor/ExternalSampleSorter.java/#L340,"private File sortAndDump(final List<Sample> samples,
            final SampleMetadata sampleMetadata) {
        long start = 0;
        if (LOG.isDebugEnabled()) {
            LOG.debug(""sortAndDump(): Sorting "" + samples.size()
                    + "" samples..."");
            start = System.currentTimeMillis();
        }
        final List<Sample> sortedSamples = sortSamplesParallel(samples);
        if (sortedSamples.size() != samples.size()) {
            throw new SampleException(""sort failed ! "" + sortedSamples.size()
                    + "" != "" + samples.size());
        }
        if (LOG.isDebugEnabled()) {
            
---------------Reference log start----------------
LOG.debug(""sortAndDump(): in "" + (System.currentTimeMillis() - start) / 1000f + "" s. Sorted  "" + samples.size() + "" samples."")
---------------Reference log end----------------
        }
        File out = getChunkFile();
        if (LOG.isDebugEnabled()) {
            LOG.debug(""sortAndDump(): Dumping chunk "" + out);
            start = System.currentTimeMillis();
        }
        try (CsvSampleWriter csvWriter = new CsvSampleWriter(out, sampleMetadata)){
            for (Sample sample : sortedSamples) {
                csvWriter.write(sample);
                chunkedSampleCount.incrementAndGet();
            }
        }
        if (LOG.isDebugEnabled()) {
            LOG.debug(""sortAndDump(): in "" + (System.currentTimeMillis() - start) / 1000f
                    + "" s : Dumped chunk "" + out.getAbsolutePath());
        }
        return out;
    }",,
jmeter,14206,"log.debug(""matchNumber({}) exceeds number of items found({}), default value will be used"", matchNumber, extractedValues.size())",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/extractor/json/jsonpath/JSONPostProcessor.java/#L190,"private void handleListResult(JMeterVariables vars, String[] defaultValues, final int i, final int matchNumber,
            String currentRefName, List<Object> extractedValues) {
        if (matchNumber < 0) {
            // Extract all
            int index = 1;
            StringBuilder concat =
                    new StringBuilder(getComputeConcatenation()
                            ? extractedValues.size() * 20
                            : 1);
            for (Object extractedObject : extractedValues) {
                String extractedString = stringify(extractedObject);
                vars.put(currentRefName + ""_"" + index,
                        extractedString); //$NON-NLS-1$
                if (getComputeConcatenation()) {
                    concat.append(extractedString)
                            .append(JSONPostProcessor.JSON_CONCATENATION_SEPARATOR);
                }
                index++;
            }
            if (getComputeConcatenation()) {
                concat.setLength(concat.length() - 1);
                vars.put(currentRefName + ALL_SUFFIX, concat.toString());
            }
            return;
        }
        if (matchNumber == 0) {
            // Random extraction
            int matchSize = extractedValues.size();
            int matchNr = JMeterUtils.getRandomInt(matchSize);
            placeObjectIntoVars(vars, currentRefName,
                    extractedValues, matchNr);
            return;
        }
        // extract at position
        if (matchNumber > extractedValues.size()) {
            if(log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""matchNumber({}) exceeds number of items found({}), default value will be used"", matchNumber, extractedValues.size())
---------------Reference log end----------------
            }
            vars.put(currentRefName, defaultValues[i]);
        } else {
            placeObjectIntoVars(vars, currentRefName, extractedValues, matchNumber - 1);
        }
    }",,
jmeter,14616,"log.debug(""End of template processing"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/HtmlTemplateExporter.java/#L463,"@Override
    public void export(SampleContext context, File file,
            ReportGeneratorConfiguration configuration) throws ExportException {
        Validate.notNull(context, MUST_NOT_BE_NULL, ""context"");
        Validate.notNull(file, MUST_NOT_BE_NULL, ""file"");
        Validate.notNull(configuration, MUST_NOT_BE_NULL, ""configuration"");

        log.debug(""Start template processing"");

        // Create data context and populate it
        DataContext dataContext = new DataContext();

        // Get the configuration of the current exporter
        final ExporterConfiguration exportCfg =
                configuration.getExportConfigurations().get(getName());

        // Get template directory property value
        File templateDirectory = getPropertyFromConfig(
                exportCfg,
                TEMPLATE_DIR,
                new File(JMeterUtils.getJMeterBinDir(), TEMPLATE_DIR_NAME_DEFAULT),
                File.class);
        if (!templateDirectory.isDirectory()) {
            String message = String.format(
                    ""\""%s\"" is not a valid template directory"",
                    templateDirectory.getAbsolutePath());
            log.error(message);
            throw new ExportException(message);
        }

        // Get output directory property value
        File outputDir = getPropertyFromConfig(exportCfg, OUTPUT_DIR,
                new File(JMeterUtils.getJMeterBinDir(), OUTPUT_DIR_NAME_DEFAULT), File.class);
        String globallyDefinedOutputDir = JMeterUtils.getProperty(JMeter.JMETER_REPORT_OUTPUT_DIR_PROPERTY);
        if(!StringUtils.isEmpty(globallyDefinedOutputDir)) {
            outputDir = new File(globallyDefinedOutputDir);
        }

        JOrphanUtils.canSafelyWriteToFolder(outputDir, this::htmlReportFileFilter);

        if (log.isInfoEnabled()) {
            log.info(""Will generate dashboard in folder: {}"", outputDir.getAbsolutePath());
        }

        // Add a flag defining if only sample series are filtered to the context
        final boolean filtersOnlySampleSeries = exportCfg.filtersOnlySampleSeries();
        addToContext(
                DATA_CTX_FILTERS_ONLY_SAMPLE_SERIES,
                filtersOnlySampleSeries,
                dataContext);

        // Add the series filter to the context
        final String seriesFilter = exportCfg.getSeriesFilter();
        Pattern filterPattern = null;
        if (StringUtils.isNotBlank(seriesFilter)) {
            try {
                filterPattern = Pattern.compile(seriesFilter);
            } catch (PatternSyntaxException ex) {
                log.error(""Invalid series filter: '{}', {}"", seriesFilter, ex.getDescription());
            }
        }
        addToContext(DATA_CTX_SERIES_FILTER, seriesFilter, dataContext);

        // Add the flag defining whether only controller series are displayed
        final boolean showControllerSeriesOnly = exportCfg.showControllerSeriesOnly();
        addToContext(
                DATA_CTX_SHOW_CONTROLLERS_ONLY,
                showControllerSeriesOnly,
                dataContext);

        JsonizerVisitor jsonizer = new JsonizerVisitor();
        Map<String, Object> storedData = context.getData();

        // Add begin date consumer result to the data context
        addResultToContext(
                ReportGenerator.BEGIN_DATE_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add end date summary consumer result to the data context
        addResultToContext(
                ReportGenerator.END_DATE_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add Apdex summary consumer result to the data context
        addResultToContext(
                ReportGenerator.APDEX_SUMMARY_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add errors summary consumer result to the data context
        addResultToContext(
                ReportGenerator.ERRORS_SUMMARY_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add requests summary consumer result to the data context
        addResultToContext(
                ReportGenerator.REQUESTS_SUMMARY_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add statistics summary consumer result to the data context
        addResultToContext(
                ReportGenerator.STATISTICS_SUMMARY_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Add Top 5 errors by sampler consumer result to the data context
        addResultToContext(
                ReportGenerator.TOP5_ERRORS_BY_SAMPLER_CONSUMER_NAME, storedData, dataContext, jsonizer);

        // Collect graph results from sample context and transform them into
        // Json strings to inject in the data context
        ExtraOptionsResultCustomizer customizer = new ExtraOptionsResultCustomizer();
        EmptyGraphChecker checker =
                new EmptyGraphChecker(filtersOnlySampleSeries, showControllerSeriesOnly, filterPattern);
        Map<String, GraphConfiguration> mapConfiguration = new HashMap<>();
        DataContext customGraphs = new DataContext();

        for (Map.Entry<String, GraphConfiguration> graphEntry : configuration.getGraphConfigurations().entrySet()) {
            final String graphId = graphEntry.getKey();
            final GraphConfiguration graphConfiguration = graphEntry.getValue();

            // Initialize customizer and checker
            customizer.setExtraOptions(exportCfg.getGraphExtraConfigurations().get(graphId));
            checker.setExcludesControllers(graphConfiguration.excludesControllers());
            checker.setGraphId(graphId);
            mapConfiguration.put(graphId, graphConfiguration);
            if (graphId.startsWith(CUSTOM_GRAPH_PREFIX)) {
                addResultToContext(
                        graphId, storedData, customGraphs, jsonizer, customizer, checker);
            } else {
                // Export graph data
                addResultToContext(
                        graphId, storedData, dataContext, jsonizer, customizer, checker);
            }
        }
        dataContext.put(""graphConfigurations"", mapConfiguration);
        dataContext.put(""customsGraphsData"", customGraphs);

        // Replace the begin date with its formatted string and store the old timestamp
        long oldTimestamp = formatTimestamp(
                ReportGenerator.BEGIN_DATE_CONSUMER_NAME, dataContext);

        // Replace the end date with its formatted string
        formatTimestamp(ReportGenerator.END_DATE_CONSUMER_NAME, dataContext);

        // Add time zone offset (that matches the begin date) to the context
        TimeZone timezone = TimeZone.getDefault();
        addToContext(
                DATA_CTX_TIMEZONE_OFFSET,
                timezone.getOffset(oldTimestamp),
                dataContext);

        // Add report title to the context
        if (StringUtils.isNotEmpty(configuration.getReportTitle())) {
            dataContext.put(DATA_CTX_REPORT_TITLE, StringEscapeUtils.escapeHtml4(configuration.getReportTitle()));
        }

        // Add the test file name to the context
        addToContext(DATA_CTX_TESTFILE, file.getName(), dataContext);

        // Add the overall filter property to the context
        addToContext(DATA_CTX_OVERALL_FILTER, configuration.getSampleFilter(), dataContext);

        // Walk template directory to copy files and process templated ones
        Configuration templateCfg = new Configuration(Configuration.VERSION_2_3_30);
        try {
            templateCfg.setDirectoryForTemplateLoading(templateDirectory);
            templateCfg.setTemplateExceptionHandler(TemplateExceptionHandler.RETHROW_HANDLER);
            if (log.isInfoEnabled()) {
                log.info(""Report will be generated in: {}, creating folder structure"", outputDir.getAbsolutePath());
            }
            FileUtils.forceMkdir(outputDir);
            TemplateVisitor visitor = new TemplateVisitor(
                    templateDirectory.toPath(),
                    outputDir.toPath(),
                    templateCfg,
                    dataContext);
            Files.walkFileTree(templateDirectory.toPath(), visitor);
        } catch (IOException ex) {
            throw new ExportException(""Unable to process template files."", ex);
        }

        
---------------Reference log start----------------
log.debug(""End of template processing"")
---------------Reference log end----------------
    }
    }",,
jmeter,14295,"slf4jLogger.info(message, throwable)",info,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/logging/Slf4jLogkitLogger.java/#L136,"@Override
    public void log(org.apache.log.Priority priority, String message, Throwable throwable) {
        if (priority == org.apache.log.Priority.FATAL_ERROR) {
            slf4jLogger.error(message, throwable);
        } else if (priority == org.apache.log.Priority.ERROR) {
            slf4jLogger.error(message, throwable);
        } else if (priority == org.apache.log.Priority.WARN) {
            slf4jLogger.warn(message, throwable);
        } else if (priority == org.apache.log.Priority.INFO) {
            
---------------Reference log start----------------
slf4jLogger.info(message, throwable)
---------------Reference log end----------------
        } else if (priority == org.apache.log.Priority.DEBUG) {
            slf4jLogger.debug(message, throwable);
        }
    }",,
jmeter,15004,"log.info(""Security Provider {} ({}) is installed at position {}"", provider.getClass().getSimpleName(), provider.getName(), Integer.valueOf(installedPosition))",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/SecurityProviderLoader.java/#L70,"public static void addSecurityProvider(String securityProviderConfig) {
        Matcher matcher = CONFIGURATION_REGEX.matcher(securityProviderConfig);

        if (matcher.matches()) {
            final String classname = matcher.group(""classname"");
            final int position = Integer.parseInt(StringUtils.defaultString(matcher.group(""position""), ""0""));
            final String config = matcher.group(""config"");

            try {
                @SuppressWarnings(""unchecked"")
                Class<Provider> providerClass = (Class<Provider>) Class.forName(classname);

                Provider provider = null;

                if (config != null) {
                    provider = tryConstructorWithString(providerClass, config);
                }

                if (provider == null) {
                    provider = providerClass.getDeclaredConstructor().newInstance();
                }
                int installedPosition = Security.insertProviderAt(provider, position);

                
---------------Reference log start----------------
log.info(""Security Provider {} ({}) is installed at position {}"", provider.getClass().getSimpleName(), provider.getName(), Integer.valueOf(installedPosition))
---------------Reference log end----------------
            } catch (Exception exception) {
                String message = String.format(""Security Provider '%s' could not be installed."", classname);
                log.error(message, exception);
                System.err.print(message);
                System.err.println("" - see the log for more information."");
            }
        }
    }",,
jmeter,14985,"log.debug(""Using threadLocal SSL context for: {}"", Thread.currentThread().getName())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JsseSSLManager.java/#L179,"public SSLContext getContext() throws GeneralSecurityException {
        if (SHARED_SESSION_CONTEXT) {
            if (log.isDebugEnabled()){
                log.debug(""Using shared SSL context for: {}"", Thread.currentThread().getName());
            }
            return this.defaultContext;
        }

        SSLContext sslContext = this.threadlocal.get();
        if (sslContext == null) {
            if (log.isDebugEnabled()){
                log.debug(""Creating threadLocal SSL context for: {}"", Thread.currentThread().getName());
            }
            sslContext = createContext();
            this.threadlocal.set(sslContext);
        }
        if (log.isDebugEnabled()){
            
---------------Reference log start----------------
log.debug(""Using threadLocal SSL context for: {}"", Thread.currentThread().getName())
---------------Reference log end----------------
        }
        return sslContext;
    }",,
jmeter,14992,"log.debug(""WrappedX509Manager: getCertificateChain({})"", alias)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JsseSSLManager.java/#L340,"@Override
        public X509Certificate[] getCertificateChain(String alias) {
            
---------------Reference log start----------------
log.debug(""WrappedX509Manager: getCertificateChain({})"", alias)
---------------Reference log end----------------
            return this.store.getCertificateChain(alias);
        }",,
jmeter,13719,"log.error(""Error reading log file"", ioe)",error,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/util/accesslog/TCLogParser.java/#L265,"protected int parse(BufferedReader breader, TestElement el, int parseCount) {
        int actualCount = 0;
        String line = null;
        try {
            // read one line at a time using
            // BufferedReader
            line = breader.readLine();
            while (line != null) {
                if (line.length() > 0) {
                    actualCount += this.parseLine(line, el);
                }
                // we check the count to see if we have exceeded
                // the number of lines to parse. There's no way
                // to know where to stop in the file. Therefore
                // we use break to escape the while loop when
                // we've reached the count.
                if (parseCount != -1 && actualCount >= parseCount) {
                    break;
                }
                line = breader.readLine();
            }
            if (line == null) {
                breader.close();
                this.READER = null;
            }
        } catch (IOException ioe) {
            
---------------Reference log start----------------
log.error(""Error reading log file"", ioe)
---------------Reference log end----------------
        }
        return actualCount;
    }",,
jmeter,13960,"log.debug(""Setting transaction isolation: {}@{}"", isolation, System.identityHashCode(dsc))",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jdbc/src/main/java/org/apache/jmeter/protocol/jdbc/config/DataSourceElement.java/#L368,"public Connection getConnection() throws SQLException {
            BasicDataSource dsc = getConfiguredDataSource();
            Connection conn=dsc.getConnection();
            int isolation = DataSourceElementBeanInfo.getTransactionIsolationMode(getTransactionIsolation());
            if (isolation >= 0 && conn.getTransactionIsolation() != isolation) {
                try {
                    // make sure setting the new isolation mode is done in an auto committed transaction
                    conn.setTransactionIsolation(isolation);
                    
---------------Reference log start----------------
log.debug(""Setting transaction isolation: {}@{}"", isolation, System.identityHashCode(dsc))
---------------Reference log end----------------
                } catch (SQLException ex) {
                    log.error(""Could not set transaction isolation: {}@{}"",
                            isolation, System.identityHashCode(dsc), ex);
                }
            }
            return conn;
        }",,
jmeter,14800,"log.info(""Unexported RemoteJMeterEngineImpl"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/RemoteJMeterEngineImpl.java/#L216,"@Override
    public void rexit() throws RemoteException {
        log.info(""Exiting"");
        // Bug 59400 - allow rexit() to return
        Thread et = new Thread(() -> {
            log.info(""Stopping the backing engine"");
            backingEngine.exit();
        });
        et.setDaemon(false);
        // Tidy up any objects we created
        Registry reg = LocateRegistry.getRegistry(
                RmiUtils.getRmiHost().getHostName(),
                this.rmiRegistryPort,
                RmiUtils.createClientSocketFactory());
        try {
            reg.unbind(JMETER_ENGINE_RMI_NAME);
        } catch (NotBoundException e) {
            log.warn(""{} is not bound"", JMETER_ENGINE_RMI_NAME, e);
        }
        log.info(""Unbound from registry"");
        try {
            UnicastRemoteObject.unexportObject(this, false);
        } catch (NoSuchObjectException e) {
            log.warn(""{} not longer exists"", this, e);
        }
        
---------------Reference log start----------------
log.info(""Unexported RemoteJMeterEngineImpl"")
---------------Reference log end----------------
        // Help with garbage control
        JMeterUtils.helpGC();
        et.start();
    }",,
jmeter,14230,"log.warn(""Error while generating result"")",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/extractor/RegexExtractor.java/#L160,"@Override
    public void process() {
        initTemplate();
        JMeterContext context = getThreadContext();
        SampleResult previousResult = context.getPreviousResult();
        if (previousResult == null) {
            return;
        }
        log.debug(""RegexExtractor processing result"");

        // Fetch some variables
        JMeterVariables vars = context.getVariables();
        String refName = getRefName();
        int matchNumber = getMatchNumber();

        final String defaultValue = getDefaultValue();
        if (defaultValue.length() > 0 || isEmptyDefaultValue()) {// Only replace default if it is provided or empty default value is explicitly requested
            vars.put(refName, defaultValue);
        }

        Perl5Matcher matcher = JMeterUtils.getMatcher();
        String regex = getRegex();
        Pattern pattern = null;
        try {
            pattern = JMeterUtils.getPatternCache().getPattern(regex, Perl5Compiler.READ_ONLY_MASK);
            List<MatchResult> matches = processMatches(pattern, regex, previousResult, matchNumber, vars);
            int prevCount = 0;
            String prevString = vars.get(refName + REF_MATCH_NR);
            if (prevString != null) {
                vars.remove(refName + REF_MATCH_NR);// ensure old value is not left defined
                try {
                    prevCount = Integer.parseInt(prevString);
                } catch (NumberFormatException nfe) {
                    log.warn(""Could not parse number: '{}'"", prevString);
                }
            }
            int matchCount=0;// Number of refName_n variable sets to keep
            try {
                MatchResult match;
                if (matchNumber >= 0) {// Original match behaviour
                    match = getCorrectMatch(matches, matchNumber);
                    if (match != null) {
                        vars.put(refName, generateResult(match));
                        saveGroups(vars, refName, match);
                    } else {
                        // refname has already been set to the default (if present)
                        removeGroups(vars, refName);
                    }
                } else // < 0 means we save all the matches
                {
                    removeGroups(vars, refName); // remove any single matches
                    matchCount = matches.size();
                    vars.put(refName + REF_MATCH_NR, Integer.toString(matchCount));// Save the count
                    for (int i = 1; i <= matchCount; i++) {
                        match = getCorrectMatch(matches, i);
                        if (match != null) {
                            final String refName_n = refName + UNDERSCORE + i;
                            vars.put(refName_n, generateResult(match));
                            saveGroups(vars, refName_n, match);
                        }
                    }
                }
                // Remove any left-over variables
                for (int i = matchCount + 1; i <= prevCount; i++) {
                    final String refName_n = refName + UNDERSCORE + i;
                    vars.remove(refName_n);
                    removeGroups(vars, refName_n);
                }
            } catch (RuntimeException e) {
                
---------------Reference log start----------------
log.warn(""Error while generating result"")
---------------Reference log end----------------
            }
        } catch (MalformedCachePatternException e) {
            log.error(""Error in pattern: '{}'"", regex);
        } finally {
            JMeterUtils.clearMatcherMemory(matcher, pattern);
        }
    }",,
jmeter,13844,"LOGGER.debug(""isBrowseOnly"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/sampler/JMSSampler.java/#L220,"private void handleBrowse(SampleResult res) throws JMSException {
        
---------------Reference log start----------------
LOGGER.debug(""isBrowseOnly"")
---------------Reference log end----------------
        StringBuilder sb = new StringBuilder(75);
        res.setSuccessful(true);
        sb.append(""Browse message on Send Queue "").append(sendQueue.getQueueName())
            .append("": "")
            .append(browseQueueDetails(sendQueue, res));
        res.setResponseData(sb.toString(), res.getDataEncodingWithDefault());
        res.setResponseCodeOK();
    }",,
jmeter,14687,"log.debug(""Test Started()"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/RemoteListenerWrapper.java/#L58,"@Override
    public void testStarted() {
        
---------------Reference log start----------------
log.debug(""Test Started()"")
---------------Reference log end----------------
        try {
            listener.testStarted();
        } catch (Error | RuntimeException ex) { // NOSONAR We want to have errors logged in log file
            log.error(""testStarted()"", ex);
            throw ex;
        } catch (Exception ex) {
            log.error(""testStarted()"", ex);
        }
    }",,
jmeter,13909,"log.debug(""{} : {}"", getClass(), ignored.getLocalizedMessage())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/java/src/main/java/org/apache/jmeter/protocol/java/sampler/BeanShellSampler.java/#L175,"@Override
    public boolean interrupt() {
        if (savedBsh != null) {
            try {
                savedBsh.evalNoLog(""interrupt()""); // $NON-NLS-1$
            } catch (JMeterException ignored) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""{} : {}"", getClass(), ignored.getLocalizedMessage())
---------------Reference log end----------------
                }
            }
            return true;
        }
        return false;
    }",,
jmeter,14729,"log.debug(""Read:{}"", line)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/services/FileServer.java/#L356,"public synchronized String readLine(String filename, boolean recycle,
            boolean ignoreFirstLine) throws IOException {
        FileEntry fileEntry = files.get(filename);
        if (fileEntry != null) {
            if (fileEntry.inputOutputObject == null) {
                fileEntry.inputOutputObject = createBufferedReader(fileEntry);
            } else if (!(fileEntry.inputOutputObject instanceof Reader)) {
                throw new IOException(""File "" + filename + "" already in use"");
            }
            BufferedReader reader = (BufferedReader) fileEntry.inputOutputObject;
            String line = reader.readLine();
            if (line == null && recycle) {
                reader.close();
                reader = createBufferedReader(fileEntry);
                fileEntry.inputOutputObject = reader;
                if (ignoreFirstLine) {
                    // read first line and forget
                    reader.readLine();//NOSONAR
                }
                line = reader.readLine();
            }
            
---------------Reference log start----------------
log.debug(""Read:{}"", line)
---------------Reference log end----------------
            return line;
        }
        throw new IOException(""File never reserved: ""+filename);
    }",,
jmeter,14205,"log.error(""Number of JSON Path variables must match number of default values and json-path expressions,"" + // $NON-NLS-1$
"" check you use separator ';' if you have many values"")",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/extractor/json/jsonpath/JSONPostProcessor.java/#L137,"private void validateSameLengthOfArguments(String[] refNames, String[] jsonPathExpressions,
            String[] defaultValues) {
        if (refNames.length != jsonPathExpressions.length ||
                refNames.length != defaultValues.length) {
            
---------------Reference log start----------------
log.error(""Number of JSON Path variables must match number of default values and json-path expressions,"" + // $NON-NLS-1$
"" check you use separator ';' if you have many values"")
---------------Reference log end----------------
            throw new IllegalArgumentException(JMeterUtils
                    .getResString(""jsonpp_error_number_arguments_mismatch_error"")); // $NON-NLS-1$
        }
    }",,
jmeter,15066,"log.info(""Using SaveService properties version {}"", propertiesVersion)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/save/SaveService.java/#L236,"private static void initProps() {
        // Load the alias properties
        try {
            Properties nameMap = loadProperties();
            try {
                fileVersion = checksum(nameMap);
            } catch (NoSuchAlgorithmException e) {
                log.error(""Can't compute checksum for saveservice properties file"", e);
                throw new JMeterError(""JMeter requires the checksum of saveservice properties file to continue"", e);
            }
            // now create the aliases
            for (Map.Entry<Object, Object> me : nameMap.entrySet()) {
                String key = (String) me.getKey();
                String val = (String) me.getValue();
                if (!key.startsWith(""_"")) { // $NON-NLS-1$
                    makeAlias(key, val);
                } else {
                    // process special keys
                    if (key.equalsIgnoreCase(""_version"")) { // $NON-NLS-1$
                        propertiesVersion = val;
                        
---------------Reference log start----------------
log.info(""Using SaveService properties version {}"", propertiesVersion)
---------------Reference log end----------------
                    } else if (key.equalsIgnoreCase(""_file_version"")) { // $NON-NLS-1$
                        log.info(""SaveService properties file version is now computed by a checksum,""
                                + ""the property _file_version is not used anymore and can be removed."");
                    } else if (key.equalsIgnoreCase(""_file_encoding"")) { // $NON-NLS-1$
                        fileEncoding = val;
                        log.info(""Using SaveService properties file encoding {}"", fileEncoding);
                    } else {
                        key = key.substring(1);// Remove the leading ""_""
                        registerConverter(key, val);
                    }
                }
            }
        } catch (IOException e) {
            log.error(""Bad saveservice properties file"", e);
            throw new JMeterError(""JMeter requires the saveservice properties file to continue"");
        }
    }",,
jmeter,14204,"log.error(""Error processing JSON content in {}, message: {}"", getName(), e.getLocalizedMessage(), e)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/extractor/json/jsonpath/JSONPostProcessor.java/#L91,"@Override
    public void process() {
        JMeterContext context = getThreadContext();
        JMeterVariables vars = context.getVariables();
        List<String> jsonResponses = extractJsonResponse(context, vars);
        String[] refNames = getRefNames().split(SEPARATOR);
        String[] jsonPathExpressions = getJsonPathExpressions().split(SEPARATOR);
        String[] defaultValues = getDefaultValues().split(SEPARATOR);
        int[] matchNumbers = getMatchNumbersAsInt(defaultValues.length);

        validateSameLengthOfArguments(refNames, jsonPathExpressions, defaultValues);

        for (int i = 0; i < jsonPathExpressions.length; i++) {
            int matchNumber = matchNumbers[i];
            String currentRefName = refNames[i].trim();
            String currentJsonPath = jsonPathExpressions[i].trim();
            clearOldRefVars(vars, currentRefName);
            try {
                if (jsonResponses.isEmpty()) {
                    handleEmptyResponse(vars, defaultValues, i, currentRefName);
                } else {
                    List<Object> extractedValues = extractValues(jsonResponses, currentJsonPath);
                    handleResult(vars, defaultValues, i, matchNumber, currentRefName, extractedValues);
                }
            } catch (Exception e) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.error(""Error processing JSON content in {}, message: {}"", getName(), e.getLocalizedMessage(), e)
---------------Reference log end----------------
                } else {
                    log.error(""Error processing JSON content in {}, message: {}"", getName(), e.getLocalizedMessage());
                }
                // if something goes wrong, add default value
                vars.put(currentRefName, defaultValues[i]);
            }
        }
    }",,
jmeter,14945,"log.warn(""Error document parsing."", e)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/Document.java/#L62,"public static String getTextFromDocument(byte[] document) {
        String errMissingTika = JMeterUtils.getResString(""view_results_response_missing_tika""); // $NON-NLS-1$
        String response = errMissingTika;
        Parser parser = new AutoDetectParser();
        ContentHandler handler = new BodyContentHandler(MAX_DOCUMENT_SIZE > 0 ? MAX_DOCUMENT_SIZE : -1); // -1 to disable the write limit
        Metadata metadata = new Metadata();
        ParseContext context = new ParseContext();
        InputStream stream = new ByteArrayInputStream(document); // open the stream
        try {
            parser.parse(stream, handler, metadata, context);
            response = handler.toString();
        } catch (Exception e) {
            response = e.toString();
            
---------------Reference log start----------------
log.warn(""Error document parsing."", e)
---------------Reference log end----------------
        } catch (NoClassDefFoundError e) {
            // put a warning if tika-app.jar missing (or some dependencies in only tika-core|parsers packages are using)
            if (!System.getProperty(""java.class.path"").contains(""tika-app"")) { // $NON-NLS-1$ $NON-NLS-2$
                log.warn(errMissingTika);
            } else {
                log.warn(errMissingTika, e);
            }
        } finally {
            try {
                stream.close(); // close the stream
            } catch (IOException ioe) {
                log.warn(""Error closing document stream"", ioe);// $NON-NLS-1$
            }
        }

        if (response.length() == 0 && document.length > 0) {
            log.warn(""Probably: {}"", errMissingTika);// $NON-NLS-1$
            response = errMissingTika;
        }
        return response;
    }",,
jmeter,14297,"slf4jLogger.error(message, throwable)",error,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/logging/Slf4jLogkitLogger.java/#L132,"@Override
    public void log(org.apache.log.Priority priority, String message, Throwable throwable) {
        if (priority == org.apache.log.Priority.FATAL_ERROR) {
            slf4jLogger.error(message, throwable);
        } else if (priority == org.apache.log.Priority.ERROR) {
            
---------------Reference log start----------------
slf4jLogger.error(message, throwable)
---------------Reference log end----------------
        } else if (priority == org.apache.log.Priority.WARN) {
            slf4jLogger.warn(message, throwable);
        } else if (priority == org.apache.log.Priority.INFO) {
            slf4jLogger.info(message, throwable);
        } else if (priority == org.apache.log.Priority.DEBUG) {
            slf4jLogger.debug(message, throwable);
        }
    }",,
jmeter,14313,"log.warn(""Problem deleting the keystore '"" + keystore + ""'"")",warn,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/exec/KeyToolUtils.java/#L226,"public static void generateProxyCA(File keystore, String password, int validity) throws IOException {
        File caCertCrt = new File(ROOT_CACERT_CRT);
        File caCertUsr = new File(ROOT_CACERT_USR);
        boolean fileExists = false;
        if (!keystore.delete() && keystore.exists()) {
            
---------------Reference log start----------------
log.warn(""Problem deleting the keystore '"" + keystore + ""'"")
---------------Reference log end----------------
            fileExists = true;
        }
        if (!caCertCrt.delete() && caCertCrt.exists()) {
            log.warn(""Problem deleting the certificate file '"" + caCertCrt + ""'"");
            fileExists = true;
        }
        if (!caCertUsr.delete() && caCertUsr.exists()) {
            log.warn(""Problem deleting the certificate file '"" + caCertUsr + ""'"");
            fileExists = true;
        }
        if (fileExists) {
            log.warn(""If problems occur when recording SSL, delete the files manually and retry."");
        }
        // Create the self-signed keypairs
        KeyToolUtils.genkeypair(keystore, ROOTCA_ALIAS, password, validity, DNAME_ROOT_CA_KEY, ""bc:c"");
        KeyToolUtils.genkeypair(keystore, INTERMEDIATE_CA_ALIAS, password, validity, DNAME_INTERMEDIATE_CA_KEY, ""bc:c"");

        // Create cert for CA using root
        ByteArrayOutputStream certReqOut = new ByteArrayOutputStream();
        // generate the request
        KeyToolUtils.keytool(""-certreq"", keystore, password, INTERMEDIATE_CA_ALIAS, null, certReqOut);

        // generate the certificate and store in output file
        InputStream certReqIn = new ByteArrayInputStream(certReqOut.toByteArray());
        ByteArrayOutputStream genCertOut = new ByteArrayOutputStream();
        KeyToolUtils.keytool(""-gencert"", keystore, password, ROOTCA_ALIAS, certReqIn, genCertOut, ""-ext"", ""BC:0"");

        // import the signed CA cert into the store (root already there) - both are needed to sign the domain certificates
        InputStream genCertIn = new ByteArrayInputStream(genCertOut.toByteArray());
        KeyToolUtils.keytool(""-importcert"", keystore, password, INTERMEDIATE_CA_ALIAS, genCertIn, null);

        // Export the Root CA for Firefox/Chrome/IE
        KeyToolUtils.keytool(""-exportcert"", keystore, password, ROOTCA_ALIAS, null, null, ""-rfc"", ""-file"", ROOT_CACERT_CRT);
        // Copy for Opera
        if(caCertCrt.exists() && caCertCrt.canRead()) {
            FileUtils.copyFile(caCertCrt, caCertUsr);
        } else {
            log.warn(""Failed creating ""+caCertCrt.getAbsolutePath()+"", check 'keytool' utility in path is available and points to a JDK >= 7"");
        }
    }",,
jmeter,14347,"log.warn(""Error creating directories for {}"", pdir)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/reporters/ResultCollector.java/#L470,"private static PrintWriter getFileWriter(final String pFilename, SampleSaveConfiguration saveConfig)
            throws IOException {
        if (pFilename == null || pFilename.length() == 0) {
            return null;
        }
        if(log.isDebugEnabled()) {
            log.debug(""Getting file: {} in thread {}"", pFilename, Thread.currentThread().getName());
        }
        String filename = FileServer.resolveBaseRelativeName(pFilename);
        filename = new File(filename).getCanonicalPath(); // try to ensure uniqueness (Bug 60822)
        FileEntry fe = files.get(filename);
        PrintWriter writer = null;
        boolean trimmed = true;

        if (fe == null) {
            if (saveConfig.saveAsXml()) {
                trimmed = trimLastLine(filename);
            } else {
                trimmed = new File(filename).exists();
            }
            // Find the name of the directory containing the file
            // and create it - if there is one
            File pdir = new File(filename).getParentFile();
            if (pdir != null) {
                // returns false if directory already exists, so need to check again
                if(pdir.mkdirs()){
                    if (log.isInfoEnabled()) {
                        log.info(""Folder at {} was created"", pdir.getAbsolutePath());
                    }
                } // else if might have been created by another process so not a problem
                if (!pdir.exists()){
                    
---------------Reference log start----------------
log.warn(""Error creating directories for {}"", pdir)
---------------Reference log end----------------
                }
            }
            writer = new PrintWriter(new OutputStreamWriter(new BufferedOutputStream(new FileOutputStream(filename,
                    trimmed)), SaveService.getFileEncoding(StandardCharsets.UTF_8.name())), SAVING_AUTOFLUSH);
            if(log.isDebugEnabled()) {
                log.debug(""Opened file: {} in thread {}"", filename, Thread.currentThread().getName());
            }
            files.put(filename, new FileEntry(writer, saveConfig));
        } else {
            writer = fe.pw;
        }
        if (!trimmed) {
            log.debug(""Writing header to file: {}"", filename);
            writeFileStart(writer, saveConfig);
        }
        return writer;
    }",,
jmeter,14153,"log.warn(""Problem in BSF script"", e)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/BSFAssertion.java/#L45,"@Override
    public AssertionResult getResult(SampleResult response) {
        AssertionResult result = new AssertionResult(getName());
        BSFManager mgr =null;
        try {
            mgr = getManager();
            mgr.declareBean(""SampleResult"", response, SampleResult.class);
            mgr.declareBean(""AssertionResult"", result, AssertionResult.class);
            processFileOrScript(mgr);
            result.setError(false);
        } catch (BSFException e) {
            
---------------Reference log start----------------
log.warn(""Problem in BSF script"", e)
---------------Reference log end----------------
            result.setFailure(true);
            result.setError(true);
            result.setFailureMessage(e.toString());
        } finally {
            if(mgr != null) {
                mgr.terminate();
            }
        }
        return result;
    }",,
jmeter,13933,"log.warn(""Could not create socket for {}"", getLabel(), e)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/TCPSampler.java/#L177,"private Socket getSocket(String socketKey) {
        Map<String, Object> cp = tp.get();
        Socket con = null;
        if (isReUseConnection()) {
            con = (Socket) cp.get(socketKey);
            if (con != null) {
                log.debug(""{} Reusing connection {}"", this, con); //$NON-NLS-1$
            }
        }
        if (con == null) {
            // Not in cache, so create new one and cache it
            try {
                closeSocket(socketKey); // Bug 44910 - close previous socket (if any)
                SocketAddress sockaddr = new InetSocketAddress(getServer(), getPort());
                con = new Socket(); // NOSONAR socket is either cache in ThreadLocal for reuse and closed at end of thread or closed here
                if (getPropertyAsString(SO_LINGER,"""").length() > 0){
                    con.setSoLinger(true, getSoLinger());
                }
                con.connect(sockaddr, getConnectTimeout());
                if(log.isDebugEnabled()) {
                    log.debug(""Created new connection {}"", con); //$NON-NLS-1$
                }
                cp.put(socketKey, con);
            } catch (UnknownHostException e) {
                log.warn(""Unknown host for {}"", getLabel(), e);//$NON-NLS-1$
                cp.put(ERRKEY, e.toString());
                return null;
            } catch (IOException e) {
                
---------------Reference log start----------------
log.warn(""Could not create socket for {}"", getLabel(), e)
---------------Reference log end----------------
                cp.put(ERRKEY, e.toString());
                return null;
            }
        }
        // (re-)Define connection params - Bug 50977
        try {
            con.setSoTimeout(getTimeout());
            con.setTcpNoDelay(getNoDelay());
            if(log.isDebugEnabled()) {
                log.debug(""{} Timeout={}, NoDelay={}"", this, getTimeout(), getNoDelay()); //$NON-NLS-1$
            }
        } catch (SocketException se) {
            log.warn(""Could not set timeout or nodelay for {}"", getLabel(), se); //$NON-NLS-1$
            cp.put(ERRKEY, se.toString());
        }
        return con;
    }",,
jmeter,13537,"log.warn(""Could not open/read key store {}, a new one will be created, ensure you install it in browser"", e.getMessage(), // message includes the file name
e)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/ProxyControl.java/#L1547,"@SuppressWarnings(""JdkObsolete"")
    private void initDynamicKeyStore() throws IOException, GeneralSecurityException {
        if (storePassword  != null) { // Assume we have already created the store
            try {
                keyStore = getKeyStore(storePassword.toCharArray());
                for(String alias : KeyToolUtils.getCAaliases()) {
                    X509Certificate  caCert = (X509Certificate) keyStore.getCertificate(alias);
                    if (caCert == null) {
                        keyStore = null; // no CA key - probably the wrong store type.
                        break; // cannot continue
                    } else {
                        caCert.checkValidity(new Date(System.currentTimeMillis()+DateUtils.MILLIS_PER_DAY));
                        log.info(""Valid alias found for {}"", alias);
                    }
                }
            } catch (IOException e) { // store is faulty, we need to recreate it
                keyStore = null; // if cert is not valid, flag up to recreate it
                if (e.getCause() instanceof UnrecoverableKeyException) {
                    log.warn(
                            ""Could not read key store {}; cause: {}, a new one will be created, ensure you install it in browser"",
                            e.getMessage(), e.getCause().getMessage(), e);
                } else {
                    
---------------Reference log start----------------
log.warn(""Could not open/read key store {}, a new one will be created, ensure you install it in browser"", e.getMessage(), // message includes the file name
e)
---------------Reference log end----------------
                }
            } catch (CertificateExpiredException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Existing ROOT Certificate has expired, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            } catch (CertificateNotYetValidException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Existing ROOT Certificate is not yet valid, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            } catch (GeneralSecurityException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Problem reading key store, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            }
        }
        if (keyStore == null) { // no existing file or not valid
            storePassword = JOrphanUtils.generateRandomAlphanumericPassword(20); // Alphanum to avoid issues with command-line quoting
            keyPassword = storePassword; // we use same password for both
            setPassword(storePassword);
            log.info(
                    ""Creating HTTP(S) Test Script Recorder Root CA in {}, ensure you install certificate in your Browser for recording"",
                    CERT_PATH_ABS);
            KeyToolUtils.generateProxyCA(CERT_PATH, storePassword, CERT_VALIDITY);
            log.info(""Created keystore in {}"", CERT_PATH_ABS);
            keyStore = getKeyStore(storePassword.toCharArray()); // This should now work
        }
        final String sslDomains = getSslDomains().trim();
        if (sslDomains.length() > 0) {
            final String[] domains = sslDomains.split("","");
            // The subject may be either a host or a domain
            for (String subject : domains) {
                if (isValid(subject)) {
                    if (!keyStore.containsAlias(subject)) {
                        log.info(""Creating entry {} in {}"", subject, CERT_PATH_ABS);
                        KeyToolUtils.generateHostCert(CERT_PATH, storePassword, subject, CERT_VALIDITY);
                        keyStore = getKeyStore(storePassword.toCharArray()); // reload to pick up new aliases
                        // reloading is very quick compared with creating an entry currently
                    }
                } else {
                    log.warn(""Attempt to create an invalid domain certificate: {}"", subject);
                }
            }
        }
    }",,
jmeter,14244,"log.info(MSG_STOP_CURRENT_THREAD, getName())",info,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/sampler/TestAction.java/#L120,"@Override
    public SampleResult sample(Entry e) {
        JMeterContext context = JMeterContextService.getContext();

        int target = getTarget();
        int action = getAction();
        if (action == PAUSE) {
            pause(getDurationAsString());
        } else if (action == STOP || action == STOP_NOW) {
            if (target == THREAD) {
                if(log.isInfoEnabled()) {
                    log.info(MSG_STOP_CURRENT_THREAD, getName());
                }
                context.getThread().stop();
            } else if (target == TEST) {
                if (action == STOP_NOW) {
                    if(log.isInfoEnabled()) {
                        log.info(MSG_STOP_CURRENT_THREAD, getName());
                    }
                    context.getThread().stop();
                    if(log.isInfoEnabled()) {
                        log.info(""Stopping all threads now from element {}"", getName());
                    }
                    context.getEngine().stopTest();
                } else {
                    if(log.isInfoEnabled()) {
                        
---------------Reference log start----------------
log.info(MSG_STOP_CURRENT_THREAD, getName())
---------------Reference log end----------------
                    }
                    context.getThread().stop();
                    if(log.isInfoEnabled()) {
                        log.info(""Stopping all threads from element {}"", getName());
                    }
                    context.getEngine().askThreadsToStop();
                }
            }
        } else if (action == RESTART_NEXT_LOOP) {
            log.info(""Restarting next thread loop from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.START_NEXT_ITERATION_OF_THREAD);
        } else if (action == START_NEXT_ITERATION_CURRENT_LOOP) {
            log.info(""Switching to next loop iteration from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.START_NEXT_ITERATION_OF_CURRENT_LOOP);
        } else if (action == BREAK_CURRENT_LOOP) {
            log.info(""Breaking current loop from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.BREAK_CURRENT_LOOP);
        }

        return null; // This means no sample is saved
    }",,
jmeter,14511,"log.error(""OpenLinkAction on {}"", url, err)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/OpenLinkAction.java/#L84,"@Override
    public void doAction(ActionEvent e) {
        String url = LINK_MAP.get(e.getActionCommand());
        if(url == null) {
            log.warn(""Action {} not handled by this class"", e.getActionCommand());
            return;
        }
        try {
            if(e.getSource() instanceof String[]) {
                url += ""#""+((String[])e.getSource())[1];
            }
            java.awt.Desktop.getDesktop().browse(java.net.URI.create(url));
        } catch (IOException err) {
            log.error(
                    ""OpenLinkAction: User default browser is not found, or it fails to be launched,""
                    + "" or the default handler application failed to be launched on {}"",
                    url, err);
        } catch (UnsupportedOperationException err) {
            log.error(""OpenLinkAction: Current platform does not support the Desktop.Action.BROWSE action on {}"", url, err);
            showBrowserWarning(url);
        } catch (SecurityException err) {
            log.error(""OpenLinkAction: Security problem on {}"", url, err);
        } catch (Exception err) {
            
---------------Reference log start----------------
log.error(""OpenLinkAction on {}"", url, err)
---------------Reference log end----------------
        }
    }",,
jmeter,14260,"log.debug(""{} process {}"", Thread.currentThread().getName(), isPerIteration())",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/modifiers/UserParameters.java/#L138,"@Override
    public void process() {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""{} process {}"", Thread.currentThread().getName(), isPerIteration())
---------------Reference log end----------------
        }
        if (!isPerIteration()) {
            setValues();
        }
    }",,
jmeter,13908,"log.warn(""Exception executing script. {}"", ex.toString())",warn,https://github.com/apache/jmeter/blob/master/src/protocol/java/src/main/java/org/apache/jmeter/protocol/java/sampler/BeanShellSampler.java/#L152,"@Override
    public SampleResult sample(Entry e)// Entry tends to be ignored ...
    {
        SampleResult res = new SampleResult();
        boolean isSuccessful = false;
        res.setSampleLabel(getName());
        res.sampleStart();
        final BeanShellInterpreter bshInterpreter = getBeanShellInterpreter();
        if (bshInterpreter == null) {
            res.sampleEnd();
            res.setResponseCode(""503"");//$NON-NLS-1$
            res.setResponseMessage(""BeanShell Interpreter not found"");
            res.setSuccessful(false);
            return res;
        }
        try {
            String request = getScript();
            String fileName = getFilename();
            if (fileName.length() == 0) {
                res.setSamplerData(request);
            } else {
                res.setSamplerData(fileName);
            }

            bshInterpreter.set(""SampleResult"", res); //$NON-NLS-1$

            // Set default values
            bshInterpreter.set(""ResponseCode"", ""200""); //$NON-NLS-1$
            bshInterpreter.set(""ResponseMessage"", ""OK"");//$NON-NLS-1$
            bshInterpreter.set(""IsSuccess"", true);//$NON-NLS-1$

            res.setDataType(SampleResult.TEXT); // assume text output - script can override if necessary

            savedBsh = bshInterpreter;
            Object bshOut = processFileOrScript(bshInterpreter);
            savedBsh = null;

            if (bshOut != null) {// Set response data
                String out = bshOut.toString();
                res.setResponseData(out, null);
            }
            // script can also use setResponseData() so long as it returns null

            res.setResponseCode(bshInterpreter.get(""ResponseCode"").toString());//$NON-NLS-1$
            res.setResponseMessage(bshInterpreter.get(""ResponseMessage"").toString());//$NON-NLS-1$
            isSuccessful = Boolean.valueOf(bshInterpreter.get(""IsSuccess"") //$NON-NLS-1$
                    .toString());
        }
        /*
         * To avoid class loading problems when bsh,jar is missing, we don't try
         * to catch this error separately catch (bsh.EvalError ex) {
         * log.debug("""",ex); res.setResponseCode(""500"");//$NON-NLS-1$
         * res.setResponseMessage(ex.toString()); }
         */
        // but we do trap this error to make tests work better
        catch (NoClassDefFoundError ex) {
            log.error(""BeanShell Jar missing? {}"", ex.toString());
            res.setResponseCode(""501"");//$NON-NLS-1$
            res.setResponseMessage(ex.toString());
            res.setStopThread(true); // No point continuing
        } catch (Exception ex) // Mainly for bsh.EvalError
        {
            if (log.isWarnEnabled()) {
                
---------------Reference log start----------------
log.warn(""Exception executing script. {}"", ex.toString())
---------------Reference log end----------------
            }
            res.setResponseCode(""500"");//$NON-NLS-1$
            res.setResponseMessage(ex.toString());
        } finally {
            savedBsh = null;
        }

        res.sampleEnd();

        // Set if we were successful or not
        res.setSuccessful(isSuccessful);

        return res;
    }",,
jmeter,13283,"log.debug(""{} name:{} value:{}"", Thread.currentThread().getName(), myName, myValue)",debug,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/RandomString.java/#L104,"@Override
    public String execute(SampleResult previousResult, Sampler currentSampler)
            throws InvalidVariableException {

        int length = Integer.parseInt(values[0].execute());

        String charsToUse = null;//means no restriction
        if (values.length >= CHARS) {
            charsToUse = values[CHARS - 1].execute().trim();
            if (charsToUse.length() <= 0) { // empty chars, return to null
                charsToUse = null;
            }
        }

        String myName = """";//$NON-NLS-1$
        if (values.length >= PARAM_NAME) {
            myName = values[PARAM_NAME - 1].execute().trim();
        }

        String myValue = null;
        if(StringUtils.isEmpty(charsToUse)) {
            myValue = RandomStringUtils.random(length);
        } else {
            myValue = RandomStringUtils.random(length, charsToUse);
        }

        if (myName.length() > 0) {
            JMeterVariables vars = getVariables();
            if (vars != null) {// Can be null if called from Config item testEnded() method
                vars.put(myName, myValue);
            }
        }

        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""{} name:{} value:{}"", Thread.currentThread().getName(), myName, myValue)
---------------Reference log end----------------
        }

        return myValue;
    }",,
jmeter,15021,"log.warn(""Exception evaluating script. {}"", e.getLocalizedMessage())",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/BSFTestElement.java/#L123,"protected Object evalFileOrScript(BSFManager mgr) throws BSFException{
        BSFEngine bsfEngine = mgr.loadScriptingEngine(getScriptLanguage());
        final String scriptFile = getFilename();
        if (scriptFile.length() == 0) {
            return bsfEngine.eval(""[script]"",0,0,getScript());
        } else {// we have a file, read and process it
            try {
                String script=FileUtils.readFileToString(new File(scriptFile), Charset.defaultCharset());
                return bsfEngine.eval(scriptFile,0,0,script);
            } catch (IOException e) {
                if (log.isWarnEnabled()) {
                    
---------------Reference log start----------------
log.warn(""Exception evaluating script. {}"", e.getLocalizedMessage())
---------------Reference log end----------------
                }
                throw new BSFException(BSFException.REASON_IO_ERROR,""Problem reading script file"",e);
            }
        }
    }",,
jmeter,14736,"log.info(""Local IP address={}"", localHost.getHostAddress())",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/rmi/RmiUtils.java/#L140,"public static InetAddress getRmiHost() throws RemoteException {
        InetAddress localHost=null;
        // Bug 47980 - allow override of local hostname
        String host = System.getProperties().getProperty(""java.rmi.server.hostname""); // $NON-NLS-1$
        try {
            if( host==null ) {
                log.info(""System property 'java.rmi.server.hostname' is not defined, using localHost address"");
                localHost = InetAddress.getLocalHost();
            } else {
                log.info(""Resolving by name the value of System property 'java.rmi.server.hostname': {}"", host);
                localHost = InetAddress.getByName(host);
            }
        } catch (UnknownHostException e) {
            throw new RemoteException(""Cannot start. Unable to get local host IP address."", e);
        }
        if (log.isInfoEnabled()) {
            
---------------Reference log start----------------
log.info(""Local IP address={}"", localHost.getHostAddress())
---------------Reference log end----------------
        }
        // BUG 52469 : Allow loopback address for SSH Tunneling of RMI traffic
        if (host == null && localHost.isLoopbackAddress()){
            String hostName = localHost.getHostName();
            throw new RemoteException(""Cannot start. "" + hostName + "" is a loopback address."");
        }
        return localHost;
    }",,
jmeter,14991,"log.debug(""WrappedX509Manager: getServerAliases: "")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JsseSSLManager.java/#L327,"@Override
        public String[] getServerAliases(String keyType, Principal[] issuers) {
            
---------------Reference log start----------------
log.debug(""WrappedX509Manager: getServerAliases: "")
---------------Reference log end----------------
            return this.manager.getServerAliases(keyType, issuers);
        }",,
jmeter,13778,"logger.debug(""transport closed"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/mail/src/main/java/org/apache/jmeter/protocol/smtp/sampler/protocol/SendMailCommand.java/#L341,"public void execute(Message message) throws MessagingException, InterruptedException {

        Transport tr = null;
        try {
            tr = session.getTransport(getProtocol());
            SynchronousTransportListener listener = null;

            if (synchronousMode) {
                listener = new SynchronousTransportListener();
                tr.addTransportListener(listener);
            }

            if (useAuthentication) {
                tr.connect(smtpServer, username, password);
            } else {
                tr.connect();
            }

            tr.sendMessage(message, message.getAllRecipients());

            if (listener != null /*synchronousMode==true*/) {
                listener.attend(); // listener cannot be null here
            }
        } finally {
            if(tr != null) {
                try {
                    tr.close();
                } catch (Exception e) {
                    // NOOP
                }
            }
            
---------------Reference log start----------------
logger.debug(""transport closed"")
---------------Reference log end----------------
        }

        logger.debug(""message sent"");
    }",,
jmeter,14487,"log.error(""Error generating output file {} from template {}"", temporaryGeneratedFile, jmxFile, ex)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/SelectTemplatesDialog.java/#L191,"void replaceTemplateParametersAndLoad(final ActionEvent actionEvent, final Template template,
            final boolean isTestPlan, File templateFile) {
        File temporaryGeneratedFile = null;
        try {
            // handle customized templates (the .jmx.fmkr files)
            if (template.getParameters() != null && !template.getParameters().isEmpty()) {
                File jmxFile = new File(templateFile.getAbsolutePath());
                Map<String, String> userParameters = getUserParameters();
                Configuration templateCfg = TemplateUtil.getTemplateConfig();
                try {
                    temporaryGeneratedFile = File.createTempFile(template.getName(), "".output"");
                    templateFile = temporaryGeneratedFile;
                    TemplateUtil.processTemplate(jmxFile, temporaryGeneratedFile, templateCfg, userParameters);
                } catch (IOException | TemplateException ex) {
                    
---------------Reference log start----------------
log.error(""Error generating output file {} from template {}"", temporaryGeneratedFile, jmxFile, ex)
---------------Reference log end----------------
                    return;
                }
            }
            Load.loadProjectFile(actionEvent, templateFile, !isTestPlan, false);
            this.dispose();
        } finally {
            if (temporaryGeneratedFile != null && !temporaryGeneratedFile.delete()) {
                log.warn(""Could not delete generated output file {} from template {}"", temporaryGeneratedFile, templateFile);
            }
        }
    }",,
jmeter,13653,"log.warn(""Could not abort pending request"", e)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPHC4Impl.java/#L1902,"@Override
    public boolean interrupt() {
        HttpUriRequest request = currentRequest;
        if (request != null) {
            currentRequest = null; // don't try twice
            try {
                request.abort();
            } catch (UnsupportedOperationException e) {
                
---------------Reference log start----------------
log.warn(""Could not abort pending request"", e)
---------------Reference log end----------------
            }
        }
        return request != null;
    }",,
jmeter,14973,"log.warn(""Error : {}"", JMeterUtils.getResString(""xpath2_extractor_empty_query""))",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/XPathUtil.java/#L683,"public static void computeAssertionResultUsingSaxon(AssertionResult result, String xmlFile, String xPathQuery,
           String namespaces, Boolean isNegated) throws SaxonApiException, FactoryConfigurationError {
       // generating the cache key
       final ImmutablePair<String, String> key = ImmutablePair.of(xPathQuery, namespaces);
       // check the cache
       XPathExecutable xPathExecutable;
       if (StringUtils.isNotEmpty(xPathQuery)) {
           xPathExecutable = XPATH_CACHE.get(key);
       } else {
           
---------------Reference log start----------------
log.warn(""Error : {}"", JMeterUtils.getResString(""xpath2_extractor_empty_query""))
---------------Reference log end----------------
           return;
       }
       try (StringReader reader = new StringReader(xmlFile)) {
           // We could instantiate it once but might trigger issues in the future
           // Sharing of a DocumentBuilder across multiple threads is not recommended.
           // However, in the current implementation sharing a DocumentBuilder (once
           // initialized)
           // will only cause problems if a SchemaValidator is used.
           net.sf.saxon.s9api.DocumentBuilder builder = PROCESSOR.newDocumentBuilder();
           XdmNode xdmNode = builder.build(new SAXSource(new InputSource(reader)));
           if (xPathExecutable != null) {
               XPathSelector selector = null;
               try {
                   Document doc;
                   doc = XPathUtil.makeDocumentBuilder(false, false, false, false).newDocument();
                   XObject xObject = XPathAPI.eval(doc, xPathQuery, getPrefixResolverForXPath2(doc, namespaces));
                   selector = xPathExecutable.load();
                   selector.setContextItem(xdmNode);
                   XdmValue nodes = selector.evaluate();
                   boolean resultOfEval = true;
                   int length = nodes.size();
                   // In case we need to extract everything
                   if (length == 0) {
                       resultOfEval = false;
                   } else if (xObject.getType() == XObject.CLASS_BOOLEAN) {
                       resultOfEval = Boolean.parseBoolean(nodes.itemAt(0).getStringValue());
                   }
                   result.setFailure(isNegated ? resultOfEval : !resultOfEval);
                   result.setFailureMessage(
                           isNegated ? ""Nodes Matched for "" + xPathQuery : ""No Nodes Matched for "" + xPathQuery);
               } catch (ParserConfigurationException | TransformerException e) { // NOSONAR Exception handled by return
                   result.setError(true);
                   result.setFailureMessage(""Exception: "" + e.getMessage() + "" for:"" + xPathQuery);
               } finally {
                   if (selector != null) {
                       try {
                           selector.getUnderlyingXPathContext().setContextItem(null);
                       } catch (Exception e) { // NOSONAR Ignored on purpose
                           result.setError(true);
                           result.setFailureMessage(""Exception: "" + e.getMessage() + "" for:"" + xPathQuery);
                       }
                   }
               }
           }
       }
   }",,
jmeter,13779,"logger.debug(""message sent"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/mail/src/main/java/org/apache/jmeter/protocol/smtp/sampler/protocol/SendMailCommand.java/#L344,"public void execute(Message message) throws MessagingException, InterruptedException {

        Transport tr = null;
        try {
            tr = session.getTransport(getProtocol());
            SynchronousTransportListener listener = null;

            if (synchronousMode) {
                listener = new SynchronousTransportListener();
                tr.addTransportListener(listener);
            }

            if (useAuthentication) {
                tr.connect(smtpServer, username, password);
            } else {
                tr.connect();
            }

            tr.sendMessage(message, message.getAllRecipients());

            if (listener != null /*synchronousMode==true*/) {
                listener.attend(); // listener cannot be null here
            }
        } finally {
            if(tr != null) {
                try {
                    tr.close();
                } catch (Exception e) {
                    // NOOP
                }
            }
            logger.debug(""transport closed"");
        }

        
---------------Reference log start----------------
logger.debug(""message sent"")
---------------Reference log end----------------
    }
    }",,
jmeter,14381,"log.debug(""Event {}: {}"", propname, comp)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/MainFrame.java/#L740,"@Override
        public void actionPerformed(ActionEvent actionEvent) {
            String propname = ""gui.quick_"" + getCurrentKey(actionEvent);
            String comp = JMeterUtils.getProperty(propname);
            
---------------Reference log start----------------
log.debug(""Event {}: {}"", propname, comp)
---------------Reference log end----------------

            if (comp == null) {
                log.warn(""No component set through property: {}"", propname);
                return;
            }

            GuiPackage guiPackage = GuiPackage.getInstance();
            try {
                guiPackage.updateCurrentNode();
                TestElement testElement = guiPackage.createTestElement(SaveService.aliasToClass(comp));
                JMeterTreeNode parentNode = guiPackage.getCurrentNode();
                while (!MenuFactory.canAddTo(parentNode, testElement)) {
                    parentNode = (JMeterTreeNode) parentNode.getParent();
                }
                if (parentNode.getParent() == null) {
                    log.debug(""Cannot add element on very top level"");
                } else {
                    JMeterTreeNode node = guiPackage.getTreeModel().addComponent(testElement, parentNode);
                    guiPackage.getMainFrame().getTree().setSelectionPath(new TreePath(node.getPath()));
                }
            } catch (Exception err) {
                log.warn(""Failed to perform quick component add: {}"", comp, err); // $NON-NLS-1$
            }
        }",,
jmeter,13496,"log.info(""{} KeyStore for SSL loaded OK and put host '{}' in map with key ({})"", port, host, hashAlias)",info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/Proxy.java/#L377,"private SSLSocketFactory getSSLSocketFactory(String host) {
        if (keyStore == null) {
            log.error(""{} No keystore available, cannot record SSL"", port);
            return null;
        }
        final String hashAlias;
        final String keyAlias;
        switch(ProxyControl.KEYSTORE_MODE) {
        case DYNAMIC_KEYSTORE:
            try {
                keyStore = target.getKeyStore(); // pick up any recent changes from other threads
                String alias = getDomainMatch(keyStore, host);
                if (alias == null) {
                    hashAlias = host;
                    keyAlias = host;
                    keyStore = target.updateKeyStore(port, keyAlias);
                } else if (alias.equals(host)) { // the host has a key already
                    hashAlias = host;
                    keyAlias = host;
                } else { // the host matches a domain; use its key
                    hashAlias = alias;
                    keyAlias = alias;
                }
            } catch (IOException | GeneralSecurityException e) {
                log.error(""{} Problem with keystore"", port, e);
                return null;
            }
            break;
        case JMETER_KEYSTORE:
            hashAlias = keyAlias = ProxyControl.JMETER_SERVER_ALIAS;
            break;
        case USER_KEYSTORE:
            hashAlias = keyAlias = ProxyControl.CERT_ALIAS;
            break;
        default:
            throw new IllegalStateException(""Impossible case: "" + ProxyControl.KEYSTORE_MODE);
        }
        synchronized (HOST2SSL_SOCK_FAC) {
            final SSLSocketFactory sslSocketFactory = HOST2SSL_SOCK_FAC.get(hashAlias);
            if (sslSocketFactory != null) {
                log.debug(""{} Good, already in map, host={} using alias {}"", port, host, hashAlias);
                return sslSocketFactory;
            }
            try {
                SSLContext sslcontext = SSLContext.getInstance(SSLCONTEXT_PROTOCOL);
                sslcontext.init(getWrappedKeyManagers(keyAlias), null, null);
                SSLSocketFactory sslFactory = sslcontext.getSocketFactory();
                HOST2SSL_SOCK_FAC.put(hashAlias, sslFactory);
                
---------------Reference log start----------------
log.info(""{} KeyStore for SSL loaded OK and put host '{}' in map with key ({})"", port, host, hashAlias)
---------------Reference log end----------------
                return sslFactory;
            } catch (GeneralSecurityException e) {
                log.error(""{} Problem with SSL certificate"", port, e);
            } catch (IOException e) {
                log.error(""{} Problem with keystore"", port, e);
            }
            return null;
        }
    }",,
jmeter,14178,"log.warn(""SyncTimer {} timeouted waiting for users after: {}ms"", getName(), getTimeoutInMs())",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/timers/SyncTimer.java/#L189,"@Override
    public long delay() {
        if(getGroupSize()>=0) {
            int arrival = 0;
            try {
                if (timeoutInMs == 0) {
                    arrival = this.barrier.await(TimerService.getInstance().adjustDelay(Long.MAX_VALUE), TimeUnit.MILLISECONDS);
                } else if (timeoutInMs > 0) {
                    arrival = this.barrier.await(TimerService.getInstance().adjustDelay(timeoutInMs), TimeUnit.MILLISECONDS);
                } else {
                    throw new IllegalArgumentException(""Negative value for timeout:""+timeoutInMs+"" in Synchronizing Timer ""+getName());
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                return 0;
            } catch (BrokenBarrierException e) {
                return 0;
            } catch (TimeoutException e) {
                if (log.isWarnEnabled()) {
                    
---------------Reference log start----------------
log.warn(""SyncTimer {} timeouted waiting for users after: {}ms"", getName(), getTimeoutInMs())
---------------Reference log end----------------
                }
                return 0;
            } finally {
                if(arrival == 0) {
                    barrier.reset();
                }
            }
        }
        return 0;
    }",,
jmeter,14631,"log.warn(""testEnded(host)"", ex)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/AsynchSampleSender.java/#L108,"@Override
    public void testEnded(String host) {
        log.debug(""Test Ended on {}"", host);
        try {
            listener.testEnded(host);
            queue.put(FINAL_EVENT);
        } catch (Exception ex) {
            
---------------Reference log start----------------
log.warn(""testEnded(host)"", ex)
---------------Reference log end----------------
        }
        if (queueWaits > 0) {
            log.info(""QueueWaits: {}; QueueWaitTime: {} (nanoseconds)"", queueWaits, queueWaitTime);
        }
    }",,
jmeter,13594,"log.debug(""RegExUserParameters element: {} => changed parameter: {} = {}, was: {}"", getName(), arg.getName(), arg.getValue(), oldValue)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/modifier/RegExUserParameters.java/#L86,"@Override
    public void process() {
        if (log.isDebugEnabled()) {
            log.debug(""{} Running up named: {}"", Thread.currentThread().getName(), getName());//$NON-NLS-1$
        }
        Sampler entry = getThreadContext().getCurrentSampler();
        if (!(entry instanceof HTTPSamplerBase)) {
            return;
        }

        Map<String, String> paramMap = buildParamsMap();
        if(paramMap == null || paramMap.isEmpty()){
            log.info(
                    ""RegExUserParameters element: {} => Referenced RegExp was not found, no parameter will be changed"",
                    getName());
            return;
        }

        HTTPSamplerBase sampler = (HTTPSamplerBase) entry;
        for (JMeterProperty jMeterProperty : sampler.getArguments()) {
            Argument arg = (Argument) jMeterProperty.getObjectValue();
            String oldValue = arg.getValue();
            // if parameter name exists in http request
            // then change its value with value obtained with regular expression
            String val = paramMap.get(arg.getName());
            if (val != null) {
                arg.setValue(val);
            }
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""RegExUserParameters element: {} => changed parameter: {} = {}, was: {}"", getName(), arg.getName(), arg.getValue(), oldValue)
---------------Reference log end----------------
            }
        }
    }",,
jmeter,15018,"log.error(""No var called '{}' found"", clientCertAliasVarName)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/keystore/JmeterKeyStore.java/#L310,"public String getAlias() {
        if (StringUtils.isNotEmpty(clientCertAliasVarName)) {
            String aliasName = JMeterContextService.getContext().getVariables().get(clientCertAliasVarName);
            if (StringUtils.isEmpty(aliasName)) {
                
---------------Reference log start----------------
log.error(""No var called '{}' found"", clientCertAliasVarName)
---------------Reference log end----------------
                throw new IllegalArgumentException(""No var called '"" + clientCertAliasVarName + ""' found"");
            }
            return aliasName;
        }
        int length = this.names.length;
        if (length == 0) { // i.e. is == null
            return null;
        }
        return this.names[getIndexAndIncrement(length)];
    }",,
jmeter,14742,"log.error(""Exiting"")",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/StandardJMeterEngine.java/#L332,"@Override
        public void run() {
            running = false;
            resetSingletonEngine();
            if (now) {
                tellThreadGroupsToStop();
                pause(10L * countStillActiveThreads());
                boolean stopped = verifyThreadsStopped();
                if (!stopped) {  // we totally failed to stop the test
                    if (JMeter.isNonGUI()) {
                        log.error(JMeterUtils.getResString(""stopping_test_failed"")); //$NON-NLS-1$
                        if (SYSTEM_EXIT_ON_STOP_FAIL) { // default is true
                            
---------------Reference log start----------------
log.error(""Exiting"")
---------------Reference log end----------------
                            System.out.println(""Fatal error, could not stop test, exiting""); // NOSONAR Intentional
                            System.exit(1); // NOSONAR Intentional
                        } else {
                            System.out.println(""Fatal error, could not stop test""); // NOSONAR Intentional
                        }
                    } else {
                        JMeterUtils.reportErrorToUser(
                                JMeterUtils.getResString(""stopping_test_failed""), //$NON-NLS-1$
                                JMeterUtils.getResString(""stopping_test_title"")); //$NON-NLS-1$
                    }
                } // else will be done by threadFinished()
            } else {
                stopAllThreadGroups();
            }
        }",,
jmeter,14634,"log.error(""Failed to return sample"", err)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/AsynchSampleSender.java/#L162,"@Override
        public void run() {
            try {
                boolean eof = false;
                while (!eof) {
                    List<SampleEvent> l = new ArrayList<>();
                    SampleEvent e = queue.take();
                    // try to process as many as possible
                    // The == comparison is not an error
                    while (!(eof = e == FINAL_EVENT) && e != null) {
                        l.add(e);
                        e = queue.poll(); // returns null if nothing on queue currently
                    }
                    int size = l.size();
                    if (size > 0) {
                        try {
                            listener.processBatch(l);
                        } catch (RemoteException err) {
                            if (err.getCause() instanceof java.net.ConnectException){
                                throw new JMeterError(""Could not return sample"",err);
                            }
                            
---------------Reference log start----------------
log.error(""Failed to return sample"", err)
---------------Reference log end----------------
                        }
                    }
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
            log.debug(""Worker ended"");
        }",,
jmeter,13980,"log.warn(""Error parsing '{}'"", valueString, e)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/control/ThroughputController.java/#L133,"protected int getMaxThroughputAsInt() {
        JMeterProperty prop = getProperty(MAXTHROUGHPUT);
        int retVal = 1;
        if (prop instanceof IntegerProperty) {
            retVal = prop.getIntValue();
        } else {
            String valueString = prop.getStringValue();
            try {
                retVal = Integer.parseInt(valueString);
            } catch (NumberFormatException e) {
                
---------------Reference log start----------------
log.warn(""Error parsing '{}'"", valueString, e)
---------------Reference log end----------------
            }
        }
        return retVal;
    }",,
jmeter,13847,"LOGGER.debug(""isRead"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/sampler/JMSSampler.java/#L252,"private void handleRead(JMeterContext context, SampleResult res) {
        
---------------Reference log start----------------
LOGGER.debug(""isRead"")
---------------Reference log end----------------
        StringBuilder sb = new StringBuilder(75);
        res.setSuccessful(true);
        Sampler sampler = context.getPreviousSampler();
        SampleResult sr = context.getPreviousResult();
        String jmsSelector = getJMSSelector();
        if (JMSSampler.PREV_SAMPLER.equals(jmsSelector)
                && (sampler instanceof JMSSampler)) {
            jmsSelector = sr.getResponseMessage();
        }
        int sampleCounter = 0;
        int sampleTries = 0;
        String result;

        StringBuilder buffer = new StringBuilder();
        StringBuilder propBuffer = new StringBuilder();

        do {
            result = browseQueueForConsumption(sendQueue, jmsSelector, res, buffer, propBuffer);
            if (result != null) {
                sb.append(result);
                sb.append('\n');
                sampleCounter++;
            }
            sampleTries++;
        } while ((result != null) && (sampleTries < getNumberOfSamplesToAggregateAsInt()));

        res.setResponseData(buffer.toString(), StandardCharsets.UTF_8.name());
        res.setResponseHeaders(propBuffer.toString());
        if (sampleCounter == 0) {
            res.setSuccessful(false);
            res.setResponseCode(""404"");
            res.setResponseMessage(sampleCounter + "" samples messages received, last try had following response message:""+
                    res.getResponseMessage());
        } else {
            res.setSuccessful(true);
            res.setResponseCodeOK();
            res.setResponseMessage(sampleCounter + "" message(s) received successfully"");
        }
        res.setSamplerData(getNumberOfSamplesToAggregateAsInt() + "" messages expected"");
        res.setSampleCount(sampleCounter);
    }",,
jmeter,14149,"log.warn(""writeOutput() -> could not write output to file: {}"", filename, ex)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/HTMLAssertion.java/#L201,"private void writeOutput(String inOutput) {
        String filename = getFilename();

        // check if filename defined
        if (StringUtils.isNotBlank(filename)) {
            try (Writer writer = Files.newBufferedWriter(Paths.get(filename))) {
                // write to file
                writer.write(inOutput);
                log.debug(""writeOutput() -> output successfully written to file: {}"", filename);
            } catch (IOException ex) {
                
---------------Reference log start----------------
log.warn(""writeOutput() -> could not write output to file: {}"", filename, ex)
---------------Reference log end----------------
            }
        }
    }",,
jmeter,13774,"logger.info(""load local truststore -Attempting to read truststore from: {}"", truststore.getAbsolutePath())",info,https://github.com/apache/jmeter/blob/master/src/protocol/mail/src/main/java/org/apache/jmeter/protocol/smtp/sampler/protocol/SendMailCommand.java/#L263,"private void configureCertificateTrust(Properties props) throws IOException {
        if (trustAllCerts) {
            if (useSSL) {
                props.setProperty(""mail.smtps.ssl.socketFactory.class"", TRUST_ALL_SOCKET_FACTORY);
                props.setProperty(""mail.smtps.ssl.socketFactory.fallback"", FALSE);
            } else if (useStartTLS) {
                props.setProperty(""mail.smtp.ssl.socketFactory.class"", TRUST_ALL_SOCKET_FACTORY);
                props.setProperty(""mail.smtp.ssl.socketFactory.fallback"", FALSE);
            }
        } else if (useLocalTrustStore){
            File truststore = new File(trustStoreToUse);
            logger.info(""load local truststore - try to load truststore from: {}"", truststore.getAbsolutePath());
            if(!truststore.exists()){
                logger.info(""load local truststore -Failed to load truststore from: {}"", truststore.getAbsolutePath());
                truststore = new File(FileServer.getFileServer().getBaseDir(), trustStoreToUse);
                
---------------Reference log start----------------
logger.info(""load local truststore -Attempting to read truststore from: {}"", truststore.getAbsolutePath())
---------------Reference log end----------------
                if(!truststore.exists()){
                    logger.info(""load local truststore -Failed to load truststore from: {}. Local truststore not available, aborting execution."",
                            truststore.getAbsolutePath());
                    throw new IOException(""Local truststore file not found. Also not available under : "" + truststore.getAbsolutePath());
                }
            }
            if (useSSL) {
                // Requires JavaMail 1.4.2+
                props.put(""mail.smtps.ssl.socketFactory"", new LocalTrustStoreSSLSocketFactory(truststore));
                props.put(""mail.smtps.ssl.socketFactory.fallback"", FALSE);
            } else if (useStartTLS) {
                // Requires JavaMail 1.4.2+
                props.put(""mail.smtp.ssl.socketFactory"", new LocalTrustStoreSSLSocketFactory(truststore));
                props.put(""mail.smtp.ssl.socketFactory.fallback"", FALSE);
            }
        }
    }",,
jmeter,14348,"log.debug(""Opened file: {} in thread {}"", filename, Thread.currentThread().getName())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/reporters/ResultCollector.java/#L476,"private static PrintWriter getFileWriter(final String pFilename, SampleSaveConfiguration saveConfig)
            throws IOException {
        if (pFilename == null || pFilename.length() == 0) {
            return null;
        }
        if(log.isDebugEnabled()) {
            log.debug(""Getting file: {} in thread {}"", pFilename, Thread.currentThread().getName());
        }
        String filename = FileServer.resolveBaseRelativeName(pFilename);
        filename = new File(filename).getCanonicalPath(); // try to ensure uniqueness (Bug 60822)
        FileEntry fe = files.get(filename);
        PrintWriter writer = null;
        boolean trimmed = true;

        if (fe == null) {
            if (saveConfig.saveAsXml()) {
                trimmed = trimLastLine(filename);
            } else {
                trimmed = new File(filename).exists();
            }
            // Find the name of the directory containing the file
            // and create it - if there is one
            File pdir = new File(filename).getParentFile();
            if (pdir != null) {
                // returns false if directory already exists, so need to check again
                if(pdir.mkdirs()){
                    if (log.isInfoEnabled()) {
                        log.info(""Folder at {} was created"", pdir.getAbsolutePath());
                    }
                } // else if might have been created by another process so not a problem
                if (!pdir.exists()){
                    log.warn(""Error creating directories for {}"", pdir);
                }
            }
            writer = new PrintWriter(new OutputStreamWriter(new BufferedOutputStream(new FileOutputStream(filename,
                    trimmed)), SaveService.getFileEncoding(StandardCharsets.UTF_8.name())), SAVING_AUTOFLUSH);
            if(log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Opened file: {} in thread {}"", filename, Thread.currentThread().getName())
---------------Reference log end----------------
            }
            files.put(filename, new FileEntry(writer, saveConfig));
        } else {
            writer = fe.pw;
        }
        if (!trimmed) {
            log.debug(""Writing header to file: {}"", filename);
            writeFileStart(writer, saveConfig);
        }
        return writer;
    }",,
jmeter,13242,"log.warn(""Exception parsing {} as int, value will not be considered as Start Number sequence"", start)",warn,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/StringFromFile.java/#L158,"private synchronized void openFile() {
        String tn = Thread.currentThread().getName();
        fileName = ((CompoundVariable) values[0]).execute();

        String start = """";
        if (values.length >= PARAM_START) {
            start = ((CompoundVariable) values[PARAM_START - 1]).execute();
            try {
                // Low chances to be non numeric, we parse
                myStart = Integer.parseInt(start);
            } catch(NumberFormatException e) {
                myStart = COUNT_UNUSED;// Don't process invalid numbers
                
---------------Reference log start----------------
log.warn(""Exception parsing {} as int, value will not be considered as Start Number sequence"", start)
---------------Reference log end----------------
            }
        }
        // Have we used myCurrent yet?
        // Set to 1 if start number is missing (to allow for end without start)
        if (myCurrent == COUNT_UNUSED) {
            myCurrent = myStart == COUNT_UNUSED ? 1 : myStart;
        }

        if (values.length >= PARAM_END) {
            String tmp = ((CompoundVariable) values[PARAM_END - 1]).execute();
            try {
                // Low chances to be non numeric, we parse
                myEnd = Integer.parseInt(tmp);
            } catch(NumberFormatException e) {
                myEnd = COUNT_UNUSED;// Don't process invalid numbers (including """")
                log.warn(""Exception parsing {} as int, value will not be considered as End Number sequence"", tmp);
            }
        }

        if (values.length >= PARAM_START) {
            if (log.isInfoEnabled()) {
                log.info(""{} Start = {} Current = {} End = {}"", tn, myStart, myCurrent, myEnd);//$NON-NLS-1$
            }
            if (myEnd != COUNT_UNUSED) {
                if (myCurrent > myEnd) {
                    if (log.isInfoEnabled()) {
                        log.info(""{} No more files to process, {} > {}"", tn, myCurrent, myEnd);//$NON-NLS-1$
                    }
                    myBread = null;
                    return;
                }
            }
            /*
             * DecimalFormat adds the number to the end of the format if there
             * are no formatting characters, so we need a way to prevent this
             * from messing up the file name.
             *
             */
            if (myStart != COUNT_UNUSED) // Only try to format if there is a
                                            // number
            {
                log.info(""{} using format {}"", tn, fileName);
                try {
                    DecimalFormat myFormatter = new DecimalFormat(fileName);
                    fileName = myFormatter.format(myCurrent);
                } catch (NumberFormatException e) {
                    log.warn(""Bad file name format "", e);
                }
            }
            myCurrent++;// for next time
        }

        log.info(""{} opening file {}"", tn, fileName);//$NON-NLS-1$
        try {
            myBread = Files.newBufferedReader(Paths.get(fileName));
        } catch (Exception e) {
            log.error(""openFile() error: {}"", e.toString());//$NON-NLS-1$
            IOUtils.closeQuietly(myBread, null);
            myBread = null;
        }
    }",,
jmeter,14456,"log.debug(""Skipping undo since there is no previous known state"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/UndoHistory.java/#L291,"private void addEdit(UndoHistoryItem item) {
        if (lastKnownState != null) {
            GlobalUndoableEdit edit = new GlobalUndoableEdit(item, lastKnownState, this::reload);
            addEdit(edit);
        } else {
            
---------------Reference log start----------------
log.debug(""Skipping undo since there is no previous known state"")
---------------Reference log end----------------
        }
        lastKnownState = item;
    }",,
jmeter,14039,"log.debug(""Created InfluxDBMetricsSender with url: {}"", url)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/influxdb/HttpMetricsSender.java/#L147,"private HttpPost createRequest(URL url, String token) throws URISyntaxException {
        RequestConfig defaultRequestConfig = RequestConfig.custom()
                .setConnectTimeout(JMeterUtils.getPropDefault(""backend_influxdb.connection_timeout"", 1000))
                .setSocketTimeout(JMeterUtils.getPropDefault(""backend_influxdb.socket_timeout"", 3000))
                .setConnectionRequestTimeout(JMeterUtils.getPropDefault(""backend_influxdb.connection_request_timeout"", 100))
                .build();

        HttpPost currentHttpRequest = new HttpPost(url.toURI());
        currentHttpRequest.setConfig(defaultRequestConfig);
        if (StringUtils.isNotBlank(token)) {
            currentHttpRequest.setHeader(AUTHORIZATION_HEADER_NAME, AUTHORIZATION_HEADER_VALUE + token);
        }
        
---------------Reference log start----------------
log.debug(""Created InfluxDBMetricsSender with url: {}"", url)
---------------Reference log end----------------
        return currentHttpRequest;
    }",,
jmeter,14152,"log.error(""Error initializing XMLReader in XMLAssertion"", e)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/XMLAssertion.java/#L56,"@Override
        protected XMLReader initialValue() {
            try {
                XMLReader reader = SAXParserFactory.newInstance()
                        .newSAXParser()
                        .getXMLReader();
                reader.setFeature(""http://apache.org/xml/features/disallow-doctype-decl"", true);
                return reader;
            } catch (SAXException | ParserConfigurationException e) {
                
---------------Reference log start----------------
log.error(""Error initializing XMLReader in XMLAssertion"", e)
---------------Reference log end----------------
                return null;
            }
        }",,
jmeter,14159,"log.debug(""Did not find signature"")",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/SMIMEAssertion.java/#L119,"public static AssertionResult getResult(SMIMEAssertionTestElement testElement, SampleResult response, String name) {
        checkForBouncycastle();
        AssertionResult res = new AssertionResult(name);
        try {
            MimeMessage msg;
            final int msgPos = testElement.getSpecificMessagePositionAsInt();
            if (msgPos < 0){ // means counting from end
                SampleResult[] subResults = response.getSubResults();
                final int pos = subResults.length + msgPos;
                log.debug(""Getting message number: {} of {}"", pos, subResults.length);
                msg = getMessageFromResponse(response,pos);
            } else {
                log.debug(""Getting message number: {}"", msgPos);
                msg = getMessageFromResponse(response, msgPos);
            }

            SMIMESignedParser signedParser = null;
            if(log.isDebugEnabled()) {
                log.debug(""Content-type: {}"", msg.getContentType());
            }
            if (msg.isMimeType(""multipart/signed"")) { // $NON-NLS-1$
                MimeMultipart multipart = (MimeMultipart) msg.getContent();
                signedParser = new SMIMESignedParser(new BcDigestCalculatorProvider(), multipart);
            } else if (msg.isMimeType(""application/pkcs7-mime"") // $NON-NLS-1$
                    || msg.isMimeType(""application/x-pkcs7-mime"")) { // $NON-NLS-1$
                signedParser = new SMIMESignedParser(new BcDigestCalculatorProvider(), msg);
            }

            if (null != signedParser) {
                log.debug(""Found signature"");

                if (testElement.isNotSigned()) {
                    res.setFailure(true);
                    res.setFailureMessage(""Mime message is signed"");
                } else if (testElement.isVerifySignature() || !testElement.isSignerNoCheck()) {
                    res = verifySignature(testElement, signedParser, name);
                }

            } else {
                
---------------Reference log start----------------
log.debug(""Did not find signature"")
---------------Reference log end----------------
                if (!testElement.isNotSigned()) {
                    res.setFailure(true);
                    res.setFailureMessage(""Mime message is not signed"");
                }
            }

        } catch (MessagingException e) {
            String msg = ""Cannot parse mime msg: "" + e.getMessage();
            log.warn(msg, e);
            res.setFailure(true);
            res.setFailureMessage(msg);
        } catch (CMSException e) {
            res.setFailure(true);
            res.setFailureMessage(""Error reading the signature: ""
                    + e.getMessage());
        } catch (SMIMEException e) {
            res.setFailure(true);
            res.setFailureMessage(""Cannot extract signed body part from signature: ""
                    + e.getMessage());
        } catch (IOException e) { // should never happen
            log.error(""Cannot read mime message content: {}"", e.getMessage(), e);
            res.setError(true);
            res.setFailureMessage(e.getMessage());
        }

        return res;
    }",,
jmeter,13857,"LOGGER.debug(""Session created"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jms/src/main/java/org/apache/jmeter/protocol/jms/sampler/JMSSampler.java/#L670,"@Override
    public void threadStarted() {
        logThreadStart();

        thrown = null;
        try {
            context = getInitialContext();
            Object obj = context.lookup(getQueueConnectionFactory());
            if (!(obj instanceof QueueConnectionFactory)) {
                String msg = ""QueueConnectionFactory expected, but got ""
                        + (obj != null ? obj.getClass().getName() : ""null"");
                LOGGER.error(msg);
                throw new IllegalStateException(msg);
            }
            QueueConnectionFactory factory = (QueueConnectionFactory) obj;
            sendQueue = (Queue) context.lookup(getSendQueue());

            if (!useTemporyQueue()) {
                receiveQueue = (Queue) context.lookup(getReceiveQueue());
                receiverThread = Receiver.createReceiver(factory, receiveQueue,
                        Utils.getFromEnvironment(context, Context.SECURITY_PRINCIPAL),
                        Utils.getFromEnvironment(context, Context.SECURITY_CREDENTIALS), isUseResMsgIdAsCorrelId(),
                        getJMSSelector());
            }

            String principal = null;
            String credentials = null;
            if (USE_SECURITY_PROPERTIES) {
                principal = Utils.getFromEnvironment(context, Context.SECURITY_PRINCIPAL);
                credentials = Utils.getFromEnvironment(context, Context.SECURITY_CREDENTIALS);
            }
            if (principal != null && credentials != null) {
                connection = factory.createQueueConnection(principal, credentials);
            } else {
                connection = factory.createQueueConnection();
            }

            session = connection.createQueueSession(false, Session.AUTO_ACKNOWLEDGE);

            
---------------Reference log start----------------
LOGGER.debug(""Session created"")
---------------Reference log end----------------

            if (!(isBrowse() || isRead() || isClearQueue())) {
                if (isOneway()) {
                    producer = session.createSender(sendQueue);
                    if (isNonPersistent()) {
                        producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT);
                    }
                    producer.setPriority(Integer.parseInt(getPriority()));
                    producer.setTimeToLive(Long.parseLong(getExpiration()));
                } else {
                    if (useTemporyQueue()) {
                        executor = new TemporaryQueueExecutor(session, sendQueue, getTimeoutAsInt());
                    } else {
                        producer = session.createSender(sendQueue);
                        executor = new FixedQueueExecutor(producer, getTimeoutAsInt(), isUseReqMsgIdAsCorrelId());
                    }
                }
            }
            LOGGER.debug(""Starting connection"");

            connection.start();

            LOGGER.debug(""Connection started"");
        } catch (Exception | NoClassDefFoundError e) {
            thrown = e;
            LOGGER.error(e.getLocalizedMessage(), e);
        }
    }",,
jmeter,13965,"log.warn(""Execution Problem in {}: {}"", getName(), ex.toString())",warn,https://github.com/apache/jmeter/blob/master/src/protocol/jdbc/src/main/java/org/apache/jmeter/protocol/jdbc/processor/AbstractJDBCProcessor.java/#L53,"protected void process() {
        if (JOrphanUtils.isBlank(getDataSource())) {
            throw new IllegalArgumentException(""Name for DataSoure must not be empty in "" + getName());
        }
        try (Connection conn = DataSourceElement.getConnection(getDataSource())){
            execute(conn);
        } catch (SQLException ex) {
            log.warn(""SQL Problem in {}: {}"", getName(), ex.toString());
        } catch (IOException ex) {
            log.warn(""IO Problem in {}: {}"", getName(), ex.toString());
        } catch (UnsupportedOperationException ex) {
            
---------------Reference log start----------------
log.warn(""Execution Problem in {}: {}"", getName(), ex.toString())
---------------Reference log end----------------
        }
    }",,
jmeter,14727,"log.info(""Stored: {} Alias: {}"", filename, alias)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/services/FileServer.java/#L267,"public synchronized String reserveFile(String filename, String charsetName, String alias, boolean hasHeader) {
        if (filename == null || filename.isEmpty()){
            throw new IllegalArgumentException(""Filename must not be null or empty"");
        }
        if (alias == null){
            throw new IllegalArgumentException(""Alias must not be null"");
        }
        FileEntry fileEntry = files.get(alias);
        if (fileEntry == null) {
            fileEntry = new FileEntry(resolveFileFromPath(filename), null, charsetName);
            if (filename.equals(alias)){
                log.info(""Stored: {}"", filename);
            } else {
                
---------------Reference log start----------------
log.info(""Stored: {} Alias: {}"", filename, alias)
---------------Reference log end----------------
            }
            files.put(alias, fileEntry);
            if (hasHeader) {
                try {
                    fileEntry.headerLine = readLine(alias, false);
                    if (fileEntry.headerLine == null) {
                        fileEntry.exception = new EOFException(""File is empty: "" + fileEntry.file);
                    }
                } catch (IOException | IllegalArgumentException e) {
                    fileEntry.exception = e;
                }
            }
        }
        if (hasHeader && fileEntry.headerLine == null) {
            throw new IllegalArgumentException(""Could not read file header line for file "" + filename,
                    fileEntry.exception);
        }
        return fileEntry.headerLine;
    }",,
jmeter,14585,"LOG.info(getClass() + ""#stopProducing(): "" + getName() + "" produced "" + producedSampleCount + "" samples"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/processor/AbstractSampleConsumer.java/#L248,"@Override
    public void stopProducing() {
        for (SampleConsumer consumer : this.sampleConsumers) {
            try {
                consumer.stopConsuming();
            } catch (Exception e) {
                throw new SampleException(""Consumer failed with message :""
                        + e.getMessage(), e);
            }
        }
        if (LOG.isInfoEnabled()) {
            
---------------Reference log start----------------
LOG.info(getClass() + ""#stopProducing(): "" + getName() + "" produced "" + producedSampleCount + "" samples"")
---------------Reference log end----------------
        }
    }",,
jmeter,13546,"log.info(""Creating entry {} in {}"", subject, CERT_PATH_ABS)",info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/ProxyControl.java/#L1586,"@SuppressWarnings(""JdkObsolete"")
    private void initDynamicKeyStore() throws IOException, GeneralSecurityException {
        if (storePassword  != null) { // Assume we have already created the store
            try {
                keyStore = getKeyStore(storePassword.toCharArray());
                for(String alias : KeyToolUtils.getCAaliases()) {
                    X509Certificate  caCert = (X509Certificate) keyStore.getCertificate(alias);
                    if (caCert == null) {
                        keyStore = null; // no CA key - probably the wrong store type.
                        break; // cannot continue
                    } else {
                        caCert.checkValidity(new Date(System.currentTimeMillis()+DateUtils.MILLIS_PER_DAY));
                        log.info(""Valid alias found for {}"", alias);
                    }
                }
            } catch (IOException e) { // store is faulty, we need to recreate it
                keyStore = null; // if cert is not valid, flag up to recreate it
                if (e.getCause() instanceof UnrecoverableKeyException) {
                    log.warn(
                            ""Could not read key store {}; cause: {}, a new one will be created, ensure you install it in browser"",
                            e.getMessage(), e.getCause().getMessage(), e);
                } else {
                    log.warn(
                            ""Could not open/read key store {}, a new one will be created, ensure you install it in browser"",
                            e.getMessage(), e); // message includes the file name
                }
            } catch (CertificateExpiredException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Existing ROOT Certificate has expired, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            } catch (CertificateNotYetValidException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Existing ROOT Certificate is not yet valid, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            } catch (GeneralSecurityException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Problem reading key store, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            }
        }
        if (keyStore == null) { // no existing file or not valid
            storePassword = JOrphanUtils.generateRandomAlphanumericPassword(20); // Alphanum to avoid issues with command-line quoting
            keyPassword = storePassword; // we use same password for both
            setPassword(storePassword);
            log.info(
                    ""Creating HTTP(S) Test Script Recorder Root CA in {}, ensure you install certificate in your Browser for recording"",
                    CERT_PATH_ABS);
            KeyToolUtils.generateProxyCA(CERT_PATH, storePassword, CERT_VALIDITY);
            log.info(""Created keystore in {}"", CERT_PATH_ABS);
            keyStore = getKeyStore(storePassword.toCharArray()); // This should now work
        }
        final String sslDomains = getSslDomains().trim();
        if (sslDomains.length() > 0) {
            final String[] domains = sslDomains.split("","");
            // The subject may be either a host or a domain
            for (String subject : domains) {
                if (isValid(subject)) {
                    if (!keyStore.containsAlias(subject)) {
                        
---------------Reference log start----------------
log.info(""Creating entry {} in {}"", subject, CERT_PATH_ABS)
---------------Reference log end----------------
                        KeyToolUtils.generateHostCert(CERT_PATH, storePassword, subject, CERT_VALIDITY);
                        keyStore = getKeyStore(storePassword.toCharArray()); // reload to pick up new aliases
                        // reloading is very quick compared with creating an entry currently
                    }
                } else {
                    log.warn(""Attempt to create an invalid domain certificate: {}"", subject);
                }
            }
        }
    }",,
jmeter,14246,"log.info(MSG_STOP_CURRENT_THREAD, getName())",info,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/sampler/TestAction.java/#L111,"@Override
    public SampleResult sample(Entry e) {
        JMeterContext context = JMeterContextService.getContext();

        int target = getTarget();
        int action = getAction();
        if (action == PAUSE) {
            pause(getDurationAsString());
        } else if (action == STOP || action == STOP_NOW) {
            if (target == THREAD) {
                if(log.isInfoEnabled()) {
                    log.info(MSG_STOP_CURRENT_THREAD, getName());
                }
                context.getThread().stop();
            } else if (target == TEST) {
                if (action == STOP_NOW) {
                    if(log.isInfoEnabled()) {
                        
---------------Reference log start----------------
log.info(MSG_STOP_CURRENT_THREAD, getName())
---------------Reference log end----------------
                    }
                    context.getThread().stop();
                    if(log.isInfoEnabled()) {
                        log.info(""Stopping all threads now from element {}"", getName());
                    }
                    context.getEngine().stopTest();
                } else {
                    if(log.isInfoEnabled()) {
                        log.info(MSG_STOP_CURRENT_THREAD, getName());
                    }
                    context.getThread().stop();
                    if(log.isInfoEnabled()) {
                        log.info(""Stopping all threads from element {}"", getName());
                    }
                    context.getEngine().askThreadsToStop();
                }
            }
        } else if (action == RESTART_NEXT_LOOP) {
            log.info(""Restarting next thread loop from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.START_NEXT_ITERATION_OF_THREAD);
        } else if (action == START_NEXT_ITERATION_CURRENT_LOOP) {
            log.info(""Switching to next loop iteration from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.START_NEXT_ITERATION_OF_CURRENT_LOOP);
        } else if (action == BREAK_CURRENT_LOOP) {
            log.info(""Breaking current loop from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.BREAK_CURRENT_LOOP);
        }

        return null; // This means no sample is saved
    }",,
jmeter,14022,"log.debug(""Canceled state: {}"", cancelState)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/graphite/GraphiteBackendListenerClient.java/#L354,"@Override
    public void teardownTest(BackendListenerContext context) throws Exception {
        boolean cancelState = timerHandle.cancel(false);
        
---------------Reference log start----------------
log.debug(""Canceled state: {}"", cancelState)
---------------Reference log end----------------
        scheduler.shutdown();
        try {
            scheduler.awaitTermination(30, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            log.error(""Error waiting for end of scheduler"");
            Thread.currentThread().interrupt();
        }
        // Send last set of data before ending
        sendMetrics();

        if (samplersToFilter != null) {
            samplersToFilter.clear();
        }
        graphiteMetricsManager.destroy();
        super.teardownTest(context);
    }",,
jmeter,13386,"log.debug(""Initialise cookies from pre-defined list"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/CookieManager.java/#L435,"@Override
    public void testIterationStart(LoopIterationEvent event) {
        JMeterVariables jMeterVariables = JMeterContextService.getContext().getVariables();
        if ((getControlledByThread() && !jMeterVariables.isSameUserOnNextIteration())
                || (!getControlledByThread() && getClearEachIteration())) {
            
---------------Reference log start----------------
log.debug(""Initialise cookies from pre-defined list"")
---------------Reference log end----------------
            // No need to call clear
            setProperty(initialCookies.clone());
        }
    }",,
jmeter,13260,"log.error(""Error calling {} function with value {}, digest algorithm {}, salt {}, "", KEY, stringToEncode, digestAlgorithm, salt, e)",error,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/DigestEncodeFunction.java/#L87,"@Override
    public String execute(SampleResult previousResult, Sampler currentSampler) throws InvalidVariableException {
        String digestAlgorithm = values[0].execute();
        String stringToEncode = values[1].execute();
        String salt = values.length > 2 ? values[2].execute() : null;
        String encodedString = null;
        try {
            MessageDigest md = MessageDigest.getInstance(digestAlgorithm);
            md.update(stringToEncode.getBytes(StandardCharsets.UTF_8));
            if (StringUtils.isNotEmpty(salt)) {
                md.update(salt.getBytes(StandardCharsets.UTF_8));
            }
            byte[] bytes = md.digest();
            encodedString = uppercase(Hex.encodeHexString(bytes), values, 3);
            addVariableValue(encodedString, values, 4);
        } catch (NoSuchAlgorithmException e) {
            
---------------Reference log start----------------
log.error(""Error calling {} function with value {}, digest algorithm {}, salt {}, "", KEY, stringToEncode, digestAlgorithm, salt, e)
---------------Reference log end----------------
        }
        return encodedString;
    }",,
jmeter,15029,"log.debug(""Resource string not found: [{}], using default value {}"", resKey, defaultValue)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JMeterUtils.java/#L521,"private static String getResStringDefault(String key, String defaultValue, Locale forcedLocale) {
        if (key == null) {
            return null;
        }
        // Resource keys cannot contain spaces, and are forced to lower case
        String resKey = key.replace(' ', '_'); // $NON-NLS-1$ // $NON-NLS-2$
        resKey = resKey.toLowerCase(java.util.Locale.ENGLISH);
        String resString = null;
        try {
            ResourceBundle bundle = resources;
            if (forcedLocale != null || bundle == null) {
                bundle = getBundle(forcedLocale);
            }

            if (bundle.containsKey(resKey)) {
                resString = bundle.getString(resKey);
            } else {
                if(defaultValue == null) {
                    log.warn(""ERROR! Resource string not found: [{}]"", resKey);
                } else {
                    log.debug(""Resource string not found: [{}], using default value {}"", resKey, defaultValue);
                }
                resString = defaultValue;
            }
            if (ignoreResources) { // Special mode for debugging resource handling
                return ""[""+key+""]"";
            }
        } catch (MissingResourceException mre) { // NOSONAR We handle correctly exception
            if (ignoreResources) { // Special mode for debugging resource handling
                return ""[?""+key+""?]"";
            }
            if(defaultValue == null) {
                log.warn(""ERROR! Resource string not found: [{}]"", resKey);
            } else {
                
---------------Reference log start----------------
log.debug(""Resource string not found: [{}], using default value {}"", resKey, defaultValue)
---------------Reference log end----------------
            }
            resString = defaultValue;
        }
        return resString;
    }",,
jmeter,13618,"log.info(""Reading httpclient parameters from "" + f.getAbsolutePath())",info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HttpClientDefaultParameters.java/#L93,"private static void load(String file, GenericHttpParams params){
        log.info(""Trying httpclient parameters from ""+file);
        File f = new File(file);
        if(! (f.exists() && f.canRead())) {
            f = new File(NewDriver.getJMeterDir() + File.separator
                    + ""bin"" + File.separator + file); // $NON-NLS-1$
            log.info(file + "" httpclient parameters does not exist, trying ""+f.getAbsolutePath());
            if(! (f.exists() && f.canRead())) {
                log.error(""Cannot read parameters file for HttpClient: ""+ file);
                return;
            }
        }
        
---------------Reference log start----------------
log.info(""Reading httpclient parameters from "" + f.getAbsolutePath())
---------------Reference log end----------------
        Properties props = new Properties();
        try ( InputStream is = new FileInputStream(f) ){
            props.load(is);
            for (Map.Entry<Object, Object> me : props.entrySet()){
                String key = (String) me.getKey();
                String value = (String)me.getValue();
                int typeSep = key.indexOf('$'); // $NON-NLS-1$
                try {
                    if (typeSep > 0){
                        String type = key.substring(typeSep+1);// get past separator
                        String name=key.substring(0,typeSep);
                        log.info(""Defining ""+name+ "" as ""+value+"" (""+type+"")"");
                        if (type.equals(""Integer"")){
                            params.setParameter(name, Integer.valueOf(value));
                        } else if (type.equals(""Long"")){
                            params.setParameter(name, Long.valueOf(value));
                        } else if (type.equals(""Boolean"")){
                            params.setParameter(name, Boolean.valueOf(value));
                        } else if (type.equals(""HttpVersion"")){ // Commons HttpClient only
                            params.setVersion(name, value);
                        } else {
                            log.warn(""Unexpected type: ""+type+"" for name ""+name);
                        }
                    } else {
                            log.info(""Defining ""+key+ "" as ""+value);
                            params.setParameter(key, value);
                    }
                } catch (Exception e) {
                    log.error(""Error in property: ""+key+""=""+value+"" ""+e.toString());
                }
            }
        } catch (IOException e) {
            log.error(""Problem loading properties ""+e.toString());
        }
    }",,
jmeter,14328,"log.debug(e.getLocalizedMessage(), e)",debug,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/reflect/ClassFinder.java/#L109,"private boolean isChildOf(
                Class<?>[] parentClasses, String strClassName, ClassLoader contextClassLoader) {
            try {
                Class<?> targetClass = Class.forName(strClassName, false, contextClassLoader);

                if (!targetClass.isInterface()
                        && !Modifier.isAbstract(targetClass.getModifiers())) {
                    return Arrays.stream(parentClasses)
                            .anyMatch(parent -> parent.isAssignableFrom(targetClass));
                }
            } catch (UnsupportedClassVersionError | ClassNotFoundException
                    | NoClassDefFoundError | VerifyError e) {
                
---------------Reference log start----------------
log.debug(e.getLocalizedMessage(), e)
---------------Reference log end----------------
            }
            return false;
        }",,
jmeter,14092,"log.warn(""Exception occurred while rendering chart."", e)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/AxisGraph.java/#L429,"private void drawSample(String _title, int _maxLength, String[] _xAxisLabels,
            String _yAxisTitle, String[] _legendLabels, double[][] _data,
            int _width, int _height, Color[] _color,
            Font legendFont, Graphics g) {
        double max = maxYAxisScale > 0 ? maxYAxisScale : findMax(_data); // define max scale y axis
        try {
            // Width and Height are already set in StatGraphVisualizer

            if (_maxLength < 3) {
                _maxLength = 3;
            }
            // if the ""Title of Graph"" is empty, we can assume some default
            if (_title.length() == 0 ) {
                _title = JMeterUtils.getResString(""aggregate_graph_title""); //$NON-NLS-1$
            }
            // if the labels are too long, they'll be ""squeezed"" to make the chart viewable.
            for (int i = 0; i < _xAxisLabels.length; i++) {
                String label = _xAxisLabels[i];
                _xAxisLabels[i]=squeeze(label, _maxLength);
            }
            this.setPreferredSize(new Dimension(_width,_height));
            // _xAxisTitle to null (don't display x axis title)
            DataSeries dataSeries = new DataSeries( _xAxisLabels, null, _yAxisTitle, _title );

            ClusteredBarChartProperties clusteredBarChartProperties= new ClusteredBarChartProperties();
            clusteredBarChartProperties.setShowOutlinesFlag(outlinesBarFlag);
            ValueLabelRenderer valueLabelRenderer = new ValueLabelRenderer(false, false, showGrouping, 0);
            valueLabelRenderer.setValueLabelPosition(ValueLabelPosition.AT_TOP);

            valueLabelRenderer.setValueChartFont(new ChartFont(valueFont, foreColor));
            valueLabelRenderer.useVerticalLabels(valueOrientation);

            clusteredBarChartProperties.addPostRenderEventListener(valueLabelRenderer);

            Paint[] paints = new Paint[_color.length];
            System.arraycopy(_color, 0, paints, 0, paints.length);

            AxisChartDataSet axisChartDataSet =
                new AxisChartDataSet(
                        _data, _legendLabels, paints, ChartType.BAR_CLUSTERED, clusteredBarChartProperties );
            dataSeries.addIAxisPlotDataSet( axisChartDataSet );

            ChartProperties chartProperties= new ChartProperties();
            LabelAxisProperties xaxis = new LabelAxisProperties();
            DataAxisProperties yaxis = new DataAxisProperties();
            yaxis.setUseCommas(showGrouping);

            if (legendFont != null) {
                yaxis.setAxisTitleChartFont(new ChartFont(legendFont, new Color(20)));
                yaxis.setScaleChartFont(new ChartFont(legendFont, new Color(20)));
                xaxis.setAxisTitleChartFont(new ChartFont(legendFont, new Color(20)));
                xaxis.setScaleChartFont(new ChartFont(legendFont, new Color(20)));
            }
            if (titleFont != null) {
                chartProperties.setTitleFont(new ChartFont(titleFont, new Color(0)));
            }

            // Y Axis
            try {
                BigDecimal round = BigDecimal.valueOf(max / 1000d);
                round = round.setScale(0, RoundingMode.HALF_EVEN);
                double topValue = round.doubleValue() * 1000;
                yaxis.setUserDefinedScale(0, 500);
                yaxis.setNumItems((int) (topValue / 500)+1);
                yaxis.setShowGridLines(1);
            } catch (PropertyException e) {
                log.warn(""Chart property exception occurred."", e);
            }

            AxisProperties axisProperties= new AxisProperties(xaxis, yaxis);
            axisProperties.setXAxisLabelsAreVertical(true);
            LegendProperties legendProperties= new LegendProperties();
            legendProperties.setBorderStroke(null);
            legendProperties.setPlacement(legendPlacement);
            legendProperties.setIconBorderPaint(Color.WHITE);
            if (legendPlacement == LegendAreaProperties.RIGHT || legendPlacement == LegendAreaProperties.LEFT) {
                legendProperties.setNumColumns(1);
            }
            if (legendFont != null) {
                legendProperties.setFont(legendFont); //new Font(""SansSerif"", Font.PLAIN, 10)
            }
            AxisChart axisChart = new AxisChart(
                    dataSeries, chartProperties, axisProperties,
                    legendProperties, _width, _height );
            axisChart.setGraphics2D((Graphics2D) g);
            axisChart.render();
        } catch (ChartDataException | PropertyException e) {
            
---------------Reference log start----------------
log.warn(""Exception occurred while rendering chart."", e)
---------------Reference log end----------------
        }
    }",,
jmeter,13370,"log.debug(""Entry {} found, but it should depend on vary {} for url {}"", entry, entry.getVaryHeader(), url)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/CacheManager.java/#L551,"private CacheEntry getEntry(String url, Header[] headers) {
        CacheEntry entry = getCache().get(url);
        log.debug(""getEntry url:{} entry:{} header:{}"", url, entry, headers);
        if (entry == null) {
            log.debug(""No entry found for url {}"", url);
            return null;
        }
        if (entry.getVaryHeader() == null) {
            log.debug(""Entry {} with no vary found for url {}"", entry, url);
            return entry;
        }
        if (headers == null) {
            if(log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Entry {} found, but it should depend on vary {} for url {}"", entry, entry.getVaryHeader(), url)
---------------Reference log end----------------
            }
            return null;
        }
        Pair<String, String> varyPair = getVaryHeader(entry.getVaryHeader(), headers);
        if (varyPair != null) {
            if(log.isDebugEnabled()) {
                log.debug(""Looking again for {} because of {} with vary: {} ({})"", url, entry, entry.getVaryHeader(), varyPair);
            }
            return getEntry(varyUrl(url, entry.getVaryHeader(), varyPair.getRight()), null);
        }
        return null;
    }",,
jmeter,13977,"log.info(""Test mail sent successfully!!"")",info,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/reporters/MailerModel.java/#L406,"public synchronized void sendTestMail() throws MessagingException {
        String to = getToAddress();
        String from = getFromAddress();
        String subject = ""Testing mail-addresses"";
        String smtpHost = getSmtpHost();
        String attText = ""JMeter-Testmail"" + ""\n"" + ""To:  "" + to + ""\n"" + ""From: "" + from + ""\n"" + ""Via:  "" + smtpHost
                + ""\n"" + ""Fail Subject:  "" + getFailureSubject() + ""\n"" + ""Success Subject:  "" + getSuccessSubject();

        log.info(attText);

        sendMail(from, getAddressList(), subject, attText, smtpHost,
                getSmtpPort(),
                getLogin(),
                getPassword(),
                getMailAuthType(),
                true);
        
---------------Reference log start----------------
log.info(""Test mail sent successfully!!"")
---------------Reference log end----------------
    }
    }",,
jmeter,14197,"log.debug(""matchNumber({}) exceeds number of items found({}), default value will be used"", matchNumber, resultList.size())",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/extractor/json/jmespath/JMESPathExtractor.java/#L141,"private void handleListResult(JMeterVariables vars, String refName, String defaultValue, int matchNumber,
            List<String> resultList) {
        if (matchNumber < 0) {
            // Extract all
            int index = 1;
            for (String extractedString : resultList) {
                vars.put(refName + ""_"" + index, extractedString); // $NON-NLS-1$
                index++;
            }
        } else if (matchNumber == 0) {
            // Random extraction
            int matchSize = resultList.size();
            int matchNr = JMeterUtils.getRandomInt(matchSize);
            placeObjectIntoVars(vars, refName, resultList, matchNr);
        } else {
            // extract at position
            if (matchNumber > resultList.size()) {
                if (log.isDebugEnabled()) {
                    
---------------Reference log start----------------
log.debug(""matchNumber({}) exceeds number of items found({}), default value will be used"", matchNumber, resultList.size())
---------------Reference log end----------------
                }
                vars.put(refName, defaultValue);
            } else {
                placeObjectIntoVars(vars, refName, resultList, matchNumber - 1);
            }
        }
    }",,
jmeter,15037,"log.warn(""Exception '{}' occurred when fetching boolean property:'{}', defaulting to: {}"", e.getMessage(), propName, defaultVal)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JMeterUtils.java/#L711,"public static boolean getPropDefault(String propName, boolean defaultVal) {
        try {
            String strVal = appProperties.getProperty(propName, Boolean.toString(defaultVal)).trim();
            if (""true"".equalsIgnoreCase(strVal) || ""t"".equalsIgnoreCase(strVal)) { // $NON-NLS-1$  // $NON-NLS-2$
                return true;
            } else if (""false"".equalsIgnoreCase(strVal) || ""f"".equalsIgnoreCase(strVal)) { // $NON-NLS-1$  // $NON-NLS-2$
                return false;
            } else {
                return Integer.parseInt(strVal) == 1;
            }
        } catch (Exception e) {
            
---------------Reference log start----------------
log.warn(""Exception '{}' occurred when fetching boolean property:'{}', defaulting to: {}"", e.getMessage(), propName, defaultVal)
---------------Reference log end----------------
        }
        return defaultVal;
    }",,
jmeter,13640,"log.debug(""Extracted from HttpContext user token:{} storing it as JMeter variable:{}"", userToken, JMETER_VARIABLE_USER_TOKEN)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPHC4Impl.java/#L843,"private void extractClientContextAfterSample(JMeterVariables jMeterVariables, HttpContext localContext) {
        Object userToken = localContext.getAttribute(HttpClientContext.USER_TOKEN);
        if(userToken != null) {
            
---------------Reference log start----------------
log.debug(""Extracted from HttpContext user token:{} storing it as JMeter variable:{}"", userToken, JMETER_VARIABLE_USER_TOKEN)
---------------Reference log end----------------
            // During recording JMeterContextService.getContext().getVariables() is null
            if (jMeterVariables != null) {
                jMeterVariables.putObject(JMETER_VARIABLE_USER_TOKEN, userToken);
            }
        }
    }",,
jmeter,14483,"log.debug(""toggling currently selected gui objects"")",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/action/EnableComponent.java/#L57,"@Override
    public void doAction(ActionEvent e) {
        JMeterTreeNode[] nodes = GuiPackage.getInstance().getTreeListener().getSelectedNodes();

        if (e.getActionCommand().equals(ActionNames.ENABLE)) {
            log.debug(""enabling currently selected gui objects"");
            enableComponents(nodes, true);
        } else if (e.getActionCommand().equals(ActionNames.DISABLE)) {
            log.debug(""disabling currently selected gui objects"");
            enableComponents(nodes, false);
        } else if (e.getActionCommand().equals(ActionNames.TOGGLE)) {
            
---------------Reference log start----------------
log.debug(""toggling currently selected gui objects"")
---------------Reference log end----------------
            toggleComponents(nodes);
        }
    }",,
jmeter,13970,"log.warn(""Error closing Connection"", e)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/jdbc/src/main/java/org/apache/jmeter/protocol/jdbc/AbstractJDBCTestElement.java/#L624,"public static void close(Connection c) {
        try {
            if (c != null) {
                c.close();
            }
        } catch (SQLException e) {
            
---------------Reference log start----------------
log.warn(""Error closing Connection"", e)
---------------Reference log end----------------
        }
    }",,
jmeter,13416,"log.debug(""Chunked"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/HttpMirrorThread.java/#L266,"@Override
    public void run() {
        log.debug(""Starting thread"");
        BufferedInputStream in = null;
        BufferedOutputStream out = null;

        try {
            in = new BufferedInputStream(clientSocket.getInputStream());

            // Read the header part, we will be looking for a content-length
            // header, so we know how much we should read.
            // We assume headers are in ISO_8859_1
            // If we do not find such a header, we will just have to read until
            // we have to block to read more, until we support chunked transfer
            int contentLength = -1;
            boolean isChunked = false;
            byte[] buffer = new byte[1024];
            StringBuilder headers = new StringBuilder();
            int length = 0;
            int positionOfBody = 0;
            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            while(positionOfBody <= 0 && ((length = in.read(buffer)) != -1)) {
                log.debug(""Write body"");
                baos.write(buffer, 0, length); // echo back
                headers.append(new String(buffer, 0, length, ISO_8859_1));
                // Check if we have read all the headers
                positionOfBody = getPositionOfBody(headers.toString());
            }

            baos.close();
            final String headerString = headers.toString();
            if(headerString.length() == 0 || headerString.indexOf('\r') < 0) {
                log.error(""Invalid request received:'{}'"", headerString);
                return;
            }
            log.debug(""Received => '{}'"", headerString);
            final String firstLine = headerString.substring(0, headerString.indexOf('\r'));
            final String[] requestParts = firstLine.split(""\\s+"");
            final String requestMethod = requestParts[0];
            final String requestPath = requestParts[1];
            final HashMap<String, String> parameters = new HashMap<>();
            if (HTTPConstants.GET.equals(requestMethod)) {
                int querypos = requestPath.indexOf('?');
                if (querypos >= 0) {
                    String query;
                    try {
                        URI uri = new URI(requestPath); // Use URI because it will decode the query
                        query = uri.getQuery();
                    } catch (URISyntaxException e) {
                        log.warn(e.getMessage());
                        query=requestPath.substring(querypos+1);
                    }
                    if (query != null) {
                        String[] params = query.split(""&"");
                        for(String param : params) {
                            String[] parts = param.split(""="",2);
                            if (parts.length==2) {
                                parameters.put(parts[0], parts[1]);
                            } else { // allow for parameter name only
                                parameters.put(parts[0], """");
                            }
                        }
                    }
                }
            }

            final boolean verbose = parameters.containsKey(VERBOSE);

            if (verbose) {
                System.out.println(firstLine); // NOSONAR
                log.info(firstLine);
            }

            // Look for special Response Length header
            String responseStatusValue = getRequestHeaderValue(headerString, ""X-ResponseStatus""); //$NON-NLS-1$
            if(responseStatusValue == null) {
                responseStatusValue = ""200 OK"";
            }
            // Do this before the status check so can override the status, e.g. with a different redirect type
            if (parameters.containsKey(REDIRECT)) {
                responseStatusValue = ""302 Temporary Redirect"";
            }
            if (parameters.containsKey(STATUS)) {
                responseStatusValue = parameters.get(STATUS);
            }

            log.debug(""Write headers"");
            out = new BufferedOutputStream(clientSocket.getOutputStream());
            // The headers are written using ISO_8859_1 encoding
            out.write((""HTTP/1.0 ""+responseStatusValue).getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);
            out.write(""Content-Type: text/plain"".getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);

            if (parameters.containsKey(REDIRECT)) {
                final String redirectLocation =
                        HTTPConstants.HEADER_LOCATION + "": "" + parameters.get(REDIRECT);
                if (verbose) {
                    System.out.println(redirectLocation); // NOSONAR
                    log.info(redirectLocation);
                }
                out.write(redirectLocation.getBytes(ISO_8859_1));
                out.write(CRLF);
            }

            // Look for special Header request
            String headersValue = getRequestHeaderValue(headerString, ""X-SetHeaders""); //$NON-NLS-1$
            if (headersValue != null) {
                String[] headersToSet = headersValue.split(""\\|"");
                for (String string : headersToSet) {
                    out.write(string.getBytes(ISO_8859_1));
                    out.write(CRLF);
                }
            }

            // Look for special Response Length header
            String responseLengthValue = getRequestHeaderValue(headerString, ""X-ResponseLength""); //$NON-NLS-1$
            int responseLength=-1;
            if(responseLengthValue != null) {
                responseLength = Integer.parseInt(responseLengthValue);
            }

            // Look for special Cookie request
            String cookieHeaderValue = getRequestHeaderValue(headerString, ""X-SetCookie""); //$NON-NLS-1$
            if (cookieHeaderValue != null) {
                out.write(""Set-Cookie: "".getBytes(ISO_8859_1));
                out.write(cookieHeaderValue.getBytes(ISO_8859_1));
                out.write(CRLF);
            }
            out.write(CRLF);
            out.flush();

            if(responseLength>=0) {
                out.write(baos.toByteArray(), 0, Math.min(baos.toByteArray().length, responseLength));
            } else {
                out.write(baos.toByteArray());
            }
            // Check if we have found a content-length header
            String contentLengthHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.HEADER_CONTENT_LENGTH);
            if(contentLengthHeaderValue != null) {
                contentLength = Integer.parseInt(contentLengthHeaderValue);
            }
            // Look for special Sleep request
            String sleepHeaderValue = getRequestHeaderValue(headerString, ""X-Sleep""); //$NON-NLS-1$
            if(sleepHeaderValue != null) {
                TimeUnit.MILLISECONDS.sleep(Integer.parseInt(sleepHeaderValue));
            }
            String transferEncodingHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.TRANSFER_ENCODING);
            if(transferEncodingHeaderValue != null) {
                isChunked = transferEncodingHeaderValue.equalsIgnoreCase(""chunked""); //$NON-NLS-1$
                // We only support chunked transfer encoding
                if(!isChunked) {
                    log.error(""Transfer-Encoding header set, the value is not supported : {}"", transferEncodingHeaderValue);
                }
            }

            // If we know the content length, we can allow the reading of
            // the request to block until more data arrives.
            // If it is chunked transfer, we cannot allow the reading to
            // block, because we do not know when to stop reading, because
            // the chunked transfer is not properly supported yet
            length = 0;
            if(contentLength > 0) {
                // Check how much of the body we have already read as part of reading
                // the headers
                // We subtract two bytes for the crlf divider between header and body
                int totalReadBytes = headerString.length() - positionOfBody - 2;

                // We know when to stop reading, so we can allow the read method to block
                log.debug(""Reading, {} < {}"", totalReadBytes, contentLength);
                while((totalReadBytes < contentLength) && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);

                    totalReadBytes += length;
                    log.debug(""totalReadBytes: {}"", totalReadBytes);
                }
            }
            else if (isChunked) {
                // It is chunked transfer encoding, which we do not really support yet.
                // So we just read without blocking, because we do not know when to
                // stop reading, so we cannot block
                // TODO properly implement support for chunked transfer, i.e. to
                // know when we have read the whole request, and therefore allow
                // the reading to block
                
---------------Reference log start----------------
log.debug(""Chunked"")
---------------Reference log end----------------
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    out.write(buffer, 0, length);
                }
            }
            else {
                // The request has no body, or it has a transfer encoding we do not support.
                // In either case, we read any data available
                log.debug(""Other"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);
                }
            }
            log.debug(""Flush"");
            out.flush();
        } catch (IOException | InterruptedException e) {
            log.error("""", e);
        } finally {
            JOrphanUtils.closeQuietly(out);
            JOrphanUtils.closeQuietly(in);
            JOrphanUtils.closeQuietly(clientSocket);
        }
        log.debug(""End of Thread"");
    }",,
jmeter,14241,"log.info(""Breaking current loop from element {}"", getName())",info,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/sampler/TestAction.java/#L136,"@Override
    public SampleResult sample(Entry e) {
        JMeterContext context = JMeterContextService.getContext();

        int target = getTarget();
        int action = getAction();
        if (action == PAUSE) {
            pause(getDurationAsString());
        } else if (action == STOP || action == STOP_NOW) {
            if (target == THREAD) {
                if(log.isInfoEnabled()) {
                    log.info(MSG_STOP_CURRENT_THREAD, getName());
                }
                context.getThread().stop();
            } else if (target == TEST) {
                if (action == STOP_NOW) {
                    if(log.isInfoEnabled()) {
                        log.info(MSG_STOP_CURRENT_THREAD, getName());
                    }
                    context.getThread().stop();
                    if(log.isInfoEnabled()) {
                        log.info(""Stopping all threads now from element {}"", getName());
                    }
                    context.getEngine().stopTest();
                } else {
                    if(log.isInfoEnabled()) {
                        log.info(MSG_STOP_CURRENT_THREAD, getName());
                    }
                    context.getThread().stop();
                    if(log.isInfoEnabled()) {
                        log.info(""Stopping all threads from element {}"", getName());
                    }
                    context.getEngine().askThreadsToStop();
                }
            }
        } else if (action == RESTART_NEXT_LOOP) {
            log.info(""Restarting next thread loop from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.START_NEXT_ITERATION_OF_THREAD);
        } else if (action == START_NEXT_ITERATION_CURRENT_LOOP) {
            log.info(""Switching to next loop iteration from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.START_NEXT_ITERATION_OF_CURRENT_LOOP);
        } else if (action == BREAK_CURRENT_LOOP) {
            
---------------Reference log start----------------
log.info(""Breaking current loop from element {}"", getName())
---------------Reference log end----------------
            context.setTestLogicalAction(TestLogicalAction.BREAK_CURRENT_LOOP);
        }

        return null; // This means no sample is saved
    }",,
jmeter,15098,"log.info(""Thread started: {}"", Thread.currentThread().getName())",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/threads/JMeterThread.java/#L727,"private IterationListener initRun(JMeterContext threadContext) {
        threadVars.putObject(JMeterVariables.VAR_IS_SAME_USER_KEY, isSameUserOnNextIteration);
        threadContext.setVariables(threadVars);
        threadContext.setThreadNum(getThreadNum());
        setLastSampleOk(threadVars, true);
        threadContext.setThread(this);
        threadContext.setThreadGroup(threadGroup);
        threadContext.setEngine(engine);
        testTree.traverse(compiler);
        if (scheduler) {
            // set the scheduler to start
            startScheduler();
        }

        rampUpDelay(); // TODO - how to handle thread stopped here
        if (log.isInfoEnabled()) {
            
---------------Reference log start----------------
log.info(""Thread started: {}"", Thread.currentThread().getName())
---------------Reference log end----------------
        }
        /*
         * Setting SamplingStarted before the controllers are initialised allows
         * them to access the running values of functions and variables (however
         * it does not seem to help with the listeners)
         */
        threadContext.setSamplingStarted(true);

        threadGroupLoopController.initialize();
        IterationListener iterationListener = new IterationListener();
        threadGroupLoopController.addIterationListener(iterationListener);

        threadStarted();
        return iterationListener;
    }",,
jmeter,14932,"log.info(""Total of {} aliases loaded OK from PKCS11"", keyStore.getAliasCount())",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/SSLManager.java/#L142,"protected synchronized JmeterKeyStore getKeyStore() {
        if (null == this.keyStore) {
            String fileName = System.getProperty(JAVAX_NET_SSL_KEY_STORE,""""); // empty if not provided
            String fileType = System.getProperty(JAVAX_NET_SSL_KEY_STORE_TYPE, // use the system property to determine the type
                    fileName.toLowerCase(Locale.ENGLISH).endsWith("".p12"") ? PKCS12 : ""JKS""); // otherwise use the name
            log.info(""JmeterKeyStore Location: {} type {}"", fileName, fileType);
            try {
                this.keyStore = JmeterKeyStore.getInstance(fileType, keystoreAliasStartIndex, keystoreAliasEndIndex, clientCertAliasVarName);
                log.info(""KeyStore created OK"");
            } catch (Exception e) {
                this.keyStore = null;
                throw new IllegalArgumentException(""Could not create keystore: ""+e.getMessage(), e);
            }

           try {

              // The string 'NONE' is used for the keystore location when using PKCS11
              // https://docs.oracle.com/javase/8/docs/technotes/guides/security/p11guide.html#JSSE
              if (""NONE"".equalsIgnoreCase(fileName)) {
                 retryLoadKeys(null, false);
                 
---------------Reference log start----------------
log.info(""Total of {} aliases loaded OK from PKCS11"", keyStore.getAliasCount())
---------------Reference log end----------------
              } else {
                 File initStore = new File(fileName);
                 if (fileName.length() > 0 && initStore.exists()) {
                     retryLoadKeys(initStore, true);
                     if (log.isInfoEnabled()) {
                         log.info(""Total of {} aliases loaded OK from keystore {}"",
                                 keyStore.getAliasCount(), fileName);
                     }
                 } else {
                    log.warn(""Keystore file not found, loading empty keystore"");
                    this.defaultpw = """"; // Ensure not null
                    this.keyStore.load(null, """");
                 }
              }
           } catch (Exception e) {
              log.error(""Problem loading keystore: {}"", e.getMessage(), e);
           }

           if (log.isDebugEnabled()) {
              log.debug(""JmeterKeyStore type: {}"", this.keyStore.getClass());
           }
        }

        return this.keyStore;
    }",,
jmeter,13651,"log.debug(""Thread state will be reset ?: {}"", RESET_STATE_ON_THREAD_GROUP_ITERATION)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPHC4Impl.java/#L1872,"@Override
    protected void notifyFirstSampleAfterLoopRestart() {
        log.debug(""notifyFirstSampleAfterLoopRestart called ""
                + ""with config(httpclient.reset_state_on_thread_group_iteration={})"",
                RESET_STATE_ON_THREAD_GROUP_ITERATION);
        JMeterVariables jMeterVariables = JMeterContextService.getContext().getVariables();
        if (jMeterVariables.isSameUserOnNextIteration()) {
            log.debug(""Thread Group is configured to simulate a returning visitor on each iteration, ignoring property value {}"",
                    RESET_STATE_ON_THREAD_GROUP_ITERATION);
            resetStateOnThreadGroupIteration.set(false);
        } else {
            log.debug(""Thread Group is configured to simulate a new visitor on each iteration, using property value {}"",
                    RESET_STATE_ON_THREAD_GROUP_ITERATION);
            resetStateOnThreadGroupIteration.set(RESET_STATE_ON_THREAD_GROUP_ITERATION);
        }
        
---------------Reference log start----------------
log.debug(""Thread state will be reset ?: {}"", RESET_STATE_ON_THREAD_GROUP_ITERATION)
---------------Reference log end----------------
    }
    }",,
jmeter,14734,"log.info(""Resolving by name the value of System property 'java.rmi.server.hostname': {}"", host)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/rmi/RmiUtils.java/#L133,"public static InetAddress getRmiHost() throws RemoteException {
        InetAddress localHost=null;
        // Bug 47980 - allow override of local hostname
        String host = System.getProperties().getProperty(""java.rmi.server.hostname""); // $NON-NLS-1$
        try {
            if( host==null ) {
                log.info(""System property 'java.rmi.server.hostname' is not defined, using localHost address"");
                localHost = InetAddress.getLocalHost();
            } else {
                
---------------Reference log start----------------
log.info(""Resolving by name the value of System property 'java.rmi.server.hostname': {}"", host)
---------------Reference log end----------------
                localHost = InetAddress.getByName(host);
            }
        } catch (UnknownHostException e) {
            throw new RemoteException(""Cannot start. Unable to get local host IP address."", e);
        }
        if (log.isInfoEnabled()) {
            log.info(""Local IP address={}"", localHost.getHostAddress());
        }
        // BUG 52469 : Allow loopback address for SSH Tunneling of RMI traffic
        if (host == null && localHost.isLoopbackAddress()){
            String hostName = localHost.getHostName();
            throw new RemoteException(""Cannot start. "" + hostName + "" is a loopback address."");
        }
        return localHost;
    }",,
jmeter,13516,"log.error(""Error parsing BASIC Auth authorization header:'{}', decoded value:'{}'"", authCredentialsBase64, authCred)",error,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/ProxyControl.java/#L721,"private Authorization createAuthorization(final TestElement[] testElements, SampleResult result) {
        Header authHeader;
        Authorization authorization = null;
        // Iterate over subconfig elements searching for HeaderManager
        for (TestElement te : testElements) {
            if (te instanceof HeaderManager) {
                @SuppressWarnings(""unchecked"") // headers should only contain the correct classes
                List<TestElementProperty> headers = (ArrayList<TestElementProperty>) ((HeaderManager) te).getHeaders().getObjectValue();
                for (Iterator<?> iterator = headers.iterator(); iterator.hasNext();) {
                    TestElementProperty tep = (TestElementProperty) iterator
                            .next();
                    if (tep.getName().equals(HTTPConstants.HEADER_AUTHORIZATION)) {
                        //Construct Authorization object from HEADER_AUTHORIZATION
                        authHeader = (Header) tep.getObjectValue();
                        String headerValue = authHeader.getValue().trim();
                        String[] authHeaderContent = headerValue.split("" "");//$NON-NLS-1$
                        String authType;
                        String authCredentialsBase64;
                        if(authHeaderContent.length>=2) {
                            authType = authHeaderContent[0];
                            // if HEADER_AUTHORIZATION contains ""Basic""
                            // then set Mechanism.BASIC_DIGEST, otherwise Mechanism.KERBEROS
                            Mechanism mechanism;
                            switch (authType) {
                                case BEARER_AUTH:
                                    // This one will need to be correlated manually by user
                                    return null;
                                case DIGEST_AUTH:
                                    mechanism = Mechanism.DIGEST;
                                    break;
                                case BASIC_AUTH:
                                    mechanism = Mechanism.BASIC;
                                    break;
                                default:
                                    mechanism = Mechanism.KERBEROS;
                                    break;
                            }
                            authCredentialsBase64 = authHeaderContent[1];
                            authorization=new Authorization();
                            authorization.setURL(computeAuthUrl(result.getUrlAsString()));
                            authorization.setMechanism(mechanism);
                            if(BASIC_AUTH.equals(authType)) {
                                String authCred = new String(Base64.decodeBase64(authCredentialsBase64), StandardCharsets.UTF_8);
                                String[] loginPassword = authCred.split("":""); //$NON-NLS-1$
                                if(loginPassword.length == 2) {
                                    authorization.setUser(loginPassword[0]);
                                    authorization.setPass(loginPassword[1]);
                                } else {
                                    
---------------Reference log start----------------
log.error(""Error parsing BASIC Auth authorization header:'{}', decoded value:'{}'"", authCredentialsBase64, authCred)
---------------Reference log end----------------
                                    // we keep initial header
                                    return null;
                                }
                            } else {
                                // Digest or Kerberos
                                authorization.setUser(""${AUTH_LOGIN}"");//$NON-NLS-1$
                                authorization.setPass(""${AUTH_PASSWORD}"");//$NON-NLS-1$
                            }
                        }
                        // remove HEADER_AUTHORIZATION from HeaderManager
                        // because it's useless after creating Authorization object
                        iterator.remove();
                        break;
                    }
                }
            }
        }
        return authorization;
    }",,
jmeter,14077,"log.error(""Error extracting data from tree node using searcher:{}"", searcher, e)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/SearchTreePanel.java/#L208,"private boolean searchInNode(Searcher searcher, SearchableTreeNode node) {
        node.reset();
        Object userObject = node.getUserObject();

        try {
            Searchable searchable;
            if(userObject instanceof Searchable) {
                searchable = (Searchable) userObject;
            } else {
                return false;
            }
            if(searcher.search(searchable.getSearchableTokens())) {
                node.setNodeHasMatched(true);
            }
            boolean foundInChildren = false;
            for (int i = 0; i < node.getChildCount(); i++) {
                searchInNode(searcher, (SearchableTreeNode)node.getChildAt(i));
                foundInChildren =
                        searchInNode(searcher, (SearchableTreeNode)node.getChildAt(i))
                        || foundInChildren; // Must be the last in condition
            }
            if(!node.isNodeHasMatched()) {
                node.setChildrenNodesHaveMatched(foundInChildren);
            }
            node.updateState();
            return node.isNodeHasMatched() || node.isChildrenNodesHaveMatched();
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(""Error extracting data from tree node using searcher:{}"", searcher, e)
---------------Reference log end----------------
            return false;
        }
    }",,
jmeter,14726,"log.info(""Set new base='{}'"", base)",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/services/FileServer.java/#L156,"public synchronized void setBase(File jmxBase) {
        if (jmxBase == null) {
            throw new IllegalArgumentException(""jmxBase must not be null"");
        }
        checkForOpenFiles();
        base = jmxBase;
        
---------------Reference log start----------------
log.info(""Set new base='{}'"", base)
---------------Reference log end----------------
    }
    }",,
jmeter,13890,"log.debug(getClass().getName() + "": setupTest"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/java/src/main/java/org/apache/jmeter/protocol/java/sampler/AbstractJavaSamplerClient.java/#L57,"@Override
    public void setupTest(JavaSamplerContext context) {
        
---------------Reference log start----------------
log.debug(getClass().getName() + "": setupTest"")
---------------Reference log end----------------
    }
    }",,
jmeter,14229,"log.warn(""Could not parse number: '{}'"", prevString)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/extractor/RegexExtractor.java/#L124,"@Override
    public void process() {
        initTemplate();
        JMeterContext context = getThreadContext();
        SampleResult previousResult = context.getPreviousResult();
        if (previousResult == null) {
            return;
        }
        log.debug(""RegexExtractor processing result"");

        // Fetch some variables
        JMeterVariables vars = context.getVariables();
        String refName = getRefName();
        int matchNumber = getMatchNumber();

        final String defaultValue = getDefaultValue();
        if (defaultValue.length() > 0 || isEmptyDefaultValue()) {// Only replace default if it is provided or empty default value is explicitly requested
            vars.put(refName, defaultValue);
        }

        Perl5Matcher matcher = JMeterUtils.getMatcher();
        String regex = getRegex();
        Pattern pattern = null;
        try {
            pattern = JMeterUtils.getPatternCache().getPattern(regex, Perl5Compiler.READ_ONLY_MASK);
            List<MatchResult> matches = processMatches(pattern, regex, previousResult, matchNumber, vars);
            int prevCount = 0;
            String prevString = vars.get(refName + REF_MATCH_NR);
            if (prevString != null) {
                vars.remove(refName + REF_MATCH_NR);// ensure old value is not left defined
                try {
                    prevCount = Integer.parseInt(prevString);
                } catch (NumberFormatException nfe) {
                    
---------------Reference log start----------------
log.warn(""Could not parse number: '{}'"", prevString)
---------------Reference log end----------------
                }
            }
            int matchCount=0;// Number of refName_n variable sets to keep
            try {
                MatchResult match;
                if (matchNumber >= 0) {// Original match behaviour
                    match = getCorrectMatch(matches, matchNumber);
                    if (match != null) {
                        vars.put(refName, generateResult(match));
                        saveGroups(vars, refName, match);
                    } else {
                        // refname has already been set to the default (if present)
                        removeGroups(vars, refName);
                    }
                } else // < 0 means we save all the matches
                {
                    removeGroups(vars, refName); // remove any single matches
                    matchCount = matches.size();
                    vars.put(refName + REF_MATCH_NR, Integer.toString(matchCount));// Save the count
                    for (int i = 1; i <= matchCount; i++) {
                        match = getCorrectMatch(matches, i);
                        if (match != null) {
                            final String refName_n = refName + UNDERSCORE + i;
                            vars.put(refName_n, generateResult(match));
                            saveGroups(vars, refName_n, match);
                        }
                    }
                }
                // Remove any left-over variables
                for (int i = matchCount + 1; i <= prevCount; i++) {
                    final String refName_n = refName + UNDERSCORE + i;
                    vars.remove(refName_n);
                    removeGroups(vars, refName_n);
                }
            } catch (RuntimeException e) {
                log.warn(""Error while generating result"");
            }
        } catch (MalformedCachePatternException e) {
            log.error(""Error in pattern: '{}'"", regex);
        } finally {
            JMeterUtils.clearMatcherMemory(matcher, pattern);
        }
    }",,
jmeter,13919,"log.warn(""Deprecated method, use read(is, sampleResult) instead"")",warn,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/BinaryTCPClientImpl.java/#L108,"@Deprecated
    public String read(InputStream is) throws ReadException {
        
---------------Reference log start----------------
log.warn(""Deprecated method, use read(is, sampleResult) instead"")
---------------Reference log end----------------
        return read(is, new SampleResult());
    }",,
jmeter,13375,log.warn(cookieHeader + e.getLocalizedMessage()),warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/HC4CookieHandler.java/#L170,"@Override
    @SuppressWarnings(""JdkObsolete"")
    public void addCookieFromHeader(CookieManager cookieManager,
            boolean checkCookies, String cookieHeader, URL url) {
            boolean debugEnabled = log.isDebugEnabled();
            if (debugEnabled) {
                log.debug(""Received Cookie: {} From: {}"", cookieHeader, url.toExternalForm());
            }
            String protocol = url.getProtocol();
            String host = url.getHost();
            int port= HTTPSamplerBase.getDefaultPort(protocol,url.getPort());
            String path = url.getPath();
            boolean isSecure=HTTPSamplerBase.isSecure(protocol);

            List<org.apache.http.cookie.Cookie> cookies = null;

            CookieOrigin cookieOrigin = new CookieOrigin(host, port, path, isSecure);
            BasicHeader basicHeader = new BasicHeader(HTTPConstants.HEADER_SET_COOKIE, cookieHeader);

            try {
                cookies = cookieSpec.parse(basicHeader, cookieOrigin);
            } catch (MalformedCookieException e) {
                log.error(""Unable to add the cookie"", e);
            }
            if (cookies == null) {
                return;
            }
            for (org.apache.http.cookie.Cookie cookie : cookies) {
                try {
                    if (checkCookies) {
                        try {
                            cookieSpec.validate(cookie, cookieOrigin);
                        } catch (MalformedCookieException e) { // This means the cookie was wrong for the URL
                            log.info(""Not storing invalid cookie: <{}> for URL {} ({})"",
                                cookieHeader, url, e.getLocalizedMessage());
                            continue;
                        }
                    }
                    Date expiryDate = cookie.getExpiryDate();
                    long exp = 0;
                    if (expiryDate!= null) {
                        exp=expiryDate.getTime();
                    }
                    Cookie newCookie = new Cookie(
                            cookie.getName(),
                            cookie.getValue(),
                            cookie.getDomain(),
                            cookie.getPath(),
                            cookie.isSecure(),
                            exp / 1000,
                            ((BasicClientCookie)cookie).containsAttribute(ClientCookie.PATH_ATTR),
                            ((BasicClientCookie)cookie).containsAttribute(ClientCookie.DOMAIN_ATTR),
                            cookie.getVersion());

                    // Store session cookies as well as unexpired ones
                    if (exp == 0 || exp >= System.currentTimeMillis()) {
                        cookieManager.add(newCookie); // Has its own debug log; removes matching cookies
                    } else {
                        cookieManager.removeMatchingCookies(newCookie);
                        if (debugEnabled){
                            log.info(""Dropping expired Cookie: {}"", newCookie);
                        }
                    }
                } catch (IllegalArgumentException e) {
                    
---------------Reference log start----------------
log.warn(cookieHeader + e.getLocalizedMessage())
---------------Reference log end----------------
                }
            }
    }",,
jmeter,13914,"log.debug(""WriteS: {}"", showEOL(s))",debug,https://github.com/apache/jmeter/blob/master/src/protocol/tcp/src/main/java/org/apache/jmeter/protocol/tcp/sampler/TCPClientImpl.java/#L67,"@Override
    public void write(OutputStream os, String s)  throws IOException{
        if(log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""WriteS: {}"", showEOL(s))
---------------Reference log end----------------
        }
        os.write(s.getBytes(CHARSET));
        os.flush();
    }",,
jmeter,13542,"log.info(""Valid alias found for {}"", alias)",info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/ProxyControl.java/#L1537,"@SuppressWarnings(""JdkObsolete"")
    private void initDynamicKeyStore() throws IOException, GeneralSecurityException {
        if (storePassword  != null) { // Assume we have already created the store
            try {
                keyStore = getKeyStore(storePassword.toCharArray());
                for(String alias : KeyToolUtils.getCAaliases()) {
                    X509Certificate  caCert = (X509Certificate) keyStore.getCertificate(alias);
                    if (caCert == null) {
                        keyStore = null; // no CA key - probably the wrong store type.
                        break; // cannot continue
                    } else {
                        caCert.checkValidity(new Date(System.currentTimeMillis()+DateUtils.MILLIS_PER_DAY));
                        
---------------Reference log start----------------
log.info(""Valid alias found for {}"", alias)
---------------Reference log end----------------
                    }
                }
            } catch (IOException e) { // store is faulty, we need to recreate it
                keyStore = null; // if cert is not valid, flag up to recreate it
                if (e.getCause() instanceof UnrecoverableKeyException) {
                    log.warn(
                            ""Could not read key store {}; cause: {}, a new one will be created, ensure you install it in browser"",
                            e.getMessage(), e.getCause().getMessage(), e);
                } else {
                    log.warn(
                            ""Could not open/read key store {}, a new one will be created, ensure you install it in browser"",
                            e.getMessage(), e); // message includes the file name
                }
            } catch (CertificateExpiredException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Existing ROOT Certificate has expired, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            } catch (CertificateNotYetValidException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Existing ROOT Certificate is not yet valid, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            } catch (GeneralSecurityException e) {
                keyStore = null; // if cert is not valid, flag up to recreate it
                log.warn(
                        ""Problem reading key store, a new one will be created, ensure you install it in browser, message: {}"",
                        e.getMessage(), e);
            }
        }
        if (keyStore == null) { // no existing file or not valid
            storePassword = JOrphanUtils.generateRandomAlphanumericPassword(20); // Alphanum to avoid issues with command-line quoting
            keyPassword = storePassword; // we use same password for both
            setPassword(storePassword);
            log.info(
                    ""Creating HTTP(S) Test Script Recorder Root CA in {}, ensure you install certificate in your Browser for recording"",
                    CERT_PATH_ABS);
            KeyToolUtils.generateProxyCA(CERT_PATH, storePassword, CERT_VALIDITY);
            log.info(""Created keystore in {}"", CERT_PATH_ABS);
            keyStore = getKeyStore(storePassword.toCharArray()); // This should now work
        }
        final String sslDomains = getSslDomains().trim();
        if (sslDomains.length() > 0) {
            final String[] domains = sslDomains.split("","");
            // The subject may be either a host or a domain
            for (String subject : domains) {
                if (isValid(subject)) {
                    if (!keyStore.containsAlias(subject)) {
                        log.info(""Creating entry {} in {}"", subject, CERT_PATH_ABS);
                        KeyToolUtils.generateHostCert(CERT_PATH, storePassword, subject, CERT_VALIDITY);
                        keyStore = getKeyStore(storePassword.toCharArray()); // reload to pick up new aliases
                        // reloading is very quick compared with creating an entry currently
                    }
                } else {
                    log.warn(""Attempt to create an invalid domain certificate: {}"", subject);
                }
            }
        }
    }",,
jmeter,14411,"log.warn(""Exception while adding button item to toolbar. {}"", e.getMessage())",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/util/JMeterToolBar.java/#L132,"private static void setupToolbarContent(JMeterToolBar toolBar) {
        List<IconToolbarBean> icons = getIconMappings();
        if (icons != null) {
            for (IconToolbarBean iconToolbarBean : icons) {
                if (iconToolbarBean == null) {
                    toolBar.addSeparator();
                } else {
                    try {
                        if(ActionNames.UNDO.equalsIgnoreCase(iconToolbarBean.getActionName())
                                        || ActionNames.REDO.equalsIgnoreCase(iconToolbarBean.getActionName())) {
                            if(UndoHistory.isEnabled()) {
                                toolBar.add(makeButtonItemRes(iconToolbarBean));
                            }
                        } else {
                            toolBar.add(makeButtonItemRes(iconToolbarBean));
                        }
                    } catch (Exception e) {
                        if (log.isWarnEnabled()) {
                            
---------------Reference log start----------------
log.warn(""Exception while adding button item to toolbar. {}"", e.getMessage())
---------------Reference log end----------------
                        }
                    }
                }
            }
            toolBar.initButtonsState();
        }
    }",,
jmeter,13365,"log.debug(""Expires= {} (Expired) for url {}"", expiresDate, url)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/CacheManager.java/#L529,"@SuppressWarnings(""JdkObsolete"")
    private boolean entryStillValid(URL url, CacheEntry entry) {
        log.debug(""Check if entry {} is still valid for url {}"", entry, url);
        if (entry != null && entry.getVaryHeader() == null) {
            final Date expiresDate = entry.getExpires();
            if (expiresDate != null) {
                if (expiresDate.after(new Date())) {
                    log.debug(""Expires= {} (Valid) for url {}"", expiresDate, url);
                    return true;
                } else {
                    
---------------Reference log start----------------
log.debug(""Expires= {} (Expired) for url {}"", expiresDate, url)
---------------Reference log end----------------
                }
            } else {
                log.debug(""expiresDate is null for url {}"", url);
            }
        }
        return false;
    }",,
jmeter,14084,"log.warn(""Error loading result renderer: {}"", clazz, e)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/ViewResultsFullVisualizer.java/#L475,"private Component createComboRender() {
        ComboBoxModel<ResultRenderer> nodesModel = new DefaultComboBoxModel<>();
        // drop-down list for renderer
        selectRenderPanel = new JComboBox<>(nodesModel);
        selectRenderPanel.setActionCommand(COMBO_CHANGE_COMMAND);
        selectRenderPanel.addActionListener(this);

        // if no results render in jmeter.properties, load Standard (default)
        List<String> classesToAdd = Collections.<String>emptyList();
        try {
            classesToAdd = JMeterUtils.findClassesThatExtend(ResultRenderer.class);
        } catch (IOException e1) {
            // ignored
        }
        String defaultRenderer = expandToClassname("".RenderAsText""); // $NON-NLS-1$
        if (VIEWERS_ORDER.length() > 0) {
            defaultRenderer = expandToClassname(VIEWERS_ORDER.split("","", 2)[0]);
        }
        Object defaultObject = null;
        Map<String, ResultRenderer> map = new HashMap<>(classesToAdd.size());
        for (String clazz : classesToAdd) {
            try {
                // Instantiate render classes
                final ResultRenderer renderer = Class.forName(clazz)
                        .asSubclass(ResultRenderer.class)
                        .getDeclaredConstructor().newInstance();
                if (defaultRenderer.equals(clazz)) {
                    defaultObject=renderer;
                }
                renderer.setBackgroundColor(getBackground());
                map.put(renderer.getClass().getName(), renderer);
            } catch (NoClassDefFoundError e) { // NOSONAR See bug 60583
                if (e.getMessage() != null && e.getMessage().contains(""javafx"")) {
                    log.info(""Add JavaFX to your Java installation if you want to use renderer: {}"", clazz);
                } else {
                    
---------------Reference log start----------------
log.warn(""Error loading result renderer: {}"", clazz, e)
---------------Reference log end----------------
                }
            } catch (Exception e) {
                log.warn(""Error loading result renderer: {}"", clazz, e);
            }
        }
        if (VIEWERS_ORDER.length() > 0) {
            Arrays.stream(VIEWERS_ORDER.split("",""))
                    .map(this::expandToClassname)
                    .forEach(key -> {
                        ResultRenderer renderer = map.remove(key);
                        if (renderer != null) {
                            selectRenderPanel.addItem(renderer);
                        } else {
                            log.warn(
                                    ""Missing (check renderer name) or already added (check doublon) result renderer,"" +
                                            "" check property 'view.results.tree.renderers_order', renderer name: '{}'"",
                                    key);
                        }
                    });
        }
        // Add remaining (plugins or missed in property)
        map.values().forEach(renderer -> selectRenderPanel.addItem(renderer));
        nodesModel.setSelectedItem(defaultObject); // preset to ""Text"" option or the first option from the view.results.tree.renderers_order property
        return selectRenderPanel;
    }",,
jmeter,14401,"log.error(""Can't get popup menu for gui"", e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/tree/JMeterTreeNode.java/#L186,"public JPopupMenu createPopupMenu() {
        try {
            return GuiPackage.getInstance().getGui(getTestElement()).createPopupMenu();
        } catch (Exception e) {
            
---------------Reference log start----------------
log.error(""Can't get popup menu for gui"", e)
---------------Reference log end----------------
            return null;
        }
    }",,
jmeter,13513,"log.error(""Could not create HTTP(S) Test Script Recorder Proxy daemon"", e)",error,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/ProxyControl.java/#L546,"public void startProxy() throws IOException {
        try {
            initKeyStore();
        } catch (GeneralSecurityException e) {
            log.error(""Could not initialise key store"", e);
            throw new IOException(""Could not create keystore"", e);
        } catch (IOException e) { // make sure we log the error
            log.error(""Could not initialise key store"", e);
            throw e;
        }
        sampleWorkerTimer = new javax.swing.Timer(200, this::putSamplesIntoModel);
        sampleWorkerTimer.start();
        notifyTestListenersOfStart();
        try {
            server = new Daemon(getPort(), this);
            if (getProxyPauseHTTPSample().isEmpty()) {
                sampleGap = JMeterUtils.getPropDefault(""proxy.pause"", 5000);
            } else {
                sampleGap = Long.parseLong(getProxyPauseHTTPSample().trim());
            }
            server.start();
            if (GuiPackage.getInstance() != null) {
                GuiPackage.getInstance().register(server);
            }
        } catch (IOException e) {
            
---------------Reference log start----------------
log.error(""Could not create HTTP(S) Test Script Recorder Proxy daemon"", e)
---------------Reference log end----------------
            throw e;
        }
    }",,
jmeter,13398,"log.info(""Couldn't convert {} as literal address to InetAddress"", address, e)",info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/DNSCacheManager.java/#L233,"private void addAsLiteralAddress(List<InetAddress> addresses, String address) {
        try {
            addresses.add(InetAddress.getByName(address));
        } catch (UnknownHostException e) {
            
---------------Reference log start----------------
log.info(""Couldn't convert {} as literal address to InetAddress"", address, e)
---------------Reference log end----------------
        }
    }",,
jmeter,13605,"log.info(""Stopping current thread"")",info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/AccessLogSampler.java/#L156,"public SampleResult sampleWithParser() {
        initFilter();
        instantiateParser();
        SampleResult res = null;
        try {

            if (parser == null) {
                throw new JMeterException(""No Parser available"");
            }
            // we call parse with 1 to get only one.
            // this also means if we change the implementation
            // to use 2, it would use every other entry and
            // so on. Not that it is really useful, but a
            // person could use it that way if they have a
            // huge gigabyte log file and they only want to
            // use a quarter of the entries.
            int thisCount = parser.parseAndConfigure(1, this);
            if (thisCount < 0) // Was there an error?
            {
                return errorResult(new Error(""Problem parsing the log file""), new HTTPSampleResult());
            }
            if (thisCount == 0) {
                if (count == 0 || filter == null) {
                    
---------------Reference log start----------------
log.info(""Stopping current thread"")
---------------Reference log end----------------
                    JMeterContextService.getContext().getThread().stop();
                }
                if (filter != null) {
                    filter.reset();
                }
                CookieManager cm = getCookieManager();
                if (cm != null) {
                    cm.clear();
                }
                count = 0;
                return errorResult(new Error(""No entries found""), new HTTPSampleResult());
            }
            count = thisCount;
            res = sample();
            if(res != null) {
                res.setSampleLabel(toString());
            }
        } catch (Exception e) {
            log.warn(""Sampling failure"", e);
            return errorResult(e, new HTTPSampleResult());
        }
        return res;
    }",,
jmeter,13488,"log.debug(""{} Reparse: {}"", port, reparsed)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/Proxy.java/#L221,"@Override
    public void run() {
        // Check which HTTPSampler class we should use
        String httpSamplerName = target.getSamplerTypeName();

        HttpRequestHdr request = new HttpRequestHdr(target.getPrefixHTTPSampleName(), httpSamplerName,
                target.getHTTPSampleNamingMode(), target.getHttpSampleNameFormat());
        request.setDetectGraphQLRequest(target.getDetectGraphQLRequest());

        SampleResult result = null;
        HeaderManager headers = null;
        HTTPSamplerBase sampler = null;
        final boolean isDebug = log.isDebugEnabled();
        log.debug(""{} ===================================================================="", port);
        SamplerCreator samplerCreator = null;
        try {
            JMeterContextService.getContext().setRecording(true);
            // Now, parse initial request (in case it is a CONNECT request)
            byte[] ba = request.parse(new BufferedInputStream(clientSocket.getInputStream()));
            if (ba.length == 0) {
                log.debug(""{} Empty request, ignored"", port);
                throw new JMeterException(); // hack to skip processing
            }
            if (isDebug) {
                @SuppressWarnings(""DefaultCharset"")
                final String reparsed = new String(ba); // NOSONAR False positive
                log.debug(""{} Initial request: {}"", port, reparsed);
            }
            // Use with SSL connection
            OutputStream outStreamClient = clientSocket.getOutputStream();

            if (request.getMethod().startsWith(HTTPConstants.CONNECT) && (outStreamClient != null)) {
                log.debug(""{} Method CONNECT => SSL"", port);
                // write a OK response to browser, to engage SSL exchange
                outStreamClient.write(
                        ""HTTP/1.0 200 OK\r\n\r\n"".getBytes(SampleResult.DEFAULT_HTTP_ENCODING)); // $NON-NLS-1$
                outStreamClient.flush();
               // With ssl request, url is host:port (without https:// or path)
                String[] param = request.getUrl().split("":"");  // $NON-NLS-1$
                if (param.length == 2) {
                    log.debug(""{} Start to negotiate SSL connection, host: {}"", port ,param[0]);
                    clientSocket = startSSL(clientSocket, param[0]);
                } else {
                    // Should not happen, but if it does we don't want to continue
                    log.error(""In SSL request, unable to find host and port in CONNECT request: {}"", request.getUrl());
                    throw new JMeterException(); // hack to skip processing
                }
                // Re-parse (now it's the http request over SSL)
                try {
                    ba = request.parse(new BufferedInputStream(clientSocket.getInputStream()));
                } catch (IOException ioe) { // most likely this is because of a certificate error
                    // param.length is 2 here
                    final String url = "" for '""+ param[0] +""'"";
                    log.warn(""{} Problem with SSL certificate for url {}? Ensure browser is set to accept the JMeter proxy cert: {}"",
                            port, url,ioe.getMessage());
                    // Generate result (if nec.) and populate it
                    result = generateErrorResult(result, request, ioe, ""\n**ensure browser is set to accept the JMeter proxy certificate**"");
                    throw new JMeterException(); // hack to skip processing
                }
                if (isDebug) {
                    @SuppressWarnings(""DefaultCharset"")
                    final String reparsed = new String(ba); // NOSONAR False positive
                    
---------------Reference log start----------------
log.debug(""{} Reparse: {}"", port, reparsed)
---------------Reference log end----------------
                }
                if (ba.length == 0) {
                    log.warn(""{} Empty response to http over SSL. Probably waiting for user to authorize the certificate for {}"",
                                port, request.getUrl());
                    throw new JMeterException(); // hack to skip processing
                }
            }

            samplerCreator = SAMPLERFACTORY.getSamplerCreator(request, pageEncodings, formEncodings);
            sampler = samplerCreator.createAndPopulateSampler(request, pageEncodings, formEncodings);
            sampler.setUseKeepAlive(false);
            /*
             * Create a Header Manager to ensure that the browsers headers are
             * captured and sent to the server
             */
            headers = request.getHeaderManager();
            sampler.setHeaderManager(headers);

            sampler.threadStarted(); // Needed for HTTPSampler2
            if (isDebug) {
                log.debug(""{} Execute sample: {} and url {}"",port, sampler.getMethod(), sampler.getUrl());
            }

            result = sampler.sample();

            // Find the page encoding and possibly encodings for forms in the page
            // in the response from the web server
            String pageEncoding = addPageEncoding(result);
            addFormEncodings(result, pageEncoding);

            writeToClient(result, new BufferedOutputStream(clientSocket.getOutputStream()));
            samplerCreator.postProcessSampler(sampler, result);
        } catch (JMeterException jme) {
            // ignored, already processed
        } catch (UnknownHostException uhe) {
            log.warn(""{} Server Not Found."", port, uhe);
            writeErrorToClient(HttpReplyHdr.formServerNotFound());
            result = generateErrorResult(result, request, uhe); // Generate result (if nec.) and populate it
        } catch (IllegalArgumentException e) {
            log.error(""{} Not implemented (probably used https)"", port, e);
            writeErrorToClient(HttpReplyHdr.formNotImplemented(""Probably used https instead of http. ""
                    + ""To record https requests, see ""
                    + ""<a href=\""http://jmeter.apache.org/usermanual/component_reference.html#HTTP(S)_Test_Script_Recorder\"">""
                    + ""HTTP(S) Test Script Recorder documentation</a>""));
            result = generateErrorResult(result, request, e); // Generate result (if nec.) and populate it
        } catch (Exception e) {
            log.error(""{} Exception when processing sample"", port, e);
            writeErrorToClient(HttpReplyHdr.formInternalError());
            result = generateErrorResult(result, request, e); // Generate result (if nec.) and populate it
        } finally {
            if(sampler != null && isDebug) {
                log.debug(""{} Will deliver sample {}"", port, sampler.getName());
            }
            /*
             * We don't want to store any cookies in the generated test plan
             */
            if (headers != null) {
                headers.removeHeaderNamed(HTTPConstants.HEADER_COOKIE);// Always remove cookies
                // See https://bz.apache.org/bugzilla/show_bug.cgi?id=25430
                // HEADER_AUTHORIZATION won't be removed, it will be used
                // for creating Authorization Manager
                // Remove additional headers
                for(String hdr : HEADERS_TO_REMOVE){
                    headers.removeHeaderNamed(hdr);
                }
            }
            if(result != null) // deliverSampler allows sampler to be null, but result must not be null
            {
                List<TestElement> children = new ArrayList<>();
                if(captureHttpHeaders) {
                    children.add(headers);
                }
                if(samplerCreator != null) {
                    children.addAll(samplerCreator.createChildren(sampler, result));
                }
                target.deliverSampler(sampler,
                         children
                                .toArray(new TestElement[children.size()]),
                        result);
            }
            try {
                clientSocket.close();
            } catch (Exception e) {
                log.error(""{} Failed to close client socket"", port, e);
            }
            if(sampler != null) {
                sampler.threadFinished(); // Needed for HTTPSampler2
            }
            JMeterContextService.getContext().setRecording(false);
        }
    }",,
jmeter,14259,"log.warn(""Error formatting {} at format {}, using default"", value, format)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/modifiers/CounterConfig.java/#L131,"private String formatNumber(long value){
        String format = getFormat();
        if (format != null && format.length() > 0) {
            try {
                DecimalFormat myFormatter = new DecimalFormat(format);
                return myFormatter.format(value);
            } catch (IllegalArgumentException ignored) {
                
---------------Reference log start----------------
log.warn(""Error formatting {} at format {}, using default"", value, format)
---------------Reference log end----------------
            }
        }
        return Long.toString(value);
    }",,
jmeter,15118,"log.warn(""Unexpected duplicate for {} and {}"", parent.getClass(), child.getClass())",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/threads/TestCompiler.java/#L169,"@Override
    public void subtractNode() {
        if (log.isDebugEnabled()) {
            log.debug(""Subtracting node, stack size = {}"", stack.size());
        }
        TestElement child = stack.getLast();
        trackIterationListeners(stack);
        if (child instanceof Sampler) {
            saveSamplerConfigs((Sampler) child);
        }
        else if(child instanceof TransactionController) {
            saveTransactionControllerConfigs((TransactionController) child);
        }
        stack.removeLast();
        if (!stack.isEmpty()) {
            TestElement parent = stack.getLast();
            boolean duplicate = false;
            // Bug 53750: this condition used to be in ObjectPair#addTestElements()
            if (parent instanceof Controller && (child instanceof Sampler || child instanceof Controller)) {
                if (parent instanceof TestCompilerHelper) {
                    TestCompilerHelper te = (TestCompilerHelper) parent;
                    duplicate = !te.addTestElementOnce(child);
                } else { // this is only possible for 3rd party controllers by default
                    ObjectPair pair = new ObjectPair(child, parent);
                    synchronized (PAIRING) {// Called from multiple threads
                        if (!PAIRING.contains(pair)) {
                            parent.addTestElement(child);
                            PAIRING.add(pair);
                        } else {
                            duplicate = true;
                        }
                    }
                }
            }
            if (duplicate) {
                if (log.isWarnEnabled()) {
                    
---------------Reference log start----------------
log.warn(""Unexpected duplicate for {} and {}"", parent.getClass(), child.getClass())
---------------Reference log end----------------
                }
            }
        }
    }",,
jmeter,14162,"log.warn(""SMIME message contains multiple signers! Checking multiple signers is not supported."")",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/assertions/SMIMEAssertion.java/#L196,"private static AssertionResult verifySignature(SMIMEAssertionTestElement testElement, SMIMESignedParser s, String name)
            throws CMSException {
        AssertionResult res = new AssertionResult(name);

        try {
            Store<?> certs = s.getCertificates();
            SignerInformationStore signers = s.getSignerInfos();
            Iterator<?> signerIt = signers.getSigners().iterator();

            if (signerIt.hasNext()) {

                SignerInformation signer = (SignerInformation) signerIt.next();
                Iterator<?> certIt = certs.getMatches(signer.getSID()).iterator();

                if (certIt.hasNext()) {
                    // the signer certificate
                    X509CertificateHolder cert = (X509CertificateHolder) certIt.next();

                    if (testElement.isVerifySignature()) {
                        verifySignature(signer, res, cert);
                    }

                    if (testElement.isSignerCheckConstraints()) {
                        StringBuilder failureMessage = new StringBuilder();

                        checkSerial(testElement, res, cert, failureMessage);
                        checkEmail(testElement, res, cert, failureMessage);
                        checkSubject(testElement, res, cert, failureMessage);
                        checkIssuer(testElement, res, cert, failureMessage);

                        if (failureMessage.length() > 0) {
                            res.setFailureMessage(failureMessage.toString());
                        }
                    }

                    if (testElement.isSignerCheckByFile()) {
                        checkSignerByFile(testElement, res, cert);
                    }

                } else {
                    res.setFailure(true);
                    res.setFailureMessage(""No signer certificate found in signature"");
                }

            }

            // TODO support multiple signers
            if (signerIt.hasNext()) {
                
---------------Reference log start----------------
log.warn(""SMIME message contains multiple signers! Checking multiple signers is not supported."")
---------------Reference log end----------------
            }

        } catch (GeneralSecurityException e) {
            log.error(e.getMessage(), e);
            res.setError(true);
            res.setFailureMessage(e.getMessage());
        }

        return res;
    }",,
jmeter,13501,"log.warn(""{} Error while closing socket"", port, ex)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/Proxy.java/#L513,"private void writeToClient(SampleResult res, OutputStream out) throws IOException {
        try {
            String responseHeaders = messageResponseHeaders(res);
            out.write(responseHeaders.getBytes(SampleResult.DEFAULT_HTTP_ENCODING));
            out.write(CRLF_BYTES);
            out.write(res.getResponseData());
            out.flush();
            log.debug(""{} Done writing to client"", port);
        } catch (IOException e) {
            log.error("""", e);
            throw e;
        } finally {
            try {
                out.close();
            } catch (Exception ex) {
                
---------------Reference log start----------------
log.warn(""{} Error while closing socket"", port, ex)
---------------Reference log end----------------
            }
        }
    }",,
jmeter,14034,"log.debug(""Adding '{}' tag with '{}' value "", tagName, tagValue)",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/influxdb/InfluxdbBackendListenerClient.java/#L358,"private void initUserTags(BackendListenerContext context) {
        // Check if more rows which started with 'TAG_' are filled ( corresponding to user tag )
        StringBuilder userTagBuilder = new StringBuilder();
        context.getParameterNamesIterator().forEachRemaining(name -> {
            if (StringUtils.isNotBlank(name)
                    && !DEFAULT_ARGS.containsKey(name.trim())
                    && name.startsWith(""TAG_"")
                    && StringUtils.isNotBlank(context.getParameter(name))) {
                final String tagName = name.trim().substring(4);
                final String tagValue = context.getParameter(name).trim();
                userTagBuilder.append(',')
                        .append(AbstractInfluxdbMetricsSender.tagToStringValue(tagName))
                        .append('=')
                        .append(AbstractInfluxdbMetricsSender.tagToStringValue(tagValue));
                
---------------Reference log start----------------
log.debug(""Adding '{}' tag with '{}' value "", tagName, tagValue)
---------------Reference log end----------------
            }
        });
        userTag = userTagBuilder.toString();
    }",,
jmeter,15114,"log.warn(""The delay timer was interrupted - probably did not wait as long as intended."")",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/threads/JMeterThread.java/#L1006,"private void delay(List<Timer> timers) {
        long totalDelay = 0;
        for (Timer timer : timers) {
            TestBeanHelper.prepare((TestElement) timer);
            long delay = timer.delay();
            if (APPLY_TIMER_FACTOR && timer.isModifiable()) {
                if (log.isDebugEnabled()) {
                    log.debug(""Applying TIMER_FACTOR:{} on timer:{} for thread:{}"", TIMER_FACTOR,
                            ((TestElement) timer).getName(), getThreadName());
                }
                delay = Math.round(delay * TIMER_FACTOR);
            }
            totalDelay += delay;
        }
        if (totalDelay > 0) {
            try {
                if (scheduler) {
                    // We reduce pause to ensure end of test is not delayed by a sleep ending after test scheduled end
                    // See Bug 60049
                    totalDelay = TIMER_SERVICE.adjustDelay(totalDelay, endTime, false);
                    if (totalDelay < 0) {
                        log.debug(""The delay would be longer than the scheduled period, so stop thread now."");
                        running = false;
                        return;
                    }
                }
                TimeUnit.MILLISECONDS.sleep(totalDelay);
            } catch (InterruptedException e) {
                
---------------Reference log start----------------
log.warn(""The delay timer was interrupted - probably did not wait as long as intended."")
---------------Reference log end----------------
                Thread.currentThread().interrupt();
            }
        }
    }",,
jmeter,13764,"log.warn("""", afex)",warn,https://github.com/apache/jmeter/blob/master/src/protocol/mail/src/main/java/org/apache/jmeter/protocol/smtp/sampler/SmtpSampler.java/#L178,"private boolean executeMessage(SampleResult result, SendMailCommand sendMailCmd, Message message) {
        boolean didSampleSucceed = false;
        try {
            sendMailCmd.execute(message);
            result.setResponseCodeOK();
            result.setResponseMessage(
                    ""Message successfully sent!\n"");
            didSampleSucceed = true;
        } catch (AuthenticationFailedException afex) {
            
---------------Reference log start----------------
log.warn("""", afex)
---------------Reference log end----------------
            result.setResponseCode(""500"");
            result.setResponseMessage(
                    ""AuthenticationFailedException: authentication failed - wrong username / password!\n""
                            + afex);
        } catch (Exception ex) {
            log.warn("""", ex);
            result.setResponseCode(""500"");
            result.setResponseMessage(ex.getMessage());
        }
        return didSampleSucceed;
    }",,
jmeter,15056,"log.warn(""System doesn't support {}"", CHAR_SET, e)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/save/converters/ConversionHelp.java/#L96,"public static String encode(String p) {
        if (p == null) {// Nulls cannot be written using PrettyPrintWriter - they cause an NPE
            return """"; // $NON-NLS-1$
        }
        // Only encode strings if outVersion = 1.0
        if (!""1.0"".equals(outVersion)) {//$NON-NLS-1$
            return p;
        }
        try {
            return URLEncoder.encode(p, CHAR_SET);
        } catch (UnsupportedEncodingException e) {
            
---------------Reference log start----------------
log.warn(""System doesn't support {}"", CHAR_SET, e)
---------------Reference log end----------------
            return p;
        }
    }",,
jmeter,13215,"log.error(""An error occurred while evaluating the expression \"""" + exp + ""\""\n"", e)",error,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/Jexl2Function.java/#L105,"@Override
    public String execute(SampleResult previousResult, Sampler currentSampler)
            throws InvalidVariableException
    {
        String str = """"; //$NON-NLS-1$

        CompoundVariable var = (CompoundVariable) values[0];
        String exp = var.execute();

        String varName = """"; //$NON-NLS-1$
        if (values.length > 1) {
            varName = ((CompoundVariable) values[1]).execute().trim();
        }

        JMeterContext jmctx = JMeterContextService.getContext();
        JMeterVariables vars = jmctx.getVariables();

        try
        {
            JexlContext jc = new MapContext();
            jc.set(""log"", log); //$NON-NLS-1$
            jc.set(""ctx"", jmctx); //$NON-NLS-1$
            jc.set(""vars"", vars); //$NON-NLS-1$
            jc.set(""props"", JMeterUtils.getJMeterProperties()); //$NON-NLS-1$
            // Previously mis-spelt as theadName
            jc.set(""threadName"", Thread.currentThread().getName()); //$NON-NLS-1$
            jc.set(""sampler"", currentSampler); //$NON-NLS-1$ (may be null)
            jc.set(""sampleResult"", previousResult); //$NON-NLS-1$ (may be null)
            jc.set(""OUT"", System.out);//$NON-NLS-1$

            // Now evaluate the script, getting the result
            Script e = getJexlEngine().createScript( exp );
            Object o = e.execute(jc);
            if (o != null)
            {
                str = o.toString();
            }
            if (vars != null && varName.length() > 0) {// vars will be null on TestPlan
                vars.put(varName, str);
            }
        } catch (Exception e)
        {
            
---------------Reference log start----------------
log.error(""An error occurred while evaluating the expression \"""" + exp + ""\""\n"", e)
---------------Reference log end----------------
        }
        return str;
    }",,
jmeter,13560,"log.debug(""Loading class: {}"", strClassName)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/SamplerCreatorFactory.java/#L69,"private void init() { // WARNING: called from ctor so must not be overridden (i.e. must be private or final)
        try {
            List<String> listClasses = ClassFinder.findClassesThatExtend(
                    JMeterUtils.getSearchPaths(),
                    new Class[] {SamplerCreator.class });
            for (String strClassName : listClasses) {
                try {
                    if(log.isDebugEnabled()) {
                        
---------------Reference log start----------------
log.debug(""Loading class: {}"", strClassName)
---------------Reference log end----------------
                    }
                    Class<?> commandClass = Class.forName(strClassName);
                    if (!Modifier.isAbstract(commandClass.getModifiers())) {
                        if(log.isDebugEnabled()) {
                            log.debug(""Instantiating: {}"", commandClass.getName());
                        }
                        SamplerCreator creator = (SamplerCreator) commandClass.getDeclaredConstructor().newInstance();
                        String[] contentTypes = creator.getManagedContentTypes();
                        for (String contentType : contentTypes) {
                            if(log.isDebugEnabled()) {
                                log.debug(""Registering samplerCreator {} for content type:{}"",
                                        commandClass.getName(), contentType);
                            }
                            SamplerCreator oldSamplerCreator = samplerCreatorMap.put(contentType, creator);
                            if(oldSamplerCreator!=null) {
                                log.warn(""A sampler creator was already registered for:{}, class:{}, it will be replaced"",
                                        contentType, oldSamplerCreator.getClass());
                            }
                        }
                    }
                } catch (Exception e) {
                    log.error(""Exception registering {} with implementation:{}"",
                            SamplerCreator.class.getName(),strClassName, e);
                }
            }
        } catch (IOException e) {
            log.error(""Exception finding implementations of {}"", SamplerCreator.class, e);
        }
    }",,
jmeter,13614,"LOG.debug(""Interrupted while waiting for resource downloads : cancelling remaining tasks"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/ResourcesDownloader.java/#L201,"public List<Future<AsynSamplerResultHolder>> invokeAllAndAwaitTermination(
            int maxConcurrentDownloads, List<Callable<AsynSamplerResultHolder>> list) throws InterruptedException {
        List<Future<AsynSamplerResultHolder>> submittedTasks = new ArrayList<>();

        // paranoid fast path
        if (list.isEmpty()) {
            return submittedTasks;
        }

        // restore MaximumPoolSize original value
        concurrentExecutor.setMaximumPoolSize(MAX_POOL_SIZE);

        if (LOG.isDebugEnabled()) {
            LOG.debug(""PoolSize={} LargestPoolSize={}"",
                    concurrentExecutor.getPoolSize(), concurrentExecutor.getLargestPoolSize());
        }

        CompletionService<AsynSamplerResultHolder> completionService =
                new ExecutorCompletionService<>(concurrentExecutor);
        int remainingTasksToTake = list.size();

        try {
            // push the task in the threadpool until <maxConcurrentDownloads> is reached
            int i = 0;
            for (i = 0; i < Math.min(maxConcurrentDownloads, list.size()); i++) {
                Callable<AsynSamplerResultHolder> task = list.get(i);
                submittedTasks.add(completionService.submit(task));
            }

            // push the remaining tasks but ensure we use at most <maxConcurrentDownloads> threads
            // wait for a previous download to finish before submitting a new one
            for (; i < list.size(); i++) {
                Callable<AsynSamplerResultHolder> task = list.get(i);
                try {
                    completionService.take().get();
                } catch (ExecutionException e) {
                    throw new RuntimeException(""Task execution failed"", e.getCause());
                }
                remainingTasksToTake--;
                submittedTasks.add(completionService.submit(task));
            }

            // all the resources downloads are in the thread pool queue
            // wait for the completion of all downloads
            while (remainingTasksToTake > 0) {
                try {
                    completionService.take().get();
                } catch (ExecutionException e) {
                    throw new RuntimeException(""Task execution failed"", e.getCause());
                }
                remainingTasksToTake--;
            }
        } finally {
            //bug 51925 : Calling Stop on Test leaks executor threads when concurrent download of resources is on
            if (remainingTasksToTake > 0) {
                
---------------Reference log start----------------
LOG.debug(""Interrupted while waiting for resource downloads : cancelling remaining tasks"")
---------------Reference log end----------------
                for (Future<AsynSamplerResultHolder> future : submittedTasks) {
                    if (!future.isDone()) {
                        future.cancel(true);
                    }
                }
            }
        }

        return submittedTasks;
    }",,
jmeter,13757,"log.info(""load local truststore - try to load truststore from: {}"", truststore.getAbsolutePath())",info,https://github.com/apache/jmeter/blob/master/src/protocol/mail/src/main/java/org/apache/jmeter/protocol/mail/sampler/MailReaderSampler.java/#L177,"@Override
    @SuppressWarnings(""JdkObsolete"")
    public SampleResult sample(Entry e) {
        SampleResult parent = new SampleResult();
        boolean isOK = false; // Did sample succeed?
        final boolean deleteMessages = getDeleteMessages();
        final String serverProtocol = getServerType();

        parent.setSampleLabel(getName());

        String samplerString = toString();
        parent.setSamplerData(samplerString);

        /*
         * Perform the sampling
         */
        parent.sampleStart(); // Start timing
        try {
            // Create empty properties
            Properties props = new Properties();

            if (isUseStartTLS()) {
                props.setProperty(mailProp(serverProtocol, ""starttls.enable""), TRUE);  // $NON-NLS-1$
                if (isEnforceStartTLS()){
                    // Requires JavaMail 1.4.2+
                    props.setProperty(mailProp(serverProtocol, ""starttls.require""), TRUE);  // $NON-NLS-1$
                }
            }

            if (isTrustAllCerts()) {
                if (isUseSSL() || isUseStartTLS()) {
                    props.setProperty(mailProp(serverProtocol, ""ssl.socketFactory.class""), TRUST_ALL_SOCKET_FACTORY);  // $NON-NLS-1$
                    props.setProperty(mailProp(serverProtocol, ""ssl.socketFactory.fallback""), FALSE);  // $NON-NLS-1$
                }
            } else if (isUseLocalTrustStore()){
                File truststore = new File(getTrustStoreToUse());
                
---------------Reference log start----------------
log.info(""load local truststore - try to load truststore from: {}"", truststore.getAbsolutePath())
---------------Reference log end----------------
                if(!truststore.exists()){
                    log.info(""load local truststore -Failed to load truststore from: {}"", truststore.getAbsolutePath());
                    truststore = new File(FileServer.getFileServer().getBaseDir(), getTrustStoreToUse());
                    log.info(""load local truststore -Attempting to read truststore from: {}"", truststore.getAbsolutePath());
                    if (!truststore.exists()){
                        log.info(
                                ""load local truststore -Failed to load truststore from: {}""
                                        + "". Local truststore not available, aborting execution."",
                                truststore.getAbsolutePath());
                        throw new IOException(
                                ""Local truststore file not found. Also not available under : ""
                                        + truststore.getAbsolutePath());
                    }
                }
                if (isUseSSL() || isUseStartTLS()) {
                    // Requires JavaMail 1.4.2+
                    props.put(mailProp(serverProtocol, ""ssl.socketFactory""),   // $NON-NLS-1$
                            new LocalTrustStoreSSLSocketFactory(truststore));
                    props.put(mailProp(serverProtocol, ""ssl.socketFactory.fallback""), FALSE);  // $NON-NLS-1$
                }
            }
            addCustomProperties(props);

            // Get session
            Session session = Session.getInstance(props, null);

            // Get the store
            Store store = session.getStore(serverProtocol);
            store.connect(getServer(), getPortAsInt(), getUserName(), getPassword());

            // Get folder
            Folder folder = store.getFolder(getFolder());
            if (deleteMessages) {
                folder.open(Folder.READ_WRITE);
            } else {
                folder.open(Folder.READ_ONLY);
            }

            final int messageTotal = folder.getMessageCount();
            int n = getNumMessages();
            if (n == ALL_MESSAGES || n > messageTotal) {
                n = messageTotal;
            }

            // Get directory
            Message[] messages = folder.getMessages(1,n);
            String pdata = messages.length + "" messages found\n"";
            parent.setResponseData(pdata,null);
            parent.setDataType(SampleResult.TEXT);
            parent.setContentType(""text/plain""); // $NON-NLS-1$

            final boolean headerOnly = getHeaderOnly();
            busy = true;
            for (Message message : messages) {
                StringBuilder cdata = new StringBuilder();
                SampleResult child = new SampleResult();
                child.sampleStart();

                cdata.append(""Message ""); // $NON-NLS-1$
                cdata.append(message.getMessageNumber());
                child.setSampleLabel(cdata.toString());
                child.setSamplerData(cdata.toString());
                cdata.setLength(0);

                final String contentType = message.getContentType();
                child.setContentType(contentType);// Store the content-type
                child.setDataEncoding(RFC_822_DEFAULT_ENCODING); // RFC 822 uses ascii per default
                child.setEncodingAndType(contentType);// Parse the content-type

                if (isStoreMimeMessage()) {
                    // Don't save headers - they are already in the raw message
                    ByteArrayOutputStream bout = new ByteArrayOutputStream();
                    message.writeTo(bout);
                    child.setResponseData(bout.toByteArray()); // Save raw message
                    child.setDataType(SampleResult.TEXT);
                } else {
                    @SuppressWarnings(""unchecked"") // Javadoc for the API says this is OK
                    Enumeration<Header> hdrs = message.getAllHeaders();
                    while(hdrs.hasMoreElements()){
                        Header hdr = hdrs.nextElement();
                        String value = hdr.getValue();
                        try {
                            value = MimeUtility.decodeText(value);
                        } catch (UnsupportedEncodingException uce) {
                            // ignored
                        }
                        cdata.append(hdr.getName()).append("": "").append(value).append(""\n"");
                    }
                    child.setResponseHeaders(cdata.toString());
                    cdata.setLength(0);
                    if (!headerOnly) {
                        appendMessageData(child, message);
                    }
                }

                if (deleteMessages) {
                    message.setFlag(Flags.Flag.DELETED, true);
                }
                child.setResponseOK();
                if (child.getEndTime()==0){// Avoid double-call if addSubResult was called.
                    child.sampleEnd();
                }
                parent.addSubResult(child);
            }

            // Close connection
            folder.close(true);
            store.close();

            parent.setResponseCodeOK();
            parent.setResponseMessageOK();
            isOK = true;
        } catch (NoClassDefFoundError | IOException ex) {
            log.debug("""",ex);// No need to log normally, as we set the status
            parent.setResponseCode(""500""); // $NON-NLS-1$
            parent.setResponseMessage(ex.toString());
        } catch (MessagingException ex) {
            log.debug("""", ex);// No need to log normally, as we set the status
            parent.setResponseCode(""500""); // $NON-NLS-1$
            parent.setResponseMessage(ex.toString() + ""\n"" + samplerString); // $NON-NLS-1$
        } finally {
            busy = false;
        }

        if (parent.getEndTime()==0){// not been set by any child samples
            parent.sampleEnd();
        }
        parent.setSuccessful(isOK);
        return parent;
    }",,
jmeter,13961,"log.debug(""Storing pool: {}@{}"", getName(), System.identityHashCode(dsc))",debug,https://github.com/apache/jmeter/blob/master/src/protocol/jdbc/src/main/java/org/apache/jmeter/protocol/jdbc/config/DataSourceElement.java/#L388,"private BasicDataSource getConfiguredDataSource() {
            BasicDataSource dsc;
            if (sharedDSC != null){ // i.e. shared pool
                dsc = sharedDSC;
            } else {
                Map<String, BasicDataSource> poolMap = perThreadPoolMap.get();
                dsc = poolMap.get(getDataSourceName());
                if (dsc == null){
                    dsc = initPool(""1"");
                    poolMap.put(getDataSourceName(),dsc);
                    
---------------Reference log start----------------
log.debug(""Storing pool: {}@{}"", getName(), System.identityHashCode(dsc))
---------------Reference log end----------------
                    perThreadPoolSet.add(dsc);
                }
            }
            return dsc;
        }",,
jmeter,13737,"log.debug(""Using configured directory:"" + directory.getAbsolutePath())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/native/src/main/java/org/apache/jmeter/protocol/system/SystemSampler.java/#L136,"@Override
    public SampleResult sample(Entry entry) {
        SampleResult results = new SampleResult();
        results.setDataType(SampleResult.TEXT);
        results.setSampleLabel(getName());

        String command = getCommand();
        Arguments args = getArguments();
        Arguments environment = getEnvironmentVariables();
        boolean checkReturnCode = getCheckReturnCode();
        int expectedReturnCode = getExpectedReturnCode();
        List<String> cmds = new ArrayList<>(args.getArgumentCount() + 1);
        StringBuilder cmdLine = new StringBuilder((null == command) ? """" : command);
        cmds.add(command);
        for (int i=0;i<args.getArgumentCount();i++) {
            Argument arg = args.getArgument(i);
            cmds.add(arg.getPropertyAsString(Argument.VALUE));
            cmdLine.append("" "");
            cmdLine.append(cmds.get(i+1));
        }

        Map<String,String> env = new HashMap<>();
        for (int i=0;i<environment.getArgumentCount();i++) {
            Argument arg = environment.getArgument(i);
            env.put(arg.getName(), arg.getPropertyAsString(Argument.VALUE));
        }

        File directory;
        if(StringUtils.isEmpty(getDirectory())) {
            directory = new File(FileServer.getDefaultBase());
            if(log.isDebugEnabled()) {
                log.debug(""Using default directory:""+directory.getAbsolutePath());
            }
        } else {
            directory = new File(getDirectory());
            if(log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Using configured directory:"" + directory.getAbsolutePath())
---------------Reference log end----------------
            }
        }

        if(log.isDebugEnabled()) {
            log.debug(""Will run : ""+cmdLine + "" using working directory:""+directory.getAbsolutePath()+
                    "" with environment: ""+env);
        }

        results.setSamplerData(""Working Directory: ""+directory.getAbsolutePath()+
                ""\nEnvironment: ""+env+
                ""\nExecuting: "" + cmdLine.toString());

        SystemCommand nativeCommand = null;
        try {
            nativeCommand = new SystemCommand(directory, getTimeout(), 0, env, getStdin(), getStdout(), getStderr());
            results.sampleStart();
            int returnCode = nativeCommand.run(cmds);
            results.sampleEnd();
            results.setResponseCode(Integer.toString(returnCode));
            if(log.isDebugEnabled()) {
                log.debug(""Ran : ""+cmdLine + "" using working directory: ""+directory.getAbsolutePath()+
                        "" with execution environment: ""+nativeCommand.getExecutionEnvironment()+ "" => "" + returnCode);
            }

            if (checkReturnCode && (returnCode != expectedReturnCode)) {
                results.setSuccessful(false);
                results.setResponseMessage(""Unexpected return code.  Expected [""+expectedReturnCode+""]. Actual [""+returnCode+""]."");
            } else {
                results.setSuccessful(true);
                results.setResponseMessage(""OK"");
            }
        } catch (IOException ioe) {
            results.sampleEnd();
            results.setSuccessful(false);
            results.setResponseCode(""500""); //$NON-NLS-1$
            results.setResponseMessage(""Exception occurred whilst executing system call: "" + ioe);
        } catch (InterruptedException ie) {
            results.sampleEnd();
            results.setSuccessful(false);
            results.setResponseCode(""500""); //$NON-NLS-1$
            results.setResponseMessage(""System Sampler interrupted whilst executing system call: "" + ie);
            Thread.currentThread().interrupt();
        } catch (TimeoutException e) {
            results.sampleEnd();
            results.setSuccessful(false);
            results.setResponseCode(""500"");
            results.setResponseMessage(e.getMessage());
        }

        if (nativeCommand != null) {
            @SuppressWarnings(""DefaultCharset"")
            final byte[] responseData = nativeCommand.getOutResult().getBytes();
            results.setResponseData(responseData); // default charset is deliberate here
        }

        return results;
    }",,
jmeter,14961,log.error(message),error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/BeanShellInterpreter.java/#L177,"private Object bshInvoke(Method m, Object[] o, boolean shouldLog) throws JMeterException {
        Object r = null;
        final String errorString = ""Error invoking bsh method: "";
        try {
            r = m.invoke(bshInstance, o);
        } catch (IllegalArgumentException | IllegalAccessException e) { // Programming error
            final String message = errorString + m.getName();
            log.error(message);
            throw new JMeterError(message, e);
        } catch (InvocationTargetException e) { // Can occur at run-time
            // could be caused by the bsh Exceptions:
            // EvalError, ParseException or TargetError
            String message = errorString + m.getName();
            Throwable cause = e.getCause();
            if (cause != null) {
                message += ""\t"" + cause.getLocalizedMessage();
            }

            if (shouldLog) {
                
---------------Reference log start----------------
log.error(message)
---------------Reference log end----------------
            }
            throw new JMeterException(message, e);
        }
        return r;
    }",,
jmeter,14068,"log.warn(""Invalid queue size '{}' defaulting to {}"", size, DEFAULT_QUEUE_SIZE)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/BackendListener.java/#L294,"@Override
    public void testStarted(String host) {
        if (log.isDebugEnabled()) {
            log.debug(""{}\ttestStarted({})"", whoAmI(), host);
        }

        int queueSize;
        final String size = getQueueSize();
        try {
            queueSize = Integer.parseInt(size);
        } catch (NumberFormatException nfe) {
            
---------------Reference log start----------------
log.warn(""Invalid queue size '{}' defaulting to {}"", size, DEFAULT_QUEUE_SIZE)
---------------Reference log end----------------
            queueSize = Integer.parseInt(DEFAULT_QUEUE_SIZE);
        }

        synchronized (LOCK) {
            myName = getName();
            listenerClientData = queuesByTestElementName.get(myName);
            if (listenerClientData == null) {
                // We need to do this to ensure in Distributed testing
                // that only 1 instance of BackendListenerClient is used
                clientClass = initClass(); // may be null
                BackendListenerClient backendListenerClient = createBackendListenerClientImpl(clientClass);
                BackendListenerContext context = new BackendListenerContext((Arguments) getArguments().clone());

                listenerClientData = new ListenerClientData();
                listenerClientData.queue = new ArrayBlockingQueue<>(queueSize);
                listenerClientData.queueWaits = new LongAdder();
                listenerClientData.queueWaitTime = new LongAdder();
                listenerClientData.latch = new CountDownLatch(1);
                listenerClientData.client = backendListenerClient;
                if (log.isInfoEnabled()) {
                    log.info(""{}: Starting worker with class: {} and queue capacity: {}"", getName(), clientClass,
                            getQueueSize());
                }
                Worker worker = new Worker(backendListenerClient, (Arguments) getArguments().clone(), listenerClientData);
                worker.setDaemon(true);
                worker.start();
                if (log.isInfoEnabled()) {
                    log.info(""{}: Started  worker with class: {}"", getName(), clientClass);
                }
                try {
                    backendListenerClient.setupTest(context);
                } catch (Exception e) {
                    throw new IllegalStateException(""Failed calling setupTest"", e);
                }
                queuesByTestElementName.put(myName, listenerClientData);
            }
            listenerClientData.instanceCount++;
        }
    }",,
jmeter,14283,"log.warn(""{} is attempting to use nonexistent {}"", caller.getName(), getMethod)",warn,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/gui/ObjectTableModel.java/#L280,"@SuppressWarnings(""deprecation"")
    public boolean checkFunctors(Object _value, Class<?> caller){
        Object value;
        if (_value == null && objectClass != null) {
            try {
                value = objectClass.getDeclaredConstructor().newInstance();
            } catch (ReflectiveOperationException e) {
                log.error(""Cannot create instance of class {}"", objectClass.getName(),e);
                return false;
            }
        } else {
            value = _value;
        }
        boolean status = true;
        for(int i=0;i<getColumnCount();i++){
            Functor setMethod = writeFunctors.get(i);
            if (setMethod != null
                 && !setMethod.checkMethod(value,getColumnClass(i))) {
                    status=false;
                    log.warn(""{} is attempting to use nonexistent {}"", caller.getName(), setMethod);
            }

            Functor getMethod = readFunctors.get(i);
            if (getMethod != null
                 && !getMethod.checkMethod(value)) {
                    status=false;
                    
---------------Reference log start----------------
log.warn(""{} is attempting to use nonexistent {}"", caller.getName(), getMethod)
---------------Reference log end----------------
            }

        }
        return status;
    }",,
jmeter,14651,"log.error(""RemoteException while handling sample started event."", err)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/samplers/RemoteSampleListenerWrapper.java/#L60,"@Override
    public void sampleStarted(SampleEvent e) {
        try {
            listener.sampleStarted(e);
        } catch (RemoteException err) {
            
---------------Reference log start----------------
log.error(""RemoteException while handling sample started event."", err)
---------------Reference log end----------------
        }
    }",,
jmeter,14091,"log.error(""Couldn't send mail..."", ex)",error,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/MailerVisualizer.java/#L342,"@Override
    public void actionPerformed(ActionEvent e) {
        if (e.getSource() == testerButton) {
            ResultCollector testElement = getModel();
            modifyTestElement(testElement);
            try {
                MailerModel model = ((MailerResultCollector) testElement).getMailerModel();
                model.sendTestMail();
                displayMessage(JMeterUtils.getResString(""mail_sent""), false); //$NON-NLS-1$
            } catch (AddressException ex) {
                log.error(""Invalid mail address "", ex);
                displayMessage(JMeterUtils.getResString(""invalid_mail_address"") //$NON-NLS-1$
                        + ""\n"" + ex.getMessage(), true); //$NON-NLS-1$
            } catch (MessagingException ex) {
                
---------------Reference log start----------------
log.error(""Couldn't send mail..."", ex)
---------------Reference log end----------------
                displayMessage(JMeterUtils.getResString(""invalid_mail"") //$NON-NLS-1$
                        + ""\n"" + ex.getMessage(), true); //$NON-NLS-1$
            }
        }
    }",,
jmeter,14357,"log.debug(""Ignoring SampleResult from Sampler {}"", s.getSampleLabel())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/reporters/ResultSaver.java/#L181,"private void saveSample(SampleResult s, int num) {
        if (ignoreSampler(s)) {
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Ignoring SampleResult from Sampler {}"", s.getSampleLabel())
---------------Reference log end----------------
            }
            return;
        }

        String fileName = makeFileName(s.getContentType(), getSkipAutoNumber(), getSkipSuffix());
        if (log.isDebugEnabled()) {
            log.debug(""Saving {} in {}"", s.getSampleLabel(), fileName);
        }
        s.setResultFileName(fileName);// Associate sample with file name
        String variable = getVariableName();
        if (variable.length() > 0) {
            if (num > 0) {
                variable = variable + num;
            }
            JMeterContextService.getContext().getVariables().put(variable, fileName);
        }
        File out = new File(fileName);
        createFoldersIfNeeded(out.getParentFile());
        try (FileOutputStream fos = new FileOutputStream(out);
                BufferedOutputStream bos = new BufferedOutputStream(fos)){
            JOrphanUtils.write(s.getResponseData(), bos); // chunk the output if necessary
        } catch (FileNotFoundException e) {
            log.error(""Error creating sample file for {}"", s.getSampleLabel(), e);
        } catch (IOException e) {
            log.error(""Error saving sample {}"", s.getSampleLabel(), e);
        }
    }",,
jmeter,13680,"log.debug(""Existing HeaderManager '{}' merged with '{}'"", mgr.getName(), lValue.getName())",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L932,"public void setHeaderManager(final HeaderManager value) {
        HeaderManager mgr = getHeaderManager();
        HeaderManager lValue = value;
        if (mgr != null) {
            lValue = mgr.merge(value);
            if (log.isDebugEnabled()) {
                
---------------Reference log start----------------
log.debug(""Existing HeaderManager '{}' merged with '{}'"", mgr.getName(), lValue.getName())
---------------Reference log end----------------
                for (int i = 0; i < lValue.getHeaders().size(); i++) {
                    log.debug(""    {}={}"", lValue.getHeader(i).getName(), lValue.getHeader(i).getValue());
                }
            }
        }
        setProperty(new TestElementProperty(HEADER_MANAGER, lValue));
    }",,
jmeter,14009,"log.warn(""Failed parsing endIndex: {}, will default to: {}, error message: {}"", this.endIndex, endIndexAsInt, e, e)",warn,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/config/KeystoreConfig.java/#L89,"@Override
    public void testStarted(String host) {
        String reuseSSLContext = JMeterUtils.getProperty(""https.use.cached.ssl.context"");
        if(StringUtils.isEmpty(reuseSSLContext)||""true"".equals(reuseSSLContext)) {
            log.warn(""https.use.cached.ssl.context property must be set to false to ensure Multiple Certificates are used"");
        }
        int startIndexAsInt = JMeterUtils.getPropDefault(KEY_STORE_START_INDEX, 0);
        int endIndexAsInt = JMeterUtils.getPropDefault(KEY_STORE_END_INDEX, -1);

        if(!StringUtils.isEmpty(this.startIndex)) {
            try {
                startIndexAsInt = Integer.parseInt(this.startIndex);
            } catch(NumberFormatException e) {
                log.warn(""Failed parsing startIndex: {}, will default to: {}, error message: {}"", this.startIndex,
                        startIndexAsInt, e, e);
            }
        }

        if(!StringUtils.isEmpty(this.endIndex)) {
            try {
                endIndexAsInt = Integer.parseInt(this.endIndex);
            } catch(NumberFormatException e) {
                
---------------Reference log start----------------
log.warn(""Failed parsing endIndex: {}, will default to: {}, error message: {}"", this.endIndex, endIndexAsInt, e, e)
---------------Reference log end----------------
            }
        }
        if(endIndexAsInt != -1 && startIndexAsInt>endIndexAsInt) {
            throw new JMeterStopTestException(""Keystore Config error : Alias start index must be lower than Alias end index"");
        }
        log.info(
                ""Configuring Keystore with (preload: '{}', startIndex: {}, endIndex: {}, clientCertAliasVarName: '{}')"",
                preload, startIndexAsInt, endIndexAsInt, clientCertAliasVarName);

        SSLManager.getInstance().configureKeystore(Boolean.parseBoolean(preload),
                startIndexAsInt,
                endIndexAsInt,
                clientCertAliasVarName);
    }",,
jmeter,14593,"log.info(""Flushing result collector before report Generation"")",info,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/ReportGenerator.java/#L195,"public void generate() throws GenerationException {

        if (resultCollector != null) {
            
---------------Reference log start----------------
log.info(""Flushing result collector before report Generation"")
---------------Reference log end----------------
            resultCollector.flushFile();
        }
        log.debug(""Start report generation"");

        File tmpDir = configuration.getTempDirectory();
        boolean tmpDirCreated = createTempDir(tmpDir);

        // Build consumers chain
        SampleContext sampleContext = new SampleContext();
        sampleContext.setWorkingDirectory(tmpDir);
        SampleSource source = new CsvFileSampleSource(testFile, CSV_DEFAULT_SEPARATOR);
        source.setSampleContext(sampleContext);

        NormalizerSampleConsumer normalizer = new NormalizerSampleConsumer();
        normalizer.setName(NORMALIZER_CONSUMER_NAME);

        FilterConsumer dateRangeConsumer = createFilterByDateRange();
        dateRangeConsumer.addSampleConsumer(createBeginDateConsumer());
        dateRangeConsumer.addSampleConsumer(createEndDateConsumer());

        FilterConsumer nameFilter = createNameFilter();

        FilterConsumer excludeControllerFilter = createExcludeControllerFilter();

        nameFilter.addSampleConsumer(excludeControllerFilter);

        dateRangeConsumer.addSampleConsumer(nameFilter);

        normalizer.addSampleConsumer(dateRangeConsumer);

        source.addSampleConsumer(normalizer);

        // Get graph configurations
        Map<String, GraphConfiguration> graphConfigurations = configuration
                .getGraphConfigurations();

        // Process configuration to build graph consumers
        for (Map.Entry<String, GraphConfiguration> entryGraphCfg : graphConfigurations.entrySet()) {
            addGraphConsumer(nameFilter, excludeControllerFilter, entryGraphCfg);
        }

        // Generate data
        log.debug(""Start samples processing"");
        try {
            source.run(); // NOSONAR
        } catch (SampleException ex) {
            throw new GenerationException(""Error while processing samples: "" + ex.getMessage(), ex);
        }
        log.debug(""End of samples processing"");

        log.debug(""Start data exporting"");

        // Process configuration to build data exporters
        String key;
        ExporterConfiguration value;
        for (Map.Entry<String, ExporterConfiguration> entry : configuration.getExportConfigurations().entrySet()) {
            key = entry.getKey();
            value = entry.getValue();
            if (log.isInfoEnabled()) {
                log.info(""Exporting data using exporter:'{}' of className:'{}'"", key, value.getClassName());
            }
            exportData(sampleContext, key, value);
        }

        log.debug(""End of data exporting"");

        removeTempDir(tmpDir, tmpDirCreated);

        log.debug(""End of report generation"");
    }",,
jmeter,13683,"log.warn(""Existing KeystoreConfig {} superseded by {}"", mgr.getName(), value.getName())",warn,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/sampler/HTTPSamplerBase.java/#L975,"public void setKeystoreConfig(KeystoreConfig value) {
        KeystoreConfig mgr = getKeystoreConfig();
        if (mgr != null && log.isWarnEnabled()) {
            
---------------Reference log start----------------
log.warn(""Existing KeystoreConfig {} superseded by {}"", mgr.getName(), value.getName())
---------------Reference log end----------------
        }
        setKeystoreConfigProperty(value);
    }",,
jmeter,13410,log.info(firstLine),info,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/HttpMirrorThread.java/#L151,"@Override
    public void run() {
        log.debug(""Starting thread"");
        BufferedInputStream in = null;
        BufferedOutputStream out = null;

        try {
            in = new BufferedInputStream(clientSocket.getInputStream());

            // Read the header part, we will be looking for a content-length
            // header, so we know how much we should read.
            // We assume headers are in ISO_8859_1
            // If we do not find such a header, we will just have to read until
            // we have to block to read more, until we support chunked transfer
            int contentLength = -1;
            boolean isChunked = false;
            byte[] buffer = new byte[1024];
            StringBuilder headers = new StringBuilder();
            int length = 0;
            int positionOfBody = 0;
            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            while(positionOfBody <= 0 && ((length = in.read(buffer)) != -1)) {
                log.debug(""Write body"");
                baos.write(buffer, 0, length); // echo back
                headers.append(new String(buffer, 0, length, ISO_8859_1));
                // Check if we have read all the headers
                positionOfBody = getPositionOfBody(headers.toString());
            }

            baos.close();
            final String headerString = headers.toString();
            if(headerString.length() == 0 || headerString.indexOf('\r') < 0) {
                log.error(""Invalid request received:'{}'"", headerString);
                return;
            }
            log.debug(""Received => '{}'"", headerString);
            final String firstLine = headerString.substring(0, headerString.indexOf('\r'));
            final String[] requestParts = firstLine.split(""\\s+"");
            final String requestMethod = requestParts[0];
            final String requestPath = requestParts[1];
            final HashMap<String, String> parameters = new HashMap<>();
            if (HTTPConstants.GET.equals(requestMethod)) {
                int querypos = requestPath.indexOf('?');
                if (querypos >= 0) {
                    String query;
                    try {
                        URI uri = new URI(requestPath); // Use URI because it will decode the query
                        query = uri.getQuery();
                    } catch (URISyntaxException e) {
                        log.warn(e.getMessage());
                        query=requestPath.substring(querypos+1);
                    }
                    if (query != null) {
                        String[] params = query.split(""&"");
                        for(String param : params) {
                            String[] parts = param.split(""="",2);
                            if (parts.length==2) {
                                parameters.put(parts[0], parts[1]);
                            } else { // allow for parameter name only
                                parameters.put(parts[0], """");
                            }
                        }
                    }
                }
            }

            final boolean verbose = parameters.containsKey(VERBOSE);

            if (verbose) {
                System.out.println(firstLine); // NOSONAR
                
---------------Reference log start----------------
log.info(firstLine)
---------------Reference log end----------------
            }

            // Look for special Response Length header
            String responseStatusValue = getRequestHeaderValue(headerString, ""X-ResponseStatus""); //$NON-NLS-1$
            if(responseStatusValue == null) {
                responseStatusValue = ""200 OK"";
            }
            // Do this before the status check so can override the status, e.g. with a different redirect type
            if (parameters.containsKey(REDIRECT)) {
                responseStatusValue = ""302 Temporary Redirect"";
            }
            if (parameters.containsKey(STATUS)) {
                responseStatusValue = parameters.get(STATUS);
            }

            log.debug(""Write headers"");
            out = new BufferedOutputStream(clientSocket.getOutputStream());
            // The headers are written using ISO_8859_1 encoding
            out.write((""HTTP/1.0 ""+responseStatusValue).getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);
            out.write(""Content-Type: text/plain"".getBytes(ISO_8859_1)); //$NON-NLS-1$
            out.write(CRLF);

            if (parameters.containsKey(REDIRECT)) {
                final String redirectLocation =
                        HTTPConstants.HEADER_LOCATION + "": "" + parameters.get(REDIRECT);
                if (verbose) {
                    System.out.println(redirectLocation); // NOSONAR
                    log.info(redirectLocation);
                }
                out.write(redirectLocation.getBytes(ISO_8859_1));
                out.write(CRLF);
            }

            // Look for special Header request
            String headersValue = getRequestHeaderValue(headerString, ""X-SetHeaders""); //$NON-NLS-1$
            if (headersValue != null) {
                String[] headersToSet = headersValue.split(""\\|"");
                for (String string : headersToSet) {
                    out.write(string.getBytes(ISO_8859_1));
                    out.write(CRLF);
                }
            }

            // Look for special Response Length header
            String responseLengthValue = getRequestHeaderValue(headerString, ""X-ResponseLength""); //$NON-NLS-1$
            int responseLength=-1;
            if(responseLengthValue != null) {
                responseLength = Integer.parseInt(responseLengthValue);
            }

            // Look for special Cookie request
            String cookieHeaderValue = getRequestHeaderValue(headerString, ""X-SetCookie""); //$NON-NLS-1$
            if (cookieHeaderValue != null) {
                out.write(""Set-Cookie: "".getBytes(ISO_8859_1));
                out.write(cookieHeaderValue.getBytes(ISO_8859_1));
                out.write(CRLF);
            }
            out.write(CRLF);
            out.flush();

            if(responseLength>=0) {
                out.write(baos.toByteArray(), 0, Math.min(baos.toByteArray().length, responseLength));
            } else {
                out.write(baos.toByteArray());
            }
            // Check if we have found a content-length header
            String contentLengthHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.HEADER_CONTENT_LENGTH);
            if(contentLengthHeaderValue != null) {
                contentLength = Integer.parseInt(contentLengthHeaderValue);
            }
            // Look for special Sleep request
            String sleepHeaderValue = getRequestHeaderValue(headerString, ""X-Sleep""); //$NON-NLS-1$
            if(sleepHeaderValue != null) {
                TimeUnit.MILLISECONDS.sleep(Integer.parseInt(sleepHeaderValue));
            }
            String transferEncodingHeaderValue = getRequestHeaderValue(headerString, HTTPConstants.TRANSFER_ENCODING);
            if(transferEncodingHeaderValue != null) {
                isChunked = transferEncodingHeaderValue.equalsIgnoreCase(""chunked""); //$NON-NLS-1$
                // We only support chunked transfer encoding
                if(!isChunked) {
                    log.error(""Transfer-Encoding header set, the value is not supported : {}"", transferEncodingHeaderValue);
                }
            }

            // If we know the content length, we can allow the reading of
            // the request to block until more data arrives.
            // If it is chunked transfer, we cannot allow the reading to
            // block, because we do not know when to stop reading, because
            // the chunked transfer is not properly supported yet
            length = 0;
            if(contentLength > 0) {
                // Check how much of the body we have already read as part of reading
                // the headers
                // We subtract two bytes for the crlf divider between header and body
                int totalReadBytes = headerString.length() - positionOfBody - 2;

                // We know when to stop reading, so we can allow the read method to block
                log.debug(""Reading, {} < {}"", totalReadBytes, contentLength);
                while((totalReadBytes < contentLength) && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);

                    totalReadBytes += length;
                    log.debug(""totalReadBytes: {}"", totalReadBytes);
                }
            }
            else if (isChunked) {
                // It is chunked transfer encoding, which we do not really support yet.
                // So we just read without blocking, because we do not know when to
                // stop reading, so we cannot block
                // TODO properly implement support for chunked transfer, i.e. to
                // know when we have read the whole request, and therefore allow
                // the reading to block
                log.debug(""Chunked"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    out.write(buffer, 0, length);
                }
            }
            else {
                // The request has no body, or it has a transfer encoding we do not support.
                // In either case, we read any data available
                log.debug(""Other"");
                while(in.available() > 0 && ((length = in.read(buffer)) != -1)) {
                    log.debug(""Read bytes: {}"", length);
                    out.write(buffer, 0, length);
                }
            }
            log.debug(""Flush"");
            out.flush();
        } catch (IOException | InterruptedException e) {
            log.error("""", e);
        } finally {
            JOrphanUtils.closeQuietly(out);
            JOrphanUtils.closeQuietly(in);
            JOrphanUtils.closeQuietly(clientSocket);
        }
        log.debug(""End of Thread"");
    }",,
jmeter,14607,"log.warn(""{} is set while the graph {} excludes controllers."", ReportGeneratorConfiguration.EXPORTER_KEY_SHOW_CONTROLLERS_ONLY, graphId)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/report/dashboard/HtmlTemplateExporter.java/#L203,"@Override
        public boolean checkResult(DataContext dataContext, ResultData result) {
            boolean supportsControllerDiscrimination = findValue(Boolean.class,
                    AbstractGraphConsumer.RESULT_SUPPORTS_CONTROLLERS_DISCRIMINATION,
                    result);

            if (supportsControllerDiscrimination
                    && showControllerSeriesOnly
                    && excludesControllers) {
                // Exporter shows controller series only
                // whereas the current graph support controller
                // discrimination and excludes controllers
                
---------------Reference log start----------------
log.warn(""{} is set while the graph {} excludes controllers."", ReportGeneratorConfiguration.EXPORTER_KEY_SHOW_CONTROLLERS_ONLY, graphId)
---------------Reference log end----------------
                return false;
            }

            if (filterPattern == null) {
                return true;
            }

            // Detect whether none series matches the series filter.
            ResultData seriesResult = findData(AbstractGraphConsumer.RESULT_SERIES, result);
            if (!(seriesResult instanceof ListResultData)) {
                return true;
            }

            // Try to find at least one pattern matching
            ListResultData seriesList = (ListResultData) seriesResult;
            int count = seriesList.getSize();
            int index = 0;
            boolean matches = false;
            while (index < count && !matches) {
                ResultData currentResult = seriesList.get(index);
                if (currentResult instanceof MapResultData) {
                    MapResultData seriesData = (MapResultData) currentResult;
                    String name = findValue(String.class,
                            AbstractGraphConsumer.RESULT_SERIES_NAME,
                            seriesData);

                    // Is the current series a controller series ?
                    boolean isController = findValue(Boolean.class,
                            AbstractGraphConsumer.RESULT_SERIES_IS_CONTROLLER,
                            seriesData);

                    matches = filterPattern.matcher(name).matches();
                    if (matches) {
                        // If the name matches pattern, other
                        // properties can discard the series
                        matches = !filtersOnlySampleSeries
                                || !supportsControllerDiscrimination
                                || isController
                                || !showControllerSeriesOnly;
                        if(log.isDebugEnabled()) {
                            log.debug(
                                    ""name:{} matches pattern:{}, supportsControllerDiscrimination:{}, ""
                                    + ""isController:{}, showControllerSeriesOnly:{}"",
                                    name, filterPattern.pattern(),
                                    supportsControllerDiscrimination,
                                    isController,
                                    showControllerSeriesOnly);
                        }
                    } else {
                        // If the name does not match the pattern,
                        // other properties can hold the series
                        matches = filtersOnlySampleSeries
                                && !supportsControllerDiscrimination;
                        if (log.isDebugEnabled()) {
                            log.debug(""name:{} does not match pattern:{}, filtersOnlySampleSeries:{},""
                                + "" supportsControllerDiscrimination:{}"",
                                name, filterPattern.pattern(),
                                filtersOnlySampleSeries,
                                supportsControllerDiscrimination);
                        }
                    }
                }
                index++;
            }
            if (!matches) {
                log.warn(""No series matches the series_filter: {} in graph: {}"",
                        ReportGeneratorConfiguration.EXPORTER_KEY_SERIES_FILTER, graphId);
                return false;
            }
            return true;
        }",,
jmeter,13303,"log.error(""Format date pattern '{}' is invalid "" + ""(see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html)"", format, // $NON-NLS-1$
ex)",error,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/TimeShift.java/#L151,"@Override
    public String execute(SampleResult previousResult, Sampler currentSampler) throws InvalidVariableException {
        String amountToShift = amountToShiftCompound.execute().trim();
        String dateToShift = dateToShiftCompound.execute().trim();
        ZonedDateTime zonedDateTimeToShift = ZonedDateTime.now(systemDefaultZoneID);

        DateTimeFormatter formatter = null;
        if (!StringUtils.isEmpty(format)) {
            try {
                LocaleFormatObject lfo = new LocaleFormatObject(format, locale);
                formatter = dateTimeFormatterCache.get(lfo, this::createFormatter);
            } catch (IllegalArgumentException ex) {
                
---------------Reference log start----------------
log.error(""Format date pattern '{}' is invalid "" + ""(see https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html)"", format, // $NON-NLS-1$
ex)
---------------Reference log end----------------
                return """";
            }
        }

        if (!dateToShift.isEmpty()) {
            try {
                if (formatter != null) {
                    zonedDateTimeToShift = ZonedDateTime.parse(dateToShift, formatter);
                } else {
                    zonedDateTimeToShift = ZonedDateTime.ofInstant(Instant.ofEpochMilli(Long.parseLong(dateToShift)),
                            systemDefaultZoneID);
                }
            } catch (DateTimeParseException | NumberFormatException ex) {
                log.error(""Failed to parse the date '{}' to shift with formatter '{}'"",
                        dateToShift, formatter, ex); // $NON-NLS-1$
            }
        }

        // Check amount value to shift
        if (!StringUtils.isEmpty(amountToShift)) {
            try {
                Duration duration = Duration.parse(amountToShift);
                zonedDateTimeToShift = zonedDateTimeToShift.plus(duration);
            } catch (DateTimeParseException ex) {
                log.error(
                        ""Failed to parse the amount duration '{}' to shift ""
                        + ""(see https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html#parse-java.lang.CharSequence-) "",
                        amountToShift, ex); // $NON-NLS-1$
            }
        }
        String dateString;
        if (formatter != null) {
            dateString = zonedDateTimeToShift.format(formatter);
        } else {
            dateString = String.valueOf(zonedDateTimeToShift.toInstant().toEpochMilli());
        }

        if (!StringUtils.isEmpty(variableName)) {
            JMeterVariables vars = getVariables();
            if (vars != null) {// vars will be null on TestPlan
                vars.put(variableName, dateString);
            }
        }
        return dateString;
    }",,
jmeter,14033,"log.debug(""Handling {} sample results"", sampleResults.size())",debug,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/visualizers/backend/influxdb/InfluxDBRawBackendListenerClient.java/#L102,"@Override
    public void handleSampleResults(
            List<SampleResult> sampleResults, BackendListenerContext context) {
        
---------------Reference log start----------------
log.debug(""Handling {} sample results"", sampleResults.size())
---------------Reference log end----------------
        synchronized (LOCK) {
            for (SampleResult sampleResult : sampleResults) {
                addMetricFromSampleResult(sampleResult);
            }
            influxDBMetricsManager.writeAndSendMetrics();
        }
    }",,
jmeter,14989,"log.debug(""Supported Cipher: {}"", sCiphers[i])",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/JsseSSLManager.java/#L255,"private SSLContext createContext() throws GeneralSecurityException {
        SSLContext context;
        if (pro != null) {
            context = SSLContext.getInstance(DEFAULT_SSL_PROTOCOL, pro); // $NON-NLS-1$
        } else {
            context = SSLContext.getInstance(DEFAULT_SSL_PROTOCOL); // $NON-NLS-1$
        }
        KeyManagerFactory managerFactory =
            KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
        JmeterKeyStore keys = this.getKeyStore();
        managerFactory.init(null, defaultpw == null ? new char[]{} : defaultpw.toCharArray());
        KeyManager[] managers = managerFactory.getKeyManagers();
        KeyManager[] newManagers = new KeyManager[managers.length];

        if (log.isDebugEnabled()) {
            log.debug(""JmeterKeyStore type: {}"", keys.getClass());
        }

        // Now wrap the default managers with our key manager
        for (int i = 0; i < managers.length; i++) {
            if (managers[i] instanceof X509KeyManager) {
                X509KeyManager manager = (X509KeyManager) managers[i];
                newManagers[i] = new WrappedX509KeyManager(manager, keys);
            } else {
                newManagers[i] = managers[i];
            }
        }

        // Get the default trust managers
        TrustManagerFactory tmfactory = TrustManagerFactory.getInstance(
                TrustManagerFactory.getDefaultAlgorithm());
        tmfactory.init(this.getTrustStore());

        // Wrap the defaults in our custom trust manager
        TrustManager[] trustmanagers = tmfactory.getTrustManagers();
        for (int i = 0; i < trustmanagers.length; i++) {
            if (trustmanagers[i] instanceof X509TrustManager) {
                trustmanagers[i] = new CustomX509TrustManager(
                    (X509TrustManager)trustmanagers[i]);
            }
        }
        context.init(newManagers, trustmanagers, this.rand);
        if (log.isDebugEnabled()){
            String[] dCiphers = context.getSocketFactory().getDefaultCipherSuites();
            String[] sCiphers = context.getSocketFactory().getSupportedCipherSuites();
            int len = (dCiphers.length > sCiphers.length) ? dCiphers.length : sCiphers.length;
            for (int i = 0; i < len; i++) {
                if (i < dCiphers.length) {
                    log.debug(""Default Cipher: {}"", dCiphers[i]);
                }
                if (i < sCiphers.length) {
                    
---------------Reference log start----------------
log.debug(""Supported Cipher: {}"", sCiphers[i])
---------------Reference log end----------------
                }
            }
        }
        return context;
    }",,
jmeter,13564,"log.debug(""Client Request Line: '{}'"", reqLine.replaceFirst(""\r\n$"", CRLF))",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/proxy/HttpRequestHdr.java/#L179,"public byte[] parse(InputStream in) throws IOException {
        boolean inHeaders = true;
        int readLength = 0;
        int dataLength = 0;
        boolean firstLine = true;
        ByteArrayOutputStream clientRequest = new ByteArrayOutputStream();
        ByteArrayOutputStream line = new ByteArrayOutputStream();
        int x;
        while ((inHeaders || readLength < dataLength) && ((x = in.read()) != -1)) {
            line.write(x);
            clientRequest.write(x);
            if (firstLine && !CharUtils.isAscii((char) x)){// includes \n
                throw new IllegalArgumentException(""Only ASCII supported in headers (perhaps SSL was used?)"");
            }
            if (inHeaders && (byte) x == (byte) '\n') { // $NON-NLS-1$
                if (line.size() < 3) {
                    inHeaders = false;
                    firstLine = false; // cannot be first line either
                }
                final String reqLine = line.toString();
                if (firstLine) {
                    parseFirstLine(reqLine);
                    firstLine = false;
                } else {
                    // parse other header lines, looking for Content-Length
                    final int contentLen = parseLine(reqLine);
                    if (contentLen > 0) {
                        dataLength = contentLen; // Save the last valid content length one
                    }
                }
                if (log.isDebugEnabled()){
                    
---------------Reference log start----------------
log.debug(""Client Request Line: '{}'"", reqLine.replaceFirst(""\r\n$"", CRLF))
---------------Reference log end----------------
                }
                line.reset();
            } else if (!inHeaders) {
                readLength++;
            }
        }
        // Keep the raw post data
        rawPostData = line.toByteArray();

        if (log.isDebugEnabled()){
            log.debug(""rawPostData in default JRE encoding: {}, Request: '{}'"",
                    new String(rawPostData, Charset.defaultCharset()),
                    clientRequest.toString().replaceAll(""\r\n"", CRLF));
        }
        return clientRequest.toByteArray();
    }",,
jmeter,15054,"log.error(""TestElement not instantiable: {}"", type, e)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/save/converters/TestElementConverter.java/#L113,"@Override
    public Object unmarshal(HierarchicalStreamReader reader, UnmarshallingContext context) {
        String classAttribute = reader.getAttribute(ConversionHelp.ATT_CLASS);
        Class<?> type;
        if (classAttribute == null) {
            type = mapper().realClass(reader.getNodeName());
        } else {
            type = mapper().realClass(classAttribute);
        }
        // Update the test class name if necessary (Bug 52466)
        String inputName = type.getName();
        String guiClassName = SaveService.aliasToClass(reader.getAttribute(ConversionHelp.ATT_TE_GUICLASS));
        String targetName = NameUpdater.getCurrentTestName(inputName, guiClassName);
        if (!targetName.equals(inputName)) { // remap the class name
            type = mapper().realClass(targetName);
        }
        context.put(SaveService.TEST_CLASS_NAME, targetName); // needed by property converters  (Bug 52466)
        try {
            TestElement el = (TestElement) type.getDeclaredConstructor().newInstance();
            // No need to check version, just process the attributes if present
            ConversionHelp.restoreSpecialProperties(el, reader);
            // Slight hack - we need to ensure the TestClass is not reset by the previous call
            el.setProperty(TestElement.TEST_CLASS, targetName);
            while (reader.hasMoreChildren()) {
                reader.moveDown();
                JMeterProperty prop = (JMeterProperty) readBareItem(reader, context, el);
                if (prop != null) { // could be null if it has been deleted via NameUpdater
                    el.setProperty(prop);
                }
                reader.moveUp();
            }
            return el;
        } catch (IllegalArgumentException | ReflectiveOperationException | SecurityException e) {
            
---------------Reference log start----------------
log.error(""TestElement not instantiable: {}"", type, e)
---------------Reference log end----------------
            return null;
        }
    }",,
jmeter,14451,"log.error(""Failed to load from history"", ex)",error,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/gui/UndoHistory.java/#L192,"private void loadHistoricalTree(JMeterTreeModel acceptorModel, GuiPackage guiInstance, HashTree newModel) {
        acceptorModel.removeTreeModelListener(this);
        working = true;
        try {
            guiInstance.getTreeModel().clearTestPlan();
            guiInstance.addSubTree(newModel);
        } catch (Exception ex) {
            
---------------Reference log start----------------
log.error(""Failed to load from history"", ex)
---------------Reference log end----------------
        } finally {
            acceptorModel.addTreeModelListener(this);
            working = false;
        }
    }",,
jmeter,13950,"log.error(""Error closing pool:{}"", getName(), ex)",error,https://github.com/apache/jmeter/blob/master/src/protocol/jdbc/src/main/java/org/apache/jmeter/protocol/jdbc/config/DataSourceElement.java/#L99,"@Override
    public void testEnded() {
        synchronized (this) {
            if (dbcpDataSource != null) {
                try {
                    dbcpDataSource.close();
                } catch (SQLException ex) {
                    log.error(""Error closing pool: {}"", getName(), ex);
                }
            }
            dbcpDataSource = null;
        }
        if (perThreadPoolSet != null) {// in case
            for(BasicDataSource dsc : perThreadPoolSet){
                log.debug(""Closing pool: {}@{}"", getDataSourceName(), System.identityHashCode(dsc));
                try {
                    dsc.close();
                } catch (SQLException ex) {
                    
---------------Reference log start----------------
log.error(""Error closing pool:{}"", getName(), ex)
---------------Reference log end----------------
                }
            }
            perThreadPoolSet=null;
        }
    }",,
jmeter,14243,"log.info(""Restarting next thread loop from element {}"", getName())",info,https://github.com/apache/jmeter/blob/master/src/components/src/main/java/org/apache/jmeter/sampler/TestAction.java/#L130,"@Override
    public SampleResult sample(Entry e) {
        JMeterContext context = JMeterContextService.getContext();

        int target = getTarget();
        int action = getAction();
        if (action == PAUSE) {
            pause(getDurationAsString());
        } else if (action == STOP || action == STOP_NOW) {
            if (target == THREAD) {
                if(log.isInfoEnabled()) {
                    log.info(MSG_STOP_CURRENT_THREAD, getName());
                }
                context.getThread().stop();
            } else if (target == TEST) {
                if (action == STOP_NOW) {
                    if(log.isInfoEnabled()) {
                        log.info(MSG_STOP_CURRENT_THREAD, getName());
                    }
                    context.getThread().stop();
                    if(log.isInfoEnabled()) {
                        log.info(""Stopping all threads now from element {}"", getName());
                    }
                    context.getEngine().stopTest();
                } else {
                    if(log.isInfoEnabled()) {
                        log.info(MSG_STOP_CURRENT_THREAD, getName());
                    }
                    context.getThread().stop();
                    if(log.isInfoEnabled()) {
                        log.info(""Stopping all threads from element {}"", getName());
                    }
                    context.getEngine().askThreadsToStop();
                }
            }
        } else if (action == RESTART_NEXT_LOOP) {
            
---------------Reference log start----------------
log.info(""Restarting next thread loop from element {}"", getName())
---------------Reference log end----------------
            context.setTestLogicalAction(TestLogicalAction.START_NEXT_ITERATION_OF_THREAD);
        } else if (action == START_NEXT_ITERATION_CURRENT_LOOP) {
            log.info(""Switching to next loop iteration from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.START_NEXT_ITERATION_OF_CURRENT_LOOP);
        } else if (action == BREAK_CURRENT_LOOP) {
            log.info(""Breaking current loop from element {}"", getName());
            context.setTestLogicalAction(TestLogicalAction.BREAK_CURRENT_LOOP);
        }

        return null; // This means no sample is saved
    }",,
jmeter,13588,"log.debug(""Matched!"")",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/modifier/AnchorModifier.java/#L184,"private void addAnchorUrls(Document html, HTTPSampleResult result, HTTPSamplerBase config,
            List<HTTPSamplerBase> potentialLinks) {
        String base = """";
        NodeList baseList = html.getElementsByTagName(""base""); // $NON-NLS-1$
        if (baseList.getLength() > 0) {
            base = baseList.item(0).getAttributes().getNamedItem(""href"").getNodeValue(); // $NON-NLS-1$
        }
        NodeList nodeList = html.getElementsByTagName(""a""); // $NON-NLS-1$
        for (int i = 0; i < nodeList.getLength(); i++) {
            Node tempNode = nodeList.item(i);
            NamedNodeMap nnm = tempNode.getAttributes();
            Node namedItem = nnm.getNamedItem(""href""); // $NON-NLS-1$
            if (namedItem == null) {
                continue;
            }
            String hrefStr = namedItem.getNodeValue();
            if (hrefStr.startsWith(""javascript:"")) { // $NON-NLS-1$
                continue; // No point trying these
            }
            try {
                HTTPSamplerBase newUrl = HtmlParsingUtils.createUrlFromAnchor(hrefStr, ConversionUtils.makeRelativeURL(result.getURL(), base));
                newUrl.setMethod(HTTPConstants.GET);
                if (log.isDebugEnabled()) {
                    log.debug(""Potential <a href> match: "" + newUrl);
                }
                if (HtmlParsingUtils.isAnchorMatched(newUrl, config)) {
                    
---------------Reference log start----------------
log.debug(""Matched!"")
---------------Reference log end----------------
                    potentialLinks.add(newUrl);
                }
            } catch (MalformedURLException e) {
                log.warn(""Bad URL ""+e);
            }
        }
    }",,
jmeter,13428,"log.debug(""Did not match against auth'n entry: {}"", uRL)",debug,https://github.com/apache/jmeter/blob/master/src/protocol/http/src/main/java/org/apache/jmeter/protocol/http/control/AuthManager.java/#L269,"public Authorization getAuthForURL(URL url) {
        if (!isSupportedProtocol(url)) {
            return null;
        }

        // TODO: replace all this url2 mess with a proper method
        // ""areEquivalent(url1, url2)"" that
        // would also ignore case in protocol and host names, etc. -- use that
        // method in the CookieManager too.

        URL url2 = null;

        try {
            if (url.getPort() == -1) {
                // Obtain another URL with an explicit port:
                int port = url.getProtocol().equalsIgnoreCase(HTTPConstants.PROTOCOL_HTTP) ? HTTPConstants.DEFAULT_HTTP_PORT : HTTPConstants.DEFAULT_HTTPS_PORT;
                // only http and https are supported
                url2 = new URL(url.getProtocol(), url.getHost(), port, url.getPath());
            } else if ((url.getPort() == HTTPConstants.DEFAULT_HTTP_PORT && url.getProtocol().equalsIgnoreCase(HTTPConstants.PROTOCOL_HTTP))
                    || (url.getPort() == HTTPConstants.DEFAULT_HTTPS_PORT && url.getProtocol().equalsIgnoreCase(HTTPConstants.PROTOCOL_HTTPS))) {
                url2 = new URL(url.getProtocol(), url.getHost(), url.getPath());
            }
        } catch (MalformedURLException e) {
            log.error(""Internal error!"", e); // this should never happen
            // anyway, we'll continue with url2 set to null.
        }

        String s1 = url.toString();
        String s2 = null;
        if (url2 != null) {
            s2 = url2.toString();
        }

        log.debug(""Target URL strings to match against: {} and {}"", s1, s2);
        // TODO should really return most specific (i.e. longest) match.
        for (JMeterProperty jMeterProperty : getAuthObjects()) {
            Authorization auth = (Authorization) jMeterProperty.getObjectValue();

            String uRL = auth.getURL();
            log.debug(""Checking match against auth'n entry: {}"", uRL);
            if (s1.startsWith(uRL) || s2 != null && s2.startsWith(uRL)) {
                log.debug(""Matched against auth'n entry: {}"", uRL);
                return auth;
            }
            
---------------Reference log start----------------
log.debug(""Did not match against auth'n entry: {}"", uRL)
---------------Reference log end----------------
        }
        return null;
    }",,
jmeter,14290,"slf4jLogger.error(message, throwable)",error,https://github.com/apache/jmeter/blob/master/src/jorphan/src/main/java/org/apache/jorphan/logging/Slf4jLogkitLogger.java/#L87,"@Override
    public void error(String message, Throwable throwable) {
        
---------------Reference log start----------------
slf4jLogger.error(message, throwable)
---------------Reference log end----------------
    }
    }",,
jmeter,13275,"log.debug(""clearAll()"")",debug,https://github.com/apache/jmeter/blob/master/src/functions/src/main/java/org/apache/jmeter/functions/XPathWrapper.java/#L115,"public static void clearAll() {
        
---------------Reference log start----------------
log.debug(""clearAll()"")
---------------Reference log end----------------
        filePacks.get().clear();
        if (log.isInfoEnabled()) {
            log.info(""{}: clearing container"", Thread.currentThread().getName());
        }
        synchronized (fileContainers) {
            fileContainers.clear();
        }
    }",,
jmeter,14349,"log.debug(""Writing header to file: {}"", filename)",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/reporters/ResultCollector.java/#L483,"private static PrintWriter getFileWriter(final String pFilename, SampleSaveConfiguration saveConfig)
            throws IOException {
        if (pFilename == null || pFilename.length() == 0) {
            return null;
        }
        if(log.isDebugEnabled()) {
            log.debug(""Getting file: {} in thread {}"", pFilename, Thread.currentThread().getName());
        }
        String filename = FileServer.resolveBaseRelativeName(pFilename);
        filename = new File(filename).getCanonicalPath(); // try to ensure uniqueness (Bug 60822)
        FileEntry fe = files.get(filename);
        PrintWriter writer = null;
        boolean trimmed = true;

        if (fe == null) {
            if (saveConfig.saveAsXml()) {
                trimmed = trimLastLine(filename);
            } else {
                trimmed = new File(filename).exists();
            }
            // Find the name of the directory containing the file
            // and create it - if there is one
            File pdir = new File(filename).getParentFile();
            if (pdir != null) {
                // returns false if directory already exists, so need to check again
                if(pdir.mkdirs()){
                    if (log.isInfoEnabled()) {
                        log.info(""Folder at {} was created"", pdir.getAbsolutePath());
                    }
                } // else if might have been created by another process so not a problem
                if (!pdir.exists()){
                    log.warn(""Error creating directories for {}"", pdir);
                }
            }
            writer = new PrintWriter(new OutputStreamWriter(new BufferedOutputStream(new FileOutputStream(filename,
                    trimmed)), SaveService.getFileEncoding(StandardCharsets.UTF_8.name())), SAVING_AUTOFLUSH);
            if(log.isDebugEnabled()) {
                log.debug(""Opened file: {} in thread {}"", filename, Thread.currentThread().getName());
            }
            files.put(filename, new FileEntry(writer, saveConfig));
        } else {
            writer = fe.pw;
        }
        if (!trimmed) {
            
---------------Reference log start----------------
log.debug(""Writing header to file: {}"", filename)
---------------Reference log end----------------
            writeFileStart(writer, saveConfig);
        }
        return writer;
    }",,
jmeter,14958,"log.warn(""Cannot read init file: {}"", fileToUse)",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/util/BeanShellInterpreter.java/#L139,"private void init() throws ClassNotFoundException {
        if (bshClass == null) {
            throw new ClassNotFoundException(BSH_INTERPRETER);
        }
        try {
            bshInstance = bshClass.getDeclaredConstructor().newInstance();
        } catch (IllegalArgumentException | ReflectiveOperationException | SecurityException e) {
            log.error(""Can't instantiate BeanShell"", e);
            throw new ClassNotFoundException(""Can't instantiate BeanShell"", e);
        }
         if (logger != null) {// Do this before starting the script
            try {
                set(""log"", logger);//$NON-NLS-1$
            } catch (JMeterException e) {
                log.warn(""Can't set logger variable"", e);
            }
        }
        if (StringUtils.isNotBlank(initFile)) {
            String fileToUse=initFile;
            // Check file so we can distinguish file error from script error
            File in = new File(fileToUse);
            if (!in.exists()){// Cannot find the file locally, so try the bin directory
                fileToUse=JMeterUtils.getJMeterHome()
                        +File.separator+""bin"" // $NON-NLS-1$
                        +File.separator+initFile;
                in = new File(fileToUse);
                if (!in.exists()) {
                    log.warn(""Cannot find init file: {}"", initFile);
                }
            }
            if (!in.canRead()) {
                
---------------Reference log start----------------
log.warn(""Cannot read init file: {}"", fileToUse)
---------------Reference log end----------------
            }
            try {
                source(fileToUse);
            } catch (JMeterException e) {
                log.warn(""Cannot source init file: {}"", fileToUse,e);
            }
        }
    }",,
jmeter,13734,"log.error(""Error instantiating class:{}:{}"", theclazz, e.getMessage(), e)",error,https://github.com/apache/jmeter/blob/master/src/protocol/junit/src/main/java/org/apache/jmeter/protocol/java/sampler/JUnitSampler.java/#L541,"private static Object getClassInstance(String className, String label){
        Object testclass = null;
        if (className != null){
            Constructor<?> con = null;
            Constructor<?> strCon = null;
            Class<?> theclazz = null;
            Object[] strParams = null;
            Object[] params = null;
            try
            {
                theclazz =
                    Thread.currentThread().getContextClassLoader().loadClass(className.trim());
            } catch (ClassNotFoundException e) {
                log.warn(""ClassNotFoundException:: {}"", e.getMessage());
            }
            if (theclazz != null) {
                // first we see if the class declares a string
                // constructor. if it is doesn't we look for
                // empty constructor.
                try {
                    strCon = theclazz.getDeclaredConstructor(
                            new Class[] {String.class});
                    // we have to check and make sure the constructor is
                    // accessible. if we didn't it would throw an exception
                    // and cause a NPE.
                    if (label == null || label.length() == 0) {
                        label = className;
                    }
                    if (strCon.getModifiers() == Modifier.PUBLIC) {
                        strParams = new Object[]{label};
                    } else {
                        strCon = null;
                    }
                } catch (NoSuchMethodException e) {
                    log.info(""Trying to find constructor with one String parameter returned error: {}"", e.getMessage());
                }
                try {
                    con = theclazz.getDeclaredConstructor(new Class[0]);
                    if (con != null){
                        params = new Object[]{};
                    }
                } catch (NoSuchMethodException e) {
                    log.info(""Trying to find empty constructor returned error: {}"", e.getMessage());
                }
                try {
                    // if the string constructor is not null, we use it.
                    // if the string constructor is null, we use the empty
                    // constructor to get a new instance
                    if (strCon != null) {
                        testclass = strCon.newInstance(strParams);
                    } else if (con != null){
                        testclass = con.newInstance(params);
                    } else {
                        log.error(""No empty constructor nor string constructor found for class:{}"", theclazz);
                    }
                } catch (InvocationTargetException | IllegalAccessException
                        | InstantiationException e) {
                    
---------------Reference log start----------------
log.error(""Error instantiating class:{}:{}"", theclazz, e.getMessage(), e)
---------------Reference log end----------------
                }
            }
        }
        return testclass;
    }",,
jmeter,14788,"log.warn(""Engine is busy - cannot create JMeter engine"")",warn,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/engine/RemoteJMeterEngineImpl.java/#L145,"@Override
    public void rconfigure(HashTree testTree, String hostAndPort, File jmxBase, String scriptName) throws RemoteException {
        log.info(""Creating JMeter engine on host {} base '{}'"", hostAndPort, jmxBase);
        try {
            if (log.isInfoEnabled()) {
                log.info(""Remote client host: {}"", getClientHost());
            }
        } catch (ServerNotActiveException e) {
            // ignored
        }
        synchronized(LOCK) { // close window where another remote client might jump in
            if (backingEngine != null && backingEngine.isActive()) {
                
---------------Reference log start----------------
log.warn(""Engine is busy - cannot create JMeter engine"")
---------------Reference log end----------------
                throw new IllegalStateException(""Engine is busy - please try later"");
            }
            ownerThread = Thread.currentThread();
            JMeterUtils.setProperty(JMeterUtils.THREAD_GROUP_DISTRIBUTED_PREFIX_PROPERTY_NAME, hostAndPort);
            backingEngine = new StandardJMeterEngine(hostAndPort);
            backingEngine.configure(testTree); // sets active = true
        }
        FileServer.getFileServer().setScriptName(scriptName);
        FileServer.getFileServer().setBase(jmxBase);
    }",,
jmeter,15117,"log.debug(""Subtracting node, stack size = {}"", stack.size())",debug,https://github.com/apache/jmeter/blob/master/src/core/src/main/java/org/apache/jmeter/threads/TestCompiler.java/#L136,"@Override
    public void subtractNode() {
        if (log.isDebugEnabled()) {
            
---------------Reference log start----------------
log.debug(""Subtracting node, stack size = {}"", stack.size())
---------------Reference log end----------------
        }
        TestElement child = stack.getLast();
        trackIterationListeners(stack);
        if (child instanceof Sampler) {
            saveSamplerConfigs((Sampler) child);
        }
        else if(child instanceof TransactionController) {
            saveTransactionControllerConfigs((TransactionController) child);
        }
        stack.removeLast();
        if (!stack.isEmpty()) {
            TestElement parent = stack.getLast();
            boolean duplicate = false;
            // Bug 53750: this condition used to be in ObjectPair#addTestElements()
            if (parent instanceof Controller && (child instanceof Sampler || child instanceof Controller)) {
                if (parent instanceof TestCompilerHelper) {
                    TestCompilerHelper te = (TestCompilerHelper) parent;
                    duplicate = !te.addTestElementOnce(child);
                } else { // this is only possible for 3rd party controllers by default
                    ObjectPair pair = new ObjectPair(child, parent);
                    synchronized (PAIRING) {// Called from multiple threads
                        if (!PAIRING.contains(pair)) {
                            parent.addTestElement(child);
                            PAIRING.add(pair);
                        } else {
                            duplicate = true;
                        }
                    }
                }
            }
            if (duplicate) {
                if (log.isWarnEnabled()) {
                    log.warn(""Unexpected duplicate for {} and {}"", parent.getClass(), child.getClass());
                }
            }
        }
    }",,